
  0%|                                                                                                            | 2/15300 [00:01<3:35:30,  1.18it/s]
{'loss': 0.6773, 'grad_norm': 3.1979563236236572, 'learning_rate': 5.446623093681918e-06, 'epoch': 0.0}
{'loss': 0.677, 'grad_norm': 3.637606620788574, 'learning_rate': 1.0893246187363835e-05, 'epoch': 0.01}

  0%|                                                                                                            | 5/15300 [00:03<3:16:42,  1.30it/s]
{'loss': 0.6491, 'grad_norm': 3.4178366661071777, 'learning_rate': 2.178649237472767e-05, 'epoch': 0.01}

  0%|                                                                                                            | 7/15300 [00:05<3:13:55,  1.31it/s]
{'loss': 0.6488, 'grad_norm': 3.9510715007781982, 'learning_rate': 3.2679738562091506e-05, 'epoch': 0.02}
{'loss': 0.6371, 'grad_norm': 4.180989742279053, 'learning_rate': 3.8126361655773424e-05, 'epoch': 0.02}

  0%|                                                                                                           | 10/15300 [00:07<3:12:52,  1.32it/s]
{'loss': 0.7684, 'grad_norm': 5.425111293792725, 'learning_rate': 4.901960784313725e-05, 'epoch': 0.03}

  0%|                                                                                                           | 12/15300 [00:09<3:12:43,  1.32it/s]
{'loss': 0.6107, 'grad_norm': 2.152737617492676, 'learning_rate': 5.991285403050109e-05, 'epoch': 0.04}
{'loss': 0.7252, 'grad_norm': 2.443161725997925, 'learning_rate': 6.535947712418301e-05, 'epoch': 0.04}

  0%|                                                                                                           | 15/15300 [00:11<3:12:35,  1.32it/s]
{'loss': 0.5399, 'grad_norm': 3.571549654006958, 'learning_rate': 7.625272331154685e-05, 'epoch': 0.05}
{'loss': 0.532, 'grad_norm': 3.3535397052764893, 'learning_rate': 8.169934640522877e-05, 'epoch': 0.05}

  0%|▏                                                                                                          | 18/15300 [00:13<3:13:20,  1.32it/s]
{'loss': 0.5924, 'grad_norm': 2.8167896270751953, 'learning_rate': 9.259259259259259e-05, 'epoch': 0.06}
{'loss': 0.9754, 'grad_norm': 11.01923942565918, 'learning_rate': 9.80392156862745e-05, 'epoch': 0.06}

  0%|▏                                                                                                          | 20/15300 [00:15<3:12:50,  1.32it/s]
{'loss': 0.5199, 'grad_norm': 5.132964611053467, 'learning_rate': 0.00010893246187363835, 'epoch': 0.07}
{'loss': 0.8771, 'grad_norm': 9.125046730041504, 'learning_rate': 0.00011437908496732026, 'epoch': 0.07}

  0%|▏                                                                                                          | 23/15300 [00:17<3:12:37,  1.32it/s]
{'loss': 0.483, 'grad_norm': 2.214566230773926, 'learning_rate': 0.0001252723311546841, 'epoch': 0.08}

  0%|▏                                                                                                          | 26/15300 [00:19<3:12:46,  1.32it/s]
{'loss': 0.6689, 'grad_norm': 2.728334665298462, 'learning_rate': 0.00013616557734204794, 'epoch': 0.08}
{'loss': 0.473, 'grad_norm': 3.3469014167785645, 'learning_rate': 0.00014161220043572983, 'epoch': 0.08}

  0%|▏                                                                                                          | 28/15300 [00:21<3:13:15,  1.32it/s]
{'loss': 0.5927, 'grad_norm': 2.315016508102417, 'learning_rate': 0.0001525054466230937, 'epoch': 0.09}
{'loss': 0.7002, 'grad_norm': 4.203560829162598, 'learning_rate': 0.00015795206971677561, 'epoch': 0.09}

  0%|▏                                                                                                          | 31/15300 [00:23<3:13:21,  1.32it/s]
{'loss': 0.6741, 'grad_norm': 4.914140701293945, 'learning_rate': 0.00016884531590413945, 'epoch': 0.1}

  0%|▏                                                                                                          | 34/15300 [00:25<3:13:46,  1.31it/s]
{'loss': 0.8967, 'grad_norm': 6.317948341369629, 'learning_rate': 0.00017973856209150326, 'epoch': 0.11}
{'loss': 0.515, 'grad_norm': 2.6427621841430664, 'learning_rate': 0.00018518518518518518, 'epoch': 0.11}

  0%|▎                                                                                                          | 36/15300 [00:27<3:13:47,  1.31it/s]
{'loss': 0.6444, 'grad_norm': 3.252957344055176, 'learning_rate': 0.000196078431372549, 'epoch': 0.12}

  0%|▎                                                                                                          | 39/15300 [00:29<3:14:14,  1.31it/s]
{'loss': 0.6014, 'grad_norm': 3.1386260986328125, 'learning_rate': 0.00020697167755991287, 'epoch': 0.12}
{'loss': 0.5761, 'grad_norm': 7.69791841506958, 'learning_rate': 0.0002124183006535948, 'epoch': 0.13}

  0%|▎                                                                                                          | 41/15300 [00:31<3:14:32,  1.31it/s]
{'loss': 0.5744, 'grad_norm': 3.0684099197387695, 'learning_rate': 0.00022331154684095863, 'epoch': 0.13}

  0%|▎                                                                                                          | 44/15300 [00:33<3:14:14,  1.31it/s]
{'loss': 0.7302, 'grad_norm': 3.7540297508239746, 'learning_rate': 0.00023420479302832244, 'epoch': 0.14}
{'loss': 0.8277, 'grad_norm': 6.967823505401611, 'learning_rate': 0.00023965141612200435, 'epoch': 0.14}

  0%|▎                                                                                                          | 47/15300 [00:35<3:14:02,  1.31it/s]
{'loss': 0.5265, 'grad_norm': 2.36381196975708, 'learning_rate': 0.0002505446623093682, 'epoch': 0.15}
{'loss': 0.5528, 'grad_norm': 2.5027854442596436, 'learning_rate': 0.0002559912854030501, 'epoch': 0.15}

  0%|▎                                                                                                          | 49/15300 [00:37<3:13:58,  1.31it/s]
{'loss': 0.7155, 'grad_norm': 6.277969837188721, 'learning_rate': 0.00026688453159041394, 'epoch': 0.16}

  0%|▎                                                                                                          | 52/15300 [00:39<3:15:42,  1.30it/s]
{'loss': 0.799, 'grad_norm': 5.174966335296631, 'learning_rate': 0.0002777777777777778, 'epoch': 0.17}
{'loss': 0.699, 'grad_norm': 12.331930160522461, 'learning_rate': 0.00028322440087145967, 'epoch': 0.17}

  0%|▍                                                                                                          | 55/15300 [00:42<3:15:25,  1.30it/s]
{'loss': 0.7103, 'grad_norm': 15.224743843078613, 'learning_rate': 0.00029411764705882356, 'epoch': 0.18}

  0%|▍                                                                                                          | 57/15300 [00:43<3:15:49,  1.30it/s]
{'loss': 0.8765, 'grad_norm': 7.531591892242432, 'learning_rate': 0.0003050108932461874, 'epoch': 0.18}
{'loss': 0.5825, 'grad_norm': 2.534271478652954, 'learning_rate': 0.0003104575163398693, 'epoch': 0.19}

  0%|▍                                                                                                          | 60/15300 [00:45<3:15:06,  1.30it/s]
{'loss': 0.8596, 'grad_norm': 14.835248947143555, 'learning_rate': 0.0003213507625272331, 'epoch': 0.19}

  0%|▍                                                                                                          | 62/15300 [00:47<3:15:05,  1.30it/s]
{'loss': 0.6178, 'grad_norm': 2.500762939453125, 'learning_rate': 0.00033224400871459695, 'epoch': 0.2}
{'loss': 0.7177, 'grad_norm': 9.901439666748047, 'learning_rate': 0.0003376906318082789, 'epoch': 0.2}

  0%|▍                                                                                                          | 65/15300 [00:49<3:14:51,  1.30it/s]
{'loss': 0.8492, 'grad_norm': 5.214389324188232, 'learning_rate': 0.00034858387799564274, 'epoch': 0.21}
{'loss': 1.0202, 'grad_norm': 10.73694896697998, 'learning_rate': 0.00035403050108932457, 'epoch': 0.21}

  0%|▍                                                                                                          | 68/15300 [00:52<3:16:42,  1.29it/s]
{'loss': 0.588, 'grad_norm': 6.874788284301758, 'learning_rate': 0.00036492374727668846, 'epoch': 0.22}

  0%|▍                                                                                                          | 70/15300 [00:53<3:18:23,  1.28it/s]
{'loss': 0.8376, 'grad_norm': 5.09677791595459, 'learning_rate': 0.0003758169934640523, 'epoch': 0.23}
{'loss': 0.6178, 'grad_norm': 2.6058688163757324, 'learning_rate': 0.0003812636165577342, 'epoch': 0.23}

  0%|▌                                                                                                          | 73/15300 [00:56<3:20:53,  1.26it/s]
{'loss': 0.6131, 'grad_norm': 3.2349932193756104, 'learning_rate': 0.000392156862745098, 'epoch': 0.24}

  0%|▌                                                                                                          | 75/15300 [00:57<3:22:28,  1.25it/s]
{'loss': 0.6452, 'grad_norm': 2.372680425643921, 'learning_rate': 0.00040305010893246186, 'epoch': 0.24}
{'loss': 0.6756, 'grad_norm': 2.8295631408691406, 'learning_rate': 0.0004084967320261438, 'epoch': 0.25}

  1%|▌                                                                                                          | 77/15300 [00:59<3:24:26,  1.24it/s]
{'loss': 0.4058, 'grad_norm': 8.592344284057617, 'learning_rate': 0.00041938997821350764, 'epoch': 0.25}
  1%|▌                                                                                                          | 77/15300 [00:59<3:24:26,  1.24it/s][34m[1mwandb[39m[22m: 429 encountered (Filestream rate limit exceeded, retrying in 2.0 seconds.), retrying request
  1%|▌                                                                                                          | 80/15300 [01:01<3:24:01,  1.24it/s]
{'loss': 0.5646, 'grad_norm': 3.262291431427002, 'learning_rate': 0.0004302832244008715, 'epoch': 0.26}
{'loss': 0.9618, 'grad_norm': 9.750032424926758, 'learning_rate': 0.0004357298474945534, 'epoch': 0.26}

  1%|▌                                                                                                          | 83/15300 [01:04<3:23:57,  1.24it/s]
{'loss': 0.5004, 'grad_norm': 2.2595314979553223, 'learning_rate': 0.00044662309368191725, 'epoch': 0.27}

  1%|▌                                                                                                          | 85/15300 [01:05<3:25:02,  1.24it/s]
{'loss': 0.8857, 'grad_norm': 8.254586219787598, 'learning_rate': 0.00045751633986928104, 'epoch': 0.27}
{'loss': 0.3467, 'grad_norm': 2.5107264518737793, 'learning_rate': 0.0004629629629629629, 'epoch': 0.28}

  1%|▌                                                                                                          | 87/15300 [01:07<3:25:53,  1.23it/s]
{'loss': 1.0388, 'grad_norm': 17.026670455932617, 'learning_rate': 0.0004738562091503268, 'epoch': 0.28}

  1%|▋                                                                                                          | 90/15300 [01:09<3:26:56,  1.22it/s]
{'loss': 1.5508, 'grad_norm': 20.163379669189453, 'learning_rate': 0.00048474945533769065, 'epoch': 0.29}
{'loss': 0.8973, 'grad_norm': 10.985169410705566, 'learning_rate': 0.0004901960784313725, 'epoch': 0.29}

  1%|▋                                                                                                          | 92/15300 [01:11<3:26:37,  1.23it/s]
{'loss': 0.5795, 'grad_norm': 2.875779628753662, 'learning_rate': 0.0005010893246187364, 'epoch': 0.3}

  1%|▋                                                                                                          | 95/15300 [01:13<3:26:25,  1.23it/s]
{'loss': 0.8474, 'grad_norm': 7.767998695373535, 'learning_rate': 0.0005119825708061002, 'epoch': 0.31}

  1%|▋                                                                                                          | 97/15300 [01:15<3:26:13,  1.23it/s]
{'loss': 0.6625, 'grad_norm': 3.886500597000122, 'learning_rate': 0.0005228758169934641, 'epoch': 0.31}
{'loss': 0.6817, 'grad_norm': 6.906421184539795, 'learning_rate': 0.000528322440087146, 'epoch': 0.32}

  1%|▋                                                                                                         | 100/15300 [01:17<3:26:05,  1.23it/s]
{'loss': 0.7271, 'grad_norm': 5.958873748779297, 'learning_rate': 0.0005392156862745099, 'epoch': 0.32}

  1%|▋                                                                                                         | 102/15300 [01:19<3:27:40,  1.22it/s]
{'loss': 0.6519, 'grad_norm': 1.8630174398422241, 'learning_rate': 0.0005501089324618737, 'epoch': 0.33}
{'loss': 0.55, 'grad_norm': 2.7954187393188477, 'learning_rate': 0.0005555555555555556, 'epoch': 0.33}

  1%|▋                                                                                                         | 105/15300 [01:22<3:26:48,  1.22it/s]
{'loss': 0.5836, 'grad_norm': 2.4271814823150635, 'learning_rate': 0.0005664488017429193, 'epoch': 0.34}

  1%|▋                                                                                                         | 107/15300 [01:23<3:26:09,  1.23it/s]
{'loss': 0.8409, 'grad_norm': 7.4937872886657715, 'learning_rate': 0.0005773420479302832, 'epoch': 0.35}
{'loss': 0.5006, 'grad_norm': 4.241870403289795, 'learning_rate': 0.0005827886710239651, 'epoch': 0.35}

  1%|▊                                                                                                         | 110/15300 [01:26<3:26:15,  1.23it/s]
{'loss': 0.7991, 'grad_norm': 7.121826648712158, 'learning_rate': 0.000593681917211329, 'epoch': 0.36}

  1%|▊                                                                                                         | 112/15300 [01:27<3:25:58,  1.23it/s]
{'loss': 0.641, 'grad_norm': 3.021559953689575, 'learning_rate': 0.0006045751633986928, 'epoch': 0.36}
{'loss': 0.6039, 'grad_norm': 4.213517665863037, 'learning_rate': 0.0006100217864923748, 'epoch': 0.37}

  1%|▊                                                                                                         | 114/15300 [01:29<3:26:24,  1.23it/s]
{'loss': 0.6747, 'grad_norm': 4.562605857849121, 'learning_rate': 0.0006209150326797386, 'epoch': 0.37}

  1%|▊                                                                                                         | 117/15300 [01:31<3:26:12,  1.23it/s]
{'loss': 0.7206, 'grad_norm': 4.322376728057861, 'learning_rate': 0.0006318082788671025, 'epoch': 0.38}
{'loss': 0.6414, 'grad_norm': 4.5091023445129395, 'learning_rate': 0.0006372549019607842, 'epoch': 0.38}

  1%|▊                                                                                                         | 119/15300 [01:33<3:26:36,  1.22it/s]
{'loss': 0.6776, 'grad_norm': 4.339499473571777, 'learning_rate': 0.0006481481481481481, 'epoch': 0.39}

  1%|▊                                                                                                         | 122/15300 [01:35<3:25:52,  1.23it/s]
{'loss': 0.6515, 'grad_norm': 7.842186450958252, 'learning_rate': 0.000659041394335512, 'epoch': 0.4}

  1%|▊                                                                                                         | 124/15300 [01:37<3:24:33,  1.24it/s]
{'loss': 0.7967, 'grad_norm': 7.067018508911133, 'learning_rate': 0.0006699346405228758, 'epoch': 0.4}
{'loss': 0.7752, 'grad_norm': 6.546376705169678, 'learning_rate': 0.0006753812636165578, 'epoch': 0.41}

  1%|▉                                                                                                         | 127/15300 [01:39<3:25:38,  1.23it/s]
{'loss': 0.8051, 'grad_norm': 5.9993133544921875, 'learning_rate': 0.0006862745098039217, 'epoch': 0.41}

  1%|▉                                                                                                         | 129/15300 [01:41<3:26:09,  1.23it/s]
{'loss': 0.5148, 'grad_norm': 1.7198126316070557, 'learning_rate': 0.0006971677559912855, 'epoch': 0.42}
{'loss': 0.6154, 'grad_norm': 2.789498805999756, 'learning_rate': 0.0007026143790849674, 'epoch': 0.42}

  1%|▉                                                                                                         | 132/15300 [01:44<3:26:39,  1.22it/s]
{'loss': 0.7094, 'grad_norm': 2.289018154144287, 'learning_rate': 0.0007135076252723311, 'epoch': 0.43}

  1%|▉                                                                                                         | 134/15300 [01:45<3:26:35,  1.22it/s]
{'loss': 0.5625, 'grad_norm': 2.4178829193115234, 'learning_rate': 0.000724400871459695, 'epoch': 0.43}
{'loss': 0.7067, 'grad_norm': 3.3015999794006348, 'learning_rate': 0.0007298474945533769, 'epoch': 0.44}

  1%|▉                                                                                                         | 137/15300 [01:48<3:26:32,  1.22it/s]
{'loss': 0.6871, 'grad_norm': 5.591442584991455, 'learning_rate': 0.0007407407407407407, 'epoch': 0.44}

  1%|▉                                                                                                         | 139/15300 [01:49<3:26:25,  1.22it/s]
{'loss': 0.7261, 'grad_norm': 2.736159324645996, 'learning_rate': 0.0007516339869281046, 'epoch': 0.45}
{'loss': 0.6875, 'grad_norm': 5.7354912757873535, 'learning_rate': 0.0007570806100217866, 'epoch': 0.45}

  1%|▉                                                                                                         | 142/15300 [01:52<3:26:47,  1.22it/s]
{'loss': 0.5742, 'grad_norm': 3.676957368850708, 'learning_rate': 0.0007679738562091504, 'epoch': 0.46}

  1%|▉                                                                                                         | 144/15300 [01:53<3:27:01,  1.22it/s]
{'loss': 0.7441, 'grad_norm': 9.66247272491455, 'learning_rate': 0.0007788671023965143, 'epoch': 0.47}
{'loss': 0.5786, 'grad_norm': 4.5567402839660645, 'learning_rate': 0.000784313725490196, 'epoch': 0.47}

  1%|█                                                                                                         | 146/15300 [01:55<3:26:51,  1.22it/s]
{'loss': 0.4938, 'grad_norm': 2.2765982151031494, 'learning_rate': 0.0007952069716775599, 'epoch': 0.48}

  1%|█                                                                                                         | 149/15300 [01:57<3:26:55,  1.22it/s]
{'loss': 0.7497, 'grad_norm': 8.806206703186035, 'learning_rate': 0.0008061002178649237, 'epoch': 0.48}

  1%|█                                                                                                         | 151/15300 [01:59<3:26:33,  1.22it/s]
{'loss': 0.6678, 'grad_norm': 2.348820209503174, 'learning_rate': 0.0008169934640522876, 'epoch': 0.49}
{'loss': 0.5634, 'grad_norm': 3.126168966293335, 'learning_rate': 0.0008224400871459695, 'epoch': 0.49}

  1%|█                                                                                                         | 154/15300 [02:02<3:26:20,  1.22it/s]
{'loss': 0.8328, 'grad_norm': 9.82223129272461, 'learning_rate': 0.0008333333333333333, 'epoch': 0.5}

  1%|█                                                                                                         | 156/15300 [02:03<3:26:12,  1.22it/s]
{'loss': 0.6054, 'grad_norm': 3.3827643394470215, 'learning_rate': 0.0008442265795206972, 'epoch': 0.51}
{'loss': 0.9305, 'grad_norm': 7.13469123840332, 'learning_rate': 0.0008496732026143792, 'epoch': 0.51}

  1%|█                                                                                                         | 159/15300 [02:06<3:26:03,  1.22it/s]
{'loss': 0.6435, 'grad_norm': 7.697090148925781, 'learning_rate': 0.000860566448801743, 'epoch': 0.52}

  1%|█                                                                                                         | 161/15300 [02:07<3:26:18,  1.22it/s]
{'loss': 1.0392, 'grad_norm': 6.704402923583984, 'learning_rate': 0.0008714596949891068, 'epoch': 0.52}
{'loss': 0.7079, 'grad_norm': 5.263738632202148, 'learning_rate': 0.0008769063180827886, 'epoch': 0.53}

  1%|█▏                                                                                                        | 164/15300 [02:10<3:26:26,  1.22it/s]
{'loss': 0.4188, 'grad_norm': 1.9619877338409424, 'learning_rate': 0.0008877995642701525, 'epoch': 0.53}

  1%|█▏                                                                                                        | 166/15300 [02:11<3:26:18,  1.22it/s]
{'loss': 0.6301, 'grad_norm': 4.4023051261901855, 'learning_rate': 0.0008986928104575164, 'epoch': 0.54}
{'loss': 0.637, 'grad_norm': 3.8649990558624268, 'learning_rate': 0.0009041394335511982, 'epoch': 0.54}

  1%|█▏                                                                                                        | 169/15300 [02:14<3:26:30,  1.22it/s]
{'loss': 0.578, 'grad_norm': 18.27153968811035, 'learning_rate': 0.0009150326797385621, 'epoch': 0.55}

  1%|█▏                                                                                                        | 171/15300 [02:15<3:26:22,  1.22it/s]
{'loss': 0.6549, 'grad_norm': 6.35228967666626, 'learning_rate': 0.0009259259259259259, 'epoch': 0.56}

  1%|█▏                                                                                                        | 173/15300 [02:17<3:27:33,  1.21it/s]
{'loss': 0.737, 'grad_norm': 9.526082992553711, 'learning_rate': 0.0009368191721132897, 'epoch': 0.56}
{'loss': 0.5079, 'grad_norm': 3.424551248550415, 'learning_rate': 0.0009422657952069717, 'epoch': 0.57}

  1%|█▏                                                                                                        | 176/15300 [02:20<3:28:31,  1.21it/s]
{'loss': 0.7521, 'grad_norm': 6.901326656341553, 'learning_rate': 0.0009531590413943355, 'epoch': 0.57}

  1%|█▏                                                                                                        | 178/15300 [02:21<3:28:33,  1.21it/s]
{'loss': 0.6814, 'grad_norm': 4.487131595611572, 'learning_rate': 0.0009640522875816994, 'epoch': 0.58}
{'loss': 0.4312, 'grad_norm': 4.6814751625061035, 'learning_rate': 0.0009694989106753813, 'epoch': 0.58}

  1%|█▎                                                                                                        | 181/15300 [02:24<3:27:17,  1.22it/s]
{'loss': 0.7314, 'grad_norm': 5.441226959228516, 'learning_rate': 0.000980392156862745, 'epoch': 0.59}

  1%|█▎                                                                                                        | 183/15300 [02:25<3:27:22,  1.21it/s]
{'loss': 0.7679, 'grad_norm': 10.754461288452148, 'learning_rate': 0.0009912854030501089, 'epoch': 0.59}
{'loss': 1.0179, 'grad_norm': 14.134782791137695, 'learning_rate': 0.0009967320261437909, 'epoch': 0.6}

  1%|█▎                                                                                                        | 186/15300 [02:28<3:27:51,  1.21it/s]
{'loss': 0.4653, 'grad_norm': 5.035191059112549, 'learning_rate': 0.0010076252723311546, 'epoch': 0.6}

  1%|█▎                                                                                                        | 188/15300 [02:29<3:30:20,  1.20it/s]
{'loss': 0.8011, 'grad_norm': 3.6284661293029785, 'learning_rate': 0.0010185185185185184, 'epoch': 0.61}

  1%|█▎                                                                                                        | 190/15300 [02:31<3:31:04,  1.19it/s]
{'loss': 0.9329, 'grad_norm': 6.234011173248291, 'learning_rate': 0.0010294117647058824, 'epoch': 0.62}
{'loss': 0.775, 'grad_norm': 5.672148704528809, 'learning_rate': 0.0010348583877995642, 'epoch': 0.62}

  1%|█▎                                                                                                        | 193/15300 [02:34<3:31:25,  1.19it/s]
{'loss': 0.581, 'grad_norm': 7.079920291900635, 'learning_rate': 0.0010457516339869282, 'epoch': 0.63}

  1%|█▎                                                                                                        | 195/15300 [02:35<3:31:37,  1.19it/s]
{'loss': 0.9502, 'grad_norm': 4.803585529327393, 'learning_rate': 0.001056644880174292, 'epoch': 0.63}
{'loss': 0.8567, 'grad_norm': 8.096994400024414, 'learning_rate': 0.0010620915032679738, 'epoch': 0.64}

  1%|█▎                                                                                                        | 198/15300 [02:38<3:27:51,  1.21it/s]
{'loss': 1.0059, 'grad_norm': 9.473939895629883, 'learning_rate': 0.0010729847494553378, 'epoch': 0.64}

  1%|█▍                                                                                                        | 200/15300 [02:39<3:28:00,  1.21it/s]
{'loss': 0.7792, 'grad_norm': 9.49027156829834, 'learning_rate': 0.0010838779956427015, 'epoch': 0.65}

  1%|█▍                                                                                                        | 202/15300 [02:41<3:26:27,  1.22it/s]
{'loss': 0.7142, 'grad_norm': 8.067599296569824, 'learning_rate': 0.0010947712418300653, 'epoch': 0.66}
{'loss': 0.7343, 'grad_norm': 3.001599073410034, 'learning_rate': 0.0011002178649237473, 'epoch': 0.66}

  1%|█▍                                                                                                        | 205/15300 [02:44<3:31:27,  1.19it/s]
{'loss': 0.5962, 'grad_norm': 3.2793357372283936, 'learning_rate': 0.0011111111111111111, 'epoch': 0.67}

  1%|█▍                                                                                                        | 207/15300 [02:45<3:32:17,  1.18it/s]
{'loss': 0.6057, 'grad_norm': 3.0165040493011475, 'learning_rate': 0.0011220043572984749, 'epoch': 0.67}
{'loss': 0.6613, 'grad_norm': 2.5585479736328125, 'learning_rate': 0.0011274509803921569, 'epoch': 0.68}

  1%|█▍                                                                                                        | 210/15300 [02:48<3:30:00,  1.20it/s]
{'loss': 0.4648, 'grad_norm': 1.3694738149642944, 'learning_rate': 0.0011383442265795207, 'epoch': 0.68}

  1%|█▍                                                                                                        | 212/15300 [02:49<3:27:21,  1.21it/s]
{'loss': 0.4671, 'grad_norm': 1.902766227722168, 'learning_rate': 0.0011492374727668847, 'epoch': 0.69}

  1%|█▍                                                                                                        | 214/15300 [02:51<3:26:00,  1.22it/s]
{'loss': 0.8045, 'grad_norm': 6.872259140014648, 'learning_rate': 0.0011601307189542485, 'epoch': 0.7}
{'loss': 0.8958, 'grad_norm': 7.364770412445068, 'learning_rate': 0.0011655773420479302, 'epoch': 0.7}

  1%|█▌                                                                                                        | 217/15300 [02:54<3:25:11,  1.23it/s]
{'loss': 0.9084, 'grad_norm': 8.722113609313965, 'learning_rate': 0.0011764705882352942, 'epoch': 0.71}

  1%|█▌                                                                                                        | 219/15300 [02:55<3:24:45,  1.23it/s]
{'loss': 0.6691, 'grad_norm': 3.775993824005127, 'learning_rate': 0.001187363834422658, 'epoch': 0.71}
{'loss': 0.7801, 'grad_norm': 4.608846664428711, 'learning_rate': 0.00119281045751634, 'epoch': 0.72}

  1%|█▌                                                                                                        | 222/15300 [02:58<3:24:23,  1.23it/s]
{'loss': 0.7577, 'grad_norm': 8.847707748413086, 'learning_rate': 0.0012037037037037036, 'epoch': 0.72}

  1%|█▌                                                                                                        | 224/15300 [02:59<3:24:08,  1.23it/s]
{'loss': 0.8225, 'grad_norm': 7.438389301300049, 'learning_rate': 0.0012145969498910676, 'epoch': 0.73}
{'loss': 0.6678, 'grad_norm': 3.1415276527404785, 'learning_rate': 0.0012200435729847496, 'epoch': 0.73}

  1%|█▌                                                                                                        | 227/15300 [03:02<3:24:31,  1.23it/s]
{'loss': 0.6634, 'grad_norm': 5.050220012664795, 'learning_rate': 0.0012309368191721134, 'epoch': 0.74}

  1%|█▌                                                                                                        | 229/15300 [03:03<3:24:15,  1.23it/s]
{'loss': 0.562, 'grad_norm': 1.8192921876907349, 'learning_rate': 0.0012418300653594771, 'epoch': 0.75}
{'loss': 0.8366, 'grad_norm': 5.68176794052124, 'learning_rate': 0.0012472766884531591, 'epoch': 0.75}

  2%|█▌                                                                                                        | 232/15300 [03:06<3:24:29,  1.23it/s]
{'loss': 0.6347, 'grad_norm': 3.784306049346924, 'learning_rate': 0.001258169934640523, 'epoch': 0.75}

  2%|█▌                                                                                                        | 234/15300 [03:07<3:24:18,  1.23it/s]
{'loss': 0.8578, 'grad_norm': 5.899080753326416, 'learning_rate': 0.001269063180827887, 'epoch': 0.76}
{'loss': 0.4772, 'grad_norm': 1.2318326234817505, 'learning_rate': 0.0012745098039215685, 'epoch': 0.76}

  2%|█▋                                                                                                        | 237/15300 [03:10<3:24:10,  1.23it/s]
{'loss': 0.725, 'grad_norm': 4.9524245262146, 'learning_rate': 0.0012854030501089325, 'epoch': 0.77}

  2%|█▋                                                                                                        | 239/15300 [03:11<3:23:52,  1.23it/s]
{'loss': 0.6995, 'grad_norm': 4.714249610900879, 'learning_rate': 0.0012962962962962963, 'epoch': 0.78}
{'loss': 0.769, 'grad_norm': 7.932751178741455, 'learning_rate': 0.0013017429193899783, 'epoch': 0.78}

  2%|█▋                                                                                                        | 242/15300 [03:14<3:24:19,  1.23it/s]
{'loss': 0.7694, 'grad_norm': 7.0025787353515625, 'learning_rate': 0.001312636165577342, 'epoch': 0.79}

  2%|█▋                                                                                                        | 244/15300 [03:15<3:21:38,  1.24it/s]
{'loss': 0.7245, 'grad_norm': 1.7404133081436157, 'learning_rate': 0.0013235294117647058, 'epoch': 0.79}
{'loss': 0.5565, 'grad_norm': 1.560180902481079, 'learning_rate': 0.0013289760348583878, 'epoch': 0.8}

  2%|█▋                                                                                                        | 247/15300 [03:18<3:22:29,  1.24it/s]
{'loss': 0.5844, 'grad_norm': 1.3941482305526733, 'learning_rate': 0.0013398692810457516, 'epoch': 0.8}

  2%|█▋                                                                                                        | 249/15300 [03:20<3:23:48,  1.23it/s]
{'loss': 0.7872, 'grad_norm': 5.660186767578125, 'learning_rate': 0.0013507625272331156, 'epoch': 0.81}

  2%|█▋                                                                                                        | 251/15300 [03:21<3:24:24,  1.23it/s]
{'loss': 0.6807, 'grad_norm': 5.088612079620361, 'learning_rate': 0.0013616557734204794, 'epoch': 0.82}
{'loss': 0.3742, 'grad_norm': 2.161090850830078, 'learning_rate': 0.0013671023965141614, 'epoch': 0.82}

  2%|█▊                                                                                                        | 254/15300 [03:24<3:21:30,  1.24it/s]
{'loss': 0.5915, 'grad_norm': 4.087501525878906, 'learning_rate': 0.001377995642701525, 'epoch': 0.83}

  2%|█▊                                                                                                        | 257/15300 [03:26<3:17:56,  1.27it/s]
{'loss': 0.482, 'grad_norm': 2.379863977432251, 'learning_rate': 0.001388888888888889, 'epoch': 0.83}
{'loss': 0.5557, 'grad_norm': 1.633147954940796, 'learning_rate': 0.001394335511982571, 'epoch': 0.84}

  2%|█▊                                                                                                        | 259/15300 [03:28<3:18:57,  1.26it/s]
{'loss': 0.4897, 'grad_norm': 2.431957721710205, 'learning_rate': 0.0014052287581699347, 'epoch': 0.84}

  2%|█▊                                                                                                        | 262/15300 [03:30<3:19:00,  1.26it/s]
{'loss': 0.688, 'grad_norm': 5.228538513183594, 'learning_rate': 0.0014161220043572983, 'epoch': 0.85}
{'loss': 0.7139, 'grad_norm': 4.025542259216309, 'learning_rate': 0.0014215686274509803, 'epoch': 0.85}

  2%|█▊                                                                                                        | 264/15300 [03:31<3:18:59,  1.26it/s]
{'loss': 0.5448, 'grad_norm': 2.7417256832122803, 'learning_rate': 0.0014324618736383443, 'epoch': 0.86}
{'loss': 0.8097, 'grad_norm': 5.879706382751465, 'learning_rate': 0.001437908496732026, 'epoch': 0.86}

  2%|█▊                                                                                                        | 267/15300 [03:34<3:19:15,  1.26it/s]
{'loss': 0.7005, 'grad_norm': 9.719427108764648, 'learning_rate': 0.00144880174291939, 'epoch': 0.87}

  2%|█▊                                                                                                        | 269/15300 [03:35<3:19:20,  1.26it/s]
{'loss': 0.6877, 'grad_norm': 9.509908676147461, 'learning_rate': 0.0014596949891067538, 'epoch': 0.88}
{'loss': 0.673, 'grad_norm': 1.9577440023422241, 'learning_rate': 0.0014651416122004358, 'epoch': 0.88}

  2%|█▉                                                                                                        | 272/15300 [03:38<3:19:24,  1.26it/s]
{'loss': 0.7028, 'grad_norm': 4.404796123504639, 'learning_rate': 0.0014760348583877996, 'epoch': 0.89}

  2%|█▉                                                                                                        | 274/15300 [03:39<3:19:49,  1.25it/s]
{'loss': 0.7031, 'grad_norm': 4.128295421600342, 'learning_rate': 0.0014869281045751634, 'epoch': 0.89}
{'loss': 0.4586, 'grad_norm': 1.6355657577514648, 'learning_rate': 0.0014923747276688454, 'epoch': 0.9}

  2%|█▉                                                                                                        | 277/15300 [03:42<3:19:50,  1.25it/s]
{'loss': 0.8249, 'grad_norm': 3.1234965324401855, 'learning_rate': 0.0015032679738562092, 'epoch': 0.9}

  2%|█▉                                                                                                        | 279/15300 [03:43<3:19:18,  1.26it/s]
{'loss': 0.5164, 'grad_norm': 4.568121433258057, 'learning_rate': 0.0015141612200435732, 'epoch': 0.91}
{'loss': 0.7022, 'grad_norm': 5.905061721801758, 'learning_rate': 0.0015196078431372548, 'epoch': 0.91}

  2%|█▉                                                                                                        | 282/15300 [03:46<3:20:51,  1.25it/s]
{'loss': 0.7294, 'grad_norm': 5.198024272918701, 'learning_rate': 0.0015305010893246187, 'epoch': 0.92}

  2%|█▉                                                                                                        | 284/15300 [03:48<3:23:24,  1.23it/s]
{'loss': 0.4603, 'grad_norm': 8.175617218017578, 'learning_rate': 0.0015413943355119825, 'epoch': 0.92}
{'loss': 0.697, 'grad_norm': 4.373956203460693, 'learning_rate': 0.0015468409586056645, 'epoch': 0.93}

  2%|█▉                                                                                                        | 287/15300 [03:50<3:25:54,  1.22it/s]
{'loss': 0.7155, 'grad_norm': 3.3091702461242676, 'learning_rate': 0.0015577342047930285, 'epoch': 0.93}

  2%|██                                                                                                        | 289/15300 [03:52<3:27:04,  1.21it/s]
{'loss': 0.7269, 'grad_norm': 6.763730049133301, 'learning_rate': 0.001568627450980392, 'epoch': 0.94}

  2%|██                                                                                                        | 291/15300 [03:53<3:26:51,  1.21it/s]
{'loss': 0.5569, 'grad_norm': 5.794096946716309, 'learning_rate': 0.001579520697167756, 'epoch': 0.95}
{'loss': 0.6864, 'grad_norm': 6.6816277503967285, 'learning_rate': 0.0015849673202614379, 'epoch': 0.95}

  2%|██                                                                                                        | 294/15300 [03:56<3:27:02,  1.21it/s]
{'loss': 0.7509, 'grad_norm': 5.604927062988281, 'learning_rate': 0.0015958605664488019, 'epoch': 0.96}

  2%|██                                                                                                        | 296/15300 [03:57<3:27:07,  1.21it/s]
{'loss': 0.6215, 'grad_norm': 4.830632209777832, 'learning_rate': 0.0016067538126361657, 'epoch': 0.96}
{'loss': 0.7743, 'grad_norm': 5.948302745819092, 'learning_rate': 0.0016122004357298474, 'epoch': 0.97}

  2%|██                                                                                                        | 299/15300 [04:00<3:27:03,  1.21it/s]
{'loss': 0.644, 'grad_norm': 3.976604700088501, 'learning_rate': 0.0016230936819172112, 'epoch': 0.97}

  2%|██                                                                                                        | 301/15300 [04:02<3:23:44,  1.23it/s]
{'loss': 0.6247, 'grad_norm': 3.9907612800598145, 'learning_rate': 0.0016339869281045752, 'epoch': 0.98}
{'loss': 0.6752, 'grad_norm': 2.560333490371704, 'learning_rate': 0.0016394335511982572, 'epoch': 0.98}

  2%|██                                                                                                        | 304/15300 [04:04<3:21:19,  1.24it/s]
{'loss': 0.4313, 'grad_norm': 2.5244369506835938, 'learning_rate': 0.001650326797385621, 'epoch': 0.99}
  2%|██                                                                                                        | 306/15300 [04:05<3:01:09,  1.38it/s][INFO|trainer.py:786] 2024-12-07 12:35:19,926 >> The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3614] 2024-12-07 12:35:19,927 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-07 12:35:19,927 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-07 12:35:19,928 >>   Batch size = 8
  6%|██████▋                                                                                                          | 3/51 [00:00<00:08,  5.70it/s]
{'loss': 0.4962, 'grad_norm': 2.877964973449707, 'learning_rate': 0.001661220043572985, 'epoch': 1.0}






 84%|██████████████████████████████████████████████████████████████████████████████████████████████▍                 | 43/51 [00:10<00:01,  4.01it/s]

  2%|██                                                                                                       | 308/15300 [04:20<14:14:45,  3.42s/it]
{'loss': 0.6365, 'grad_norm': 2.992779493331909, 'learning_rate': 0.0016721132897603486, 'epoch': 1.0}
{'loss': 0.5393, 'grad_norm': 3.3803040981292725, 'learning_rate': 0.0016775599128540306, 'epoch': 1.01}

  2%|██▏                                                                                                       | 311/15300 [04:22<7:04:21,  1.70s/it]
{'loss': 0.7826, 'grad_norm': 4.072023391723633, 'learning_rate': 0.0016884531590413943, 'epoch': 1.01}

  2%|██▏                                                                                                       | 313/15300 [04:23<5:07:19,  1.23s/it]
{'loss': 1.0011, 'grad_norm': 13.230195045471191, 'learning_rate': 0.0016993464052287583, 'epoch': 1.02}
{'loss': 0.9453, 'grad_norm': 10.50960922241211, 'learning_rate': 0.00170479302832244, 'epoch': 1.02}

  2%|██▏                                                                                                       | 316/15300 [04:26<3:53:25,  1.07it/s]
{'loss': 0.6749, 'grad_norm': 6.146346092224121, 'learning_rate': 0.001715686274509804, 'epoch': 1.03}

  2%|██▏                                                                                                       | 318/15300 [04:27<3:33:32,  1.17it/s]
{'loss': 0.5278, 'grad_norm': 3.4871487617492676, 'learning_rate': 0.0017265795206971677, 'epoch': 1.04}
{'loss': 0.5206, 'grad_norm': 2.805753231048584, 'learning_rate': 0.0017320261437908497, 'epoch': 1.04}

  2%|██▏                                                                                                       | 321/15300 [04:30<3:21:02,  1.24it/s]
{'loss': 1.0894, 'grad_norm': 9.246336936950684, 'learning_rate': 0.0017429193899782137, 'epoch': 1.05}

  2%|██▏                                                                                                       | 324/15300 [04:32<3:17:22,  1.26it/s]
{'loss': 0.995, 'grad_norm': 5.981271743774414, 'learning_rate': 0.0017538126361655772, 'epoch': 1.05}
{'loss': 0.6748, 'grad_norm': 6.095678806304932, 'learning_rate': 0.0017592592592592592, 'epoch': 1.06}

  2%|██▎                                                                                                       | 326/15300 [04:34<3:15:36,  1.28it/s]
{'loss': 0.773, 'grad_norm': 3.7574703693389893, 'learning_rate': 0.001770152505446623, 'epoch': 1.06}

  2%|██▎                                                                                                       | 329/15300 [04:36<3:15:01,  1.28it/s]
{'loss': 0.514, 'grad_norm': 6.5433759689331055, 'learning_rate': 0.001781045751633987, 'epoch': 1.07}
{'loss': 0.6779, 'grad_norm': 13.070613861083984, 'learning_rate': 0.001786492374727669, 'epoch': 1.07}

  2%|██▎                                                                                                       | 331/15300 [04:38<3:14:32,  1.28it/s]
{'loss': 0.6894, 'grad_norm': 4.471255302429199, 'learning_rate': 0.0017973856209150328, 'epoch': 1.08}
{'loss': 0.428, 'grad_norm': 1.9114019870758057, 'learning_rate': 0.0018028322440087148, 'epoch': 1.08}

  2%|██▎                                                                                                       | 334/15300 [04:40<3:14:25,  1.28it/s]
{'loss': 0.6481, 'grad_norm': 5.485915184020996, 'learning_rate': 0.0018137254901960784, 'epoch': 1.09}

  2%|██▎                                                                                                       | 336/15300 [04:41<3:14:27,  1.28it/s]
{'loss': 0.7425, 'grad_norm': 24.4970703125, 'learning_rate': 0.0018246187363834424, 'epoch': 1.09}
{'loss': 0.729, 'grad_norm': 5.387465000152588, 'learning_rate': 0.0018300653594771241, 'epoch': 1.1}

  2%|██▎                                                                                                       | 339/15300 [04:44<3:19:54,  1.25it/s]
{'loss': 0.5871, 'grad_norm': 4.304498672485352, 'learning_rate': 0.0018409586056644881, 'epoch': 1.1}

  2%|██▎                                                                                                       | 341/15300 [04:45<3:21:20,  1.24it/s]
{'loss': 0.7181, 'grad_norm': 7.389320373535156, 'learning_rate': 0.0018518518518518517, 'epoch': 1.11}
{'loss': 0.6191, 'grad_norm': 2.5892295837402344, 'learning_rate': 0.0018572984749455337, 'epoch': 1.11}

  2%|██▍                                                                                                       | 344/15300 [04:48<3:17:15,  1.26it/s]
{'loss': 0.5632, 'grad_norm': 6.73402738571167, 'learning_rate': 0.0018681917211328977, 'epoch': 1.12}

  2%|██▍                                                                                                       | 346/15300 [04:49<3:17:55,  1.26it/s]
{'loss': 0.5632, 'grad_norm': 1.6691843271255493, 'learning_rate': 0.0018790849673202615, 'epoch': 1.13}
{'loss': 1.041, 'grad_norm': 10.217364311218262, 'learning_rate': 0.0018845315904139435, 'epoch': 1.13}

  2%|██▍                                                                                                       | 349/15300 [04:52<3:18:44,  1.25it/s]
{'loss': 0.4071, 'grad_norm': 4.386535167694092, 'learning_rate': 0.0018954248366013073, 'epoch': 1.14}

  2%|██▍                                                                                                       | 351/15300 [04:53<3:18:50,  1.25it/s]
{'loss': 0.6074, 'grad_norm': 5.283146381378174, 'learning_rate': 0.001906318082788671, 'epoch': 1.14}
{'loss': 0.6614, 'grad_norm': 4.7618207931518555, 'learning_rate': 0.0019117647058823528, 'epoch': 1.15}

  2%|██▍                                                                                                       | 354/15300 [04:56<3:16:10,  1.27it/s]
{'loss': 0.643, 'grad_norm': 4.573472023010254, 'learning_rate': 0.0019226579520697168, 'epoch': 1.15}

  2%|██▍                                                                                                       | 357/15300 [04:58<3:15:24,  1.27it/s]
{'loss': 0.6462, 'grad_norm': 2.0712082386016846, 'learning_rate': 0.0019335511982570806, 'epoch': 1.16}
{'loss': 0.681, 'grad_norm': 3.2771270275115967, 'learning_rate': 0.0019389978213507626, 'epoch': 1.16}

  2%|██▍                                                                                                       | 359/15300 [05:00<3:15:11,  1.28it/s]
{'loss': 1.0006, 'grad_norm': 9.374625205993652, 'learning_rate': 0.0019498910675381266, 'epoch': 1.17}

  2%|██▌                                                                                                       | 362/15300 [05:02<3:15:03,  1.28it/s]
{'loss': 0.704, 'grad_norm': 9.661459922790527, 'learning_rate': 0.00196078431372549, 'epoch': 1.18}
{'loss': 0.6385, 'grad_norm': 10.53079605102539, 'learning_rate': 0.0019662309368191724, 'epoch': 1.18}

  2%|██▌                                                                                                       | 364/15300 [05:04<3:14:40,  1.28it/s]
{'loss': 0.721, 'grad_norm': 4.0278825759887695, 'learning_rate': 0.001977124183006536, 'epoch': 1.19}
{'loss': 0.3887, 'grad_norm': 1.7270821332931519, 'learning_rate': 0.0019825708061002177, 'epoch': 1.19}

  2%|██▌                                                                                                       | 367/15300 [05:06<3:15:38,  1.27it/s]
{'loss': 0.7443, 'grad_norm': 5.617408752441406, 'learning_rate': 0.0019934640522875817, 'epoch': 1.2}

  2%|██▌                                                                                                       | 369/15300 [05:08<3:17:04,  1.26it/s]
{'loss': 0.5462, 'grad_norm': 3.002183437347412, 'learning_rate': 0.0020043572984749457, 'epoch': 1.2}
{'loss': 0.7119, 'grad_norm': 4.924098491668701, 'learning_rate': 0.0020098039215686275, 'epoch': 1.21}

  2%|██▌                                                                                                       | 372/15300 [05:10<3:16:37,  1.27it/s]
{'loss': 0.5758, 'grad_norm': 7.623201370239258, 'learning_rate': 0.002020697167755991, 'epoch': 1.21}

  2%|██▌                                                                                                       | 374/15300 [05:12<3:17:01,  1.26it/s]
{'loss': 0.85, 'grad_norm': 8.9545316696167, 'learning_rate': 0.002031590413943355, 'epoch': 1.22}
{'loss': 0.6093, 'grad_norm': 3.9798645973205566, 'learning_rate': 0.002037037037037037, 'epoch': 1.22}

  2%|██▌                                                                                                       | 377/15300 [05:14<3:16:38,  1.26it/s]
{'loss': 0.677, 'grad_norm': 4.736642837524414, 'learning_rate': 0.002047930283224401, 'epoch': 1.23}

  2%|██▋                                                                                                       | 379/15300 [05:15<3:16:37,  1.26it/s]
{'loss': 0.8462, 'grad_norm': 5.26218318939209, 'learning_rate': 0.002058823529411765, 'epoch': 1.24}
{'loss': 0.656, 'grad_norm': 4.200141429901123, 'learning_rate': 0.0020642701525054466, 'epoch': 1.24}

  2%|██▋                                                                                                       | 382/15300 [05:18<3:16:13,  1.27it/s]
{'loss': 0.2029, 'grad_norm': 2.92258358001709, 'learning_rate': 0.0020751633986928106, 'epoch': 1.25}

  3%|██▋                                                                                                       | 385/15300 [05:20<3:16:04,  1.27it/s]
{'loss': 0.6243, 'grad_norm': 5.427060604095459, 'learning_rate': 0.002086056644880174, 'epoch': 1.25}
{'loss': 0.8263, 'grad_norm': 5.407768726348877, 'learning_rate': 0.0020915032679738564, 'epoch': 1.25}

  3%|██▋                                                                                                       | 387/15300 [05:22<3:15:09,  1.27it/s]
{'loss': 0.5617, 'grad_norm': 4.830712795257568, 'learning_rate': 0.00210239651416122, 'epoch': 1.26}

  3%|██▋                                                                                                       | 390/15300 [05:24<3:13:14,  1.29it/s]
{'loss': 0.9836, 'grad_norm': 6.832959175109863, 'learning_rate': 0.002113289760348584, 'epoch': 1.27}
{'loss': 1.0581, 'grad_norm': 9.549012184143066, 'learning_rate': 0.0021187363834422658, 'epoch': 1.27}

  3%|██▋                                                                                                       | 392/15300 [05:26<3:15:13,  1.27it/s]
{'loss': 0.5316, 'grad_norm': 2.00239634513855, 'learning_rate': 0.0021296296296296298, 'epoch': 1.28}

  3%|██▋                                                                                                       | 395/15300 [05:28<3:16:18,  1.27it/s]
{'loss': 0.4666, 'grad_norm': 6.410666465759277, 'learning_rate': 0.0021405228758169933, 'epoch': 1.28}
{'loss': 0.4354, 'grad_norm': 2.0636532306671143, 'learning_rate': 0.0021459694989106755, 'epoch': 1.29}

  3%|██▊                                                                                                       | 397/15300 [05:30<3:15:50,  1.27it/s]
{'loss': 0.8033, 'grad_norm': 5.559630870819092, 'learning_rate': 0.0021568627450980395, 'epoch': 1.29}
{'loss': 0.684, 'grad_norm': 4.495370864868164, 'learning_rate': 0.002162309368191721, 'epoch': 1.3}

  3%|██▊                                                                                                       | 400/15300 [05:32<3:17:14,  1.26it/s]
{'loss': 0.6595, 'grad_norm': 4.861813068389893, 'learning_rate': 0.002173202614379085, 'epoch': 1.3}

  3%|██▊                                                                                                       | 402/15300 [05:34<3:16:56,  1.26it/s]
{'loss': 0.8293, 'grad_norm': 10.532394409179688, 'learning_rate': 0.002184095860566449, 'epoch': 1.31}
{'loss': 0.6374, 'grad_norm': 6.678553104400635, 'learning_rate': 0.0021895424836601307, 'epoch': 1.31}

  3%|██▊                                                                                                       | 405/15300 [05:36<3:15:02,  1.27it/s]
{'loss': 0.6668, 'grad_norm': 4.911308288574219, 'learning_rate': 0.0022004357298474947, 'epoch': 1.32}

  3%|██▊                                                                                                       | 407/15300 [05:38<3:17:03,  1.26it/s]
{'loss': 0.4021, 'grad_norm': 2.355879783630371, 'learning_rate': 0.0022113289760348587, 'epoch': 1.33}
{'loss': 0.7646, 'grad_norm': 7.71948766708374, 'learning_rate': 0.0022167755991285404, 'epoch': 1.33}

  3%|██▊                                                                                                       | 410/15300 [05:40<3:18:11,  1.25it/s]
{'loss': 0.9967, 'grad_norm': 6.809668064117432, 'learning_rate': 0.002227668845315904, 'epoch': 1.34}

  3%|██▊                                                                                                       | 412/15300 [05:42<3:19:00,  1.25it/s]
{'loss': 0.7693, 'grad_norm': 5.368899822235107, 'learning_rate': 0.002238562091503268, 'epoch': 1.34}
{'loss': 0.8845, 'grad_norm': 14.293641090393066, 'learning_rate': 0.0022440087145969498, 'epoch': 1.35}

  3%|██▉                                                                                                       | 415/15300 [05:44<3:16:34,  1.26it/s]
{'loss': 0.9295, 'grad_norm': 10.968441009521484, 'learning_rate': 0.0022549019607843138, 'epoch': 1.35}

  3%|██▉                                                                                                       | 417/15300 [05:46<3:16:57,  1.26it/s]
{'loss': 0.5396, 'grad_norm': 4.647984504699707, 'learning_rate': 0.0022657952069716773, 'epoch': 1.36}
{'loss': 0.397, 'grad_norm': 2.8626184463500977, 'learning_rate': 0.0022712418300653596, 'epoch': 1.36}

  3%|██▉                                                                                                       | 420/15300 [05:48<3:16:58,  1.26it/s]
{'loss': 0.6875, 'grad_norm': 6.504561424255371, 'learning_rate': 0.0022821350762527236, 'epoch': 1.37}

  3%|██▉                                                                                                       | 423/15300 [05:50<3:15:11,  1.27it/s]
{'loss': 0.7568, 'grad_norm': 6.306308746337891, 'learning_rate': 0.002293028322440087, 'epoch': 1.38}
{'loss': 0.6691, 'grad_norm': 6.9715576171875, 'learning_rate': 0.0022984749455337693, 'epoch': 1.38}

  3%|██▉                                                                                                       | 425/15300 [05:52<3:17:48,  1.25it/s]
{'loss': 0.3317, 'grad_norm': 3.913365125656128, 'learning_rate': 0.002309368191721133, 'epoch': 1.39}

  3%|██▉                                                                                                       | 427/15300 [05:54<3:19:45,  1.24it/s]
{'loss': 0.354, 'grad_norm': 6.078952312469482, 'learning_rate': 0.002320261437908497, 'epoch': 1.39}
{'loss': 0.4441, 'grad_norm': 5.961400508880615, 'learning_rate': 0.0023257080610021787, 'epoch': 1.4}

  3%|██▉                                                                                                       | 430/15300 [05:56<3:20:26,  1.24it/s]
{'loss': 0.4788, 'grad_norm': 8.096851348876953, 'learning_rate': 0.0023366013071895427, 'epoch': 1.4}

  3%|██▉                                                                                                       | 432/15300 [05:58<3:20:55,  1.23it/s]
{'loss': 0.8474, 'grad_norm': 7.176963806152344, 'learning_rate': 0.0023474945533769062, 'epoch': 1.41}
{'loss': 0.5462, 'grad_norm': 3.779348134994507, 'learning_rate': 0.0023529411764705885, 'epoch': 1.41}

  3%|███                                                                                                       | 435/15300 [06:00<3:20:44,  1.23it/s]
{'loss': 0.6643, 'grad_norm': 6.4806108474731445, 'learning_rate': 0.002363834422657952, 'epoch': 1.42}

  3%|███                                                                                                       | 438/15300 [06:02<3:15:30,  1.27it/s]
{'loss': 0.4981, 'grad_norm': 2.23065185546875, 'learning_rate': 0.002374727668845316, 'epoch': 1.42}
{'loss': 0.5153, 'grad_norm': 3.1328117847442627, 'learning_rate': 0.002380174291938998, 'epoch': 1.43}

  3%|███                                                                                                       | 440/15300 [06:04<3:15:26,  1.27it/s]
{'loss': 0.5862, 'grad_norm': 5.734306335449219, 'learning_rate': 0.002391067538126362, 'epoch': 1.43}

  3%|███                                                                                                       | 443/15300 [06:06<3:14:32,  1.27it/s]
{'loss': 0.8271, 'grad_norm': 4.389397621154785, 'learning_rate': 0.002401960784313726, 'epoch': 1.44}
{'loss': 0.7679, 'grad_norm': 7.691598892211914, 'learning_rate': 0.002407407407407407, 'epoch': 1.44}

  3%|███                                                                                                       | 445/15300 [06:08<3:14:46,  1.27it/s]
{'loss': 0.5395, 'grad_norm': 8.247447967529297, 'learning_rate': 0.002418300653594771, 'epoch': 1.45}

  3%|███                                                                                                       | 448/15300 [06:10<3:15:24,  1.27it/s]
{'loss': 0.1983, 'grad_norm': 4.280827045440674, 'learning_rate': 0.002429193899782135, 'epoch': 1.46}
{'loss': 0.8061, 'grad_norm': 5.5737080574035645, 'learning_rate': 0.002434640522875817, 'epoch': 1.46}

  3%|███                                                                                                       | 450/15300 [06:12<3:15:43,  1.26it/s]
{'loss': 0.3781, 'grad_norm': 2.3631350994110107, 'learning_rate': 0.002445533769063181, 'epoch': 1.47}

  3%|███▏                                                                                                      | 453/15300 [06:14<3:16:48,  1.26it/s]
{'loss': 0.8359, 'grad_norm': 5.370508193969727, 'learning_rate': 0.0024564270152505445, 'epoch': 1.47}
{'loss': 0.7508, 'grad_norm': 7.740370273590088, 'learning_rate': 0.0024618736383442267, 'epoch': 1.48}

  3%|███▏                                                                                                      | 455/15300 [06:16<3:17:20,  1.25it/s]
{'loss': 0.9793, 'grad_norm': 12.808149337768555, 'learning_rate': 0.0024727668845315903, 'epoch': 1.48}

  3%|███▏                                                                                                      | 458/15300 [06:18<3:17:00,  1.26it/s]
{'loss': 0.8169, 'grad_norm': 7.192113399505615, 'learning_rate': 0.0024836601307189543, 'epoch': 1.49}
{'loss': 0.3958, 'grad_norm': 1.8699469566345215, 'learning_rate': 0.0024891067538126365, 'epoch': 1.49}

  3%|███▏                                                                                                      | 460/15300 [06:20<3:17:17,  1.25it/s]
{'loss': 1.0804, 'grad_norm': 15.798730850219727, 'learning_rate': 0.0025, 'epoch': 1.5}

  3%|███▏                                                                                                      | 463/15300 [06:22<3:17:22,  1.25it/s]
{'loss': 1.4587, 'grad_norm': 14.179068565368652, 'learning_rate': 0.002510893246187364, 'epoch': 1.51}
{'loss': 0.8364, 'grad_norm': 8.505611419677734, 'learning_rate': 0.002516339869281046, 'epoch': 1.51}

  3%|███▏                                                                                                      | 465/15300 [06:24<3:17:17,  1.25it/s]
{'loss': 1.1554, 'grad_norm': 11.234855651855469, 'learning_rate': 0.00252723311546841, 'epoch': 1.52}

  3%|███▏                                                                                                      | 468/15300 [06:26<3:15:50,  1.26it/s]
{'loss': 0.6724, 'grad_norm': 2.7311978340148926, 'learning_rate': 0.002538126361655774, 'epoch': 1.52}
{'loss': 0.682, 'grad_norm': 8.007031440734863, 'learning_rate': 0.0025435729847494556, 'epoch': 1.53}

  3%|███▎                                                                                                      | 470/15300 [06:28<3:16:31,  1.26it/s]
{'loss': 0.8201, 'grad_norm': 8.944253921508789, 'learning_rate': 0.0025544662309368196, 'epoch': 1.53}
{'loss': 0.4945, 'grad_norm': 3.111051082611084, 'learning_rate': 0.002559912854030501, 'epoch': 1.54}

  3%|███▎                                                                                                      | 473/15300 [06:30<3:17:11,  1.25it/s]
{'loss': 0.6595, 'grad_norm': 4.689993381500244, 'learning_rate': 0.002570806100217865, 'epoch': 1.54}

  3%|███▎                                                                                                      | 475/15300 [06:32<3:16:58,  1.25it/s]
{'loss': 0.4745, 'grad_norm': 2.821714401245117, 'learning_rate': 0.002581699346405229, 'epoch': 1.55}
{'loss': 0.753, 'grad_norm': 5.741585731506348, 'learning_rate': 0.0025871459694989107, 'epoch': 1.55}

  3%|███▎                                                                                                      | 478/15300 [06:34<3:15:08,  1.27it/s]
{'loss': 0.6079, 'grad_norm': 3.8680715560913086, 'learning_rate': 0.0025980392156862747, 'epoch': 1.56}

  3%|███▎                                                                                                      | 480/15300 [06:36<3:15:01,  1.27it/s]
{'loss': 0.6639, 'grad_norm': 3.941596269607544, 'learning_rate': 0.0026089324618736383, 'epoch': 1.57}
{'loss': 0.6104, 'grad_norm': 3.2455623149871826, 'learning_rate': 0.0026143790849673205, 'epoch': 1.57}

  3%|███▎                                                                                                      | 483/15300 [06:38<3:13:40,  1.28it/s]
{'loss': 0.6005, 'grad_norm': 5.242608070373535, 'learning_rate': 0.002625272331154684, 'epoch': 1.58}

  3%|███▎                                                                                                      | 486/15300 [06:40<3:14:22,  1.27it/s]
{'loss': 0.6032, 'grad_norm': 5.339611053466797, 'learning_rate': 0.002636165577342048, 'epoch': 1.58}
{'loss': 0.6616, 'grad_norm': 3.566068410873413, 'learning_rate': 0.0026416122004357303, 'epoch': 1.58}

  3%|███▍                                                                                                      | 488/15300 [06:42<3:12:35,  1.28it/s]
{'loss': 0.2784, 'grad_norm': 3.2712438106536865, 'learning_rate': 0.0026525054466230934, 'epoch': 1.59}

  3%|███▍                                                                                                      | 491/15300 [06:44<3:15:59,  1.26it/s]
{'loss': 1.3225, 'grad_norm': 10.534188270568848, 'learning_rate': 0.0026633986928104574, 'epoch': 1.6}
{'loss': 0.9895, 'grad_norm': 9.08336353302002, 'learning_rate': 0.002668845315904139, 'epoch': 1.6}

  3%|███▍                                                                                                      | 493/15300 [06:46<3:17:38,  1.25it/s]
{'loss': 0.5711, 'grad_norm': 2.901796817779541, 'learning_rate': 0.002679738562091503, 'epoch': 1.61}

  3%|███▍                                                                                                      | 496/15300 [06:48<3:18:12,  1.24it/s]
{'loss': 0.8084, 'grad_norm': 6.0630202293396, 'learning_rate': 0.002690631808278867, 'epoch': 1.61}
{'loss': 0.7304, 'grad_norm': 6.4487175941467285, 'learning_rate': 0.002696078431372549, 'epoch': 1.62}

  3%|███▍                                                                                                      | 498/15300 [06:50<3:13:58,  1.27it/s]
{'loss': 0.82, 'grad_norm': 4.836056709289551, 'learning_rate': 0.002706971677559913, 'epoch': 1.62}

  3%|███▍                                                                                                      | 501/15300 [06:52<3:15:31,  1.26it/s]
{'loss': 0.624, 'grad_norm': 4.716770172119141, 'learning_rate': 0.002717864923747277, 'epoch': 1.63}
{'loss': 0.4405, 'grad_norm': 2.755830764770508, 'learning_rate': 0.0027233115468409588, 'epoch': 1.63}

  3%|███▍                                                                                                      | 503/15300 [06:54<3:16:07,  1.26it/s]
{'loss': 0.8045, 'grad_norm': 12.844388961791992, 'learning_rate': 0.0027342047930283228, 'epoch': 1.64}

  3%|███▌                                                                                                      | 506/15300 [06:56<3:15:30,  1.26it/s]
{'loss': 0.2975, 'grad_norm': 4.224328994750977, 'learning_rate': 0.0027450980392156868, 'epoch': 1.65}
{'loss': 0.366, 'grad_norm': 2.28295636177063, 'learning_rate': 0.002750544662309368, 'epoch': 1.65}

  3%|███▌                                                                                                      | 508/15300 [06:58<3:17:00,  1.25it/s]
{'loss': 0.6117, 'grad_norm': 4.2874369621276855, 'learning_rate': 0.002761437908496732, 'epoch': 1.66}

  3%|███▌                                                                                                      | 511/15300 [07:00<3:18:04,  1.24it/s]
{'loss': 0.6747, 'grad_norm': 3.4815738201141357, 'learning_rate': 0.0027723311546840957, 'epoch': 1.66}
{'loss': 1.0191, 'grad_norm': 9.301448822021484, 'learning_rate': 0.002777777777777778, 'epoch': 1.67}

  3%|███▌                                                                                                      | 513/15300 [07:02<3:18:34,  1.24it/s]
{'loss': 0.76, 'grad_norm': 7.664247512817383, 'learning_rate': 0.002788671023965142, 'epoch': 1.67}

  3%|███▌                                                                                                      | 516/15300 [07:04<3:15:49,  1.26it/s]
{'loss': 0.6836, 'grad_norm': 7.061661720275879, 'learning_rate': 0.0027995642701525054, 'epoch': 1.68}
{'loss': 0.827, 'grad_norm': 6.478907585144043, 'learning_rate': 0.0028050108932461877, 'epoch': 1.68}

  3%|███▌                                                                                                      | 518/15300 [07:06<3:12:46,  1.28it/s]
{'loss': 0.9959, 'grad_norm': 19.255931854248047, 'learning_rate': 0.0028159041394335512, 'epoch': 1.69}
{'loss': 0.3982, 'grad_norm': 1.8270601034164429, 'learning_rate': 0.0028213507625272334, 'epoch': 1.69}

  3%|███▌                                                                                                      | 521/15300 [07:08<3:11:26,  1.29it/s]
{'loss': 0.6952, 'grad_norm': 6.5860676765441895, 'learning_rate': 0.0028322440087145966, 'epoch': 1.7}

  3%|███▌                                                                                                      | 523/15300 [07:10<3:14:00,  1.27it/s]
{'loss': 0.6783, 'grad_norm': 9.184975624084473, 'learning_rate': 0.0028431372549019606, 'epoch': 1.71}
{'loss': 0.7269, 'grad_norm': 8.081568717956543, 'learning_rate': 0.002848583877995643, 'epoch': 1.71}

  3%|███▋                                                                                                      | 526/15300 [07:12<3:15:18,  1.26it/s]
{'loss': 0.7351, 'grad_norm': 4.179781913757324, 'learning_rate': 0.0028594771241830064, 'epoch': 1.72}

  3%|███▋                                                                                                      | 529/15300 [07:14<3:13:36,  1.27it/s]
{'loss': 0.2105, 'grad_norm': 2.0365586280822754, 'learning_rate': 0.0028703703703703703, 'epoch': 1.72}
{'loss': 0.6203, 'grad_norm': 3.455122947692871, 'learning_rate': 0.002875816993464052, 'epoch': 1.73}

  3%|███▋                                                                                                      | 531/15300 [07:16<3:12:36,  1.28it/s]
{'loss': 0.1784, 'grad_norm': 1.531013011932373, 'learning_rate': 0.002886710239651416, 'epoch': 1.73}

  3%|███▋                                                                                                      | 534/15300 [07:18<3:12:37,  1.28it/s]
{'loss': 1.1801, 'grad_norm': 8.851468086242676, 'learning_rate': 0.00289760348583878, 'epoch': 1.74}
{'loss': 0.5259, 'grad_norm': 5.140933990478516, 'learning_rate': 0.002903050108932462, 'epoch': 1.74}

  4%|███▋                                                                                                      | 536/15300 [07:20<3:13:31,  1.27it/s]
{'loss': 0.5611, 'grad_norm': 8.827563285827637, 'learning_rate': 0.002913943355119826, 'epoch': 1.75}

  4%|███▋                                                                                                      | 539/15300 [07:22<3:14:00,  1.27it/s]
{'loss': 0.5731, 'grad_norm': 7.299391746520996, 'learning_rate': 0.00292483660130719, 'epoch': 1.75}
{'loss': 0.7146, 'grad_norm': 6.047609806060791, 'learning_rate': 0.0029302832244008717, 'epoch': 1.76}

  4%|███▋                                                                                                      | 541/15300 [07:24<3:13:33,  1.27it/s]
{'loss': 0.857, 'grad_norm': 4.862908363342285, 'learning_rate': 0.0029411764705882353, 'epoch': 1.76}

  4%|███▊                                                                                                      | 544/15300 [07:26<3:14:07,  1.27it/s]
{'loss': 0.5563, 'grad_norm': 3.5554909706115723, 'learning_rate': 0.0029520697167755993, 'epoch': 1.77}
{'loss': 0.9989, 'grad_norm': 8.036521911621094, 'learning_rate': 0.002957516339869281, 'epoch': 1.77}

  4%|███▊                                                                                                      | 546/15300 [07:28<3:14:13,  1.27it/s]
{'loss': 0.826, 'grad_norm': 7.774596214294434, 'learning_rate': 0.002968409586056645, 'epoch': 1.78}

  4%|███▊                                                                                                      | 549/15300 [07:30<3:14:00,  1.27it/s]
{'loss': 0.5166, 'grad_norm': 4.6994829177856445, 'learning_rate': 0.0029793028322440086, 'epoch': 1.79}
{'loss': 0.8401, 'grad_norm': 10.307562828063965, 'learning_rate': 0.002984749455337691, 'epoch': 1.79}

  4%|███▊                                                                                                      | 551/15300 [07:32<3:13:53,  1.27it/s]
{'loss': 0.7856, 'grad_norm': 7.327240943908691, 'learning_rate': 0.002995642701525055, 'epoch': 1.8}
{'loss': 0.6713, 'grad_norm': 7.549788475036621, 'learning_rate': 0.0030010893246187366, 'epoch': 1.8}

  4%|███▊                                                                                                      | 554/15300 [07:34<3:13:36,  1.27it/s]
{'loss': 0.4439, 'grad_norm': 3.4530293941497803, 'learning_rate': 0.0030119825708061006, 'epoch': 1.81}

  4%|███▊                                                                                                      | 557/15300 [07:37<3:14:42,  1.26it/s]
{'loss': 0.4872, 'grad_norm': 3.1733598709106445, 'learning_rate': 0.0030228758169934637, 'epoch': 1.81}
{'loss': 0.7114, 'grad_norm': 5.652830123901367, 'learning_rate': 0.0030283224400871464, 'epoch': 1.82}

  4%|███▊                                                                                                      | 559/15300 [07:38<3:14:59,  1.26it/s]
{'loss': 0.631, 'grad_norm': 4.306851387023926, 'learning_rate': 0.0030392156862745095, 'epoch': 1.82}

  4%|███▉                                                                                                      | 562/15300 [07:41<3:15:15,  1.26it/s]
{'loss': 0.7529, 'grad_norm': 4.400333404541016, 'learning_rate': 0.0030501089324618735, 'epoch': 1.83}
{'loss': 0.6154, 'grad_norm': 5.58242654800415, 'learning_rate': 0.0030555555555555557, 'epoch': 1.83}

  4%|███▉                                                                                                      | 564/15300 [07:42<3:16:02,  1.25it/s]
{'loss': 0.3786, 'grad_norm': 2.5086097717285156, 'learning_rate': 0.0030664488017429193, 'epoch': 1.84}

  4%|███▉                                                                                                      | 566/15300 [07:44<3:16:40,  1.25it/s]
{'loss': 0.644, 'grad_norm': 4.247122287750244, 'learning_rate': 0.0030773420479302833, 'epoch': 1.85}

  4%|███▉                                                                                                      | 569/15300 [07:46<3:17:22,  1.24it/s]
{'loss': 0.3145, 'grad_norm': 3.055820941925049, 'learning_rate': 0.0030882352941176473, 'epoch': 1.85}
{'loss': 0.6054, 'grad_norm': 7.199653625488281, 'learning_rate': 0.003093681917211329, 'epoch': 1.86}

  4%|███▉                                                                                                      | 572/15300 [07:49<3:17:23,  1.24it/s]
{'loss': 0.7154, 'grad_norm': 11.190669059753418, 'learning_rate': 0.003104575163398693, 'epoch': 1.86}
{'loss': 0.3482, 'grad_norm': 3.8693268299102783, 'learning_rate': 0.003110021786492375, 'epoch': 1.87}

  4%|███▉                                                                                                      | 574/15300 [07:50<3:17:40,  1.24it/s]
{'loss': 0.4917, 'grad_norm': 3.654292106628418, 'learning_rate': 0.003120915032679739, 'epoch': 1.87}

  4%|███▉                                                                                                      | 577/15300 [07:53<3:15:46,  1.25it/s]
{'loss': 0.7498, 'grad_norm': 7.735769748687744, 'learning_rate': 0.003131808278867103, 'epoch': 1.88}
{'loss': 0.2848, 'grad_norm': 6.925143718719482, 'learning_rate': 0.003137254901960784, 'epoch': 1.88}

  4%|████                                                                                                      | 579/15300 [07:54<3:17:18,  1.24it/s]
{'loss': 0.9203, 'grad_norm': 1273.9638671875, 'learning_rate': 0.003148148148148148, 'epoch': 1.89}

  4%|████                                                                                                      | 581/15300 [07:56<3:20:03,  1.23it/s]
{'loss': 1.8677, 'grad_norm': 15.750360488891602, 'learning_rate': 0.003159041394335512, 'epoch': 1.9}
{'loss': 0.5145, 'grad_norm': 7.592057228088379, 'learning_rate': 0.003164488017429194, 'epoch': 1.9}

  4%|████                                                                                                      | 584/15300 [07:58<3:18:33,  1.24it/s]
{'loss': 0.2985, 'grad_norm': 4.278110027313232, 'learning_rate': 0.003175381263616558, 'epoch': 1.91}

  4%|████                                                                                                      | 586/15300 [08:00<3:16:33,  1.25it/s]
{'loss': 0.4634, 'grad_norm': 8.340409278869629, 'learning_rate': 0.0031862745098039215, 'epoch': 1.91}
{'loss': 0.3864, 'grad_norm': 13.23554801940918, 'learning_rate': 0.0031917211328976037, 'epoch': 1.92}

  4%|████                                                                                                      | 589/15300 [08:02<3:14:11,  1.26it/s]
{'loss': 0.896, 'grad_norm': 11.198904991149902, 'learning_rate': 0.0032026143790849673, 'epoch': 1.92}

  4%|████                                                                                                      | 591/15300 [08:04<3:16:35,  1.25it/s]
{'loss': 0.3113, 'grad_norm': 2.743049383163452, 'learning_rate': 0.0032135076252723313, 'epoch': 1.93}
{'loss': 0.8362, 'grad_norm': 12.698291778564453, 'learning_rate': 0.0032189542483660135, 'epoch': 1.93}

  4%|████                                                                                                      | 594/15300 [08:06<3:19:04,  1.23it/s]
{'loss': 0.9983, 'grad_norm': 9.807674407958984, 'learning_rate': 0.0032298474945533766, 'epoch': 1.94}

  4%|████▏                                                                                                     | 596/15300 [08:08<3:16:25,  1.25it/s]
{'loss': 0.2903, 'grad_norm': 1.9671928882598877, 'learning_rate': 0.0032407407407407406, 'epoch': 1.94}
{'loss': 0.5884, 'grad_norm': 6.190065860748291, 'learning_rate': 0.0032461873638344224, 'epoch': 1.95}

  4%|████▏                                                                                                     | 599/15300 [08:10<3:14:45,  1.26it/s]
{'loss': 0.4673, 'grad_norm': 4.97799015045166, 'learning_rate': 0.0032570806100217864, 'epoch': 1.95}

  4%|████▏                                                                                                     | 602/15300 [08:13<3:14:04,  1.26it/s]
{'loss': 0.9446, 'grad_norm': 8.268658638000488, 'learning_rate': 0.0032679738562091504, 'epoch': 1.96}
{'loss': 1.5421, 'grad_norm': 13.530609130859375, 'learning_rate': 0.003273420479302832, 'epoch': 1.96}

  4%|████▏                                                                                                     | 604/15300 [08:14<3:16:08,  1.25it/s]
{'loss': 0.681, 'grad_norm': 10.288629531860352, 'learning_rate': 0.003284313725490196, 'epoch': 1.97}

  4%|████▏                                                                                                     | 606/15300 [08:16<3:20:17,  1.22it/s]
{'loss': 0.5284, 'grad_norm': 1.866494059562683, 'learning_rate': 0.00329520697167756, 'epoch': 1.98}

  4%|████▏                                                                                                     | 608/15300 [08:18<3:21:29,  1.22it/s]
{'loss': 0.611, 'grad_norm': 3.506383180618286, 'learning_rate': 0.0033061002178649233, 'epoch': 1.98}
{'loss': 0.5868, 'grad_norm': 2.8418588638305664, 'learning_rate': 0.003311546840958606, 'epoch': 1.99}

  4%|████▏                                                                                                     | 611/15300 [08:20<3:22:19,  1.21it/s]
{'loss': 0.5774, 'grad_norm': 5.852254390716553, 'learning_rate': 0.00332244008714597, 'epoch': 1.99}
{'loss': 0.4794, 'grad_norm': 3.8434455394744873, 'learning_rate': 0.0033278867102396513, 'epoch': 2.0}
  4%|████▏                                                                                                     | 612/15300 [08:21<3:02:47,  1.34it/s][INFO|trainer.py:786] 2024-12-07 12:39:35,240 >> The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.
[INFO|trainer.py:3614] 2024-12-07 12:39:35,243 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-07 12:39:35,243 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-07 12:39:35,243 >>   Batch size = 8






 88%|██████████████████████████████████████████████████████████████████████████████████████████████████▊             | 45/51 [00:11<00:01,  3.83it/s]
{'eval_loss': 0.5275247097015381, 'eval_accuracy': 0.7720588235294118, 'eval_f1': 0.8248587570621468, 'eval_combined_score': 0.7984587902957794, 'eval_runtime': 13.1075, 'eval_samples_per_second': 31.127, 'eval_steps_per_second': 3.891, 'epoch': 2.0}

  4%|████▏                                                                                                    | 615/15300 [08:36<11:04:30,  2.72s/it]
{'loss': 0.4901, 'grad_norm': 3.8735666275024414, 'learning_rate': 0.003344226579520697, 'epoch': 2.01}

  4%|████▎                                                                                                     | 617/15300 [08:38<7:05:47,  1.74s/it]
{'loss': 0.7237, 'grad_norm': 3.9028992652893066, 'learning_rate': 0.003355119825708061, 'epoch': 2.01}
{'loss': 0.6835, 'grad_norm': 3.043515205383301, 'learning_rate': 0.003360566448801743, 'epoch': 2.02}

  4%|████▎                                                                                                     | 620/15300 [08:40<4:35:36,  1.13s/it]
{'loss': 0.7278, 'grad_norm': 3.9668734073638916, 'learning_rate': 0.003371459694989107, 'epoch': 2.02}

  4%|████▎                                                                                                     | 622/15300 [08:42<3:55:30,  1.04it/s]
{'loss': 0.8646, 'grad_norm': 6.932123184204102, 'learning_rate': 0.003382352941176471, 'epoch': 2.03}
{'loss': 0.6479, 'grad_norm': 7.885545253753662, 'learning_rate': 0.0033877995642701527, 'epoch': 2.03}

  4%|████▎                                                                                                     | 625/15300 [08:44<3:29:44,  1.17it/s]
{'loss': 0.4379, 'grad_norm': 3.0011186599731445, 'learning_rate': 0.0033986928104575167, 'epoch': 2.04}

  4%|████▎                                                                                                     | 627/15300 [08:46<3:23:25,  1.20it/s]
{'loss': 0.6601, 'grad_norm': 4.358660697937012, 'learning_rate': 0.00340958605664488, 'epoch': 2.05}
{'loss': 0.4383, 'grad_norm': 3.1611485481262207, 'learning_rate': 0.0034150326797385624, 'epoch': 2.05}

  4%|████▎                                                                                                     | 629/15300 [08:47<3:21:15,  1.21it/s]
{'loss': 0.5964, 'grad_norm': 4.009643077850342, 'learning_rate': 0.003425925925925926, 'epoch': 2.06}

  4%|████▍                                                                                                     | 632/15300 [08:50<3:18:54,  1.23it/s]
{'loss': 0.7903, 'grad_norm': 8.840960502624512, 'learning_rate': 0.0034368191721132896, 'epoch': 2.06}
{'loss': 0.3876, 'grad_norm': 8.508979797363281, 'learning_rate': 0.003442265795206972, 'epoch': 2.07}

  4%|████▍                                                                                                     | 634/15300 [08:51<3:18:27,  1.23it/s]
{'loss': 0.438, 'grad_norm': 2.7754721641540527, 'learning_rate': 0.0034531590413943354, 'epoch': 2.07}

  4%|████▍                                                                                                     | 637/15300 [08:54<3:17:21,  1.24it/s]
{'loss': 0.2539, 'grad_norm': 4.969586372375488, 'learning_rate': 0.0034640522875816994, 'epoch': 2.08}
{'loss': 0.9143, 'grad_norm': 5.32499885559082, 'learning_rate': 0.0034694989106753816, 'epoch': 2.08}

  4%|████▍                                                                                                     | 639/15300 [08:55<3:17:11,  1.24it/s]
{'loss': 1.2448, 'grad_norm': 12.845622062683105, 'learning_rate': 0.003480392156862745, 'epoch': 2.09}

  4%|████▍                                                                                                     | 642/15300 [08:58<3:17:06,  1.24it/s]
{'loss': 0.8007, 'grad_norm': 13.441935539245605, 'learning_rate': 0.003491285403050109, 'epoch': 2.09}
{'loss': 0.7734, 'grad_norm': 6.621903896331787, 'learning_rate': 0.003496732026143791, 'epoch': 2.1}

  4%|████▍                                                                                                     | 644/15300 [09:00<3:17:36,  1.24it/s]
{'loss': 1.0468, 'grad_norm': 13.80347728729248, 'learning_rate': 0.0035076252723311545, 'epoch': 2.1}

  4%|████▍                                                                                                     | 647/15300 [09:02<3:17:48,  1.23it/s]
{'loss': 0.61, 'grad_norm': 9.915854454040527, 'learning_rate': 0.0035185185185185185, 'epoch': 2.11}

  4%|████▍                                                                                                     | 649/15300 [09:04<3:17:52,  1.23it/s]
{'loss': 0.5334, 'grad_norm': 3.061732530593872, 'learning_rate': 0.0035294117647058825, 'epoch': 2.12}
{'loss': 0.8782, 'grad_norm': 10.340775489807129, 'learning_rate': 0.0035348583877995643, 'epoch': 2.12}

  4%|████▌                                                                                                     | 652/15300 [09:06<3:17:46,  1.23it/s]
{'loss': 0.9576, 'grad_norm': 8.68490219116211, 'learning_rate': 0.0035457516339869283, 'epoch': 2.13}

  4%|████▌                                                                                                     | 654/15300 [09:08<3:17:28,  1.24it/s]
{'loss': 0.878, 'grad_norm': 7.879440784454346, 'learning_rate': 0.003556644880174292, 'epoch': 2.13}
{'loss': 0.6509, 'grad_norm': 4.226966857910156, 'learning_rate': 0.003562091503267974, 'epoch': 2.14}

  4%|████▌                                                                                                     | 657/15300 [09:10<3:17:48,  1.23it/s]
{'loss': 0.7182, 'grad_norm': 4.310473918914795, 'learning_rate': 0.003572984749455338, 'epoch': 2.14}

  4%|████▌                                                                                                     | 659/15300 [09:12<3:18:16,  1.23it/s]
{'loss': 0.5206, 'grad_norm': 7.9982099533081055, 'learning_rate': 0.0035838779956427016, 'epoch': 2.15}
{'loss': 0.496, 'grad_norm': 2.4592392444610596, 'learning_rate': 0.003589324618736384, 'epoch': 2.15}

  4%|████▌                                                                                                     | 662/15300 [09:14<3:17:27,  1.24it/s]
{'loss': 0.4393, 'grad_norm': 2.4714701175689697, 'learning_rate': 0.003600217864923747, 'epoch': 2.16}

  4%|████▌                                                                                                     | 664/15300 [09:16<3:17:11,  1.24it/s]
{'loss': 0.6192, 'grad_norm': 5.426260948181152, 'learning_rate': 0.003611111111111111, 'epoch': 2.17}
{'loss': 0.5957, 'grad_norm': 5.818917274475098, 'learning_rate': 0.0036165577342047927, 'epoch': 2.17}

  4%|████▌                                                                                                     | 667/15300 [09:18<3:19:50,  1.22it/s]
{'loss': 1.1494, 'grad_norm': 14.572441101074219, 'learning_rate': 0.0036274509803921567, 'epoch': 2.18}

  4%|████▋                                                                                                     | 669/15300 [09:20<3:21:00,  1.21it/s]
{'loss': 0.4012, 'grad_norm': 8.36872673034668, 'learning_rate': 0.0036383442265795207, 'epoch': 2.18}
{'loss': 0.7597, 'grad_norm': 4.272834300994873, 'learning_rate': 0.0036437908496732025, 'epoch': 2.19}

  4%|████▋                                                                                                     | 672/15300 [09:22<3:19:26,  1.22it/s]
{'loss': 0.6522, 'grad_norm': 5.5038018226623535, 'learning_rate': 0.0036546840958605665, 'epoch': 2.19}

  4%|████▋                                                                                                     | 674/15300 [09:24<3:18:49,  1.23it/s]
{'loss': 0.3606, 'grad_norm': 4.765964984893799, 'learning_rate': 0.0036655773420479305, 'epoch': 2.2}
{'loss': 0.2696, 'grad_norm': 2.134340286254883, 'learning_rate': 0.0036710239651416123, 'epoch': 2.2}

  4%|████▋                                                                                                     | 676/15300 [09:26<3:19:48,  1.22it/s]
{'loss': 0.0792, 'grad_norm': 2.304600954055786, 'learning_rate': 0.0036819172113289763, 'epoch': 2.21}

  4%|████▋                                                                                                     | 679/15300 [09:28<3:19:38,  1.22it/s]
{'loss': 0.5964, 'grad_norm': 4.340017795562744, 'learning_rate': 0.0036928104575163403, 'epoch': 2.22}

  4%|████▋                                                                                                     | 681/15300 [09:30<3:19:34,  1.22it/s]
{'loss': 0.4971, 'grad_norm': 4.290706634521484, 'learning_rate': 0.0037037037037037034, 'epoch': 2.22}
{'loss': 0.4975, 'grad_norm': 6.324495792388916, 'learning_rate': 0.0037091503267973856, 'epoch': 2.23}

  4%|████▋                                                                                                     | 684/15300 [09:32<3:19:22,  1.22it/s]
{'loss': 0.1614, 'grad_norm': 13.5527925491333, 'learning_rate': 0.003720043572984749, 'epoch': 2.23}

  4%|████▊                                                                                                     | 686/15300 [09:34<3:20:33,  1.21it/s]
{'loss': 0.9838, 'grad_norm': 13.172545433044434, 'learning_rate': 0.003730936819172113, 'epoch': 2.24}
{'loss': 0.3291, 'grad_norm': 5.041721820831299, 'learning_rate': 0.0037363834422657954, 'epoch': 2.24}

  5%|████▊                                                                                                     | 689/15300 [09:36<3:22:02,  1.21it/s]
{'loss': 0.5152, 'grad_norm': 8.186641693115234, 'learning_rate': 0.003747276688453159, 'epoch': 2.25}

  5%|████▊                                                                                                     | 691/15300 [09:38<3:22:56,  1.20it/s]
{'loss': 0.4615, 'grad_norm': 4.624795913696289, 'learning_rate': 0.003758169934640523, 'epoch': 2.25}
{'loss': 0.2676, 'grad_norm': 3.5251102447509766, 'learning_rate': 0.0037636165577342048, 'epoch': 2.26}

  5%|████▊                                                                                                     | 693/15300 [09:40<3:23:51,  1.19it/s]
{'loss': 0.8742, 'grad_norm': 11.785468101501465, 'learning_rate': 0.0037745098039215687, 'epoch': 2.26}

  5%|████▊                                                                                                     | 696/15300 [09:42<3:24:58,  1.19it/s]
{'loss': 0.3978, 'grad_norm': 7.311168670654297, 'learning_rate': 0.0037854030501089327, 'epoch': 2.27}

  5%|████▊                                                                                                     | 698/15300 [09:44<3:22:09,  1.20it/s]
{'loss': 0.8266, 'grad_norm': 15.66875171661377, 'learning_rate': 0.0037962962962962967, 'epoch': 2.28}
{'loss': 1.154, 'grad_norm': 15.263500213623047, 'learning_rate': 0.003801742919389978, 'epoch': 2.28}

  5%|████▊                                                                                                     | 701/15300 [09:46<3:19:30,  1.22it/s]
{'loss': 1.6502, 'grad_norm': 18.123971939086914, 'learning_rate': 0.003812636165577342, 'epoch': 2.29}

  5%|████▊                                                                                                     | 703/15300 [09:48<3:19:35,  1.22it/s]
{'loss': 0.6818, 'grad_norm': 6.411632537841797, 'learning_rate': 0.0038235294117647057, 'epoch': 2.29}
{'loss': 0.8141, 'grad_norm': 8.617701530456543, 'learning_rate': 0.003828976034858388, 'epoch': 2.3}

  5%|████▉                                                                                                     | 705/15300 [09:50<3:20:23,  1.21it/s]
{'loss': 0.9574, 'grad_norm': 8.363704681396484, 'learning_rate': 0.003839869281045752, 'epoch': 2.3}

  5%|████▉                                                                                                     | 708/15300 [09:52<3:18:55,  1.22it/s]
{'loss': 0.4806, 'grad_norm': 5.58227014541626, 'learning_rate': 0.0038507625272331154, 'epoch': 2.31}
{'loss': 0.5492, 'grad_norm': 6.250818729400635, 'learning_rate': 0.0038562091503267977, 'epoch': 2.31}

  5%|████▉                                                                                                     | 710/15300 [09:54<3:17:19,  1.23it/s]
{'loss': 0.5687, 'grad_norm': 5.848653316497803, 'learning_rate': 0.003867102396514161, 'epoch': 2.32}

  5%|████▉                                                                                                     | 713/15300 [09:56<3:18:40,  1.22it/s]
{'loss': 0.5891, 'grad_norm': 3.499174118041992, 'learning_rate': 0.003877995642701525, 'epoch': 2.33}

  5%|████▉                                                                                                     | 715/15300 [09:58<3:18:31,  1.22it/s]
{'loss': 1.094, 'grad_norm': 10.61905574798584, 'learning_rate': 0.003888888888888889, 'epoch': 2.33}
{'loss': 0.5985, 'grad_norm': 5.477505207061768, 'learning_rate': 0.0038943355119825706, 'epoch': 2.34}

  5%|████▉                                                                                                     | 718/15300 [10:00<3:19:24,  1.22it/s]
{'loss': 0.9036, 'grad_norm': 12.370668411254883, 'learning_rate': 0.0039052287581699346, 'epoch': 2.34}

  5%|████▉                                                                                                     | 720/15300 [10:02<3:19:27,  1.22it/s]
{'loss': 0.7829, 'grad_norm': 7.383716583251953, 'learning_rate': 0.0039161220043572986, 'epoch': 2.35}
{'loss': 0.689, 'grad_norm': 9.641345977783203, 'learning_rate': 0.00392156862745098, 'epoch': 2.35}

  5%|█████                                                                                                     | 723/15300 [10:04<3:19:28,  1.22it/s]
{'loss': 0.1832, 'grad_norm': 1.242186188697815, 'learning_rate': 0.003932461873638345, 'epoch': 2.36}

  5%|█████                                                                                                     | 725/15300 [10:06<3:16:34,  1.24it/s]
{'loss': 0.4564, 'grad_norm': 4.103728294372559, 'learning_rate': 0.003943355119825708, 'epoch': 2.37}
{'loss': 1.0192, 'grad_norm': 9.580889701843262, 'learning_rate': 0.00394880174291939, 'epoch': 2.37}

  5%|█████                                                                                                     | 728/15300 [10:08<3:18:17,  1.22it/s]
{'loss': 0.4971, 'grad_norm': 4.878339767456055, 'learning_rate': 0.003959694989106754, 'epoch': 2.38}

  5%|█████                                                                                                     | 730/15300 [10:10<3:19:13,  1.22it/s]
{'loss': 0.1587, 'grad_norm': 1.751222014427185, 'learning_rate': 0.003970588235294117, 'epoch': 2.38}
{'loss': 0.8685, 'grad_norm': 7.851234436035156, 'learning_rate': 0.0039760348583878, 'epoch': 2.39}

  5%|█████                                                                                                     | 732/15300 [10:12<3:19:13,  1.22it/s]
{'loss': 0.3695, 'grad_norm': 5.1262526512146, 'learning_rate': 0.0039869281045751635, 'epoch': 2.39}
  5%|█████                                                                                                     | 733/15300 [10:12<3:17:47,  1.23it/s]Traceback (most recent call last):
  File "main_glue.py", line 872, in <module>
    main()
  File "main_glue.py", line 761, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/transformers/trainer.py", line 1859, in train
    return inner_training_loop(
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/transformers/trainer.py", line 2203, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/transformers/trainer.py", line 3147, in training_step
    self.accelerator.backward(loss)
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/accelerate/accelerator.py", line 1966, in backward
    loss.backward(**kwargs)
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt