MaskingCallback triggered: Selected k = 23
Applying mask to parameter: base_model.model.roberta.encoder.layer.0.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.0.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.0.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.0.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.1.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.1.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.1.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.1.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.2.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.2.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.2.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.2.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.3.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.3.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.3.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.3.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.4.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.4.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.4.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.4.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.5.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.5.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.5.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.5.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.6.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.6.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.6.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.6.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.7.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.7.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.7.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.7.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.8.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.8.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.8.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.8.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.9.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.9.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.9.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.9.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.10.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.10.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.10.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.10.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.11.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.11.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.11.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.11.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.12.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.12.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.12.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.12.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.13.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.13.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.13.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.13.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.14.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.14.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.14.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.14.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.15.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.15.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.15.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.15.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.16.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.16.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.16.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.16.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.17.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.17.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.17.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.17.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.18.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.18.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.18.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.18.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.19.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.19.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.19.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.19.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.20.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.20.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.20.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.20.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.21.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.21.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.21.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.21.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.22.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.22.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.22.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.22.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.23.attention.self.query.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.23.attention.self.value.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.23.attention.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.roberta.encoder.layer.23.output.dense.default_lora_latent_mapping.weight, with shape: torch.Size([25, 25])
Applying mask to parameter: base_model.model.classifier.modules_to_save.default.dense.weight, with shape: torch.Size([1024, 1024])
  0%|                                                                                                                       | 0/21420 [00:00<?, ?it/s]Traceback (most recent call last):
  File "my_experiments/tasks/task1/rank_dropout.py", line 937, in <module>
    main()
  File "my_experiments/tasks/task1/rank_dropout.py", line 826, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/transformers/trainer.py", line 1859, in train
    return inner_training_loop(
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/transformers/trainer.py", line 2200, in _inner_training_loop
    self.control = self.callback_handler.on_step_begin(args, self.state, self.control)
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/transformers/trainer_callback.py", line 387, in on_step_begin
    return self.call_event("on_step_begin", args, state, control)
  File "/home/mallahova/miniconda3/envs/loraxs/lib/python3.8/site-packages/transformers/trainer_callback.py", line 415, in call_event
    result = getattr(callback, event)(
  File "/home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/my_experiments/tasks/task1/my_utils/custom_trainer.py", line 29, in on_step_begin
    mask = get_mask(rank, k)
  File "/home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/my_experiments/tasks/task1/my_utils/custom_trainer.py", line 9, in get_mask
    mask[:k, :k] = 1
IndexError: too many indices for tensor of dimension 1