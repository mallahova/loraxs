2024-12-05 16:24:14,762 INFO    StreamThr :26706 [internal.py:wandb_internal():86] W&B internal server running at pid: 26706, started at: 2024-12-05 16:24:14.761591
2024-12-05 16:24:14,762 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: status
2024-12-05 16:24:14,767 INFO    WriterThread:26706 [datastore.py:open_for_write():87] open: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/run-gmzxz8cs.wandb
2024-12-05 16:24:14,767 DEBUG   SenderThread:26706 [sender.py:send():379] send: header
2024-12-05 16:24:14,815 DEBUG   SenderThread:26706 [sender.py:send():379] send: run
2024-12-05 16:24:14,816 INFO    SenderThread:26706 [sender.py:_setup_resume():749] checking resume status for None/huggingface/gmzxz8cs
2024-12-05 16:24:15,289 INFO    SenderThread:26706 [sender.py:_setup_resume():827] configured resuming with: ResumeState(resumed=True,step=23,history=1262,events=1105,output=10019,runtime=802.271913,wandb_runtime=798,summary={'_runtime': 788.6334066390991, '_step': 22, '_timestamp': 1733408577.6449976, '_wandb': {'runtime': 798}, 'eval/accuracy': 0.8553921568627451, 'eval/accuracy_10': 0.8553921568627451, 'eval/accuracy_11': 0.8553921568627451, 'eval/accuracy_12': 0.8553921568627451, 'eval/accuracy_13': 0.8553921568627451, 'eval/accuracy_14': 0.8553921568627451, 'eval/accuracy_15': 0.8553921568627451, 'eval/accuracy_16': 0.8553921568627451, 'eval/accuracy_17': 0.8553921568627451, 'eval/accuracy_18': 0.8553921568627451, 'eval/accuracy_19': 0.8553921568627451, 'eval/accuracy_20': 0.8553921568627451, 'eval/accuracy_21': 0.8553921568627451, 'eval/accuracy_22': 0.8553921568627451, 'eval/accuracy_23': 0.8553921568627451, 'eval/accuracy_24': 0.8553921568627451, 'eval/accuracy_25': 0.8553921568627451, 'eval/combined_score': 0.8767461647871584, 'eval/f1': 0.8981001727115717, 'eval/loss': 0.8314821720123291, 'eval/runtime': 203.558, 'eval/samples_per_second': 2.004, 'eval/steps_per_second': 0.251, 'train/epoch': 66.58682634730539, 'train/global_step': 22240, 'train/grad_norm': 0.23220767080783844, 'train/learning_rate': 0.00026706586826347303, 'train/loss': 0.1918},config={'bf16': {'desc': None, 'value': False}, 'fp16': {'desc': None, 'value': False}, 'fsdp': {'desc': None, 'value': []}, 'seed': {'desc': None, 'value': 0}, 'tf32': {'desc': None, 'value': None}, 'debug': {'desc': None, 'value': []}, 'optim': {'desc': None, 'value': 'adamw_torch'}, 'top_k': {'desc': None, 'value': 50}, 'top_p': {'desc': None, 'value': 1}, '_wandb': {'desc': None, 'value': {'m': [{'1': 'train/global_step', '6': [3]}, {'1': 'train/loss', '5': 1, '6': [1]}, {'1': 'train/grad_norm', '5': 1, '6': [1]}, {'1': 'train/learning_rate', '5': 1, '6': [1]}, {'1': 'train/epoch', '5': 1, '6': [1]}, {'1': 'eval/loss', '5': 1, '6': [1]}, {'1': 'eval/accuracy', '5': 1, '6': [1]}, {'1': 'eval/f1', '5': 1, '6': [1]}, {'1': 'eval/combined_score', '5': 1, '6': [1]}, {'1': 'eval/accuracy_10', '5': 1, '6': [1]}, {'1': 'eval/accuracy_11', '5': 1, '6': [1]}, {'1': 'eval/accuracy_12', '5': 1, '6': [1]}, {'1': 'eval/accuracy_13', '5': 1, '6': [1]}, {'1': 'eval/accuracy_14', '5': 1, '6': [1]}, {'1': 'eval/accuracy_15', '5': 1, '6': [1]}, {'1': 'eval/accuracy_16', '5': 1, '6': [1]}, {'1': 'eval/accuracy_17', '5': 1, '6': [1]}, {'1': 'eval/accuracy_18', '5': 1, '6': [1]}, {'1': 'eval/accuracy_19', '5': 1, '6': [1]}, {'1': 'eval/accuracy_20', '5': 1, '6': [1]}, {'1': 'eval/accuracy_21', '5': 1, '6': [1]}, {'1': 'eval/accuracy_22', '5': 1, '6': [1]}, {'1': 'eval/accuracy_23', '5': 1, '6': [1]}, {'1': 'eval/accuracy_24', '5': 1, '6': [1]}, {'1': 'eval/accuracy_25', '5': 1, '6': [1]}, {'1': 'eval/runtime', '5': 1, '6': [1]}, {'1': 'eval/samples_per_second', '5': 1, '6': [1]}, {'1': 'eval/steps_per_second', '5': 1, '6': [1]}], 't': {'1': [1, 5, 11, 49, 51, 53, 55, 71, 98, 100], '2': [1, 5, 11, 49, 51, 53, 55, 71, 98, 100], '3': [5, 7, 13, 23, 62], '4': '3.8.13', '5': '0.16.6', '6': '4.40.1', '8': [5], '9': {'1': 'transformers_trainer'}, '13': 'linux-x86_64'}, 'framework': 'huggingface', 'start_time': 1733408202.0, 'cli_version': '0.16.6', 'is_jupyter_run': False, 'python_version': '3.8.13', 'is_kaggle_kernel': False, 'huggingface_version': '4.40.1'}}, 'prefix': {'desc': None, 'value': None}, 'do_eval': {'desc': None, 'value': True}, 'no_cuda': {'desc': None, 'value': False}, 'use_cpu': {'desc': None, 'value': False}, 'do_train': {'desc': None, 'value': True}, 'id2label': {'desc': None, 'value': {'0': 'LABEL_0', '1': 'LABEL_1'}}, 'label2id': {'desc': None, 'value': {'equivalent': 1, 'not_equivalent': 0}}, 'run_name': {'desc': None, 'value': 'results_mrpc_25'}, 'use_ipex': {'desc': None, 'value': False}, 'adafactor': {'desc': None, 'value': False}, 'data_seed': {'desc': None, 'value': None}, 'deepspeed': {'desc': None, 'value': None}, 'do_sample': {'desc': None, 'value': False}, 'hub_token': {'desc': None, 'value': '<HUB_TOKEN>'}, 'log_level': {'desc': None, 'value': 'passive'}, 'max_steps': {'desc': None, 'value': -1}, 'num_beams': {'desc': None, 'value': 1}, 'ray_scope': {'desc': None, 'value': 'last'}, 'report_to': {'desc': None, 'value': ['tensorboard', 'wandb']}, 'typical_p': {'desc': None, 'value': 1}, 'use_cache': {'desc': None, 'value': True}, 'adam_beta1': {'desc': None, 'value': 0.9}, 'adam_beta2': {'desc': None, 'value': 0.999}, 'do_predict': {'desc': None, 'value': False}, 'eval_delay': {'desc': None, 'value': 0}, 'eval_steps': {'desc': None, 'value': None}, 'hidden_act': {'desc': None, 'value': 'gelu'}, 'is_decoder': {'desc': None, 'value': False}, 'local_rank': {'desc': None, 'value': 0}, 'max_length': {'desc': None, 'value': 20}, 'min_length': {'desc': None, 'value': 0}, 'model_type': {'desc': None, 'value': 'roberta'}, 'optim_args': {'desc': None, 'value': None}, 'output_dir': {'desc': None, 'value': 'results_mrpc_25/roberta-large/mrpc/pretrained_LoRA_init_svd_rank_25_lr_0.001_clsLR_0.0006_seed_0/last'}, 'past_index': {'desc': None, 'value': -1}, 'save_steps': {'desc': None, 'value': 1000000}, 'vocab_size': {'desc': None, 'value': 50265}, 'ddp_backend': {'desc': None, 'value': None}, 'ddp_timeout': {'desc': None, 'value': 1800}, 'fsdp_config': {'desc': None, 'value': {'xla': False, 'xla_fsdp_v2': False, 'min_num_params': 0, 'xla_fsdp_grad_ckpt': False}}, 'hidden_size': {'desc': None, 'value': 1024}, 'label_names': {'desc': None, 'value': None}, 'logging_dir': {'desc': None, 'value': 'results_mrpc_25/runs/Dec05_15-15-44_mallahova'}, 'push_to_hub': {'desc': None, 'value': False}, 'return_dict': {'desc': None, 'value': True}, 'temperature': {'desc': None, 'value': 1}, 'torch_dtype': {'desc': None, 'value': None}, 'torchdynamo': {'desc': None, 'value': None}, 'torchscript': {'desc': None, 'value': False}, 'adam_epsilon': {'desc': None, 'value': 1e-08}, 'bos_token_id': {'desc': None, 'value': 0}, 'disable_tqdm': {'desc': None, 'value': False}, 'eos_token_id': {'desc': None, 'value': 2}, 'fp16_backend': {'desc': None, 'value': 'auto'}, 'hub_model_id': {'desc': None, 'value': None}, 'hub_strategy': {'desc': None, 'value': 'every_save'}, 'pad_token_id': {'desc': None, 'value': 1}, 'problem_type': {'desc': None, 'value': None}, 'pruned_heads': {'desc': None, 'value': {}}, 'sep_token_id': {'desc': None, 'value': None}, 'use_bfloat16': {'desc': None, 'value': False}, 'warmup_ratio': {'desc': None, 'value': 0}, 'warmup_steps': {'desc': None, 'value': 0}, 'weight_decay': {'desc': None, 'value': 0}, '_name_or_path': {'desc': None, 'value': 'roberta-large'}, 'architectures': {'desc': None, 'value': ['RobertaForMaskedLM']}, 'bad_words_ids': {'desc': None, 'value': None}, 'jit_mode_eval': {'desc': None, 'value': False}, 'learning_rate': {'desc': None, 'value': 0.001}, 'logging_steps': {'desc': None, 'value': 20}, 'max_grad_norm': {'desc': None, 'value': 1}, 'mp_parameters': {'desc': None, 'value': ''}, 'output_scores': {'desc': None, 'value': False}, 'save_strategy': {'desc': None, 'value': 'steps'}, 'split_batches': {'desc': None, 'value': None}, 'torch_compile': {'desc': None, 'value': False}, 'tpu_num_cores': {'desc': None, 'value': None}, 'bf16_full_eval': {'desc': None, 'value': False}, 'early_stopping': {'desc': None, 'value': False}, 'fp16_full_eval': {'desc': None, 'value': False}, 'fp16_opt_level': {'desc': None, 'value': 'O1'}, 'layer_norm_eps': {'desc': None, 'value': 1e-05}, 'length_penalty': {'desc': None, 'value': 1}, 'tf_legacy_loss': {'desc': None, 'value': False}, 'use_mps_device': {'desc': None, 'value': False}, 'finetuning_task': {'desc': None, 'value': 'mrpc'}, 'group_by_length': {'desc': None, 'value': False}, 'hub_always_push': {'desc': None, 'value': False}, 'num_beam_groups': {'desc': None, 'value': 1}, 'save_only_model': {'desc': None, 'value': False}, 'suppress_tokens': {'desc': None, 'value': None}, 'tokenizer_class': {'desc': None, 'value': None}, 'type_vocab_size': {'desc': None, 'value': 1}, 'dispatch_batches': {'desc': None, 'value': None}, 'full_determinism': {'desc': None, 'value': False}, 'hub_private_repo': {'desc': None, 'value': False}, 'ignore_data_skip': {'desc': None, 'value': False}, 'log_on_each_node': {'desc': None, 'value': True}, 'logging_strategy': {'desc': None, 'value': 'steps'}, 'num_train_epochs': {'desc': None, 'value': 120}, 'save_safetensors': {'desc': None, 'value': True}, 'save_total_limit': {'desc': None, 'value': None}, 'ddp_bucket_cap_mb': {'desc': None, 'value': None}, 'diversity_penalty': {'desc': None, 'value': 0}, 'greater_is_better': {'desc': None, 'value': None}, 'initializer_range': {'desc': None, 'value': 0.02}, 'intermediate_size': {'desc': None, 'value': 4096}, 'log_level_replica': {'desc': None, 'value': 'warning'}, 'lr_scheduler_type': {'desc': None, 'value': 'linear'}, 'num_hidden_layers': {'desc': None, 'value': 24}, 'output_attentions': {'desc': None, 'value': False}, 'push_to_hub_token': {'desc': None, 'value': '<PUSH_TO_HUB_TOKEN>'}, 'save_on_each_node': {'desc': None, 'value': False}, 'tpu_metrics_debug': {'desc': None, 'value': False}, 'accelerator_config': {'desc': None, 'value': {'even_batches': True, 'split_batches': False, 'dispatch_batches': None, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None}}, 'classifier_dropout': {'desc': None, 'value': None}, 'is_encoder_decoder': {'desc': None, 'value': False}, 'length_column_name': {'desc': None, 'value': 'length'}, 'logging_first_step': {'desc': None, 'value': False}, 'repetition_penalty': {'desc': None, 'value': 1}, 'torch_compile_mode': {'desc': None, 'value': None}, 'add_cross_attention': {'desc': None, 'value': False}, 'evaluation_strategy': {'desc': None, 'value': 'epoch'}, 'forced_bos_token_id': {'desc': None, 'value': None}, 'forced_eos_token_id': {'desc': None, 'value': None}, 'fsdp_min_num_params': {'desc': None, 'value': 0}, 'hidden_dropout_prob': {'desc': None, 'value': 0.1}, 'lr_scheduler_kwargs': {'desc': None, 'value': {}}, 'neftune_noise_alpha': {'desc': None, 'value': None}, 'num_attention_heads': {'desc': None, 'value': 16}, 'skip_memory_metrics': {'desc': None, 'value': True}, 'tie_encoder_decoder': {'desc': None, 'value': False}, 'tie_word_embeddings': {'desc': None, 'value': True}, 'auto_find_batch_size': {'desc': None, 'value': False}, 'dataloader_drop_last': {'desc': None, 'value': False}, 'no_repeat_ngram_size': {'desc': None, 'value': 0}, 'num_return_sequences': {'desc': None, 'value': 1}, 'optim_target_modules': {'desc': None, 'value': None}, 'output_hidden_states': {'desc': None, 'value': False}, 'overwrite_output_dir': {'desc': None, 'value': False}, 'prediction_loss_only': {'desc': None, 'value': False}, 'push_to_hub_model_id': {'desc': None, 'value': None}, 'task_specific_params': {'desc': None, 'value': None}, 'transformers_version': {'desc': None, 'value': '4.40.1'}, 'begin_suppress_tokens': {'desc': None, 'value': None}, 'dataloader_pin_memory': {'desc': None, 'value': True}, 'ddp_broadcast_buffers': {'desc': None, 'value': None}, 'metric_for_best_model': {'desc': None, 'value': None}, 'remove_invalid_values': {'desc': None, 'value': False}, 'remove_unused_columns': {'desc': None, 'value': True}, 'torch_compile_backend': {'desc': None, 'value': None}, 'dataloader_num_workers': {'desc': None, 'value': 0}, 'decoder_start_token_id': {'desc': None, 'value': None}, 'eval_do_concat_batches': {'desc': None, 'value': True}, 'gradient_checkpointing': {'desc': None, 'value': False}, 'half_precision_backend': {'desc': None, 'value': 'auto'}, 'label_smoothing_factor': {'desc': None, 'value': 0}, 'load_best_model_at_end': {'desc': None, 'value': False}, 'logging_nan_inf_filter': {'desc': None, 'value': True}, 'resume_from_checkpoint': {'desc': None, 'value': None}, 'chunk_size_feed_forward': {'desc': None, 'value': 0}, 'eval_accumulation_steps': {'desc': None, 'value': None}, 'max_position_embeddings': {'desc': None, 'value': 514}, 'per_gpu_eval_batch_size': {'desc': None, 'value': None}, 'position_embedding_type': {'desc': None, 'value': 'absolute'}, 'return_dict_in_generate': {'desc': None, 'value': False}, 'per_gpu_train_batch_size': {'desc': None, 'value': None}, 'push_to_hub_organization': {'desc': None, 'value': None}, 'include_tokens_per_second': {'desc': None, 'value': False}, 'dataloader_prefetch_factor': {'desc': None, 'value': None}, 'ddp_find_unused_parameters': {'desc': None, 'value': None}, 'include_inputs_for_metrics': {'desc': None, 'value': False}, 'per_device_eval_batch_size': {'desc': None, 'value': 8}, 'use_legacy_prediction_loop': {'desc': None, 'value': False}, 'cross_attention_hidden_size': {'desc': None, 'value': None}, 'gradient_accumulation_steps': {'desc': None, 'value': 1}, 'per_device_train_batch_size': {'desc': None, 'value': 11}, 'attention_probs_dropout_prob': {'desc': None, 'value': 0.1}, 'encoder_no_repeat_ngram_size': {'desc': None, 'value': 0}, 'dataloader_persistent_workers': {'desc': None, 'value': False}, 'gradient_checkpointing_kwargs': {'desc': None, 'value': None}, 'include_num_input_tokens_seen': {'desc': None, 'value': False}, 'exponential_decay_length_penalty': {'desc': None, 'value': None}, 'fsdp_transformer_layer_cls_to_wrap': {'desc': None, 'value': None}},tags=[])
2024-12-05 16:24:15,683 INFO    SenderThread:26706 [dir_watcher.py:__init__():211] watching files in: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files
2024-12-05 16:24:15,683 INFO    SenderThread:26706 [sender.py:_start_run_threads():1124] run started: gmzxz8cs with start time 1733411452.491005
2024-12-05 16:24:15,688 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: summary_record
2024-12-05 16:24:15,689 INFO    SenderThread:26706 [sender.py:_save_file():1390] saving file wandb-summary.json with policy end
2024-12-05 16:24:15,694 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: check_version
2024-12-05 16:24:15,694 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: check_version
2024-12-05 16:24:15,898 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: run_start
2024-12-05 16:24:15,903 DEBUG   HandlerThread:26706 [system_info.py:__init__():26] System info init
2024-12-05 16:24:15,903 DEBUG   HandlerThread:26706 [system_info.py:__init__():41] System info init done
2024-12-05 16:24:15,903 INFO    HandlerThread:26706 [system_monitor.py:start():194] Starting system monitor
2024-12-05 16:24:15,903 INFO    SystemMonitor:26706 [system_monitor.py:_start():158] Starting system asset monitoring threads
2024-12-05 16:24:15,904 INFO    SystemMonitor:26706 [interfaces.py:start():190] Started cpu monitoring
2024-12-05 16:24:15,904 INFO    SystemMonitor:26706 [interfaces.py:start():190] Started disk monitoring
2024-12-05 16:24:15,904 INFO    SystemMonitor:26706 [interfaces.py:start():190] Started gpu monitoring
2024-12-05 16:24:15,905 INFO    SystemMonitor:26706 [interfaces.py:start():190] Started memory monitoring
2024-12-05 16:24:15,905 INFO    SystemMonitor:26706 [interfaces.py:start():190] Started network monitoring
2024-12-05 16:24:16,053 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: python_packages
2024-12-05 16:24:16,053 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: python_packages
2024-12-05 16:24:16,094 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: stop_status
2024-12-05 16:24:16,094 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: internal_messages
2024-12-05 16:24:16,095 DEBUG   SenderThread:26706 [sender.py:send():379] send: telemetry
2024-12-05 16:24:16,095 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: stop_status
2024-12-05 16:24:16,301 DEBUG   SenderThread:26706 [sender.py:send():379] send: config
2024-12-05 16:24:16,302 DEBUG   SenderThread:26706 [sender.py:send():379] send: metric
2024-12-05 16:24:16,302 DEBUG   SenderThread:26706 [sender.py:send():379] send: telemetry
2024-12-05 16:24:16,302 DEBUG   SenderThread:26706 [sender.py:send():379] send: metric
2024-12-05 16:24:16,302 WARNING SenderThread:26706 [sender.py:send_metric():1341] Seen metric with glob (shouldn't happen)
2024-12-05 16:24:16,303 DEBUG   SenderThread:26706 [sender.py:send():379] send: telemetry
2024-12-05 16:24:16,683 INFO    Thread-12 :26706 [dir_watcher.py:_on_file_created():271] file/dir created: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/wandb-summary.json
2024-12-05 16:24:16,684 INFO    Thread-12 :26706 [dir_watcher.py:_on_file_created():271] file/dir created: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/output.log
2024-12-05 16:24:16,684 INFO    Thread-12 :26706 [dir_watcher.py:_on_file_created():271] file/dir created: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/requirements.txt
2024-12-05 16:24:18,683 INFO    Thread-12 :26706 [dir_watcher.py:_on_file_modified():288] file/dir modified: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/output.log
2024-12-05 16:24:19,897 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: status_report
2024-12-05 16:24:20,338 DEBUG   SenderThread:26706 [sender.py:send():379] send: exit
2024-12-05 16:24:20,338 INFO    SenderThread:26706 [sender.py:send_exit():586] handling exit code: 255
2024-12-05 16:24:20,338 INFO    SenderThread:26706 [sender.py:send_exit():588] handling runtime: 802
2024-12-05 16:24:20,338 INFO    SenderThread:26706 [sender.py:_save_file():1390] saving file wandb-summary.json with policy end
2024-12-05 16:24:20,338 INFO    SenderThread:26706 [sender.py:send_exit():594] send defer
2024-12-05 16:24:20,338 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:20,338 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 0
2024-12-05 16:24:20,338 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:20,339 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 0
2024-12-05 16:24:20,339 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 1
2024-12-05 16:24:20,339 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:20,339 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 1
2024-12-05 16:24:20,339 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:20,339 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 1
2024-12-05 16:24:20,339 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 2
2024-12-05 16:24:20,339 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:20,339 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 2
2024-12-05 16:24:20,339 INFO    HandlerThread:26706 [system_monitor.py:finish():203] Stopping system monitor
2024-12-05 16:24:20,339 DEBUG   SystemMonitor:26706 [system_monitor.py:_start():172] Starting system metrics aggregation loop
2024-12-05 16:24:20,339 INFO    HandlerThread:26706 [interfaces.py:finish():202] Joined cpu monitor
2024-12-05 16:24:20,339 DEBUG   SystemMonitor:26706 [system_monitor.py:_start():179] Finished system metrics aggregation loop
2024-12-05 16:24:20,339 INFO    HandlerThread:26706 [interfaces.py:finish():202] Joined disk monitor
2024-12-05 16:24:20,339 DEBUG   SystemMonitor:26706 [system_monitor.py:_start():183] Publishing last batch of metrics
2024-12-05 16:24:20,376 INFO    HandlerThread:26706 [interfaces.py:finish():202] Joined gpu monitor
2024-12-05 16:24:20,376 INFO    HandlerThread:26706 [interfaces.py:finish():202] Joined memory monitor
2024-12-05 16:24:20,376 INFO    HandlerThread:26706 [interfaces.py:finish():202] Joined network monitor
2024-12-05 16:24:20,377 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:20,377 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 2
2024-12-05 16:24:20,377 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 3
2024-12-05 16:24:20,377 DEBUG   SenderThread:26706 [sender.py:send():379] send: stats
2024-12-05 16:24:20,377 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:20,377 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 3
2024-12-05 16:24:20,377 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:20,377 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 3
2024-12-05 16:24:20,377 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 4
2024-12-05 16:24:20,377 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:20,377 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 4
2024-12-05 16:24:20,377 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:20,377 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 4
2024-12-05 16:24:20,377 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 5
2024-12-05 16:24:20,377 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:20,377 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 5
2024-12-05 16:24:20,378 DEBUG   SenderThread:26706 [sender.py:send():379] send: summary
2024-12-05 16:24:20,378 INFO    SenderThread:26706 [sender.py:_save_file():1390] saving file wandb-summary.json with policy end
2024-12-05 16:24:20,378 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:20,378 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 5
2024-12-05 16:24:20,378 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 6
2024-12-05 16:24:20,378 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:20,378 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 6
2024-12-05 16:24:20,378 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:20,378 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 6
2024-12-05 16:24:20,381 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: status_report
2024-12-05 16:24:20,684 INFO    Thread-12 :26706 [dir_watcher.py:_on_file_modified():288] file/dir modified: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/wandb-summary.json
2024-12-05 16:24:20,875 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 7
2024-12-05 16:24:20,875 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:20,875 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 7
2024-12-05 16:24:20,875 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:20,875 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 7
2024-12-05 16:24:21,338 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: poll_exit
2024-12-05 16:24:21,685 INFO    Thread-12 :26706 [dir_watcher.py:_on_file_modified():288] file/dir modified: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/config.yaml
2024-12-05 16:24:22,322 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 8
2024-12-05 16:24:22,323 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: poll_exit
2024-12-05 16:24:22,323 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:22,323 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 8
2024-12-05 16:24:22,323 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:22,323 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 8
2024-12-05 16:24:22,323 INFO    SenderThread:26706 [job_builder.py:build():318] Attempting to build job artifact
2024-12-05 16:24:22,323 WARNING SenderThread:26706 [job_builder.py:_log_if_verbose():210] Ensure read and write access to run files dir: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files, control this via the WANDB_DIR env var. See https://docs.wandb.ai/guides/track/environment-variables
2024-12-05 16:24:22,323 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 9
2024-12-05 16:24:22,323 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:22,323 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 9
2024-12-05 16:24:22,323 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:22,323 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 9
2024-12-05 16:24:22,323 INFO    SenderThread:26706 [dir_watcher.py:finish():358] shutting down directory watcher
2024-12-05 16:24:22,339 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: poll_exit
2024-12-05 16:24:22,685 INFO    Thread-12 :26706 [dir_watcher.py:_on_file_modified():288] file/dir modified: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/output.log
2024-12-05 16:24:22,686 INFO    SenderThread:26706 [dir_watcher.py:finish():388] scan: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files
2024-12-05 16:24:22,686 INFO    SenderThread:26706 [dir_watcher.py:finish():402] scan save: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/config.yaml config.yaml
2024-12-05 16:24:22,687 INFO    SenderThread:26706 [dir_watcher.py:finish():402] scan save: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/wandb-summary.json wandb-summary.json
2024-12-05 16:24:22,688 INFO    SenderThread:26706 [dir_watcher.py:finish():402] scan save: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/output.log output.log
2024-12-05 16:24:22,695 INFO    SenderThread:26706 [dir_watcher.py:finish():402] scan save: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/requirements.txt requirements.txt
2024-12-05 16:24:22,695 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 10
2024-12-05 16:24:22,695 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: poll_exit
2024-12-05 16:24:22,696 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:22,696 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 10
2024-12-05 16:24:22,704 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:22,704 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 10
2024-12-05 16:24:22,704 INFO    SenderThread:26706 [file_pusher.py:finish():172] shutting down file pusher
2024-12-05 16:24:23,341 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: poll_exit
2024-12-05 16:24:23,342 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: poll_exit
2024-12-05 16:24:23,444 INFO    wandb-upload_0:26706 [upload_job.py:push():131] Uploaded file /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/config.yaml
2024-12-05 16:24:23,581 INFO    wandb-upload_3:26706 [upload_job.py:push():131] Uploaded file /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/requirements.txt
2024-12-05 16:24:23,586 INFO    wandb-upload_2:26706 [upload_job.py:push():131] Uploaded file /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/output.log
2024-12-05 16:24:23,602 INFO    wandb-upload_1:26706 [upload_job.py:push():131] Uploaded file /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/files/wandb-summary.json
2024-12-05 16:24:23,802 INFO    Thread-11 :26706 [sender.py:transition_state():614] send defer: 11
2024-12-05 16:24:23,803 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:23,803 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 11
2024-12-05 16:24:23,804 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:23,804 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 11
2024-12-05 16:24:23,804 INFO    SenderThread:26706 [file_pusher.py:join():178] waiting for file pusher
2024-12-05 16:24:23,805 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 12
2024-12-05 16:24:23,805 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:23,805 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 12
2024-12-05 16:24:23,805 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:23,805 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 12
2024-12-05 16:24:23,805 INFO    SenderThread:26706 [file_stream.py:finish():614] file stream finish called
2024-12-05 16:24:24,342 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: poll_exit
2024-12-05 16:24:24,572 INFO    SenderThread:26706 [file_stream.py:finish():618] file stream finish is done
2024-12-05 16:24:24,572 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 13
2024-12-05 16:24:24,572 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: poll_exit
2024-12-05 16:24:24,573 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:24,573 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 13
2024-12-05 16:24:24,574 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:24,574 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 13
2024-12-05 16:24:24,574 INFO    SenderThread:26706 [sender.py:transition_state():614] send defer: 14
2024-12-05 16:24:24,574 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: defer
2024-12-05 16:24:24,575 INFO    HandlerThread:26706 [handler.py:handle_request_defer():172] handle defer: 14
2024-12-05 16:24:24,575 DEBUG   SenderThread:26706 [sender.py:send():379] send: final
2024-12-05 16:24:24,575 DEBUG   SenderThread:26706 [sender.py:send():379] send: footer
2024-12-05 16:24:24,576 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: defer
2024-12-05 16:24:24,576 INFO    SenderThread:26706 [sender.py:send_request_defer():610] handle sender defer: 14
2024-12-05 16:24:24,577 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: poll_exit
2024-12-05 16:24:24,577 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: poll_exit
2024-12-05 16:24:24,578 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: poll_exit
2024-12-05 16:24:24,579 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: poll_exit
2024-12-05 16:24:24,579 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: server_info
2024-12-05 16:24:24,580 DEBUG   SenderThread:26706 [sender.py:send_request():406] send_request: server_info
2024-12-05 16:24:24,584 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: get_summary
2024-12-05 16:24:24,585 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: sampled_history
2024-12-05 16:24:24,586 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: internal_messages
2024-12-05 16:24:24,740 INFO    MainThread:26706 [wandb_run.py:_footer_history_summary_info():3936] rendering history
2024-12-05 16:24:24,740 INFO    MainThread:26706 [wandb_run.py:_footer_history_summary_info():3968] rendering summary
2024-12-05 16:24:24,741 INFO    MainThread:26706 [wandb_run.py:_footer_sync_info():3895] logging synced files
2024-12-05 16:24:24,741 DEBUG   HandlerThread:26706 [handler.py:handle_request():146] handle_request: shutdown
2024-12-05 16:24:24,742 INFO    HandlerThread:26706 [handler.py:finish():866] shutting down handler
2024-12-05 16:24:25,580 INFO    WriterThread:26706 [datastore.py:close():296] close: /home/mallahova/code/basics/projects/uj/lora_xs/LoRA-XS/wandb/run-20241205_162414-gmzxz8cs/run-gmzxz8cs.wandb
2024-12-05 16:24:25,739 INFO    SenderThread:26706 [sender.py:finish():1546] shutting down sender
2024-12-05 16:24:25,739 INFO    SenderThread:26706 [file_pusher.py:finish():172] shutting down file pusher
2024-12-05 16:24:25,739 INFO    SenderThread:26706 [file_pusher.py:join():178] waiting for file pusher
