







  0%|                                                                                             | 22/40080 [00:15<7:54:41,  1.41it/s]







  0%|                                                                                             | 42/40080 [00:30<7:57:52,  1.40it/s]







  0%|▏                                                                                            | 61/40080 [00:43<7:56:15,  1.40it/s]







  0%|▏                                                                                            | 81/40080 [00:58<7:57:54,  1.39it/s]







  0%|▏                                                                                           | 101/40080 [01:12<7:55:46,  1.40it/s]







  0%|▎                                                                                           | 120/40080 [01:25<7:57:33,  1.39it/s]







  0%|▎                                                                                           | 140/40080 [01:40<7:56:36,  1.40it/s]








  0%|▎                                                                                           | 161/40080 [01:55<8:00:00,  1.39it/s]







  0%|▍                                                                                           | 181/40080 [02:09<7:58:43,  1.39it/s]







  0%|▍                                                                                           | 200/40080 [02:23<8:05:27,  1.37it/s]







  1%|▌                                                                                           | 219/40080 [02:37<8:04:57,  1.37it/s]







  1%|▌                                                                                           | 239/40080 [02:51<8:03:32,  1.37it/s]








  1%|▌                                                                                           | 261/40080 [03:08<8:07:41,  1.36it/s]







  1%|▋                                                                                           | 280/40080 [03:21<7:56:43,  1.39it/s]







  1%|▋                                                                                           | 299/40080 [03:35<7:56:18,  1.39it/s]







  1%|▋                                                                                           | 319/40080 [03:49<7:53:40,  1.40it/s]





  1%|▊                                                                                           | 334/40080 [04:00<6:46:10,  1.63it/s][INFO|trainer.py:3614] 2024-12-06 11:49:58,987 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 11:49:58,987 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 11:49:58,988 >>   Batch size = 8






100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:12<00:00,  4.10it/s]
Computing accuracy for k=10: 0.7083333333333334
Computing accuracy for k=11: 0.7107843137254902
Computing accuracy for k=12: 0.7107843137254902
Computing accuracy for k=13: 0.7083333333333334
Computing accuracy for k=14: 0.7083333333333334
Computing accuracy for k=15: 0.7083333333333334
Computing accuracy for k=16: 0.7058823529411765
Computing accuracy for k=17: 0.7058823529411765
Computing accuracy for k=18: 0.7058823529411765
Computing accuracy for k=19: 0.7058823529411765
Computing accuracy for k=20: 0.7058823529411765
Computing accuracy for k=21: 0.7083333333333334
Computing accuracy for k=22: 0.7132352941176471
Computing accuracy for k=23: 0.7132352941176471
Computing accuracy for k=24: 0.7107843137254902

Computing accuracy for k=25: 0.7107843137254902
{'accuracy': 0.7083333333333334, 'f1': 0.8210526315789474, 'combined_score': 0.7646929824561404, 'accuracy_10': 0.7083333333333334, 'accuracy_11': 0.7107843137254902, 'accuracy_12': 0.7107843137254902, 'accuracy_13': 0.7083333333333334, 'accuracy_14': 0.7083333333333334, 'accuracy_15': 0.7083333333333334, 'accuracy_16': 0.7058823529411765, 'accuracy_17': 0.7058823529411765, 'accuracy_18': 0.7058823529411765, 'accuracy_19': 0.7058823529411765, 'accuracy_20': 0.7058823529411765, 'accuracy_21': 0.7083333333333334, 'accuracy_22': 0.7132352941176471, 'accuracy_23': 0.7132352941176471, 'accuracy_24': 0.7107843137254902, 'accuracy_25': 0.7107843137254902}


  1%|▊                                                                                          | 341/40080 [07:34<89:06:27,  8.07s/it]







  1%|▊                                                                                           | 360/40080 [07:47<8:12:17,  1.34it/s]







  1%|▊                                                                                           | 379/40080 [08:01<8:16:54,  1.33it/s]








  1%|▉                                                                                           | 401/40080 [08:18<8:11:34,  1.35it/s]







  1%|▉                                                                                           | 420/40080 [08:32<8:17:36,  1.33it/s]








  1%|█                                                                                           | 441/40080 [08:48<8:19:03,  1.32it/s]







  1%|█                                                                                           | 459/40080 [09:01<8:12:29,  1.34it/s]








  1%|█                                                                                           | 481/40080 [09:18<8:13:26,  1.34it/s]







  1%|█▏                                                                                          | 499/40080 [09:32<8:29:00,  1.30it/s]








  1%|█▏                                                                                          | 520/40080 [09:48<8:16:56,  1.33it/s]








  1%|█▏                                                                                          | 541/40080 [10:04<8:19:49,  1.32it/s]







  1%|█▎                                                                                          | 560/40080 [10:18<8:13:16,  1.34it/s]








  1%|█▎                                                                                          | 581/40080 [10:34<8:16:40,  1.33it/s]







  1%|█▍                                                                                          | 600/40080 [10:48<8:08:09,  1.35it/s]







  2%|█▍                                                                                          | 619/40080 [11:02<8:09:13,  1.34it/s]








  2%|█▍                                                                                          | 640/40080 [11:18<8:09:53,  1.34it/s]







  2%|█▌                                                                                          | 659/40080 [11:32<8:11:36,  1.34it/s]


  2%|█▌                                                                                          | 668/40080 [11:38<6:50:48,  1.60it/s][INFO|trainer.py:3614] 2024-12-06 11:57:37,141 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 11:57:37,141 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 11:57:37,142 >>   Batch size = 8






100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:12<00:00,  3.87it/s]
Computing accuracy for k=10: 0.75
Computing accuracy for k=11: 0.75
Computing accuracy for k=12: 0.7573529411764706
Computing accuracy for k=13: 0.7524509803921569
Computing accuracy for k=14: 0.7524509803921569
Computing accuracy for k=15: 0.7549019607843137
Computing accuracy for k=16: 0.7573529411764706
Computing accuracy for k=17: 0.7573529411764706
Computing accuracy for k=18: 0.7598039215686274
Computing accuracy for k=19: 0.7524509803921569
Computing accuracy for k=20: 0.7573529411764706
Computing accuracy for k=21: 0.7622549019607843
Computing accuracy for k=22: 0.7720588235294118
Computing accuracy for k=23: 0.7696078431372549
Computing accuracy for k=24: 0.7671568627450981






  2%|█▌                                                                                         | 681/40080 [15:27<18:15:37,  1.67s/it]
{'accuracy': 0.7696078431372549, 'f1': 0.8443708609271523, 'combined_score': 0.8069893520322036, 'accuracy_10': 0.75, 'accuracy_11': 0.75, 'accuracy_12': 0.7573529411764706, 'accuracy_13': 0.7524509803921569, 'accuracy_14': 0.7524509803921569, 'accuracy_15': 0.7549019607843137, 'accuracy_16': 0.7573529411764706, 'accuracy_17': 0.7573529411764706, 'accuracy_18': 0.7598039215686274, 'accuracy_19': 0.7524509803921569, 'accuracy_20': 0.7573529411764706, 'accuracy_21': 0.7622549019607843, 'accuracy_22': 0.7720588235294118, 'accuracy_23': 0.7696078431372549, 'accuracy_24': 0.7671568627450981, 'accuracy_25': 0.7696078431372549}
{'eval_loss': 0.5471738576889038, 'eval_accuracy': 0.7696078431372549, 'eval_f1': 0.8443708609271523, 'eval_combined_score': 0.8069893520322036, 'eval_accuracy_10': 0.75, 'eval_accuracy_11': 0.75, 'eval_accuracy_12': 0.7573529411764706, 'eval_accuracy_13': 0.7524509803921569, 'eval_accuracy_14': 0.7524509803921569, 'eval_accuracy_15': 0.7549019607843137, 'eval_accuracy_16': 0.7573529411764706, 'eval_accuracy_17': 0.7573529411764706, 'eval_accuracy_18': 0.7598039215686274, 'eval_accuracy_19': 0.7524509803921569, 'eval_accuracy_20': 0.7573529411764706, 'eval_accuracy_21': 0.7622549019607843, 'eval_accuracy_22': 0.7720588235294118, 'eval_accuracy_23': 0.7696078431372549, 'eval_accuracy_24': 0.7671568627450981, 'eval_accuracy_25': 0.7696078431372549, 'eval_runtime': 218.6263, 'eval_samples_per_second': 1.866, 'eval_steps_per_second': 0.233, 'epoch': 2.0}







  2%|█▌                                                                                          | 699/40080 [15:40<8:17:09,  1.32it/s]








  2%|█▋                                                                                          | 720/40080 [15:56<8:22:43,  1.30it/s]








  2%|█▋                                                                                          | 741/40080 [16:12<8:12:27,  1.33it/s]







  2%|█▋                                                                                          | 760/40080 [16:26<8:06:05,  1.35it/s]








  2%|█▊                                                                                          | 781/40080 [16:42<8:06:23,  1.35it/s]







  2%|█▊                                                                                          | 800/40080 [16:56<8:11:01,  1.33it/s]








  2%|█▉                                                                                          | 821/40080 [17:12<8:09:26,  1.34it/s]







  2%|█▉                                                                                          | 840/40080 [17:26<8:16:24,  1.32it/s]








  2%|█▉                                                                                          | 862/40080 [17:43<8:11:39,  1.33it/s]







  2%|██                                                                                          | 880/40080 [17:56<8:10:40,  1.33it/s]








  2%|██                                                                                          | 901/40080 [18:12<8:21:04,  1.30it/s]







  2%|██                                                                                          | 920/40080 [18:27<8:08:11,  1.34it/s]








  2%|██▏                                                                                         | 941/40080 [18:42<8:17:52,  1.31it/s]








  2%|██▏                                                                                         | 962/40080 [18:59<8:18:11,  1.31it/s]







  2%|██▏                                                                                         | 980/40080 [19:12<8:22:31,  1.30it/s]







  2%|██▎                                                                                        | 1002/40080 [19:29<6:54:49,  1.57it/s][INFO|trainer.py:3614] 2024-12-06 12:05:27,858 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 12:05:27,858 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 12:05:27,858 >>   Batch size = 8
{'loss': 0.5992, 'grad_norm': 3.7665536403656006, 'learning_rate': 9.750499001996009e-05, 'epoch': 2.99}






100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:12<00:00,  4.05it/s]
Computing accuracy for k=10: 0.7647058823529411
Computing accuracy for k=11: 0.7671568627450981
Computing accuracy for k=12: 0.7671568627450981
Computing accuracy for k=13: 0.7720588235294118
Computing accuracy for k=14: 0.7720588235294118
Computing accuracy for k=15: 0.7696078431372549
Computing accuracy for k=16: 0.7622549019607843
Computing accuracy for k=17: 0.7696078431372549
Computing accuracy for k=18: 0.7696078431372549
Computing accuracy for k=19: 0.7720588235294118
Computing accuracy for k=20: 0.7720588235294118
Computing accuracy for k=21: 0.7671568627450981
Computing accuracy for k=22: 0.7671568627450981
Computing accuracy for k=23: 0.7671568627450981
Computing accuracy for k=25: 0.7647058823529411

{'accuracy': 0.7622549019607843, 'f1': 0.8330464716006885, 'combined_score': 0.7976506867807364, 'accuracy_10': 0.7647058823529411, 'accuracy_11': 0.7671568627450981, 'accuracy_12': 0.7671568627450981, 'accuracy_13': 0.7720588235294118, 'accuracy_14': 0.7720588235294118, 'accuracy_15': 0.7696078431372549, 'accuracy_16': 0.7622549019607843, 'accuracy_17': 0.7696078431372549, 'accuracy_18': 0.7696078431372549, 'accuracy_19': 0.7720588235294118, 'accuracy_20': 0.7720588235294118, 'accuracy_21': 0.7671568627450981, 'accuracy_22': 0.7671568627450981, 'accuracy_23': 0.7671568627450981, 'accuracy_24': 0.7647058823529411, 'accuracy_25': 0.7622549019607843}
{'accuracy': 0.7622549019607843, 'f1': 0.8330464716006885, 'combined_score': 0.7976506867807364, 'accuracy_10': 0.7647058823529411, 'accuracy_11': 0.7671568627450981, 'accuracy_12': 0.7671568627450981, 'accuracy_13': 0.7720588235294118, 'accuracy_14': 0.7720588235294118, 'accuracy_15': 0.7696078431372549, 'accuracy_16': 0.7622549019607843, 'accuracy_17': 0.7696078431372549, 'accuracy_18': 0.7696078431372549, 'accuracy_19': 0.7720588235294118, 'accuracy_20': 0.7720588235294118, 'accuracy_21': 0.7671568627450981, 'accuracy_22': 0.7671568627450981, 'accuracy_23': 0.7671568627450981, 'accuracy_24': 0.7647058823529411, 'accuracy_25': 0.7622549019607843}







  3%|██▎                                                                                        | 1021/40080 [23:21<9:30:27,  1.14it/s]







  3%|██▎                                                                                        | 1040/40080 [23:35<8:07:38,  1.33it/s]








  3%|██▍                                                                                        | 1061/40080 [23:51<8:20:18,  1.30it/s]








  3%|██▍                                                                                        | 1082/40080 [24:07<8:15:20,  1.31it/s]







  3%|██▍                                                                                        | 1100/40080 [24:21<8:08:07,  1.33it/s]








  3%|██▌                                                                                        | 1121/40080 [24:37<8:10:28,  1.32it/s]







  3%|██▌                                                                                        | 1140/40080 [24:51<8:03:54,  1.34it/s]








  3%|██▋                                                                                        | 1161/40080 [25:07<8:11:01,  1.32it/s]







  3%|██▋                                                                                        | 1180/40080 [25:21<8:06:12,  1.33it/s]








  3%|██▋                                                                                        | 1201/40080 [25:37<8:12:49,  1.31it/s]







  3%|██▊                                                                                        | 1219/40080 [25:51<8:08:33,  1.33it/s]







  3%|██▊                                                                                        | 1238/40080 [26:05<8:01:51,  1.34it/s]







  3%|██▊                                                                                        | 1257/40080 [26:19<8:05:46,  1.33it/s]








  3%|██▉                                                                                        | 1279/40080 [26:35<7:56:23,  1.36it/s]







  3%|██▉                                                                                        | 1298/40080 [26:49<8:02:25,  1.34it/s]








  3%|██▉                                                                                        | 1319/40080 [27:05<8:03:26,  1.34it/s]





  3%|███                                                                                        | 1336/40080 [27:17<6:40:47,  1.61it/s][INFO|trainer.py:3614] 2024-12-06 12:13:16,193 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 12:13:16,193 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 12:13:16,193 >>   Batch size = 8






 96%|██████████████████████████████████████████████████████████████████████████████████████████████▏   | 49/51 [00:11<00:00,  4.10it/s]

Computing accuracy for k=10: 0.7769607843137255
Computing accuracy for k=11: 0.7794117647058824
Computing accuracy for k=12: 0.7794117647058824
Computing accuracy for k=13: 0.7843137254901961
Computing accuracy for k=14: 0.7843137254901961
Computing accuracy for k=15: 0.7843137254901961
Computing accuracy for k=16: 0.7818627450980392
Computing accuracy for k=17: 0.7769607843137255
Computing accuracy for k=18: 0.7745098039215687
Computing accuracy for k=19: 0.7720588235294118
Computing accuracy for k=20: 0.7769607843137255
Computing accuracy for k=21: 0.7720588235294118
Computing accuracy for k=22: 0.7794117647058824
Computing accuracy for k=23: 0.7818627450980392
Computing accuracy for k=24: 0.7818627450980392
Computing accuracy for k=25: 0.7818627450980392
{'accuracy': 0.7794117647058824, 'f1': 0.8509933774834437, 'combined_score': 0.8152025710946631, 'accuracy_10': 0.7769607843137255, 'accuracy_11': 0.7794117647058824, 'accuracy_12': 0.7794117647058824, 'accuracy_13': 0.7843137254901961, 'accuracy_14': 0.7843137254901961, 'accuracy_15': 0.7843137254901961, 'accuracy_16': 0.7818627450980392, 'accuracy_17': 0.7769607843137255, 'accuracy_18': 0.7745098039215687, 'accuracy_19': 0.7720588235294118, 'accuracy_20': 0.7769607843137255, 'accuracy_21': 0.7720588235294118, 'accuracy_22': 0.7794117647058824, 'accuracy_23': 0.7818627450980392, 'accuracy_24': 0.7818627450980392, 'accuracy_25': 0.7818627450980392}


  3%|██▉                                                                                      | 1338/40080 [30:53<491:58:26, 45.72s/it]







  3%|███                                                                                        | 1357/40080 [31:07<8:29:49,  1.27it/s]








  3%|███▏                                                                                       | 1379/40080 [31:24<8:01:46,  1.34it/s]







  3%|███▏                                                                                       | 1397/40080 [31:37<7:57:30,  1.35it/s]







  4%|███▏                                                                                       | 1417/40080 [31:52<7:52:35,  1.36it/s]








  4%|███▎                                                                                       | 1438/40080 [32:07<7:56:43,  1.35it/s]







  4%|███▎                                                                                       | 1457/40080 [32:22<8:02:25,  1.33it/s]








  4%|███▎                                                                                       | 1478/40080 [32:37<7:58:37,  1.34it/s]







  4%|███▍                                                                                       | 1497/40080 [32:51<7:53:48,  1.36it/s]








  4%|███▍                                                                                       | 1519/40080 [33:07<7:50:49,  1.37it/s]







  4%|███▍                                                                                       | 1538/40080 [33:21<7:54:52,  1.35it/s]







  4%|███▌                                                                                       | 1557/40080 [33:35<7:53:57,  1.35it/s]








  4%|███▌                                                                                       | 1579/40080 [33:52<7:57:21,  1.34it/s]







  4%|███▋                                                                                       | 1598/40080 [34:06<8:07:34,  1.32it/s]








  4%|███▋                                                                                       | 1618/40080 [34:21<8:20:38,  1.28it/s]







  4%|███▋                                                                                       | 1637/40080 [34:36<8:07:30,  1.31it/s]








  4%|███▊                                                                                       | 1658/40080 [34:52<7:57:23,  1.34it/s]




  4%|███▊                                                                                       | 1670/40080 [35:00<6:49:01,  1.57it/s][INFO|trainer.py:3614] 2024-12-06 12:20:59,407 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 12:20:59,407 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 12:20:59,407 >>   Batch size = 8





 90%|████████████████████████████████████████████████████████████████████████████████████████▍         | 46/51 [00:11<00:01,  3.90it/s]

Computing accuracy for k=10: 0.7696078431372549
Computing accuracy for k=11: 0.7671568627450981
Computing accuracy for k=12: 0.7696078431372549
Computing accuracy for k=13: 0.7671568627450981
Computing accuracy for k=14: 0.7696078431372549
Computing accuracy for k=15: 0.7720588235294118
Computing accuracy for k=16: 0.7720588235294118
Computing accuracy for k=17: 0.7720588235294118

Computing accuracy for k=18: 0.7720588235294118
Computing accuracy for k=19: 0.7720588235294118
Computing accuracy for k=20: 0.7696078431372549
Computing accuracy for k=21: 0.7720588235294118
Computing accuracy for k=22: 0.7745098039215687
Computing accuracy for k=23: 0.7745098039215687
Computing accuracy for k=24: 0.7745098039215687
Computing accuracy for k=25: 0.7745098039215687
{'accuracy': 0.7745098039215687, 'f1': 0.8466666666666667, 'combined_score': 0.8105882352941176, 'accuracy_10': 0.7696078431372549, 'accuracy_11': 0.7671568627450981, 'accuracy_12': 0.7696078431372549, 'accuracy_13': 0.7671568627450981, 'accuracy_14': 0.7696078431372549, 'accuracy_15': 0.7720588235294118, 'accuracy_16': 0.7720588235294118, 'accuracy_17': 0.7720588235294118, 'accuracy_18': 0.7720588235294118, 'accuracy_19': 0.7720588235294118, 'accuracy_20': 0.7696078431372549, 'accuracy_21': 0.7720588235294118, 'accuracy_22': 0.7745098039215687, 'accuracy_23': 0.7745098039215687, 'accuracy_24': 0.7745098039215687, 'accuracy_25': 0.7745098039215687}




  4%|███▊                                                                                      | 1678/40080 [38:44<65:11:57,  6.11s/it]







  4%|███▊                                                                                       | 1697/40080 [38:58<8:06:40,  1.31it/s]








  4%|███▉                                                                                       | 1718/40080 [39:14<7:53:00,  1.35it/s]







  4%|███▉                                                                                       | 1737/40080 [39:28<7:58:09,  1.34it/s]








  4%|███▉                                                                                       | 1759/40080 [39:44<7:51:23,  1.35it/s]







  4%|████                                                                                       | 1777/40080 [39:58<8:11:05,  1.30it/s]








  4%|████                                                                                       | 1798/40080 [40:14<8:09:31,  1.30it/s]








  5%|████▏                                                                                      | 1819/40080 [40:30<7:54:59,  1.34it/s]







  5%|████▏                                                                                      | 1838/40080 [40:44<7:50:29,  1.35it/s]








  5%|████▏                                                                                      | 1859/40080 [41:00<8:05:06,  1.31it/s]







  5%|████▎                                                                                      | 1877/40080 [41:14<8:08:51,  1.30it/s]








  5%|████▎                                                                                      | 1899/40080 [41:31<7:58:54,  1.33it/s]







  5%|████▎                                                                                      | 1917/40080 [41:44<7:54:42,  1.34it/s]








  5%|████▍                                                                                      | 1939/40080 [42:00<7:59:23,  1.33it/s]







  5%|████▍                                                                                      | 1957/40080 [42:14<7:55:48,  1.34it/s]








  5%|████▍                                                                                      | 1979/40080 [42:31<7:56:03,  1.33it/s]







  5%|████▌                                                                                      | 1997/40080 [42:44<7:48:06,  1.36it/s]

  5%|████▌                                                                                      | 2000/40080 [42:46<7:47:40,  1.36it/s][INFO|trainer.py:3305] 2024-12-06 12:28:45,227 >> Saving model checkpoint to results_mrpc_25/roberta-large/mrpc/pretrained_LoRA_init_svd_rank_25_lr_0.0001_clsLR_0.0001_seed_0/2024-12-06T11:45:03-43/checkpoint-2000
[INFO|configuration_utils.py:726] 2024-12-06 12:28:45,834 >> loading configuration file config.json from cache at /home/mallahova/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json
[INFO|configuration_utils.py:789] 2024-12-06 12:28:45,835 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.40.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}
[INFO|tokenization_utils_base.py:2488] 2024-12-06 12:28:45,891 >> tokenizer config file saved in results_mrpc_25/roberta-large/mrpc/pretrained_LoRA_init_svd_rank_25_lr_0.0001_clsLR_0.0001_seed_0/2024-12-06T11:45:03-43/checkpoint-2000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2497] 2024-12-06 12:28:45,892 >> Special tokens file saved in results_mrpc_25/roberta-large/mrpc/pretrained_LoRA_init_svd_rank_25_lr_0.0001_clsLR_0.0001_seed_0/2024-12-06T11:45:03-43/checkpoint-2000/special_tokens_map.json
  5%|████▌                                                                                      | 2004/40080 [42:49<7:15:20,  1.46it/s][INFO|trainer.py:3614] 2024-12-06 12:28:48,457 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 12:28:48,458 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 12:28:48,458 >>   Batch size = 8





 88%|██████████████████████████████████████████████████████████████████████████████████████▍           | 45/51 [00:10<00:01,  3.90it/s]

Computing accuracy for k=10: 0.7769607843137255
Computing accuracy for k=11: 0.7843137254901961
Computing accuracy for k=12: 0.7818627450980392
Computing accuracy for k=13: 0.7843137254901961
Computing accuracy for k=14: 0.7794117647058824
Computing accuracy for k=15: 0.7818627450980392
Computing accuracy for k=16: 0.7843137254901961
Computing accuracy for k=17: 0.7769607843137255
Computing accuracy for k=18: 0.7696078431372549
Computing accuracy for k=19: 0.7745098039215687
Computing accuracy for k=20: 0.7794117647058824
Computing accuracy for k=21: 0.7794117647058824
Computing accuracy for k=22: 0.7794117647058824
Computing accuracy for k=23: 0.7769607843137255
Computing accuracy for k=24: 0.7818627450980392
Computing accuracy for k=25: 0.7794117647058824
{'accuracy': 0.7794117647058824, 'f1': 0.8474576271186441, 'combined_score': 0.8134346959122633, 'accuracy_10': 0.7769607843137255, 'accuracy_11': 0.7843137254901961, 'accuracy_12': 0.7818627450980392, 'accuracy_13': 0.7843137254901961, 'accuracy_14': 0.7794117647058824, 'accuracy_15': 0.7818627450980392, 'accuracy_16': 0.7843137254901961, 'accuracy_17': 0.7769607843137255, 'accuracy_18': 0.7696078431372549, 'accuracy_19': 0.7745098039215687, 'accuracy_20': 0.7794117647058824, 'accuracy_21': 0.7794117647058824, 'accuracy_22': 0.7794117647058824, 'accuracy_23': 0.7769607843137255, 'accuracy_24': 0.7818627450980392, 'accuracy_25': 0.7794117647058824}






  5%|████▌                                                                                     | 2018/40080 [46:32<14:14:54,  1.35s/it]







  5%|████▌                                                                                      | 2037/40080 [46:46<7:41:57,  1.37it/s]








  5%|████▋                                                                                      | 2059/40080 [47:02<7:47:09,  1.36it/s]







  5%|████▋                                                                                      | 2078/40080 [47:16<7:53:31,  1.34it/s]








  5%|████▊                                                                                      | 2099/40080 [47:32<7:55:20,  1.33it/s]







  5%|████▊                                                                                      | 2118/40080 [47:47<7:56:06,  1.33it/s]








  5%|████▊                                                                                      | 2139/40080 [48:03<8:03:33,  1.31it/s]







  5%|████▉                                                                                      | 2158/40080 [48:17<8:00:16,  1.32it/s]








  5%|████▉                                                                                      | 2179/40080 [48:33<7:56:22,  1.33it/s]







  5%|████▉                                                                                      | 2198/40080 [48:47<7:46:01,  1.35it/s]








  6%|█████                                                                                      | 2219/40080 [49:03<7:49:14,  1.34it/s]







  6%|█████                                                                                      | 2238/40080 [49:17<7:49:09,  1.34it/s]







  6%|█████                                                                                      | 2257/40080 [49:31<7:41:06,  1.37it/s]








  6%|█████▏                                                                                     | 2279/40080 [49:47<7:42:40,  1.36it/s]







  6%|█████▏                                                                                     | 2298/40080 [50:01<7:46:28,  1.35it/s]








  6%|█████▎                                                                                     | 2319/40080 [50:17<7:47:29,  1.35it/s]






  6%|█████▎                                                                                     | 2338/40080 [50:31<6:43:07,  1.56it/s][INFO|trainer.py:3614] 2024-12-06 12:36:29,671 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 12:36:29,671 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 12:36:29,671 >>   Batch size = 8






 98%|████████████████████████████████████████████████████████████████████████████████████████████████  | 50/51 [00:12<00:00,  4.06it/s]

Computing accuracy for k=10: 0.7818627450980392
Computing accuracy for k=11: 0.7941176470588235
Computing accuracy for k=12: 0.7941176470588235
Computing accuracy for k=13: 0.7916666666666666
Computing accuracy for k=14: 0.7892156862745098
Computing accuracy for k=15: 0.7892156862745098
Computing accuracy for k=16: 0.7867647058823529
Computing accuracy for k=17: 0.7892156862745098

Computing accuracy for k=18: 0.7892156862745098
Computing accuracy for k=19: 0.7867647058823529
Computing accuracy for k=20: 0.7892156862745098
Computing accuracy for k=21: 0.7916666666666666
Computing accuracy for k=22: 0.7892156862745098
Computing accuracy for k=23: 0.7892156862745098
Computing accuracy for k=24: 0.7916666666666666


Computing accuracy for k=25: 0.7892156862745098
{'accuracy': 0.7892156862745098, 'f1': 0.8599348534201955, 'combined_score': 0.8245752698473526, 'accuracy_10': 0.7818627450980392, 'accuracy_11': 0.7941176470588235, 'accuracy_12': 0.7941176470588235, 'accuracy_13': 0.7916666666666666, 'accuracy_14': 0.7892156862745098, 'accuracy_15': 0.7892156862745098, 'accuracy_16': 0.7867647058823529, 'accuracy_17': 0.7892156862745098, 'accuracy_18': 0.7892156862745098, 'accuracy_19': 0.7867647058823529, 'accuracy_20': 0.7892156862745098, 'accuracy_21': 0.7916666666666666, 'accuracy_22': 0.7892156862745098, 'accuracy_23': 0.7892156862745098, 'accuracy_24': 0.7916666666666666, 'accuracy_25': 0.7892156862745098}
{'eval_loss': 0.46331098675727844, 'eval_accuracy': 0.7892156862745098, 'eval_f1': 0.8599348534201955, 'eval_combined_score': 0.8245752698473526, 'eval_accuracy_10': 0.7818627450980392, 'eval_accuracy_11': 0.7941176470588235, 'eval_accuracy_12': 0.7941176470588235, 'eval_accuracy_13': 0.7916666666666666, 'eval_accuracy_14': 0.7892156862745098, 'eval_accuracy_15': 0.7892156862745098, 'eval_accuracy_16': 0.7867647058823529, 'eval_accuracy_17': 0.7892156862745098, 'eval_accuracy_18': 0.7892156862745098, 'eval_accuracy_19': 0.7867647058823529, 'eval_accuracy_20': 0.7892156862745098, 'eval_accuracy_21': 0.7916666666666666, 'eval_accuracy_22': 0.7892156862745098, 'eval_accuracy_23': 0.7892156862745098, 'eval_accuracy_24': 0.7916666666666666, 'eval_accuracy_25': 0.7892156862745098, 'eval_runtime': 216.7241, 'eval_samples_per_second': 1.883, 'eval_steps_per_second': 0.235, 'epoch': 7.0}








  6%|█████▎                                                                                     | 2359/40080 [54:23<8:32:13,  1.23it/s]








  6%|█████▍                                                                                     | 2380/40080 [54:39<8:02:44,  1.30it/s]







  6%|█████▍                                                                                     | 2398/40080 [54:53<7:57:43,  1.31it/s]








  6%|█████▍                                                                                     | 2419/40080 [55:09<7:48:09,  1.34it/s]







  6%|█████▌                                                                                     | 2438/40080 [55:23<7:45:53,  1.35it/s]








  6%|█████▌                                                                                     | 2459/40080 [55:39<8:04:31,  1.29it/s]







  6%|█████▌                                                                                     | 2477/40080 [55:53<7:59:21,  1.31it/s]








  6%|█████▋                                                                                     | 2499/40080 [56:09<7:46:32,  1.34it/s]







  6%|█████▋                                                                                     | 2518/40080 [56:23<7:43:36,  1.35it/s]








  6%|█████▊                                                                                     | 2539/40080 [56:39<7:42:20,  1.35it/s]







  6%|█████▊                                                                                     | 2558/40080 [56:53<7:38:59,  1.36it/s]







  6%|█████▊                                                                                     | 2577/40080 [57:07<7:51:03,  1.33it/s]








  6%|█████▉                                                                                     | 2599/40080 [57:23<7:47:24,  1.34it/s]







  7%|█████▉                                                                                     | 2618/40080 [57:38<7:39:52,  1.36it/s]








  7%|█████▉                                                                                     | 2639/40080 [57:53<7:39:34,  1.36it/s]







  7%|██████                                                                                     | 2658/40080 [58:07<7:43:40,  1.35it/s]




  7%|██████                                                                                     | 2672/40080 [58:17<6:29:40,  1.60it/s][INFO|trainer.py:3614] 2024-12-06 12:44:16,273 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 12:44:16,273 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 12:44:16,273 >>   Batch size = 8






 98%|████████████████████████████████████████████████████████████████████████████████████████████████  | 50/51 [00:11<00:00,  4.11it/s]

Computing accuracy for k=10: 0.7965686274509803
Computing accuracy for k=11: 0.7990196078431373
Computing accuracy for k=12: 0.7965686274509803
Computing accuracy for k=13: 0.7867647058823529
Computing accuracy for k=14: 0.7892156862745098
Computing accuracy for k=15: 0.7916666666666666
Computing accuracy for k=16: 0.7867647058823529
Computing accuracy for k=17: 0.7867647058823529
Computing accuracy for k=18: 0.7867647058823529
Computing accuracy for k=19: 0.7867647058823529
Computing accuracy for k=20: 0.7843137254901961
Computing accuracy for k=21: 0.7892156862745098
Computing accuracy for k=22: 0.7892156862745098
Computing accuracy for k=23: 0.7892156862745098
Computing accuracy for k=24: 0.7867647058823529
Computing accuracy for k=25: 0.7843137254901961
{'accuracy': 0.7843137254901961, 'f1': 0.8547854785478548, 'combined_score': 0.8195496020190254, 'accuracy_10': 0.7965686274509803, 'accuracy_11': 0.7990196078431373, 'accuracy_12': 0.7965686274509803, 'accuracy_13': 0.7867647058823529, 'accuracy_14': 0.7892156862745098, 'accuracy_15': 0.7916666666666666, 'accuracy_16': 0.7867647058823529, 'accuracy_17': 0.7867647058823529, 'accuracy_18': 0.7867647058823529, 'accuracy_19': 0.7867647058823529, 'accuracy_20': 0.7843137254901961, 'accuracy_21': 0.7892156862745098, 'accuracy_22': 0.7892156862745098, 'accuracy_23': 0.7892156862745098, 'accuracy_24': 0.7867647058823529, 'accuracy_25': 0.7843137254901961}



  7%|█████▉                                                                                  | 2679/40080 [1:01:56<85:54:02,  8.27s/it]







  7%|█████▉                                                                                   | 2698/40080 [1:02:10<7:43:47,  1.34it/s]








  7%|██████                                                                                   | 2719/40080 [1:02:26<7:45:27,  1.34it/s]







  7%|██████                                                                                   | 2738/40080 [1:02:40<7:34:14,  1.37it/s]







  7%|██████                                                                                   | 2757/40080 [1:02:53<7:39:02,  1.36it/s]








  7%|██████▏                                                                                  | 2779/40080 [1:03:10<7:37:59,  1.36it/s]







  7%|██████▏                                                                                  | 2798/40080 [1:03:24<7:33:50,  1.37it/s]







  7%|██████▎                                                                                  | 2817/40080 [1:03:37<7:28:06,  1.39it/s]








  7%|██████▎                                                                                  | 2839/40080 [1:03:54<7:35:32,  1.36it/s]







  7%|██████▎                                                                                  | 2859/40080 [1:04:08<7:29:13,  1.38it/s]







  7%|██████▍                                                                                  | 2878/40080 [1:04:22<7:34:11,  1.37it/s]








  7%|██████▍                                                                                  | 2899/40080 [1:04:38<7:34:53,  1.36it/s]







  7%|██████▍                                                                                  | 2918/40080 [1:04:51<7:31:11,  1.37it/s]







  7%|██████▌                                                                                  | 2937/40080 [1:05:05<7:33:01,  1.37it/s]








  7%|██████▌                                                                                  | 2959/40080 [1:05:22<7:35:01,  1.36it/s]







  7%|██████▌                                                                                  | 2978/40080 [1:05:35<7:30:31,  1.37it/s]







  7%|██████▋                                                                                  | 2997/40080 [1:05:49<7:35:18,  1.36it/s]


  8%|██████▋                                                                                  | 3006/40080 [1:05:56<6:19:35,  1.63it/s][INFO|trainer.py:3614] 2024-12-06 12:51:54,607 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 12:51:54,608 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 12:51:54,608 >>   Batch size = 8






 98%|████████████████████████████████████████████████████████████████████████████████████████████████  | 50/51 [00:12<00:00,  4.05it/s]

Computing accuracy for k=10: 0.8014705882352942
Computing accuracy for k=11: 0.8112745098039216
Computing accuracy for k=12: 0.8112745098039216
Computing accuracy for k=13: 0.8137254901960784
Computing accuracy for k=14: 0.8161764705882353
Computing accuracy for k=15: 0.8014705882352942
Computing accuracy for k=16: 0.7990196078431373
Computing accuracy for k=17: 0.7941176470588235
Computing accuracy for k=18: 0.7941176470588235
Computing accuracy for k=19: 0.7916666666666666
Computing accuracy for k=20: 0.7941176470588235
Computing accuracy for k=21: 0.7965686274509803
Computing accuracy for k=22: 0.7990196078431373
Computing accuracy for k=23: 0.8014705882352942
Computing accuracy for k=24: 0.7990196078431373
Computing accuracy for k=25: 0.8063725490196079
{'accuracy': 0.8063725490196079, 'f1': 0.8663282571912013, 'combined_score': 0.8363504031054045, 'accuracy_10': 0.8014705882352942, 'accuracy_11': 0.8112745098039216, 'accuracy_12': 0.8112745098039216, 'accuracy_13': 0.8137254901960784, 'accuracy_14': 0.8161764705882353, 'accuracy_15': 0.8014705882352942, 'accuracy_16': 0.7990196078431373, 'accuracy_17': 0.7941176470588235, 'accuracy_18': 0.7941176470588235, 'accuracy_19': 0.7916666666666666, 'accuracy_20': 0.7941176470588235, 'accuracy_21': 0.7965686274509803, 'accuracy_22': 0.7990196078431373, 'accuracy_23': 0.8014705882352942, 'accuracy_24': 0.7990196078431373, 'accuracy_25': 0.8063725490196079}





  8%|██████▋                                                                                 | 3018/40080 [1:09:36<20:21:45,  1.98s/it]







  8%|██████▋                                                                                  | 3037/40080 [1:09:50<7:29:21,  1.37it/s]








  8%|██████▊                                                                                  | 3059/40080 [1:10:06<7:33:21,  1.36it/s]







  8%|██████▊                                                                                  | 3078/40080 [1:10:20<7:29:46,  1.37it/s]







  8%|██████▉                                                                                  | 3097/40080 [1:10:34<7:30:07,  1.37it/s]








  8%|██████▉                                                                                  | 3119/40080 [1:10:50<7:31:45,  1.36it/s]







  8%|██████▉                                                                                  | 3138/40080 [1:11:04<7:31:08,  1.36it/s]







  8%|███████                                                                                  | 3157/40080 [1:11:18<7:28:19,  1.37it/s]








  8%|███████                                                                                  | 3179/40080 [1:11:34<7:34:40,  1.35it/s]







  8%|███████                                                                                  | 3198/40080 [1:11:48<7:28:16,  1.37it/s]







  8%|███████▏                                                                                 | 3217/40080 [1:12:02<7:34:56,  1.35it/s]








  8%|███████▏                                                                                 | 3239/40080 [1:12:18<7:32:41,  1.36it/s]







  8%|███████▏                                                                                 | 3258/40080 [1:12:32<7:35:24,  1.35it/s]







  8%|███████▎                                                                                 | 3277/40080 [1:12:46<7:33:54,  1.35it/s]








  8%|███████▎                                                                                 | 3299/40080 [1:13:02<7:32:24,  1.35it/s]







  8%|███████▎                                                                                 | 3318/40080 [1:13:16<7:31:26,  1.36it/s]







  8%|███████▍                                                                                 | 3337/40080 [1:13:30<7:28:32,  1.37it/s]
  8%|███████▍                                                                                 | 3340/40080 [1:13:32<6:25:45,  1.59it/s][INFO|trainer.py:3614] 2024-12-06 12:59:31,374 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 12:59:31,374 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 12:59:31,374 >>   Batch size = 8





 96%|██████████████████████████████████████████████████████████████████████████████████████████████▏   | 49/51 [00:11<00:00,  4.09it/s]

Computing accuracy for k=10: 0.7990196078431373
Computing accuracy for k=11: 0.803921568627451
Computing accuracy for k=12: 0.8014705882352942
Computing accuracy for k=13: 0.7965686274509803
Computing accuracy for k=14: 0.7965686274509803
Computing accuracy for k=15: 0.7892156862745098
Computing accuracy for k=16: 0.7867647058823529
Computing accuracy for k=17: 0.7892156862745098
Computing accuracy for k=18: 0.7941176470588235
Computing accuracy for k=19: 0.7941176470588235
Computing accuracy for k=20: 0.7916666666666666
Computing accuracy for k=21: 0.7965686274509803
Computing accuracy for k=22: 0.7965686274509803
Computing accuracy for k=23: 0.7990196078431373
Computing accuracy for k=24: 0.7941176470588235
Computing accuracy for k=25: 0.7990196078431373
{'accuracy': 0.7990196078431373, 'f1': 0.8642384105960265, 'combined_score': 0.8316290092195819, 'accuracy_10': 0.7990196078431373, 'accuracy_11': 0.803921568627451, 'accuracy_12': 0.8014705882352942, 'accuracy_13': 0.7965686274509803, 'accuracy_14': 0.7965686274509803, 'accuracy_15': 0.7892156862745098, 'accuracy_16': 0.7867647058823529, 'accuracy_17': 0.7892156862745098, 'accuracy_18': 0.7941176470588235, 'accuracy_19': 0.7941176470588235, 'accuracy_20': 0.7916666666666666, 'accuracy_21': 0.7965686274509803, 'accuracy_22': 0.7965686274509803, 'accuracy_23': 0.7990196078431373, 'accuracy_24': 0.7941176470588235, 'accuracy_25': 0.7990196078431373}








  8%|███████▍                                                                                 | 3359/40080 [1:17:26<9:05:11,  1.12it/s]








  8%|███████▌                                                                                 | 3379/40080 [1:17:42<8:01:41,  1.27it/s]











  8%|███████▍                                                                                | 3401/40080 [1:18:21<15:41:22,  1.54s/it]







  9%|███████▌                                                                                 | 3421/40080 [1:18:35<7:21:37,  1.38it/s]







  9%|███████▋                                                                                 | 3439/40080 [1:18:49<7:45:30,  1.31it/s]








  9%|███████▋                                                                                 | 3460/40080 [1:19:05<7:47:31,  1.31it/s]








  9%|███████▋                                                                                 | 3481/40080 [1:19:21<7:49:56,  1.30it/s]







  9%|███████▊                                                                                 | 3499/40080 [1:19:35<7:59:39,  1.27it/s]








  9%|███████▊                                                                                 | 3520/40080 [1:19:51<7:47:26,  1.30it/s]








  9%|███████▊                                                                                 | 3541/40080 [1:20:07<7:46:53,  1.30it/s]







  9%|███████▉                                                                                 | 3559/40080 [1:20:21<7:51:36,  1.29it/s]








  9%|███████▉                                                                                 | 3580/40080 [1:20:37<7:48:29,  1.30it/s]








  9%|███████▉                                                                                 | 3601/40080 [1:20:54<7:40:44,  1.32it/s]







  9%|████████                                                                                 | 3619/40080 [1:21:07<7:48:07,  1.30it/s]








  9%|████████                                                                                 | 3640/40080 [1:21:23<7:41:11,  1.32it/s]








  9%|████████▏                                                                                | 3661/40080 [1:21:39<7:40:12,  1.32it/s]




  9%|████████▏                                                                                | 3674/40080 [1:21:49<6:36:31,  1.53it/s][INFO|trainer.py:3614] 2024-12-06 13:07:48,114 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 13:07:48,115 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 13:07:48,115 >>   Batch size = 8







100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:13<00:00,  3.83it/s]
Computing accuracy for k=10: 0.8308823529411765
Computing accuracy for k=11: 0.8333333333333334
Computing accuracy for k=12: 0.8333333333333334
Computing accuracy for k=13: 0.8259803921568627
Computing accuracy for k=14: 0.8308823529411765
Computing accuracy for k=15: 0.8259803921568627
Computing accuracy for k=16: 0.8186274509803921
Computing accuracy for k=17: 0.8137254901960784
Computing accuracy for k=18: 0.821078431372549
Computing accuracy for k=19: 0.8259803921568627
Computing accuracy for k=20: 0.8186274509803921
Computing accuracy for k=21: 0.8161764705882353
Computing accuracy for k=22: 0.8259803921568627
Computing accuracy for k=23: 0.8259803921568627
Computing accuracy for k=24: 0.8259803921568627

Computing accuracy for k=25: 0.8333333333333334
{'accuracy': 0.8308823529411765, 'f1': 0.8791593695271455, 'combined_score': 0.855020861234161, 'accuracy_10': 0.8308823529411765, 'accuracy_11': 0.8333333333333334, 'accuracy_12': 0.8333333333333334, 'accuracy_13': 0.8259803921568627, 'accuracy_14': 0.8308823529411765, 'accuracy_15': 0.8259803921568627, 'accuracy_16': 0.8186274509803921, 'accuracy_17': 0.8137254901960784, 'accuracy_18': 0.821078431372549, 'accuracy_19': 0.8259803921568627, 'accuracy_20': 0.8186274509803921, 'accuracy_21': 0.8161764705882353, 'accuracy_22': 0.8259803921568627, 'accuracy_23': 0.8259803921568627, 'accuracy_24': 0.8259803921568627, 'accuracy_25': 0.8333333333333334}


  9%|███████▉                                                                               | 3680/40080 [1:25:36<120:49:23, 11.95s/it]








  9%|████████▏                                                                                | 3701/40080 [1:25:52<7:40:30,  1.32it/s]







  9%|████████▎                                                                                | 3719/40080 [1:26:06<7:44:05,  1.31it/s]








  9%|████████▎                                                                                | 3740/40080 [1:26:21<7:36:21,  1.33it/s]







  9%|████████▎                                                                                | 3759/40080 [1:26:36<7:35:08,  1.33it/s]








  9%|████████▍                                                                                | 3780/40080 [1:26:52<7:47:07,  1.30it/s]








  9%|████████▍                                                                                | 3801/40080 [1:27:08<7:56:09,  1.27it/s]








 10%|████████▍                                                                                | 3821/40080 [1:27:24<7:48:41,  1.29it/s]








 10%|████████▌                                                                                | 3841/40080 [1:27:40<7:46:25,  1.29it/s]







 10%|████████▌                                                                                | 3860/40080 [1:27:54<7:44:16,  1.30it/s]








 10%|████████▌                                                                                | 3881/40080 [1:28:10<7:41:38,  1.31it/s]








 10%|████████▋                                                                                | 3901/40080 [1:28:26<7:45:17,  1.30it/s]







 10%|████████▋                                                                                | 3920/40080 [1:28:40<7:46:16,  1.29it/s]








 10%|████████▋                                                                                | 3940/40080 [1:28:56<7:43:45,  1.30it/s]








 10%|████████▊                                                                                | 3961/40080 [1:29:12<7:48:25,  1.29it/s]








 10%|████████▊                                                                                | 3982/40080 [1:29:28<7:45:23,  1.29it/s]







 10%|████████▉                                                                                | 4000/40080 [1:29:42<7:32:01,  1.33it/s][INFO|trainer.py:3305] 2024-12-06 13:15:41,069 >> Saving model checkpoint to results_mrpc_25/roberta-large/mrpc/pretrained_LoRA_init_svd_rank_25_lr_0.0001_clsLR_0.0001_seed_0/2024-12-06T11:45:03-43/checkpoint-4000
{'loss': 0.4407, 'grad_norm': 2.167894124984741, 'learning_rate': 9.001996007984033e-05, 'epoch': 11.98}
[INFO|configuration_utils.py:726] 2024-12-06 13:15:41,638 >> loading configuration file config.json from cache at /home/mallahova/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json
[INFO|configuration_utils.py:789] 2024-12-06 13:15:41,640 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.40.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}
[INFO|tokenization_utils_base.py:2488] 2024-12-06 13:15:41,694 >> tokenizer config file saved in results_mrpc_25/roberta-large/mrpc/pretrained_LoRA_init_svd_rank_25_lr_0.0001_clsLR_0.0001_seed_0/2024-12-06T11:45:03-43/checkpoint-4000/tokenizer_config.json
[INFO|tokenization_utils_base.py:2497] 2024-12-06 13:15:41,694 >> Special tokens file saved in results_mrpc_25/roberta-large/mrpc/pretrained_LoRA_init_svd_rank_25_lr_0.0001_clsLR_0.0001_seed_0/2024-12-06T11:45:03-43/checkpoint-4000/special_tokens_map.json

 10%|████████▉                                                                                | 4008/40080 [1:29:48<6:30:50,  1.54it/s][INFO|trainer.py:3614] 2024-12-06 13:15:47,369 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-12-06 13:15:47,370 >>   Num examples = 408
[INFO|trainer.py:3619] 2024-12-06 13:15:47,370 >>   Batch size = 8






100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:12<00:00,  3.90it/s]
Computing accuracy for k=10: 0.8063725490196079
Computing accuracy for k=11: 0.8137254901960784
Computing accuracy for k=12: 0.803921568627451
Computing accuracy for k=13: 0.8112745098039216
Computing accuracy for k=14: 0.8088235294117647
Computing accuracy for k=15: 0.8088235294117647
Computing accuracy for k=16: 0.8088235294117647
Computing accuracy for k=17: 0.8063725490196079
Computing accuracy for k=18: 0.8112745098039216
Computing accuracy for k=19: 0.8088235294117647
Computing accuracy for k=20: 0.8161764705882353
Computing accuracy for k=21: 0.8186274509803921
Computing accuracy for k=22: 0.8186274509803921
Computing accuracy for k=23: 0.8137254901960784
Computing accuracy for k=24: 0.821078431372549

Computing accuracy for k=25: 0.821078431372549
{'accuracy': 0.821078431372549, 'f1': 0.8781302170283807, 'combined_score': 0.8496043242004648, 'accuracy_10': 0.8063725490196079, 'accuracy_11': 0.8137254901960784, 'accuracy_12': 0.803921568627451, 'accuracy_13': 0.8112745098039216, 'accuracy_14': 0.8088235294117647, 'accuracy_15': 0.8088235294117647, 'accuracy_16': 0.8088235294117647, 'accuracy_17': 0.8063725490196079, 'accuracy_18': 0.8112745098039216, 'accuracy_19': 0.8088235294117647, 'accuracy_20': 0.8161764705882353, 'accuracy_21': 0.8186274509803921, 'accuracy_22': 0.8186274509803921, 'accuracy_23': 0.8137254901960784, 'accuracy_24': 0.821078431372549, 'accuracy_25': 0.821078431372549}




 10%|████████▊                                                                               | 4020/40080 [1:33:39<20:53:24,  2.09s/it]








 10%|████████▉                                                                                | 4041/40080 [1:33:54<7:31:58,  1.33it/s]







 10%|█████████                                                                                | 4060/40080 [1:34:09<7:33:44,  1.32it/s]








 10%|█████████                                                                                | 4081/40080 [1:34:25<7:31:59,  1.33it/s]







 10%|█████████                                                                                | 4099/40080 [1:34:38<7:31:55,  1.33it/s]








 10%|█████████▏                                                                               | 4121/40080 [1:34:55<7:28:04,  1.34it/s]








 10%|█████████▏                                                                               | 4141/40080 [1:35:10<7:54:24,  1.26it/s]











 10%|█████████▏                                                                              | 4158/40080 [1:35:37<12:19:46,  1.24s/it]








 10%|█████████▎                                                                               | 4179/40080 [1:35:53<7:28:28,  1.33it/s]







 10%|█████████▎                                                                               | 4198/40080 [1:36:07<7:18:48,  1.36it/s]







 11%|█████████▎                                                                               | 4217/40080 [1:36:21<7:24:59,  1.34it/s]








 11%|█████████▍                                                                               | 4238/40080 [1:36:36<7:25:34,  1.34it/s]








 11%|█████████▍                                                                               | 4259/40080 [1:36:52<7:41:33,  1.29it/s]










 11%|█████████▌                                                                               | 4279/40080 [1:37:13<9:28:53,  1.05it/s]


