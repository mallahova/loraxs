{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 3060,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 4.779833793640137,
      "learning_rate": 0.000596078431372549,
      "loss": 0.0906,
      "step": 20
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 0.0008020166424103081,
      "learning_rate": 0.0005921568627450981,
      "loss": 0.0846,
      "step": 40
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.00015379344404209405,
      "learning_rate": 0.000588235294117647,
      "loss": 0.1366,
      "step": 60
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 0.02560286782681942,
      "learning_rate": 0.0005843137254901961,
      "loss": 0.136,
      "step": 80
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 0.07226923108100891,
      "learning_rate": 0.000580392156862745,
      "loss": 0.0969,
      "step": 100
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 1.9816572666168213,
      "learning_rate": 0.0005764705882352941,
      "loss": 0.0379,
      "step": 120
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 0.04668699577450752,
      "learning_rate": 0.0005725490196078431,
      "loss": 0.0476,
      "step": 140
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 0.0017042717663571239,
      "learning_rate": 0.0005686274509803921,
      "loss": 0.0545,
      "step": 160
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 1.3857741355895996,
      "learning_rate": 0.0005647058823529411,
      "loss": 0.0707,
      "step": 180
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 0.4732770621776581,
      "learning_rate": 0.0005607843137254902,
      "loss": 0.0927,
      "step": 200
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 0.2657531201839447,
      "learning_rate": 0.0005568627450980392,
      "loss": 0.0594,
      "step": 220
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 0.00024617151939310133,
      "learning_rate": 0.0005529411764705882,
      "loss": 0.1005,
      "step": 240
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 0.007472196593880653,
      "learning_rate": 0.0005490196078431371,
      "loss": 0.0092,
      "step": 260
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 5.3470477723749354e-05,
      "learning_rate": 0.0005450980392156862,
      "loss": 0.0793,
      "step": 280
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 5.377971172332764,
      "learning_rate": 0.0005411764705882352,
      "loss": 0.1651,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8676470588235294,
      "eval_combined_score": 0.8877484440875327,
      "eval_f1": 0.9078498293515359,
      "eval_loss": 1.0764439105987549,
      "eval_runtime": 13.2564,
      "eval_samples_per_second": 30.777,
      "eval_steps_per_second": 3.847,
      "step": 306
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 12.915597915649414,
      "learning_rate": 0.0005372549019607843,
      "loss": 0.1185,
      "step": 320
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.2929735481739044,
      "learning_rate": 0.0005333333333333333,
      "loss": 0.1036,
      "step": 340
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.018341640010476112,
      "learning_rate": 0.0005294117647058823,
      "loss": 0.0843,
      "step": 360
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 0.0001642366114538163,
      "learning_rate": 0.0005254901960784314,
      "loss": 0.005,
      "step": 380
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 0.5134514570236206,
      "learning_rate": 0.0005215686274509803,
      "loss": 0.0725,
      "step": 400
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 0.07273823767900467,
      "learning_rate": 0.0005176470588235294,
      "loss": 0.0619,
      "step": 420
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.0740455836057663,
      "learning_rate": 0.0005137254901960783,
      "loss": 0.0559,
      "step": 440
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 6.797605514526367,
      "learning_rate": 0.0005098039215686274,
      "loss": 0.1309,
      "step": 460
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 42.467445373535156,
      "learning_rate": 0.0005058823529411764,
      "loss": 0.067,
      "step": 480
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 0.00028381191077642143,
      "learning_rate": 0.0005019607843137255,
      "loss": 0.0175,
      "step": 500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 11.260405540466309,
      "learning_rate": 0.0004980392156862745,
      "loss": 0.0759,
      "step": 520
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.005949355661869049,
      "learning_rate": 0.0004941176470588235,
      "loss": 0.108,
      "step": 540
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 9.773799896240234,
      "learning_rate": 0.0004901960784313725,
      "loss": 0.113,
      "step": 560
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 0.06661909073591232,
      "learning_rate": 0.00048627450980392154,
      "loss": 0.0604,
      "step": 580
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 12.088007926940918,
      "learning_rate": 0.00048235294117647055,
      "loss": 0.1216,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9068627450980392,
      "eval_combined_score": 0.9193811933375501,
      "eval_f1": 0.931899641577061,
      "eval_loss": 0.6603978276252747,
      "eval_runtime": 13.3177,
      "eval_samples_per_second": 30.636,
      "eval_steps_per_second": 3.829,
      "step": 612
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 0.0008731276029720902,
      "learning_rate": 0.0004784313725490196,
      "loss": 0.0359,
      "step": 620
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 12.027984619140625,
      "learning_rate": 0.00047450980392156855,
      "loss": 0.0669,
      "step": 640
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 2.6862173080444336,
      "learning_rate": 0.0004705882352941176,
      "loss": 0.0259,
      "step": 660
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.028260398656129837,
      "learning_rate": 0.0004666666666666666,
      "loss": 0.0602,
      "step": 680
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 1.4619909524917603,
      "learning_rate": 0.00046274509803921566,
      "loss": 0.1406,
      "step": 700
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.0002309723786311224,
      "learning_rate": 0.0004588235294117646,
      "loss": 0.0072,
      "step": 720
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 13.833651542663574,
      "learning_rate": 0.00045490196078431367,
      "loss": 0.0614,
      "step": 740
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 0.0037748022004961967,
      "learning_rate": 0.0004509803921568627,
      "loss": 0.0357,
      "step": 760
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.9518294334411621,
      "learning_rate": 0.0004470588235294117,
      "loss": 0.0546,
      "step": 780
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 5.960460662841797,
      "learning_rate": 0.0004431372549019608,
      "loss": 0.1523,
      "step": 800
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.06233345344662666,
      "learning_rate": 0.00043921568627450973,
      "loss": 0.0254,
      "step": 820
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 1.7753117084503174,
      "learning_rate": 0.0004352941176470588,
      "loss": 0.0785,
      "step": 840
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 0.195906862616539,
      "learning_rate": 0.0004313725490196078,
      "loss": 0.0536,
      "step": 860
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 13.32868766784668,
      "learning_rate": 0.00042745098039215684,
      "loss": 0.1229,
      "step": 880
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 5.595110893249512,
      "learning_rate": 0.0004235294117647059,
      "loss": 0.0644,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9055859254696643,
      "eval_f1": 0.9214659685863874,
      "eval_loss": 0.9140712022781372,
      "eval_runtime": 13.3384,
      "eval_samples_per_second": 30.588,
      "eval_steps_per_second": 3.824,
      "step": 918
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 0.003733826568350196,
      "learning_rate": 0.00041960784313725485,
      "loss": 0.0378,
      "step": 920
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 0.010413588024675846,
      "learning_rate": 0.00041568627450980385,
      "loss": 0.1041,
      "step": 940
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 0.0026672128587961197,
      "learning_rate": 0.0004117647058823529,
      "loss": 0.0213,
      "step": 960
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 0.1376163810491562,
      "learning_rate": 0.00040784313725490196,
      "loss": 0.06,
      "step": 980
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 8.91495132446289,
      "learning_rate": 0.00040392156862745096,
      "loss": 0.0149,
      "step": 1000
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 10.212037086486816,
      "learning_rate": 0.00039999999999999996,
      "loss": 0.02,
      "step": 1020
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 3.32321687892545e-05,
      "learning_rate": 0.00039607843137254897,
      "loss": 0.0039,
      "step": 1040
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 0.001248713000677526,
      "learning_rate": 0.000392156862745098,
      "loss": 0.0542,
      "step": 1060
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 0.04381125047802925,
      "learning_rate": 0.000388235294117647,
      "loss": 0.0438,
      "step": 1080
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 0.004662211053073406,
      "learning_rate": 0.000384313725490196,
      "loss": 0.0576,
      "step": 1100
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 0.0016782233724370599,
      "learning_rate": 0.00038039215686274503,
      "loss": 0.0186,
      "step": 1120
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 0.002317334059625864,
      "learning_rate": 0.0003764705882352941,
      "loss": 0.1214,
      "step": 1140
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 0.006767991464585066,
      "learning_rate": 0.0003725490196078431,
      "loss": 0.003,
      "step": 1160
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 0.435232549905777,
      "learning_rate": 0.00036862745098039214,
      "loss": 0.0299,
      "step": 1180
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 0.0009130659163929522,
      "learning_rate": 0.0003647058823529411,
      "loss": 0.083,
      "step": 1200
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 0.11168546229600906,
      "learning_rate": 0.00036078431372549015,
      "loss": 0.0917,
      "step": 1220
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9031344932339133,
      "eval_f1": 0.9190140845070423,
      "eval_loss": 0.6772629022598267,
      "eval_runtime": 13.306,
      "eval_samples_per_second": 30.663,
      "eval_steps_per_second": 3.833,
      "step": 1224
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 2.8922150135040283,
      "learning_rate": 0.0003568627450980392,
      "loss": 0.0209,
      "step": 1240
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.016388431191444397,
      "learning_rate": 0.0003529411764705882,
      "loss": 0.033,
      "step": 1260
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 16.68511199951172,
      "learning_rate": 0.00034901960784313726,
      "loss": 0.0344,
      "step": 1280
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 0.000325821980368346,
      "learning_rate": 0.0003450980392156862,
      "loss": 0.0692,
      "step": 1300
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 0.00023575808154419065,
      "learning_rate": 0.00034117647058823526,
      "loss": 0.0365,
      "step": 1320
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 0.01703101024031639,
      "learning_rate": 0.00033725490196078427,
      "loss": 0.0477,
      "step": 1340
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 0.2698762118816376,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.0569,
      "step": 1360
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 0.01517085637897253,
      "learning_rate": 0.0003294117647058824,
      "loss": 0.0322,
      "step": 1380
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 0.003515237011015415,
      "learning_rate": 0.0003254901960784313,
      "loss": 0.0289,
      "step": 1400
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 0.0014077036175876856,
      "learning_rate": 0.00032156862745098033,
      "loss": 0.0719,
      "step": 1420
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.3564579486846924,
      "learning_rate": 0.0003176470588235294,
      "loss": 0.0102,
      "step": 1440
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 0.00031479974859394133,
      "learning_rate": 0.00031372549019607844,
      "loss": 0.0165,
      "step": 1460
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 0.00018577056471258402,
      "learning_rate": 0.00030980392156862744,
      "loss": 0.072,
      "step": 1480
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 0.02731364592909813,
      "learning_rate": 0.00030588235294117644,
      "loss": 0.0782,
      "step": 1500
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 0.008837440051138401,
      "learning_rate": 0.00030196078431372545,
      "loss": 0.0336,
      "step": 1520
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.875,
      "eval_combined_score": 0.8933058925476604,
      "eval_f1": 0.9116117850953207,
      "eval_loss": 0.925862193107605,
      "eval_runtime": 13.3287,
      "eval_samples_per_second": 30.611,
      "eval_steps_per_second": 3.826,
      "step": 1530
    },
    {
      "epoch": 5.032679738562091,
      "grad_norm": 0.018878985196352005,
      "learning_rate": 0.0002980392156862745,
      "loss": 0.0327,
      "step": 1540
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 0.007801805157214403,
      "learning_rate": 0.0002941176470588235,
      "loss": 0.0913,
      "step": 1560
    },
    {
      "epoch": 5.163398692810458,
      "grad_norm": 0.02401873655617237,
      "learning_rate": 0.0002901960784313725,
      "loss": 0.0484,
      "step": 1580
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 0.006909809075295925,
      "learning_rate": 0.00028627450980392156,
      "loss": 0.0308,
      "step": 1600
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 0.013606629334390163,
      "learning_rate": 0.00028235294117647056,
      "loss": 0.0235,
      "step": 1620
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 0.08996216952800751,
      "learning_rate": 0.0002784313725490196,
      "loss": 0.0337,
      "step": 1640
    },
    {
      "epoch": 5.42483660130719,
      "grad_norm": 0.0008616126142442226,
      "learning_rate": 0.00027450980392156857,
      "loss": 0.001,
      "step": 1660
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 0.0007554169278591871,
      "learning_rate": 0.0002705882352941176,
      "loss": 0.0001,
      "step": 1680
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 0.0013906901003792882,
      "learning_rate": 0.0002666666666666666,
      "loss": 0.0003,
      "step": 1700
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 0.0005546808824874461,
      "learning_rate": 0.0002627450980392157,
      "loss": 0.021,
      "step": 1720
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 8.760089874267578,
      "learning_rate": 0.0002588235294117647,
      "loss": 0.0195,
      "step": 1740
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 0.8581616282463074,
      "learning_rate": 0.0002549019607843137,
      "loss": 0.0776,
      "step": 1760
    },
    {
      "epoch": 5.816993464052287,
      "grad_norm": 0.0014914346393197775,
      "learning_rate": 0.00025098039215686274,
      "loss": 0.0568,
      "step": 1780
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.001899117138236761,
      "learning_rate": 0.00024705882352941174,
      "loss": 0.0213,
      "step": 1800
    },
    {
      "epoch": 5.947712418300654,
      "grad_norm": 0.01615731790661812,
      "learning_rate": 0.00024313725490196077,
      "loss": 0.0437,
      "step": 1820
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8725490196078431,
      "eval_combined_score": 0.8909783425565347,
      "eval_f1": 0.9094076655052264,
      "eval_loss": 0.8065774440765381,
      "eval_runtime": 13.3056,
      "eval_samples_per_second": 30.664,
      "eval_steps_per_second": 3.833,
      "step": 1836
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 0.012165136635303497,
      "learning_rate": 0.0002392156862745098,
      "loss": 0.0251,
      "step": 1840
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 0.01905904710292816,
      "learning_rate": 0.0002352941176470588,
      "loss": 0.0245,
      "step": 1860
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 0.0005510703194886446,
      "learning_rate": 0.00023137254901960783,
      "loss": 0.0072,
      "step": 1880
    },
    {
      "epoch": 6.209150326797386,
      "grad_norm": 0.0004409161047078669,
      "learning_rate": 0.00022745098039215683,
      "loss": 0.0293,
      "step": 1900
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 9.75548267364502,
      "learning_rate": 0.00022352941176470586,
      "loss": 0.0066,
      "step": 1920
    },
    {
      "epoch": 6.339869281045751,
      "grad_norm": 0.13381071388721466,
      "learning_rate": 0.00021960784313725486,
      "loss": 0.0109,
      "step": 1940
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 0.3798103630542755,
      "learning_rate": 0.0002156862745098039,
      "loss": 0.0004,
      "step": 1960
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 0.0019046696834266186,
      "learning_rate": 0.00021176470588235295,
      "loss": 0.0618,
      "step": 1980
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 0.0011541486019268632,
      "learning_rate": 0.00020784313725490192,
      "loss": 0.001,
      "step": 2000
    },
    {
      "epoch": 6.601307189542483,
      "grad_norm": 0.00028008598019368947,
      "learning_rate": 0.00020392156862745098,
      "loss": 0.0607,
      "step": 2020
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.0002776129695121199,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.0116,
      "step": 2040
    },
    {
      "epoch": 6.73202614379085,
      "grad_norm": 0.0006656977348029613,
      "learning_rate": 0.000196078431372549,
      "loss": 0.1031,
      "step": 2060
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 0.11223404109477997,
      "learning_rate": 0.000192156862745098,
      "loss": 0.0024,
      "step": 2080
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 0.026309076696634293,
      "learning_rate": 0.00018823529411764704,
      "loss": 0.0252,
      "step": 2100
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 0.018956582993268967,
      "learning_rate": 0.00018431372549019607,
      "loss": 0.0169,
      "step": 2120
    },
    {
      "epoch": 6.993464052287582,
      "grad_norm": 0.003955329768359661,
      "learning_rate": 0.00018039215686274507,
      "loss": 0.005,
      "step": 2140
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.907346037006352,
      "eval_f1": 0.9225352112676057,
      "eval_loss": 0.9084118604660034,
      "eval_runtime": 13.3084,
      "eval_samples_per_second": 30.657,
      "eval_steps_per_second": 3.832,
      "step": 2142
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.0004890212439931929,
      "learning_rate": 0.0001764705882352941,
      "loss": 0.0234,
      "step": 2160
    },
    {
      "epoch": 7.124183006535947,
      "grad_norm": 1.4786490201950073,
      "learning_rate": 0.0001725490196078431,
      "loss": 0.0928,
      "step": 2180
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 0.0030078748241066933,
      "learning_rate": 0.00016862745098039213,
      "loss": 0.0002,
      "step": 2200
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 0.00361959682777524,
      "learning_rate": 0.0001647058823529412,
      "loss": 0.0357,
      "step": 2220
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 0.023636629804968834,
      "learning_rate": 0.00016078431372549016,
      "loss": 0.0692,
      "step": 2240
    },
    {
      "epoch": 7.38562091503268,
      "grad_norm": 0.35432660579681396,
      "learning_rate": 0.00015686274509803922,
      "loss": 0.001,
      "step": 2260
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 0.08523187786340714,
      "learning_rate": 0.00015294117647058822,
      "loss": 0.0186,
      "step": 2280
    },
    {
      "epoch": 7.516339869281046,
      "grad_norm": 0.08555536717176437,
      "learning_rate": 0.00014901960784313725,
      "loss": 0.0134,
      "step": 2300
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 0.0011439138324931264,
      "learning_rate": 0.00014509803921568625,
      "loss": 0.0006,
      "step": 2320
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 0.016272183507680893,
      "learning_rate": 0.00014117647058823528,
      "loss": 0.0306,
      "step": 2340
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 0.00096245261374861,
      "learning_rate": 0.00013725490196078428,
      "loss": 0.0011,
      "step": 2360
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 0.0032598325051367283,
      "learning_rate": 0.0001333333333333333,
      "loss": 0.0446,
      "step": 2380
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 10.475591659545898,
      "learning_rate": 0.00012941176470588234,
      "loss": 0.042,
      "step": 2400
    },
    {
      "epoch": 7.908496732026144,
      "grad_norm": 0.004957235883921385,
      "learning_rate": 0.00012549019607843137,
      "loss": 0.0332,
      "step": 2420
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 0.004855630453675985,
      "learning_rate": 0.00012156862745098039,
      "loss": 0.0073,
      "step": 2440
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8951714832274373,
      "eval_f1": 0.9128919860627178,
      "eval_loss": 0.8323652744293213,
      "eval_runtime": 13.2353,
      "eval_samples_per_second": 30.827,
      "eval_steps_per_second": 3.853,
      "step": 2448
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 7.251827239990234,
      "learning_rate": 0.0001176470588235294,
      "loss": 0.0465,
      "step": 2460
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 0.5721966624259949,
      "learning_rate": 0.00011372549019607842,
      "loss": 0.0234,
      "step": 2480
    },
    {
      "epoch": 8.169934640522875,
      "grad_norm": 0.06827948987483978,
      "learning_rate": 0.00010980392156862743,
      "loss": 0.0221,
      "step": 2500
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 0.0020857041236013174,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.0232,
      "step": 2520
    },
    {
      "epoch": 8.300653594771243,
      "grad_norm": 0.0017943325219675899,
      "learning_rate": 0.00010196078431372549,
      "loss": 0.0263,
      "step": 2540
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 0.001687080948613584,
      "learning_rate": 9.80392156862745e-05,
      "loss": 0.0006,
      "step": 2560
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.9110609889030457,
      "learning_rate": 9.411764705882352e-05,
      "loss": 0.0427,
      "step": 2580
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 0.00734037347137928,
      "learning_rate": 9.019607843137254e-05,
      "loss": 0.0228,
      "step": 2600
    },
    {
      "epoch": 8.562091503267974,
      "grad_norm": 0.0015816999366506934,
      "learning_rate": 8.627450980392155e-05,
      "loss": 0.0007,
      "step": 2620
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 0.026757599785923958,
      "learning_rate": 8.23529411764706e-05,
      "loss": 0.0536,
      "step": 2640
    },
    {
      "epoch": 8.69281045751634,
      "grad_norm": 0.005743276793509722,
      "learning_rate": 7.843137254901961e-05,
      "loss": 0.0019,
      "step": 2660
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 12.592613220214844,
      "learning_rate": 7.450980392156863e-05,
      "loss": 0.0418,
      "step": 2680
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 0.0022965900134295225,
      "learning_rate": 7.058823529411764e-05,
      "loss": 0.0345,
      "step": 2700
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 0.003425771137699485,
      "learning_rate": 6.666666666666666e-05,
      "loss": 0.0593,
      "step": 2720
    },
    {
      "epoch": 8.954248366013072,
      "grad_norm": 10.002388954162598,
      "learning_rate": 6.274509803921569e-05,
      "loss": 0.0058,
      "step": 2740
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9069325238992394,
      "eval_f1": 0.9217081850533807,
      "eval_loss": 0.7980672717094421,
      "eval_runtime": 12.4497,
      "eval_samples_per_second": 32.772,
      "eval_steps_per_second": 4.096,
      "step": 2754
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 18.976558685302734,
      "learning_rate": 5.88235294117647e-05,
      "loss": 0.0215,
      "step": 2760
    },
    {
      "epoch": 9.084967320261438,
      "grad_norm": 0.0020229588262736797,
      "learning_rate": 5.4901960784313716e-05,
      "loss": 0.0296,
      "step": 2780
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 0.31980159878730774,
      "learning_rate": 5.0980392156862745e-05,
      "loss": 0.0542,
      "step": 2800
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 0.0025815931148827076,
      "learning_rate": 4.705882352941176e-05,
      "loss": 0.0005,
      "step": 2820
    },
    {
      "epoch": 9.281045751633988,
      "grad_norm": 0.003865256439894438,
      "learning_rate": 4.3137254901960776e-05,
      "loss": 0.003,
      "step": 2840
    },
    {
      "epoch": 9.34640522875817,
      "grad_norm": 0.006353839300572872,
      "learning_rate": 3.9215686274509805e-05,
      "loss": 0.0083,
      "step": 2860
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 0.2747364640235901,
      "learning_rate": 3.529411764705882e-05,
      "loss": 0.0005,
      "step": 2880
    },
    {
      "epoch": 9.477124183006536,
      "grad_norm": 0.0028742565773427486,
      "learning_rate": 3.137254901960784e-05,
      "loss": 0.0007,
      "step": 2900
    },
    {
      "epoch": 9.542483660130719,
      "grad_norm": 0.0019189984304830432,
      "learning_rate": 2.7450980392156858e-05,
      "loss": 0.0505,
      "step": 2920
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 1.2253268957138062,
      "learning_rate": 2.352941176470588e-05,
      "loss": 0.0004,
      "step": 2940
    },
    {
      "epoch": 9.673202614379084,
      "grad_norm": 0.001733982702717185,
      "learning_rate": 1.9607843137254903e-05,
      "loss": 0.0007,
      "step": 2960
    },
    {
      "epoch": 9.738562091503269,
      "grad_norm": 0.0027870882768183947,
      "learning_rate": 1.568627450980392e-05,
      "loss": 0.0051,
      "step": 2980
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 0.0024139457382261753,
      "learning_rate": 1.176470588235294e-05,
      "loss": 0.0025,
      "step": 3000
    },
    {
      "epoch": 9.869281045751634,
      "grad_norm": 0.04478262737393379,
      "learning_rate": 7.84313725490196e-06,
      "loss": 0.0326,
      "step": 3020
    },
    {
      "epoch": 9.934640522875817,
      "grad_norm": 0.001073828898370266,
      "learning_rate": 3.92156862745098e-06,
      "loss": 0.0045,
      "step": 3040
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0007560770609416068,
      "learning_rate": 0.0,
      "loss": 0.0024,
      "step": 3060
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9092508242234947,
      "eval_f1": 0.9238938053097344,
      "eval_loss": 0.8781148791313171,
      "eval_runtime": 12.5092,
      "eval_samples_per_second": 32.616,
      "eval_steps_per_second": 4.077,
      "step": 3060
    },
    {
      "epoch": 10.0,
      "step": 3060,
      "total_flos": 8767511799029760.0,
      "train_loss": 0.044308778036194034,
      "train_runtime": 2641.9849,
      "train_samples_per_second": 13.884,
      "train_steps_per_second": 1.158
    }
  ],
  "logging_steps": 20,
  "max_steps": 3060,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1530,
  "total_flos": 8767511799029760.0,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
