{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 15300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 3.5865588188171387,
      "learning_rate": 0.0005992156862745097,
      "loss": 0.6159,
      "step": 20
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 3.8598239421844482,
      "learning_rate": 0.0005984313725490196,
      "loss": 0.5878,
      "step": 40
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 6.837767601013184,
      "learning_rate": 0.0005976470588235294,
      "loss": 0.5867,
      "step": 60
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 5.172019958496094,
      "learning_rate": 0.0005968627450980391,
      "loss": 0.5019,
      "step": 80
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 9.981646537780762,
      "learning_rate": 0.000596078431372549,
      "loss": 0.563,
      "step": 100
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 8.171764373779297,
      "learning_rate": 0.0005952941176470588,
      "loss": 0.5131,
      "step": 120
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 4.035241603851318,
      "learning_rate": 0.0005945098039215686,
      "loss": 0.4345,
      "step": 140
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 4.620355129241943,
      "learning_rate": 0.0005937254901960784,
      "loss": 0.4345,
      "step": 160
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 2.0226502418518066,
      "learning_rate": 0.0005929411764705882,
      "loss": 0.4714,
      "step": 180
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 1.996655821800232,
      "learning_rate": 0.0005921568627450981,
      "loss": 0.5524,
      "step": 200
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 2.5172183513641357,
      "learning_rate": 0.0005913725490196078,
      "loss": 0.4515,
      "step": 220
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 4.34665584564209,
      "learning_rate": 0.0005905882352941176,
      "loss": 0.4696,
      "step": 240
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 6.855485916137695,
      "learning_rate": 0.0005898039215686274,
      "loss": 0.375,
      "step": 260
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 5.125339508056641,
      "learning_rate": 0.0005890196078431371,
      "loss": 0.4533,
      "step": 280
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 2.4317257404327393,
      "learning_rate": 0.000588235294117647,
      "loss": 0.4517,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8431372549019608,
      "eval_combined_score": 0.8680569217653618,
      "eval_f1": 0.8929765886287626,
      "eval_loss": 0.38650158047676086,
      "eval_runtime": 11.977,
      "eval_samples_per_second": 34.065,
      "eval_steps_per_second": 4.258,
      "step": 306
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 1.256857991218567,
      "learning_rate": 0.0005874509803921568,
      "loss": 0.361,
      "step": 320
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 2.333192825317383,
      "learning_rate": 0.0005866666666666665,
      "loss": 0.44,
      "step": 340
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 2.9775335788726807,
      "learning_rate": 0.0005858823529411764,
      "loss": 0.3756,
      "step": 360
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 1.016000747680664,
      "learning_rate": 0.0005850980392156862,
      "loss": 0.2886,
      "step": 380
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 5.968440532684326,
      "learning_rate": 0.0005843137254901961,
      "loss": 0.4403,
      "step": 400
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 3.5627238750457764,
      "learning_rate": 0.0005835294117647058,
      "loss": 0.3493,
      "step": 420
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 0.9553930759429932,
      "learning_rate": 0.0005827450980392156,
      "loss": 0.229,
      "step": 440
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 7.890577793121338,
      "learning_rate": 0.0005819607843137255,
      "loss": 0.3578,
      "step": 460
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 3.653390645980835,
      "learning_rate": 0.0005811764705882352,
      "loss": 0.4244,
      "step": 480
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 6.276457786560059,
      "learning_rate": 0.000580392156862745,
      "loss": 0.3725,
      "step": 500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 3.0368220806121826,
      "learning_rate": 0.0005796078431372549,
      "loss": 0.3293,
      "step": 520
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.9781089425086975,
      "learning_rate": 0.0005788235294117647,
      "loss": 0.3266,
      "step": 540
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 4.798120021820068,
      "learning_rate": 0.0005780392156862744,
      "loss": 0.3093,
      "step": 560
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 5.108992576599121,
      "learning_rate": 0.0005772549019607843,
      "loss": 0.3562,
      "step": 580
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 3.915264844894409,
      "learning_rate": 0.0005764705882352941,
      "loss": 0.3058,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.8958068362480127,
      "eval_f1": 0.9117117117117116,
      "eval_loss": 0.31179144978523254,
      "eval_runtime": 11.988,
      "eval_samples_per_second": 34.034,
      "eval_steps_per_second": 4.254,
      "step": 612
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 2.127309799194336,
      "learning_rate": 0.0005756862745098039,
      "loss": 0.3572,
      "step": 620
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 3.912926197052002,
      "learning_rate": 0.0005749019607843137,
      "loss": 0.264,
      "step": 640
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 1.2812317609786987,
      "learning_rate": 0.0005741176470588235,
      "loss": 0.3201,
      "step": 660
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 3.199191093444824,
      "learning_rate": 0.0005733333333333334,
      "loss": 0.2597,
      "step": 680
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 2.4264168739318848,
      "learning_rate": 0.0005725490196078431,
      "loss": 0.3126,
      "step": 700
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 4.591676712036133,
      "learning_rate": 0.0005717647058823529,
      "loss": 0.3429,
      "step": 720
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 10.123967170715332,
      "learning_rate": 0.0005709803921568627,
      "loss": 0.2563,
      "step": 740
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 2.669175863265991,
      "learning_rate": 0.0005701960784313724,
      "loss": 0.259,
      "step": 760
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 1.7260504961013794,
      "learning_rate": 0.0005694117647058823,
      "loss": 0.277,
      "step": 780
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 5.692016124725342,
      "learning_rate": 0.0005686274509803921,
      "loss": 0.3521,
      "step": 800
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.5488306879997253,
      "learning_rate": 0.0005678431372549018,
      "loss": 0.2938,
      "step": 820
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 5.743874549865723,
      "learning_rate": 0.0005670588235294117,
      "loss": 0.2825,
      "step": 840
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 4.939997673034668,
      "learning_rate": 0.0005662745098039215,
      "loss": 0.3022,
      "step": 860
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 3.908890962600708,
      "learning_rate": 0.0005654901960784314,
      "loss": 0.3644,
      "step": 880
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 2.1935300827026367,
      "learning_rate": 0.0005647058823529411,
      "loss": 0.307,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8973808501502791,
      "eval_f1": 0.9124087591240876,
      "eval_loss": 0.3219076097011566,
      "eval_runtime": 11.9985,
      "eval_samples_per_second": 34.004,
      "eval_steps_per_second": 4.251,
      "step": 918
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 6.412009239196777,
      "learning_rate": 0.0005639215686274509,
      "loss": 0.3488,
      "step": 920
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 1.6390577554702759,
      "learning_rate": 0.0005631372549019608,
      "loss": 0.2853,
      "step": 940
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 4.509494304656982,
      "learning_rate": 0.0005623529411764705,
      "loss": 0.2941,
      "step": 960
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 1.9304240942001343,
      "learning_rate": 0.0005615686274509803,
      "loss": 0.2653,
      "step": 980
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 6.627244472503662,
      "learning_rate": 0.0005607843137254902,
      "loss": 0.3959,
      "step": 1000
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 2.5691003799438477,
      "learning_rate": 0.00056,
      "loss": 0.3703,
      "step": 1020
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 0.9856283664703369,
      "learning_rate": 0.0005592156862745097,
      "loss": 0.1635,
      "step": 1040
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 4.635031700134277,
      "learning_rate": 0.0005584313725490196,
      "loss": 0.2943,
      "step": 1060
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 4.150508403778076,
      "learning_rate": 0.0005576470588235294,
      "loss": 0.3266,
      "step": 1080
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 1.8580126762390137,
      "learning_rate": 0.0005568627450980392,
      "loss": 0.2516,
      "step": 1100
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 4.151242733001709,
      "learning_rate": 0.000556078431372549,
      "loss": 0.2093,
      "step": 1120
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 8.200870513916016,
      "learning_rate": 0.0005552941176470588,
      "loss": 0.4244,
      "step": 1140
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 3.4821696281433105,
      "learning_rate": 0.0005545098039215687,
      "loss": 0.3205,
      "step": 1160
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 4.875072002410889,
      "learning_rate": 0.0005537254901960784,
      "loss": 0.247,
      "step": 1180
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 1.625887393951416,
      "learning_rate": 0.0005529411764705882,
      "loss": 0.2714,
      "step": 1200
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 2.1933374404907227,
      "learning_rate": 0.000552156862745098,
      "loss": 0.2367,
      "step": 1220
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9005124777183601,
      "eval_f1": 0.9162210338680927,
      "eval_loss": 0.31249263882637024,
      "eval_runtime": 11.9996,
      "eval_samples_per_second": 34.001,
      "eval_steps_per_second": 4.25,
      "step": 1224
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 4.77280855178833,
      "learning_rate": 0.0005513725490196077,
      "loss": 0.2538,
      "step": 1240
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 3.91383957862854,
      "learning_rate": 0.0005505882352941176,
      "loss": 0.1731,
      "step": 1260
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 4.975812911987305,
      "learning_rate": 0.0005498039215686274,
      "loss": 0.2218,
      "step": 1280
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 0.33954599499702454,
      "learning_rate": 0.0005490196078431371,
      "loss": 0.2957,
      "step": 1300
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 4.252421855926514,
      "learning_rate": 0.000548235294117647,
      "loss": 0.2263,
      "step": 1320
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 5.641117095947266,
      "learning_rate": 0.0005474509803921568,
      "loss": 0.1701,
      "step": 1340
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 3.1201298236846924,
      "learning_rate": 0.0005466666666666667,
      "loss": 0.3011,
      "step": 1360
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 1.228849172592163,
      "learning_rate": 0.0005458823529411764,
      "loss": 0.2005,
      "step": 1380
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 4.8035454750061035,
      "learning_rate": 0.0005450980392156862,
      "loss": 0.2448,
      "step": 1400
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 4.150080680847168,
      "learning_rate": 0.0005443137254901961,
      "loss": 0.3073,
      "step": 1420
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 1.9908698797225952,
      "learning_rate": 0.0005435294117647058,
      "loss": 0.2382,
      "step": 1440
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 2.16255259513855,
      "learning_rate": 0.0005427450980392156,
      "loss": 0.1922,
      "step": 1460
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 0.27512672543525696,
      "learning_rate": 0.0005419607843137255,
      "loss": 0.2726,
      "step": 1480
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 3.8010048866271973,
      "learning_rate": 0.0005411764705882352,
      "loss": 0.279,
      "step": 1500
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 1.2297954559326172,
      "learning_rate": 0.000540392156862745,
      "loss": 0.224,
      "step": 1520
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.9157691245512289,
      "eval_f1": 0.9295774647887324,
      "eval_loss": 0.36674264073371887,
      "eval_runtime": 11.9987,
      "eval_samples_per_second": 34.004,
      "eval_steps_per_second": 4.25,
      "step": 1530
    },
    {
      "epoch": 5.032679738562091,
      "grad_norm": 0.8064534068107605,
      "learning_rate": 0.0005396078431372549,
      "loss": 0.2555,
      "step": 1540
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 0.9185703992843628,
      "learning_rate": 0.0005388235294117647,
      "loss": 0.1667,
      "step": 1560
    },
    {
      "epoch": 5.163398692810458,
      "grad_norm": 4.325257301330566,
      "learning_rate": 0.0005380392156862745,
      "loss": 0.2972,
      "step": 1580
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 2.814107656478882,
      "learning_rate": 0.0005372549019607843,
      "loss": 0.1593,
      "step": 1600
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 6.722737789154053,
      "learning_rate": 0.0005364705882352941,
      "loss": 0.2021,
      "step": 1620
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 4.858774662017822,
      "learning_rate": 0.000535686274509804,
      "loss": 0.2284,
      "step": 1640
    },
    {
      "epoch": 5.42483660130719,
      "grad_norm": 1.7786436080932617,
      "learning_rate": 0.0005349019607843137,
      "loss": 0.1655,
      "step": 1660
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 0.19583936035633087,
      "learning_rate": 0.0005341176470588235,
      "loss": 0.175,
      "step": 1680
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 5.727477073669434,
      "learning_rate": 0.0005333333333333333,
      "loss": 0.1763,
      "step": 1700
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 1.593807578086853,
      "learning_rate": 0.000532549019607843,
      "loss": 0.2314,
      "step": 1720
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 2.5582306385040283,
      "learning_rate": 0.0005317647058823529,
      "loss": 0.2165,
      "step": 1740
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 2.438447952270508,
      "learning_rate": 0.0005309803921568627,
      "loss": 0.3116,
      "step": 1760
    },
    {
      "epoch": 5.816993464052287,
      "grad_norm": 4.445949554443359,
      "learning_rate": 0.0005301960784313724,
      "loss": 0.2501,
      "step": 1780
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 1.831668734550476,
      "learning_rate": 0.0005294117647058823,
      "loss": 0.2655,
      "step": 1800
    },
    {
      "epoch": 5.947712418300654,
      "grad_norm": 1.6360946893692017,
      "learning_rate": 0.0005286274509803921,
      "loss": 0.2776,
      "step": 1820
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9005124777183601,
      "eval_f1": 0.9162210338680927,
      "eval_loss": 0.3696609139442444,
      "eval_runtime": 12.0,
      "eval_samples_per_second": 34.0,
      "eval_steps_per_second": 4.25,
      "step": 1836
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 3.9109108448028564,
      "learning_rate": 0.000527843137254902,
      "loss": 0.2966,
      "step": 1840
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 1.812873125076294,
      "learning_rate": 0.0005270588235294117,
      "loss": 0.1803,
      "step": 1860
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 0.5075085759162903,
      "learning_rate": 0.0005262745098039215,
      "loss": 0.1721,
      "step": 1880
    },
    {
      "epoch": 6.209150326797386,
      "grad_norm": 2.4386091232299805,
      "learning_rate": 0.0005254901960784314,
      "loss": 0.2351,
      "step": 1900
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 5.388186454772949,
      "learning_rate": 0.0005247058823529411,
      "loss": 0.1342,
      "step": 1920
    },
    {
      "epoch": 6.339869281045751,
      "grad_norm": 5.326596260070801,
      "learning_rate": 0.0005239215686274509,
      "loss": 0.1789,
      "step": 1940
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 5.251621246337891,
      "learning_rate": 0.0005231372549019608,
      "loss": 0.3162,
      "step": 1960
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 1.6781909465789795,
      "learning_rate": 0.0005223529411764705,
      "loss": 0.1358,
      "step": 1980
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 0.1881646066904068,
      "learning_rate": 0.0005215686274509803,
      "loss": 0.1636,
      "step": 2000
    },
    {
      "epoch": 6.601307189542483,
      "grad_norm": 2.8942580223083496,
      "learning_rate": 0.0005207843137254902,
      "loss": 0.1661,
      "step": 2020
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.6749730706214905,
      "learning_rate": 0.00052,
      "loss": 0.3078,
      "step": 2040
    },
    {
      "epoch": 6.73202614379085,
      "grad_norm": 7.1391472816467285,
      "learning_rate": 0.0005192156862745098,
      "loss": 0.1856,
      "step": 2060
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 3.108400344848633,
      "learning_rate": 0.0005184313725490196,
      "loss": 0.2132,
      "step": 2080
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 3.2351882457733154,
      "learning_rate": 0.0005176470588235294,
      "loss": 0.1875,
      "step": 2100
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 3.7417705059051514,
      "learning_rate": 0.0005168627450980392,
      "loss": 0.2196,
      "step": 2120
    },
    {
      "epoch": 6.993464052287582,
      "grad_norm": 1.6602263450622559,
      "learning_rate": 0.000516078431372549,
      "loss": 0.1966,
      "step": 2140
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9059928375495276,
      "eval_f1": 0.922279792746114,
      "eval_loss": 0.35122373700141907,
      "eval_runtime": 12.003,
      "eval_samples_per_second": 33.991,
      "eval_steps_per_second": 4.249,
      "step": 2142
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 2.5401668548583984,
      "learning_rate": 0.0005152941176470588,
      "loss": 0.1237,
      "step": 2160
    },
    {
      "epoch": 7.124183006535947,
      "grad_norm": 15.392572402954102,
      "learning_rate": 0.0005145098039215685,
      "loss": 0.2615,
      "step": 2180
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 0.739861249923706,
      "learning_rate": 0.0005137254901960783,
      "loss": 0.1782,
      "step": 2200
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 0.27326035499572754,
      "learning_rate": 0.0005129411764705882,
      "loss": 0.071,
      "step": 2220
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 1.2673345804214478,
      "learning_rate": 0.000512156862745098,
      "loss": 0.2774,
      "step": 2240
    },
    {
      "epoch": 7.38562091503268,
      "grad_norm": 3.2353081703186035,
      "learning_rate": 0.0005113725490196077,
      "loss": 0.1977,
      "step": 2260
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 1.761186957359314,
      "learning_rate": 0.0005105882352941176,
      "loss": 0.1369,
      "step": 2280
    },
    {
      "epoch": 7.516339869281046,
      "grad_norm": 5.124111175537109,
      "learning_rate": 0.0005098039215686274,
      "loss": 0.1479,
      "step": 2300
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 3.0974674224853516,
      "learning_rate": 0.0005090196078431372,
      "loss": 0.1974,
      "step": 2320
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 5.1031622886657715,
      "learning_rate": 0.000508235294117647,
      "loss": 0.2252,
      "step": 2340
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 0.19454678893089294,
      "learning_rate": 0.0005074509803921568,
      "loss": 0.1452,
      "step": 2360
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 4.767483234405518,
      "learning_rate": 0.0005066666666666667,
      "loss": 0.1525,
      "step": 2380
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 4.6314826011657715,
      "learning_rate": 0.0005058823529411764,
      "loss": 0.2612,
      "step": 2400
    },
    {
      "epoch": 7.908496732026144,
      "grad_norm": 1.174654245376587,
      "learning_rate": 0.0005050980392156862,
      "loss": 0.1616,
      "step": 2420
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 3.981252670288086,
      "learning_rate": 0.0005043137254901961,
      "loss": 0.2258,
      "step": 2440
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8725490196078431,
      "eval_combined_score": 0.891753961858716,
      "eval_f1": 0.9109589041095889,
      "eval_loss": 0.5095651745796204,
      "eval_runtime": 12.0199,
      "eval_samples_per_second": 33.944,
      "eval_steps_per_second": 4.243,
      "step": 2448
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 5.2335591316223145,
      "learning_rate": 0.0005035294117647058,
      "loss": 0.1867,
      "step": 2460
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 0.920656144618988,
      "learning_rate": 0.0005027450980392156,
      "loss": 0.1022,
      "step": 2480
    },
    {
      "epoch": 8.169934640522875,
      "grad_norm": 0.07727310806512833,
      "learning_rate": 0.0005019607843137255,
      "loss": 0.1678,
      "step": 2500
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 0.665855348110199,
      "learning_rate": 0.0005011764705882353,
      "loss": 0.1841,
      "step": 2520
    },
    {
      "epoch": 8.300653594771243,
      "grad_norm": 0.43521666526794434,
      "learning_rate": 0.0005003921568627451,
      "loss": 0.1419,
      "step": 2540
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 4.698870658874512,
      "learning_rate": 0.0004996078431372549,
      "loss": 0.1718,
      "step": 2560
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.610788881778717,
      "learning_rate": 0.0004988235294117647,
      "loss": 0.2536,
      "step": 2580
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 0.29495730996131897,
      "learning_rate": 0.0004980392156862745,
      "loss": 0.1321,
      "step": 2600
    },
    {
      "epoch": 8.562091503267974,
      "grad_norm": 0.049942728132009506,
      "learning_rate": 0.0004972549019607843,
      "loss": 0.0936,
      "step": 2620
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 4.133994102478027,
      "learning_rate": 0.0004964705882352941,
      "loss": 0.2469,
      "step": 2640
    },
    {
      "epoch": 8.69281045751634,
      "grad_norm": 9.31672477722168,
      "learning_rate": 0.0004956862745098038,
      "loss": 0.1718,
      "step": 2660
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 8.648422241210938,
      "learning_rate": 0.0004949019607843136,
      "loss": 0.1614,
      "step": 2680
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 0.7355451583862305,
      "learning_rate": 0.0004941176470588235,
      "loss": 0.2037,
      "step": 2700
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 5.265970230102539,
      "learning_rate": 0.0004933333333333333,
      "loss": 0.2308,
      "step": 2720
    },
    {
      "epoch": 8.954248366013072,
      "grad_norm": 3.7099356651306152,
      "learning_rate": 0.0004925490196078431,
      "loss": 0.1571,
      "step": 2740
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9122777538803455,
      "eval_f1": 0.9250457038391224,
      "eval_loss": 0.39980196952819824,
      "eval_runtime": 11.993,
      "eval_samples_per_second": 34.02,
      "eval_steps_per_second": 4.252,
      "step": 2754
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 3.2992658615112305,
      "learning_rate": 0.0004917647058823529,
      "loss": 0.2619,
      "step": 2760
    },
    {
      "epoch": 9.084967320261438,
      "grad_norm": 3.4591732025146484,
      "learning_rate": 0.0004909803921568627,
      "loss": 0.1004,
      "step": 2780
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 5.473526954650879,
      "learning_rate": 0.0004901960784313725,
      "loss": 0.176,
      "step": 2800
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 1.899003505706787,
      "learning_rate": 0.0004894117647058823,
      "loss": 0.1363,
      "step": 2820
    },
    {
      "epoch": 9.281045751633988,
      "grad_norm": 2.723038673400879,
      "learning_rate": 0.0004886274509803921,
      "loss": 0.1507,
      "step": 2840
    },
    {
      "epoch": 9.34640522875817,
      "grad_norm": 2.6041595935821533,
      "learning_rate": 0.0004878431372549019,
      "loss": 0.0767,
      "step": 2860
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 7.233971118927002,
      "learning_rate": 0.0004870588235294117,
      "loss": 0.1175,
      "step": 2880
    },
    {
      "epoch": 9.477124183006536,
      "grad_norm": 3.787527322769165,
      "learning_rate": 0.00048627450980392154,
      "loss": 0.1689,
      "step": 2900
    },
    {
      "epoch": 9.542483660130719,
      "grad_norm": 5.309449672698975,
      "learning_rate": 0.0004854901960784313,
      "loss": 0.2258,
      "step": 2920
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 5.421896457672119,
      "learning_rate": 0.00048470588235294113,
      "loss": 0.1549,
      "step": 2940
    },
    {
      "epoch": 9.673202614379084,
      "grad_norm": 0.5750452280044556,
      "learning_rate": 0.00048392156862745096,
      "loss": 0.1158,
      "step": 2960
    },
    {
      "epoch": 9.738562091503269,
      "grad_norm": 7.432914733886719,
      "learning_rate": 0.0004831372549019608,
      "loss": 0.2818,
      "step": 2980
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 3.4818148612976074,
      "learning_rate": 0.00048235294117647055,
      "loss": 0.1017,
      "step": 3000
    },
    {
      "epoch": 9.869281045751634,
      "grad_norm": 6.811845302581787,
      "learning_rate": 0.00048156862745098037,
      "loss": 0.2308,
      "step": 3020
    },
    {
      "epoch": 9.934640522875817,
      "grad_norm": 5.738829612731934,
      "learning_rate": 0.0004807843137254902,
      "loss": 0.2378,
      "step": 3040
    },
    {
      "epoch": 10.0,
      "grad_norm": 5.113211154937744,
      "learning_rate": 0.00047999999999999996,
      "loss": 0.1358,
      "step": 3060
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9062233589087809,
      "eval_f1": 0.9202898550724639,
      "eval_loss": 0.4364567995071411,
      "eval_runtime": 12.0026,
      "eval_samples_per_second": 33.993,
      "eval_steps_per_second": 4.249,
      "step": 3060
    },
    {
      "epoch": 10.065359477124183,
      "grad_norm": 0.07022903859615326,
      "learning_rate": 0.0004792156862745098,
      "loss": 0.1214,
      "step": 3080
    },
    {
      "epoch": 10.130718954248366,
      "grad_norm": 1.0081621408462524,
      "learning_rate": 0.0004784313725490196,
      "loss": 0.1313,
      "step": 3100
    },
    {
      "epoch": 10.196078431372548,
      "grad_norm": 0.048536501824855804,
      "learning_rate": 0.0004776470588235293,
      "loss": 0.0628,
      "step": 3120
    },
    {
      "epoch": 10.261437908496733,
      "grad_norm": 0.07718738168478012,
      "learning_rate": 0.00047686274509803914,
      "loss": 0.1876,
      "step": 3140
    },
    {
      "epoch": 10.326797385620916,
      "grad_norm": 1.1424428224563599,
      "learning_rate": 0.00047607843137254896,
      "loss": 0.131,
      "step": 3160
    },
    {
      "epoch": 10.392156862745098,
      "grad_norm": 9.406655311584473,
      "learning_rate": 0.0004752941176470588,
      "loss": 0.106,
      "step": 3180
    },
    {
      "epoch": 10.457516339869281,
      "grad_norm": 11.439162254333496,
      "learning_rate": 0.00047450980392156855,
      "loss": 0.1993,
      "step": 3200
    },
    {
      "epoch": 10.522875816993464,
      "grad_norm": 4.745781421661377,
      "learning_rate": 0.00047372549019607837,
      "loss": 0.1648,
      "step": 3220
    },
    {
      "epoch": 10.588235294117647,
      "grad_norm": 8.10031509399414,
      "learning_rate": 0.0004729411764705882,
      "loss": 0.1914,
      "step": 3240
    },
    {
      "epoch": 10.65359477124183,
      "grad_norm": 5.326769828796387,
      "learning_rate": 0.00047215686274509796,
      "loss": 0.1295,
      "step": 3260
    },
    {
      "epoch": 10.718954248366012,
      "grad_norm": 7.710208415985107,
      "learning_rate": 0.0004713725490196078,
      "loss": 0.171,
      "step": 3280
    },
    {
      "epoch": 10.784313725490197,
      "grad_norm": 1.9116575717926025,
      "learning_rate": 0.0004705882352941176,
      "loss": 0.1185,
      "step": 3300
    },
    {
      "epoch": 10.84967320261438,
      "grad_norm": 0.22166551649570465,
      "learning_rate": 0.00046980392156862743,
      "loss": 0.083,
      "step": 3320
    },
    {
      "epoch": 10.915032679738562,
      "grad_norm": 0.2574527859687805,
      "learning_rate": 0.0004690196078431372,
      "loss": 0.1785,
      "step": 3340
    },
    {
      "epoch": 10.980392156862745,
      "grad_norm": 6.548220634460449,
      "learning_rate": 0.000468235294117647,
      "loss": 0.2162,
      "step": 3360
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8992184286301933,
      "eval_f1": 0.916083916083916,
      "eval_loss": 0.45778724551200867,
      "eval_runtime": 11.9881,
      "eval_samples_per_second": 34.034,
      "eval_steps_per_second": 4.254,
      "step": 3366
    },
    {
      "epoch": 11.045751633986928,
      "grad_norm": 4.550793170928955,
      "learning_rate": 0.00046745098039215684,
      "loss": 0.1306,
      "step": 3380
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 3.614558458328247,
      "learning_rate": 0.0004666666666666666,
      "loss": 0.1591,
      "step": 3400
    },
    {
      "epoch": 11.176470588235293,
      "grad_norm": 6.190760135650635,
      "learning_rate": 0.00046588235294117643,
      "loss": 0.1262,
      "step": 3420
    },
    {
      "epoch": 11.241830065359476,
      "grad_norm": 7.517851829528809,
      "learning_rate": 0.00046509803921568625,
      "loss": 0.101,
      "step": 3440
    },
    {
      "epoch": 11.30718954248366,
      "grad_norm": 5.8039398193359375,
      "learning_rate": 0.0004643137254901961,
      "loss": 0.1755,
      "step": 3460
    },
    {
      "epoch": 11.372549019607844,
      "grad_norm": 4.066125392913818,
      "learning_rate": 0.00046352941176470584,
      "loss": 0.1133,
      "step": 3480
    },
    {
      "epoch": 11.437908496732026,
      "grad_norm": 0.5846657752990723,
      "learning_rate": 0.00046274509803921566,
      "loss": 0.1166,
      "step": 3500
    },
    {
      "epoch": 11.50326797385621,
      "grad_norm": 0.1208641454577446,
      "learning_rate": 0.0004619607843137255,
      "loss": 0.1084,
      "step": 3520
    },
    {
      "epoch": 11.568627450980392,
      "grad_norm": 4.059571266174316,
      "learning_rate": 0.00046117647058823525,
      "loss": 0.1231,
      "step": 3540
    },
    {
      "epoch": 11.633986928104575,
      "grad_norm": 4.942056179046631,
      "learning_rate": 0.0004603921568627451,
      "loss": 0.1698,
      "step": 3560
    },
    {
      "epoch": 11.699346405228757,
      "grad_norm": 0.826496422290802,
      "learning_rate": 0.0004596078431372549,
      "loss": 0.1035,
      "step": 3580
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 4.019071102142334,
      "learning_rate": 0.0004588235294117646,
      "loss": 0.081,
      "step": 3600
    },
    {
      "epoch": 11.830065359477125,
      "grad_norm": 0.08590830862522125,
      "learning_rate": 0.00045803921568627443,
      "loss": 0.2098,
      "step": 3620
    },
    {
      "epoch": 11.895424836601308,
      "grad_norm": 6.115595817565918,
      "learning_rate": 0.00045725490196078426,
      "loss": 0.0604,
      "step": 3640
    },
    {
      "epoch": 11.96078431372549,
      "grad_norm": 0.64927077293396,
      "learning_rate": 0.0004564705882352941,
      "loss": 0.1917,
      "step": 3660
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9032765737874097,
      "eval_f1": 0.9192982456140351,
      "eval_loss": 0.5490643382072449,
      "eval_runtime": 11.9927,
      "eval_samples_per_second": 34.021,
      "eval_steps_per_second": 4.253,
      "step": 3672
    },
    {
      "epoch": 12.026143790849673,
      "grad_norm": 0.40525877475738525,
      "learning_rate": 0.00045568627450980385,
      "loss": 0.0756,
      "step": 3680
    },
    {
      "epoch": 12.091503267973856,
      "grad_norm": 1.3958903551101685,
      "learning_rate": 0.00045490196078431367,
      "loss": 0.0851,
      "step": 3700
    },
    {
      "epoch": 12.156862745098039,
      "grad_norm": 0.0914238765835762,
      "learning_rate": 0.0004541176470588235,
      "loss": 0.1369,
      "step": 3720
    },
    {
      "epoch": 12.222222222222221,
      "grad_norm": 0.10802342742681503,
      "learning_rate": 0.00045333333333333326,
      "loss": 0.1177,
      "step": 3740
    },
    {
      "epoch": 12.287581699346406,
      "grad_norm": 5.159332275390625,
      "learning_rate": 0.0004525490196078431,
      "loss": 0.1658,
      "step": 3760
    },
    {
      "epoch": 12.352941176470589,
      "grad_norm": 0.05958089604973793,
      "learning_rate": 0.0004517647058823529,
      "loss": 0.1048,
      "step": 3780
    },
    {
      "epoch": 12.418300653594772,
      "grad_norm": 0.5102843642234802,
      "learning_rate": 0.0004509803921568627,
      "loss": 0.1397,
      "step": 3800
    },
    {
      "epoch": 12.483660130718954,
      "grad_norm": 5.013127326965332,
      "learning_rate": 0.0004501960784313725,
      "loss": 0.1154,
      "step": 3820
    },
    {
      "epoch": 12.549019607843137,
      "grad_norm": 2.415388822555542,
      "learning_rate": 0.0004494117647058823,
      "loss": 0.1492,
      "step": 3840
    },
    {
      "epoch": 12.61437908496732,
      "grad_norm": 3.4889140129089355,
      "learning_rate": 0.00044862745098039214,
      "loss": 0.114,
      "step": 3860
    },
    {
      "epoch": 12.679738562091503,
      "grad_norm": 7.319027423858643,
      "learning_rate": 0.0004478431372549019,
      "loss": 0.13,
      "step": 3880
    },
    {
      "epoch": 12.745098039215687,
      "grad_norm": 16.82548713684082,
      "learning_rate": 0.0004470588235294117,
      "loss": 0.1036,
      "step": 3900
    },
    {
      "epoch": 12.81045751633987,
      "grad_norm": 9.202482223510742,
      "learning_rate": 0.00044627450980392155,
      "loss": 0.1233,
      "step": 3920
    },
    {
      "epoch": 12.875816993464053,
      "grad_norm": 1.028054118156433,
      "learning_rate": 0.00044549019607843137,
      "loss": 0.1045,
      "step": 3940
    },
    {
      "epoch": 12.941176470588236,
      "grad_norm": 0.09258922189474106,
      "learning_rate": 0.00044470588235294114,
      "loss": 0.0657,
      "step": 3960
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.8676470588235294,
      "eval_combined_score": 0.8877484440875327,
      "eval_f1": 0.9078498293515359,
      "eval_loss": 0.6344640254974365,
      "eval_runtime": 11.9865,
      "eval_samples_per_second": 34.038,
      "eval_steps_per_second": 4.255,
      "step": 3978
    },
    {
      "epoch": 13.006535947712418,
      "grad_norm": 6.538832187652588,
      "learning_rate": 0.00044392156862745096,
      "loss": 0.0918,
      "step": 3980
    },
    {
      "epoch": 13.071895424836601,
      "grad_norm": 8.62497615814209,
      "learning_rate": 0.0004431372549019608,
      "loss": 0.0839,
      "step": 4000
    },
    {
      "epoch": 13.137254901960784,
      "grad_norm": 0.23056085407733917,
      "learning_rate": 0.0004423529411764706,
      "loss": 0.1114,
      "step": 4020
    },
    {
      "epoch": 13.202614379084967,
      "grad_norm": 6.847031116485596,
      "learning_rate": 0.00044156862745098037,
      "loss": 0.1674,
      "step": 4040
    },
    {
      "epoch": 13.267973856209151,
      "grad_norm": 0.2511226534843445,
      "learning_rate": 0.0004407843137254902,
      "loss": 0.088,
      "step": 4060
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 2.3568665981292725,
      "learning_rate": 0.0004399999999999999,
      "loss": 0.1495,
      "step": 4080
    },
    {
      "epoch": 13.398692810457517,
      "grad_norm": 12.205896377563477,
      "learning_rate": 0.00043921568627450973,
      "loss": 0.1723,
      "step": 4100
    },
    {
      "epoch": 13.4640522875817,
      "grad_norm": 13.13808536529541,
      "learning_rate": 0.00043843137254901955,
      "loss": 0.1652,
      "step": 4120
    },
    {
      "epoch": 13.529411764705882,
      "grad_norm": 0.16678127646446228,
      "learning_rate": 0.0004376470588235294,
      "loss": 0.1701,
      "step": 4140
    },
    {
      "epoch": 13.594771241830065,
      "grad_norm": 5.163177013397217,
      "learning_rate": 0.00043686274509803914,
      "loss": 0.122,
      "step": 4160
    },
    {
      "epoch": 13.660130718954248,
      "grad_norm": 1.5804625749588013,
      "learning_rate": 0.00043607843137254896,
      "loss": 0.0911,
      "step": 4180
    },
    {
      "epoch": 13.72549019607843,
      "grad_norm": 1.2711668014526367,
      "learning_rate": 0.0004352941176470588,
      "loss": 0.1159,
      "step": 4200
    },
    {
      "epoch": 13.790849673202615,
      "grad_norm": 6.6574177742004395,
      "learning_rate": 0.00043450980392156855,
      "loss": 0.1683,
      "step": 4220
    },
    {
      "epoch": 13.856209150326798,
      "grad_norm": 0.6227266192436218,
      "learning_rate": 0.0004337254901960784,
      "loss": 0.0832,
      "step": 4240
    },
    {
      "epoch": 13.92156862745098,
      "grad_norm": 0.0882168561220169,
      "learning_rate": 0.0004329411764705882,
      "loss": 0.1134,
      "step": 4260
    },
    {
      "epoch": 13.986928104575163,
      "grad_norm": 0.02416241727769375,
      "learning_rate": 0.000432156862745098,
      "loss": 0.0501,
      "step": 4280
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8992184286301933,
      "eval_f1": 0.916083916083916,
      "eval_loss": 0.6087535619735718,
      "eval_runtime": 11.994,
      "eval_samples_per_second": 34.017,
      "eval_steps_per_second": 4.252,
      "step": 4284
    },
    {
      "epoch": 14.052287581699346,
      "grad_norm": 0.04117973893880844,
      "learning_rate": 0.0004313725490196078,
      "loss": 0.1047,
      "step": 4300
    },
    {
      "epoch": 14.117647058823529,
      "grad_norm": 0.985446572303772,
      "learning_rate": 0.0004305882352941176,
      "loss": 0.1686,
      "step": 4320
    },
    {
      "epoch": 14.183006535947712,
      "grad_norm": 0.1305432915687561,
      "learning_rate": 0.00042980392156862743,
      "loss": 0.0562,
      "step": 4340
    },
    {
      "epoch": 14.248366013071895,
      "grad_norm": 2.390040397644043,
      "learning_rate": 0.0004290196078431372,
      "loss": 0.1236,
      "step": 4360
    },
    {
      "epoch": 14.313725490196079,
      "grad_norm": 0.20334553718566895,
      "learning_rate": 0.000428235294117647,
      "loss": 0.0973,
      "step": 4380
    },
    {
      "epoch": 14.379084967320262,
      "grad_norm": 0.06070900708436966,
      "learning_rate": 0.00042745098039215684,
      "loss": 0.0753,
      "step": 4400
    },
    {
      "epoch": 14.444444444444445,
      "grad_norm": 11.036190032958984,
      "learning_rate": 0.00042666666666666667,
      "loss": 0.0349,
      "step": 4420
    },
    {
      "epoch": 14.509803921568627,
      "grad_norm": 0.024548381567001343,
      "learning_rate": 0.00042588235294117643,
      "loss": 0.152,
      "step": 4440
    },
    {
      "epoch": 14.57516339869281,
      "grad_norm": 16.281980514526367,
      "learning_rate": 0.00042509803921568626,
      "loss": 0.0872,
      "step": 4460
    },
    {
      "epoch": 14.640522875816993,
      "grad_norm": 0.844567060470581,
      "learning_rate": 0.0004243137254901961,
      "loss": 0.1655,
      "step": 4480
    },
    {
      "epoch": 14.705882352941176,
      "grad_norm": 1.9962348937988281,
      "learning_rate": 0.0004235294117647059,
      "loss": 0.1783,
      "step": 4500
    },
    {
      "epoch": 14.77124183006536,
      "grad_norm": 0.06535618007183075,
      "learning_rate": 0.00042274509803921567,
      "loss": 0.0194,
      "step": 4520
    },
    {
      "epoch": 14.836601307189543,
      "grad_norm": 6.065388202667236,
      "learning_rate": 0.0004219607843137255,
      "loss": 0.0875,
      "step": 4540
    },
    {
      "epoch": 14.901960784313726,
      "grad_norm": 6.475483417510986,
      "learning_rate": 0.0004211764705882352,
      "loss": 0.1466,
      "step": 4560
    },
    {
      "epoch": 14.967320261437909,
      "grad_norm": 0.012424821965396404,
      "learning_rate": 0.000420392156862745,
      "loss": 0.115,
      "step": 4580
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9031344932339133,
      "eval_f1": 0.9190140845070423,
      "eval_loss": 0.5817215442657471,
      "eval_runtime": 11.9951,
      "eval_samples_per_second": 34.014,
      "eval_steps_per_second": 4.252,
      "step": 4590
    },
    {
      "epoch": 15.032679738562091,
      "grad_norm": 0.019848277792334557,
      "learning_rate": 0.00041960784313725485,
      "loss": 0.0529,
      "step": 4600
    },
    {
      "epoch": 15.098039215686274,
      "grad_norm": 1.5538054704666138,
      "learning_rate": 0.00041882352941176467,
      "loss": 0.1529,
      "step": 4620
    },
    {
      "epoch": 15.163398692810457,
      "grad_norm": 0.023379184305667877,
      "learning_rate": 0.00041803921568627444,
      "loss": 0.0579,
      "step": 4640
    },
    {
      "epoch": 15.22875816993464,
      "grad_norm": 0.012553848326206207,
      "learning_rate": 0.00041725490196078426,
      "loss": 0.0536,
      "step": 4660
    },
    {
      "epoch": 15.294117647058824,
      "grad_norm": 8.034707069396973,
      "learning_rate": 0.0004164705882352941,
      "loss": 0.1191,
      "step": 4680
    },
    {
      "epoch": 15.359477124183007,
      "grad_norm": 0.02932908572256565,
      "learning_rate": 0.00041568627450980385,
      "loss": 0.0772,
      "step": 4700
    },
    {
      "epoch": 15.42483660130719,
      "grad_norm": 0.1762479692697525,
      "learning_rate": 0.00041490196078431367,
      "loss": 0.0776,
      "step": 4720
    },
    {
      "epoch": 15.490196078431373,
      "grad_norm": 0.012416237965226173,
      "learning_rate": 0.0004141176470588235,
      "loss": 0.0919,
      "step": 4740
    },
    {
      "epoch": 15.555555555555555,
      "grad_norm": 2.0451865196228027,
      "learning_rate": 0.0004133333333333333,
      "loss": 0.1177,
      "step": 4760
    },
    {
      "epoch": 15.620915032679738,
      "grad_norm": 6.768567085266113,
      "learning_rate": 0.0004125490196078431,
      "loss": 0.0532,
      "step": 4780
    },
    {
      "epoch": 15.686274509803921,
      "grad_norm": 0.5851014852523804,
      "learning_rate": 0.0004117647058823529,
      "loss": 0.1026,
      "step": 4800
    },
    {
      "epoch": 15.751633986928105,
      "grad_norm": 0.05534288287162781,
      "learning_rate": 0.00041098039215686273,
      "loss": 0.0701,
      "step": 4820
    },
    {
      "epoch": 15.816993464052288,
      "grad_norm": 6.277298450469971,
      "learning_rate": 0.0004101960784313725,
      "loss": 0.1673,
      "step": 4840
    },
    {
      "epoch": 15.882352941176471,
      "grad_norm": 1.0368406772613525,
      "learning_rate": 0.0004094117647058823,
      "loss": 0.0689,
      "step": 4860
    },
    {
      "epoch": 15.947712418300654,
      "grad_norm": 0.2815481424331665,
      "learning_rate": 0.00040862745098039214,
      "loss": 0.1386,
      "step": 4880
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.9142156862745098,
      "eval_combined_score": 0.9258019397383283,
      "eval_f1": 0.9373881932021467,
      "eval_loss": 0.44265538454055786,
      "eval_runtime": 11.9995,
      "eval_samples_per_second": 34.002,
      "eval_steps_per_second": 4.25,
      "step": 4896
    },
    {
      "epoch": 16.013071895424837,
      "grad_norm": 0.08059908449649811,
      "learning_rate": 0.00040784313725490196,
      "loss": 0.0491,
      "step": 4900
    },
    {
      "epoch": 16.07843137254902,
      "grad_norm": 0.11812493205070496,
      "learning_rate": 0.00040705882352941173,
      "loss": 0.0747,
      "step": 4920
    },
    {
      "epoch": 16.143790849673202,
      "grad_norm": 0.2953971326351166,
      "learning_rate": 0.00040627450980392155,
      "loss": 0.0696,
      "step": 4940
    },
    {
      "epoch": 16.209150326797385,
      "grad_norm": 7.502279281616211,
      "learning_rate": 0.0004054901960784314,
      "loss": 0.0777,
      "step": 4960
    },
    {
      "epoch": 16.274509803921568,
      "grad_norm": 0.1543598771095276,
      "learning_rate": 0.0004047058823529412,
      "loss": 0.0482,
      "step": 4980
    },
    {
      "epoch": 16.33986928104575,
      "grad_norm": 4.995491027832031,
      "learning_rate": 0.00040392156862745096,
      "loss": 0.0931,
      "step": 5000
    },
    {
      "epoch": 16.405228758169933,
      "grad_norm": 0.0868416503071785,
      "learning_rate": 0.0004031372549019608,
      "loss": 0.1016,
      "step": 5020
    },
    {
      "epoch": 16.470588235294116,
      "grad_norm": 14.170440673828125,
      "learning_rate": 0.0004023529411764705,
      "loss": 0.0817,
      "step": 5040
    },
    {
      "epoch": 16.535947712418302,
      "grad_norm": 14.384482383728027,
      "learning_rate": 0.0004015686274509803,
      "loss": 0.0995,
      "step": 5060
    },
    {
      "epoch": 16.601307189542485,
      "grad_norm": 5.2969770431518555,
      "learning_rate": 0.00040078431372549014,
      "loss": 0.1367,
      "step": 5080
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.3260495662689209,
      "learning_rate": 0.00039999999999999996,
      "loss": 0.0586,
      "step": 5100
    },
    {
      "epoch": 16.73202614379085,
      "grad_norm": 0.16785278916358948,
      "learning_rate": 0.00039921568627450973,
      "loss": 0.1225,
      "step": 5120
    },
    {
      "epoch": 16.797385620915033,
      "grad_norm": 11.433778762817383,
      "learning_rate": 0.00039843137254901955,
      "loss": 0.0927,
      "step": 5140
    },
    {
      "epoch": 16.862745098039216,
      "grad_norm": 4.3479743003845215,
      "learning_rate": 0.0003976470588235294,
      "loss": 0.1156,
      "step": 5160
    },
    {
      "epoch": 16.9281045751634,
      "grad_norm": 6.315467834472656,
      "learning_rate": 0.00039686274509803914,
      "loss": 0.0587,
      "step": 5180
    },
    {
      "epoch": 16.99346405228758,
      "grad_norm": 5.9361162185668945,
      "learning_rate": 0.00039607843137254897,
      "loss": 0.0936,
      "step": 5200
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.8700980392156863,
      "eval_combined_score": 0.8897498743086978,
      "eval_f1": 0.9094017094017094,
      "eval_loss": 0.678075909614563,
      "eval_runtime": 11.9835,
      "eval_samples_per_second": 34.047,
      "eval_steps_per_second": 4.256,
      "step": 5202
    },
    {
      "epoch": 17.058823529411764,
      "grad_norm": 3.594960927963257,
      "learning_rate": 0.0003952941176470588,
      "loss": 0.0929,
      "step": 5220
    },
    {
      "epoch": 17.124183006535947,
      "grad_norm": 5.01365327835083,
      "learning_rate": 0.0003945098039215686,
      "loss": 0.0797,
      "step": 5240
    },
    {
      "epoch": 17.18954248366013,
      "grad_norm": 0.08200513571500778,
      "learning_rate": 0.0003937254901960784,
      "loss": 0.09,
      "step": 5260
    },
    {
      "epoch": 17.254901960784313,
      "grad_norm": 0.05677863955497742,
      "learning_rate": 0.0003929411764705882,
      "loss": 0.0498,
      "step": 5280
    },
    {
      "epoch": 17.320261437908496,
      "grad_norm": 0.420645147562027,
      "learning_rate": 0.000392156862745098,
      "loss": 0.1242,
      "step": 5300
    },
    {
      "epoch": 17.38562091503268,
      "grad_norm": 5.20556640625,
      "learning_rate": 0.0003913725490196078,
      "loss": 0.0697,
      "step": 5320
    },
    {
      "epoch": 17.45098039215686,
      "grad_norm": 10.096973419189453,
      "learning_rate": 0.0003905882352941176,
      "loss": 0.098,
      "step": 5340
    },
    {
      "epoch": 17.516339869281047,
      "grad_norm": 0.20864024758338928,
      "learning_rate": 0.00038980392156862743,
      "loss": 0.0646,
      "step": 5360
    },
    {
      "epoch": 17.58169934640523,
      "grad_norm": 13.694211959838867,
      "learning_rate": 0.00038901960784313726,
      "loss": 0.0988,
      "step": 5380
    },
    {
      "epoch": 17.647058823529413,
      "grad_norm": 2.143299102783203,
      "learning_rate": 0.000388235294117647,
      "loss": 0.0138,
      "step": 5400
    },
    {
      "epoch": 17.712418300653596,
      "grad_norm": 0.03972645103931427,
      "learning_rate": 0.00038745098039215685,
      "loss": 0.1224,
      "step": 5420
    },
    {
      "epoch": 17.77777777777778,
      "grad_norm": 9.314294815063477,
      "learning_rate": 0.00038666666666666667,
      "loss": 0.1417,
      "step": 5440
    },
    {
      "epoch": 17.84313725490196,
      "grad_norm": 0.015215576626360416,
      "learning_rate": 0.0003858823529411765,
      "loss": 0.0954,
      "step": 5460
    },
    {
      "epoch": 17.908496732026144,
      "grad_norm": 17.097702026367188,
      "learning_rate": 0.00038509803921568626,
      "loss": 0.1471,
      "step": 5480
    },
    {
      "epoch": 17.973856209150327,
      "grad_norm": 0.06116409972310066,
      "learning_rate": 0.000384313725490196,
      "loss": 0.1017,
      "step": 5500
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9106232745805904,
      "eval_f1": 0.924187725631769,
      "eval_loss": 0.4530421197414398,
      "eval_runtime": 12.0025,
      "eval_samples_per_second": 33.993,
      "eval_steps_per_second": 4.249,
      "step": 5508
    },
    {
      "epoch": 18.03921568627451,
      "grad_norm": 0.0331110954284668,
      "learning_rate": 0.0003835294117647058,
      "loss": 0.0647,
      "step": 5520
    },
    {
      "epoch": 18.104575163398692,
      "grad_norm": 0.03708299249410629,
      "learning_rate": 0.0003827450980392156,
      "loss": 0.0178,
      "step": 5540
    },
    {
      "epoch": 18.169934640522875,
      "grad_norm": 0.02400870807468891,
      "learning_rate": 0.00038196078431372544,
      "loss": 0.0514,
      "step": 5560
    },
    {
      "epoch": 18.235294117647058,
      "grad_norm": 0.2944275438785553,
      "learning_rate": 0.00038117647058823526,
      "loss": 0.0426,
      "step": 5580
    },
    {
      "epoch": 18.30065359477124,
      "grad_norm": 0.10062964260578156,
      "learning_rate": 0.00038039215686274503,
      "loss": 0.1243,
      "step": 5600
    },
    {
      "epoch": 18.366013071895424,
      "grad_norm": 0.05924883112311363,
      "learning_rate": 0.00037960784313725485,
      "loss": 0.1017,
      "step": 5620
    },
    {
      "epoch": 18.431372549019606,
      "grad_norm": 10.717727661132812,
      "learning_rate": 0.00037882352941176467,
      "loss": 0.1334,
      "step": 5640
    },
    {
      "epoch": 18.49673202614379,
      "grad_norm": 2.6830809116363525,
      "learning_rate": 0.00037803921568627444,
      "loss": 0.1126,
      "step": 5660
    },
    {
      "epoch": 18.562091503267975,
      "grad_norm": 0.9243857860565186,
      "learning_rate": 0.00037725490196078426,
      "loss": 0.0993,
      "step": 5680
    },
    {
      "epoch": 18.627450980392158,
      "grad_norm": 5.377822399139404,
      "learning_rate": 0.0003764705882352941,
      "loss": 0.0613,
      "step": 5700
    },
    {
      "epoch": 18.69281045751634,
      "grad_norm": 6.399561405181885,
      "learning_rate": 0.0003756862745098039,
      "loss": 0.0561,
      "step": 5720
    },
    {
      "epoch": 18.758169934640524,
      "grad_norm": 0.005387107841670513,
      "learning_rate": 0.0003749019607843137,
      "loss": 0.0662,
      "step": 5740
    },
    {
      "epoch": 18.823529411764707,
      "grad_norm": 4.823254585266113,
      "learning_rate": 0.0003741176470588235,
      "loss": 0.0683,
      "step": 5760
    },
    {
      "epoch": 18.88888888888889,
      "grad_norm": 2.009244918823242,
      "learning_rate": 0.0003733333333333333,
      "loss": 0.1289,
      "step": 5780
    },
    {
      "epoch": 18.954248366013072,
      "grad_norm": 9.932202339172363,
      "learning_rate": 0.0003725490196078431,
      "loss": 0.0613,
      "step": 5800
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.897342284739983,
      "eval_f1": 0.9147826086956522,
      "eval_loss": 0.5417059659957886,
      "eval_runtime": 12.0115,
      "eval_samples_per_second": 33.967,
      "eval_steps_per_second": 4.246,
      "step": 5814
    },
    {
      "epoch": 19.019607843137255,
      "grad_norm": 0.04467798396945,
      "learning_rate": 0.0003717647058823529,
      "loss": 0.0727,
      "step": 5820
    },
    {
      "epoch": 19.084967320261438,
      "grad_norm": 4.994533538818359,
      "learning_rate": 0.00037098039215686273,
      "loss": 0.0578,
      "step": 5840
    },
    {
      "epoch": 19.15032679738562,
      "grad_norm": 0.17422932386398315,
      "learning_rate": 0.00037019607843137255,
      "loss": 0.0368,
      "step": 5860
    },
    {
      "epoch": 19.215686274509803,
      "grad_norm": 1.273329734802246,
      "learning_rate": 0.0003694117647058823,
      "loss": 0.0542,
      "step": 5880
    },
    {
      "epoch": 19.281045751633986,
      "grad_norm": 3.5922558307647705,
      "learning_rate": 0.00036862745098039214,
      "loss": 0.0534,
      "step": 5900
    },
    {
      "epoch": 19.34640522875817,
      "grad_norm": 2.7812070846557617,
      "learning_rate": 0.00036784313725490196,
      "loss": 0.0437,
      "step": 5920
    },
    {
      "epoch": 19.41176470588235,
      "grad_norm": 0.010470796376466751,
      "learning_rate": 0.0003670588235294118,
      "loss": 0.085,
      "step": 5940
    },
    {
      "epoch": 19.477124183006534,
      "grad_norm": 30.65260124206543,
      "learning_rate": 0.00036627450980392155,
      "loss": 0.1361,
      "step": 5960
    },
    {
      "epoch": 19.54248366013072,
      "grad_norm": 8.3262939453125,
      "learning_rate": 0.0003654901960784313,
      "loss": 0.0389,
      "step": 5980
    },
    {
      "epoch": 19.607843137254903,
      "grad_norm": 0.5201091766357422,
      "learning_rate": 0.0003647058823529411,
      "loss": 0.132,
      "step": 6000
    },
    {
      "epoch": 19.673202614379086,
      "grad_norm": 0.09644396603107452,
      "learning_rate": 0.0003639215686274509,
      "loss": 0.0858,
      "step": 6020
    },
    {
      "epoch": 19.73856209150327,
      "grad_norm": 0.3503391146659851,
      "learning_rate": 0.00036313725490196073,
      "loss": 0.0955,
      "step": 6040
    },
    {
      "epoch": 19.80392156862745,
      "grad_norm": 0.03376975655555725,
      "learning_rate": 0.00036235294117647056,
      "loss": 0.121,
      "step": 6060
    },
    {
      "epoch": 19.869281045751634,
      "grad_norm": 0.013202374801039696,
      "learning_rate": 0.0003615686274509803,
      "loss": 0.0928,
      "step": 6080
    },
    {
      "epoch": 19.934640522875817,
      "grad_norm": 3.352323293685913,
      "learning_rate": 0.00036078431372549015,
      "loss": 0.1027,
      "step": 6100
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.0032360299956053495,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.1537,
      "step": 6120
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.91500916913528,
      "eval_f1": 0.9280575539568345,
      "eval_loss": 0.5590128898620605,
      "eval_runtime": 12.0083,
      "eval_samples_per_second": 33.976,
      "eval_steps_per_second": 4.247,
      "step": 6120
    },
    {
      "epoch": 20.065359477124183,
      "grad_norm": 0.011028346605598927,
      "learning_rate": 0.00035921568627450974,
      "loss": 0.0641,
      "step": 6140
    },
    {
      "epoch": 20.130718954248366,
      "grad_norm": 2.864109516143799,
      "learning_rate": 0.00035843137254901956,
      "loss": 0.06,
      "step": 6160
    },
    {
      "epoch": 20.19607843137255,
      "grad_norm": 2.0184311866760254,
      "learning_rate": 0.0003576470588235294,
      "loss": 0.1375,
      "step": 6180
    },
    {
      "epoch": 20.26143790849673,
      "grad_norm": 1.1464864015579224,
      "learning_rate": 0.0003568627450980392,
      "loss": 0.1049,
      "step": 6200
    },
    {
      "epoch": 20.326797385620914,
      "grad_norm": 3.1074318885803223,
      "learning_rate": 0.00035607843137254897,
      "loss": 0.0906,
      "step": 6220
    },
    {
      "epoch": 20.392156862745097,
      "grad_norm": 0.3994820713996887,
      "learning_rate": 0.0003552941176470588,
      "loss": 0.0628,
      "step": 6240
    },
    {
      "epoch": 20.45751633986928,
      "grad_norm": 0.06753510236740112,
      "learning_rate": 0.0003545098039215686,
      "loss": 0.0707,
      "step": 6260
    },
    {
      "epoch": 20.522875816993466,
      "grad_norm": 0.2835911214351654,
      "learning_rate": 0.0003537254901960784,
      "loss": 0.0716,
      "step": 6280
    },
    {
      "epoch": 20.58823529411765,
      "grad_norm": 0.004468563944101334,
      "learning_rate": 0.0003529411764705882,
      "loss": 0.0135,
      "step": 6300
    },
    {
      "epoch": 20.65359477124183,
      "grad_norm": 0.005091889761388302,
      "learning_rate": 0.000352156862745098,
      "loss": 0.0686,
      "step": 6320
    },
    {
      "epoch": 20.718954248366014,
      "grad_norm": 1.5365302562713623,
      "learning_rate": 0.00035137254901960785,
      "loss": 0.0515,
      "step": 6340
    },
    {
      "epoch": 20.784313725490197,
      "grad_norm": 0.026490170508623123,
      "learning_rate": 0.0003505882352941176,
      "loss": 0.0444,
      "step": 6360
    },
    {
      "epoch": 20.84967320261438,
      "grad_norm": 2.94305682182312,
      "learning_rate": 0.00034980392156862744,
      "loss": 0.0844,
      "step": 6380
    },
    {
      "epoch": 20.915032679738562,
      "grad_norm": 0.7990691661834717,
      "learning_rate": 0.00034901960784313726,
      "loss": 0.0608,
      "step": 6400
    },
    {
      "epoch": 20.980392156862745,
      "grad_norm": 0.053828123956918716,
      "learning_rate": 0.0003482352941176471,
      "loss": 0.1169,
      "step": 6420
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9035577645692423,
      "eval_f1": 0.9198606271777002,
      "eval_loss": 0.6291120052337646,
      "eval_runtime": 12.0135,
      "eval_samples_per_second": 33.962,
      "eval_steps_per_second": 4.245,
      "step": 6426
    },
    {
      "epoch": 21.045751633986928,
      "grad_norm": 0.1087222546339035,
      "learning_rate": 0.00034745098039215685,
      "loss": 0.0796,
      "step": 6440
    },
    {
      "epoch": 21.11111111111111,
      "grad_norm": 0.3078213036060333,
      "learning_rate": 0.0003466666666666666,
      "loss": 0.066,
      "step": 6460
    },
    {
      "epoch": 21.176470588235293,
      "grad_norm": 20.11471176147461,
      "learning_rate": 0.0003458823529411764,
      "loss": 0.0802,
      "step": 6480
    },
    {
      "epoch": 21.241830065359476,
      "grad_norm": 1.6702959537506104,
      "learning_rate": 0.0003450980392156862,
      "loss": 0.0464,
      "step": 6500
    },
    {
      "epoch": 21.30718954248366,
      "grad_norm": 0.06340808421373367,
      "learning_rate": 0.00034431372549019603,
      "loss": 0.0605,
      "step": 6520
    },
    {
      "epoch": 21.372549019607842,
      "grad_norm": 0.07691365480422974,
      "learning_rate": 0.00034352941176470585,
      "loss": 0.025,
      "step": 6540
    },
    {
      "epoch": 21.437908496732025,
      "grad_norm": 0.005226930137723684,
      "learning_rate": 0.0003427450980392156,
      "loss": 0.0792,
      "step": 6560
    },
    {
      "epoch": 21.50326797385621,
      "grad_norm": 0.1178731918334961,
      "learning_rate": 0.00034196078431372544,
      "loss": 0.1303,
      "step": 6580
    },
    {
      "epoch": 21.568627450980394,
      "grad_norm": 0.956119954586029,
      "learning_rate": 0.00034117647058823526,
      "loss": 0.0594,
      "step": 6600
    },
    {
      "epoch": 21.633986928104576,
      "grad_norm": 0.010401199571788311,
      "learning_rate": 0.00034039215686274503,
      "loss": 0.1004,
      "step": 6620
    },
    {
      "epoch": 21.69934640522876,
      "grad_norm": 7.5876946449279785,
      "learning_rate": 0.00033960784313725485,
      "loss": 0.054,
      "step": 6640
    },
    {
      "epoch": 21.764705882352942,
      "grad_norm": 0.019559821113944054,
      "learning_rate": 0.0003388235294117647,
      "loss": 0.0582,
      "step": 6660
    },
    {
      "epoch": 21.830065359477125,
      "grad_norm": 7.564747333526611,
      "learning_rate": 0.0003380392156862745,
      "loss": 0.0198,
      "step": 6680
    },
    {
      "epoch": 21.895424836601308,
      "grad_norm": 0.008043155074119568,
      "learning_rate": 0.00033725490196078427,
      "loss": 0.0656,
      "step": 6700
    },
    {
      "epoch": 21.96078431372549,
      "grad_norm": 0.6011846661567688,
      "learning_rate": 0.0003364705882352941,
      "loss": 0.0591,
      "step": 6720
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.9044117647058824,
      "eval_combined_score": 0.9171969056922589,
      "eval_f1": 0.9299820466786355,
      "eval_loss": 0.6223642230033875,
      "eval_runtime": 12.0062,
      "eval_samples_per_second": 33.982,
      "eval_steps_per_second": 4.248,
      "step": 6732
    },
    {
      "epoch": 22.026143790849673,
      "grad_norm": 0.06303819268941879,
      "learning_rate": 0.0003356862745098039,
      "loss": 0.0223,
      "step": 6740
    },
    {
      "epoch": 22.091503267973856,
      "grad_norm": 0.010777107439935207,
      "learning_rate": 0.00033490196078431373,
      "loss": 0.0419,
      "step": 6760
    },
    {
      "epoch": 22.15686274509804,
      "grad_norm": 0.006473288405686617,
      "learning_rate": 0.0003341176470588235,
      "loss": 0.0534,
      "step": 6780
    },
    {
      "epoch": 22.22222222222222,
      "grad_norm": 0.0021026853937655687,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.0102,
      "step": 6800
    },
    {
      "epoch": 22.287581699346404,
      "grad_norm": 0.03490885719656944,
      "learning_rate": 0.00033254901960784314,
      "loss": 0.0355,
      "step": 6820
    },
    {
      "epoch": 22.352941176470587,
      "grad_norm": 0.005874911323189735,
      "learning_rate": 0.0003317647058823529,
      "loss": 0.1298,
      "step": 6840
    },
    {
      "epoch": 22.41830065359477,
      "grad_norm": 25.55400276184082,
      "learning_rate": 0.00033098039215686273,
      "loss": 0.0861,
      "step": 6860
    },
    {
      "epoch": 22.483660130718953,
      "grad_norm": 0.02800225280225277,
      "learning_rate": 0.00033019607843137256,
      "loss": 0.1145,
      "step": 6880
    },
    {
      "epoch": 22.54901960784314,
      "grad_norm": 0.033058278262615204,
      "learning_rate": 0.0003294117647058824,
      "loss": 0.0316,
      "step": 6900
    },
    {
      "epoch": 22.61437908496732,
      "grad_norm": 9.754769325256348,
      "learning_rate": 0.00032862745098039215,
      "loss": 0.0998,
      "step": 6920
    },
    {
      "epoch": 22.679738562091504,
      "grad_norm": 0.0985712930560112,
      "learning_rate": 0.0003278431372549019,
      "loss": 0.0467,
      "step": 6940
    },
    {
      "epoch": 22.745098039215687,
      "grad_norm": 0.05870862305164337,
      "learning_rate": 0.0003270588235294117,
      "loss": 0.082,
      "step": 6960
    },
    {
      "epoch": 22.81045751633987,
      "grad_norm": 3.85199236869812,
      "learning_rate": 0.0003262745098039215,
      "loss": 0.0664,
      "step": 6980
    },
    {
      "epoch": 22.875816993464053,
      "grad_norm": 0.22788779437541962,
      "learning_rate": 0.0003254901960784313,
      "loss": 0.1165,
      "step": 7000
    },
    {
      "epoch": 22.941176470588236,
      "grad_norm": 0.43766912817955017,
      "learning_rate": 0.00032470588235294115,
      "loss": 0.0585,
      "step": 7020
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9011014335435404,
      "eval_f1": 0.9173989455184535,
      "eval_loss": 0.6943023800849915,
      "eval_runtime": 12.0065,
      "eval_samples_per_second": 33.982,
      "eval_steps_per_second": 4.248,
      "step": 7038
    },
    {
      "epoch": 23.00653594771242,
      "grad_norm": 0.003018648363649845,
      "learning_rate": 0.0003239215686274509,
      "loss": 0.0105,
      "step": 7040
    },
    {
      "epoch": 23.0718954248366,
      "grad_norm": 0.003254709532484412,
      "learning_rate": 0.00032313725490196074,
      "loss": 0.1058,
      "step": 7060
    },
    {
      "epoch": 23.137254901960784,
      "grad_norm": 0.04650616645812988,
      "learning_rate": 0.00032235294117647056,
      "loss": 0.0465,
      "step": 7080
    },
    {
      "epoch": 23.202614379084967,
      "grad_norm": 3.515672206878662,
      "learning_rate": 0.00032156862745098033,
      "loss": 0.063,
      "step": 7100
    },
    {
      "epoch": 23.26797385620915,
      "grad_norm": 0.5311785936355591,
      "learning_rate": 0.00032078431372549015,
      "loss": 0.0311,
      "step": 7120
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 0.02496771141886711,
      "learning_rate": 0.00031999999999999997,
      "loss": 0.1255,
      "step": 7140
    },
    {
      "epoch": 23.398692810457515,
      "grad_norm": 0.04897240921854973,
      "learning_rate": 0.0003192156862745098,
      "loss": 0.0842,
      "step": 7160
    },
    {
      "epoch": 23.464052287581698,
      "grad_norm": 0.042237572371959686,
      "learning_rate": 0.00031843137254901956,
      "loss": 0.1017,
      "step": 7180
    },
    {
      "epoch": 23.529411764705884,
      "grad_norm": 0.021471906453371048,
      "learning_rate": 0.0003176470588235294,
      "loss": 0.0083,
      "step": 7200
    },
    {
      "epoch": 23.594771241830067,
      "grad_norm": 0.012032408267259598,
      "learning_rate": 0.0003168627450980392,
      "loss": 0.0089,
      "step": 7220
    },
    {
      "epoch": 23.66013071895425,
      "grad_norm": 0.00875929743051529,
      "learning_rate": 0.00031607843137254903,
      "loss": 0.0625,
      "step": 7240
    },
    {
      "epoch": 23.725490196078432,
      "grad_norm": 7.807574272155762,
      "learning_rate": 0.0003152941176470588,
      "loss": 0.0252,
      "step": 7260
    },
    {
      "epoch": 23.790849673202615,
      "grad_norm": 10.623785018920898,
      "learning_rate": 0.0003145098039215686,
      "loss": 0.1095,
      "step": 7280
    },
    {
      "epoch": 23.856209150326798,
      "grad_norm": 4.81137228012085,
      "learning_rate": 0.00031372549019607844,
      "loss": 0.0644,
      "step": 7300
    },
    {
      "epoch": 23.92156862745098,
      "grad_norm": 11.824658393859863,
      "learning_rate": 0.0003129411764705882,
      "loss": 0.1119,
      "step": 7320
    },
    {
      "epoch": 23.986928104575163,
      "grad_norm": 0.005490490701049566,
      "learning_rate": 0.00031215686274509803,
      "loss": 0.0609,
      "step": 7340
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9009557526714389,
      "eval_f1": 0.9171075837742505,
      "eval_loss": 0.6692590117454529,
      "eval_runtime": 12.0146,
      "eval_samples_per_second": 33.959,
      "eval_steps_per_second": 4.245,
      "step": 7344
    },
    {
      "epoch": 24.052287581699346,
      "grad_norm": 5.388145923614502,
      "learning_rate": 0.00031137254901960785,
      "loss": 0.099,
      "step": 7360
    },
    {
      "epoch": 24.11764705882353,
      "grad_norm": 0.003532925620675087,
      "learning_rate": 0.0003105882352941177,
      "loss": 0.0495,
      "step": 7380
    },
    {
      "epoch": 24.18300653594771,
      "grad_norm": 0.007167914416640997,
      "learning_rate": 0.00030980392156862744,
      "loss": 0.0087,
      "step": 7400
    },
    {
      "epoch": 24.248366013071895,
      "grad_norm": 0.00873215775936842,
      "learning_rate": 0.0003090196078431372,
      "loss": 0.0826,
      "step": 7420
    },
    {
      "epoch": 24.313725490196077,
      "grad_norm": 0.049264244735240936,
      "learning_rate": 0.000308235294117647,
      "loss": 0.0531,
      "step": 7440
    },
    {
      "epoch": 24.37908496732026,
      "grad_norm": 0.0057931202463805676,
      "learning_rate": 0.0003074509803921568,
      "loss": 0.0366,
      "step": 7460
    },
    {
      "epoch": 24.444444444444443,
      "grad_norm": 0.0600152388215065,
      "learning_rate": 0.0003066666666666666,
      "loss": 0.0786,
      "step": 7480
    },
    {
      "epoch": 24.509803921568626,
      "grad_norm": 0.014469554647803307,
      "learning_rate": 0.00030588235294117644,
      "loss": 0.054,
      "step": 7500
    },
    {
      "epoch": 24.575163398692812,
      "grad_norm": 0.01248082984238863,
      "learning_rate": 0.0003050980392156862,
      "loss": 0.0314,
      "step": 7520
    },
    {
      "epoch": 24.640522875816995,
      "grad_norm": 6.69572114944458,
      "learning_rate": 0.00030431372549019603,
      "loss": 0.135,
      "step": 7540
    },
    {
      "epoch": 24.705882352941178,
      "grad_norm": 0.023034753277897835,
      "learning_rate": 0.00030352941176470586,
      "loss": 0.0747,
      "step": 7560
    },
    {
      "epoch": 24.77124183006536,
      "grad_norm": 0.16311492025852203,
      "learning_rate": 0.0003027450980392156,
      "loss": 0.0881,
      "step": 7580
    },
    {
      "epoch": 24.836601307189543,
      "grad_norm": 0.19240647554397583,
      "learning_rate": 0.00030196078431372545,
      "loss": 0.0804,
      "step": 7600
    },
    {
      "epoch": 24.901960784313726,
      "grad_norm": 0.0184504222124815,
      "learning_rate": 0.00030117647058823527,
      "loss": 0.1078,
      "step": 7620
    },
    {
      "epoch": 24.96732026143791,
      "grad_norm": 0.018402528017759323,
      "learning_rate": 0.0003003921568627451,
      "loss": 0.0345,
      "step": 7640
    },
    {
      "epoch": 25.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9012460938841386,
      "eval_f1": 0.9176882661996497,
      "eval_loss": 0.6789982914924622,
      "eval_runtime": 12.0099,
      "eval_samples_per_second": 33.972,
      "eval_steps_per_second": 4.246,
      "step": 7650
    },
    {
      "epoch": 25.03267973856209,
      "grad_norm": 11.691998481750488,
      "learning_rate": 0.00029960784313725486,
      "loss": 0.0309,
      "step": 7660
    },
    {
      "epoch": 25.098039215686274,
      "grad_norm": 3.16778302192688,
      "learning_rate": 0.0002988235294117647,
      "loss": 0.088,
      "step": 7680
    },
    {
      "epoch": 25.163398692810457,
      "grad_norm": 0.02236487716436386,
      "learning_rate": 0.0002980392156862745,
      "loss": 0.051,
      "step": 7700
    },
    {
      "epoch": 25.22875816993464,
      "grad_norm": 3.1957831382751465,
      "learning_rate": 0.0002972549019607843,
      "loss": 0.0774,
      "step": 7720
    },
    {
      "epoch": 25.294117647058822,
      "grad_norm": 0.12973344326019287,
      "learning_rate": 0.0002964705882352941,
      "loss": 0.0826,
      "step": 7740
    },
    {
      "epoch": 25.359477124183005,
      "grad_norm": 7.402441024780273,
      "learning_rate": 0.0002956862745098039,
      "loss": 0.0684,
      "step": 7760
    },
    {
      "epoch": 25.424836601307188,
      "grad_norm": 0.027848074212670326,
      "learning_rate": 0.0002949019607843137,
      "loss": 0.0151,
      "step": 7780
    },
    {
      "epoch": 25.49019607843137,
      "grad_norm": 0.008819024078547955,
      "learning_rate": 0.0002941176470588235,
      "loss": 0.0983,
      "step": 7800
    },
    {
      "epoch": 25.555555555555557,
      "grad_norm": 0.015396502800285816,
      "learning_rate": 0.00029333333333333327,
      "loss": 0.0558,
      "step": 7820
    },
    {
      "epoch": 25.62091503267974,
      "grad_norm": 0.021361198276281357,
      "learning_rate": 0.0002925490196078431,
      "loss": 0.0695,
      "step": 7840
    },
    {
      "epoch": 25.686274509803923,
      "grad_norm": 0.0008758684271015227,
      "learning_rate": 0.0002917647058823529,
      "loss": 0.0685,
      "step": 7860
    },
    {
      "epoch": 25.751633986928105,
      "grad_norm": 0.003692994359880686,
      "learning_rate": 0.00029098039215686274,
      "loss": 0.006,
      "step": 7880
    },
    {
      "epoch": 25.81699346405229,
      "grad_norm": 0.006198038347065449,
      "learning_rate": 0.0002901960784313725,
      "loss": 0.001,
      "step": 7900
    },
    {
      "epoch": 25.88235294117647,
      "grad_norm": 0.0016438557067885995,
      "learning_rate": 0.00028941176470588233,
      "loss": 0.0861,
      "step": 7920
    },
    {
      "epoch": 25.947712418300654,
      "grad_norm": 0.2510659992694855,
      "learning_rate": 0.00028862745098039215,
      "loss": 0.06,
      "step": 7940
    },
    {
      "epoch": 26.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.89719356328919,
      "eval_f1": 0.9144851657940662,
      "eval_loss": 0.6846166849136353,
      "eval_runtime": 11.9995,
      "eval_samples_per_second": 34.002,
      "eval_steps_per_second": 4.25,
      "step": 7956
    },
    {
      "epoch": 26.013071895424837,
      "grad_norm": 4.037231922149658,
      "learning_rate": 0.00028784313725490197,
      "loss": 0.0993,
      "step": 7960
    },
    {
      "epoch": 26.07843137254902,
      "grad_norm": 0.04684584215283394,
      "learning_rate": 0.00028705882352941174,
      "loss": 0.0547,
      "step": 7980
    },
    {
      "epoch": 26.143790849673202,
      "grad_norm": 0.004404300358146429,
      "learning_rate": 0.00028627450980392156,
      "loss": 0.0162,
      "step": 8000
    },
    {
      "epoch": 26.209150326797385,
      "grad_norm": 17.09327507019043,
      "learning_rate": 0.00028549019607843133,
      "loss": 0.0173,
      "step": 8020
    },
    {
      "epoch": 26.274509803921568,
      "grad_norm": 0.0121859610080719,
      "learning_rate": 0.00028470588235294115,
      "loss": 0.0365,
      "step": 8040
    },
    {
      "epoch": 26.33986928104575,
      "grad_norm": 0.024962207302451134,
      "learning_rate": 0.0002839215686274509,
      "loss": 0.0768,
      "step": 8060
    },
    {
      "epoch": 26.405228758169933,
      "grad_norm": 0.16502758860588074,
      "learning_rate": 0.00028313725490196074,
      "loss": 0.0561,
      "step": 8080
    },
    {
      "epoch": 26.470588235294116,
      "grad_norm": 0.7229812145233154,
      "learning_rate": 0.00028235294117647056,
      "loss": 0.0231,
      "step": 8100
    },
    {
      "epoch": 26.535947712418302,
      "grad_norm": 0.0020718916784971952,
      "learning_rate": 0.0002815686274509804,
      "loss": 0.0916,
      "step": 8120
    },
    {
      "epoch": 26.601307189542485,
      "grad_norm": 0.014079316519200802,
      "learning_rate": 0.00028078431372549015,
      "loss": 0.0245,
      "step": 8140
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 2.857909679412842,
      "learning_rate": 0.00028,
      "loss": 0.0478,
      "step": 8160
    },
    {
      "epoch": 26.73202614379085,
      "grad_norm": 0.2362801432609558,
      "learning_rate": 0.0002792156862745098,
      "loss": 0.0796,
      "step": 8180
    },
    {
      "epoch": 26.797385620915033,
      "grad_norm": 6.962057590484619,
      "learning_rate": 0.0002784313725490196,
      "loss": 0.0168,
      "step": 8200
    },
    {
      "epoch": 26.862745098039216,
      "grad_norm": 0.003123113652691245,
      "learning_rate": 0.0002776470588235294,
      "loss": 0.05,
      "step": 8220
    },
    {
      "epoch": 26.9281045751634,
      "grad_norm": 0.01543976366519928,
      "learning_rate": 0.0002768627450980392,
      "loss": 0.0738,
      "step": 8240
    },
    {
      "epoch": 26.99346405228758,
      "grad_norm": 0.04102041572332382,
      "learning_rate": 0.000276078431372549,
      "loss": 0.0335,
      "step": 8260
    },
    {
      "epoch": 27.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9050299323269131,
      "eval_f1": 0.9203539823008849,
      "eval_loss": 0.758413553237915,
      "eval_runtime": 11.9911,
      "eval_samples_per_second": 34.025,
      "eval_steps_per_second": 4.253,
      "step": 8262
    },
    {
      "epoch": 27.058823529411764,
      "grad_norm": 0.03812249377369881,
      "learning_rate": 0.0002752941176470588,
      "loss": 0.0202,
      "step": 8280
    },
    {
      "epoch": 27.124183006535947,
      "grad_norm": 0.0022912733256816864,
      "learning_rate": 0.00027450980392156857,
      "loss": 0.0317,
      "step": 8300
    },
    {
      "epoch": 27.18954248366013,
      "grad_norm": 0.0032108770683407784,
      "learning_rate": 0.0002737254901960784,
      "loss": 0.0005,
      "step": 8320
    },
    {
      "epoch": 27.254901960784313,
      "grad_norm": 0.05244746059179306,
      "learning_rate": 0.0002729411764705882,
      "loss": 0.0828,
      "step": 8340
    },
    {
      "epoch": 27.320261437908496,
      "grad_norm": 0.33065739274024963,
      "learning_rate": 0.00027215686274509803,
      "loss": 0.0617,
      "step": 8360
    },
    {
      "epoch": 27.38562091503268,
      "grad_norm": 0.0057662054896354675,
      "learning_rate": 0.0002713725490196078,
      "loss": 0.0012,
      "step": 8380
    },
    {
      "epoch": 27.45098039215686,
      "grad_norm": 0.020137565210461617,
      "learning_rate": 0.0002705882352941176,
      "loss": 0.0091,
      "step": 8400
    },
    {
      "epoch": 27.516339869281047,
      "grad_norm": 20.472436904907227,
      "learning_rate": 0.00026980392156862745,
      "loss": 0.0781,
      "step": 8420
    },
    {
      "epoch": 27.58169934640523,
      "grad_norm": 0.002443647012114525,
      "learning_rate": 0.00026901960784313727,
      "loss": 0.0332,
      "step": 8440
    },
    {
      "epoch": 27.647058823529413,
      "grad_norm": 15.83090591430664,
      "learning_rate": 0.00026823529411764704,
      "loss": 0.0657,
      "step": 8460
    },
    {
      "epoch": 27.712418300653596,
      "grad_norm": 0.3683137595653534,
      "learning_rate": 0.00026745098039215686,
      "loss": 0.0425,
      "step": 8480
    },
    {
      "epoch": 27.77777777777778,
      "grad_norm": 0.005745349917560816,
      "learning_rate": 0.0002666666666666666,
      "loss": 0.0542,
      "step": 8500
    },
    {
      "epoch": 27.84313725490196,
      "grad_norm": 0.11462726444005966,
      "learning_rate": 0.00026588235294117645,
      "loss": 0.0595,
      "step": 8520
    },
    {
      "epoch": 27.908496732026144,
      "grad_norm": 0.46881669759750366,
      "learning_rate": 0.0002650980392156862,
      "loss": 0.0826,
      "step": 8540
    },
    {
      "epoch": 27.973856209150327,
      "grad_norm": 0.008297687396407127,
      "learning_rate": 0.00026431372549019604,
      "loss": 0.1192,
      "step": 8560
    },
    {
      "epoch": 28.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9114269382664727,
      "eval_f1": 0.9257950530035336,
      "eval_loss": 0.6639465689659119,
      "eval_runtime": 11.9859,
      "eval_samples_per_second": 34.04,
      "eval_steps_per_second": 4.255,
      "step": 8568
    },
    {
      "epoch": 28.03921568627451,
      "grad_norm": 0.012508601881563663,
      "learning_rate": 0.00026352941176470586,
      "loss": 0.0645,
      "step": 8580
    },
    {
      "epoch": 28.104575163398692,
      "grad_norm": 0.19138222932815552,
      "learning_rate": 0.0002627450980392157,
      "loss": 0.0708,
      "step": 8600
    },
    {
      "epoch": 28.169934640522875,
      "grad_norm": 7.047468185424805,
      "learning_rate": 0.00026196078431372545,
      "loss": 0.0483,
      "step": 8620
    },
    {
      "epoch": 28.235294117647058,
      "grad_norm": 61.31098937988281,
      "learning_rate": 0.00026117647058823527,
      "loss": 0.0608,
      "step": 8640
    },
    {
      "epoch": 28.30065359477124,
      "grad_norm": 14.53004264831543,
      "learning_rate": 0.0002603921568627451,
      "loss": 0.0279,
      "step": 8660
    },
    {
      "epoch": 28.366013071895424,
      "grad_norm": 0.5537616610527039,
      "learning_rate": 0.0002596078431372549,
      "loss": 0.0685,
      "step": 8680
    },
    {
      "epoch": 28.431372549019606,
      "grad_norm": 0.002670929068699479,
      "learning_rate": 0.0002588235294117647,
      "loss": 0.0327,
      "step": 8700
    },
    {
      "epoch": 28.49673202614379,
      "grad_norm": 0.005019540898501873,
      "learning_rate": 0.0002580392156862745,
      "loss": 0.0752,
      "step": 8720
    },
    {
      "epoch": 28.562091503267975,
      "grad_norm": 0.4272562563419342,
      "learning_rate": 0.0002572549019607843,
      "loss": 0.0292,
      "step": 8740
    },
    {
      "epoch": 28.627450980392158,
      "grad_norm": 0.007915455847978592,
      "learning_rate": 0.0002564705882352941,
      "loss": 0.1233,
      "step": 8760
    },
    {
      "epoch": 28.69281045751634,
      "grad_norm": 0.006124783772975206,
      "learning_rate": 0.00025568627450980386,
      "loss": 0.0572,
      "step": 8780
    },
    {
      "epoch": 28.758169934640524,
      "grad_norm": 0.12549757957458496,
      "learning_rate": 0.0002549019607843137,
      "loss": 0.0563,
      "step": 8800
    },
    {
      "epoch": 28.823529411764707,
      "grad_norm": 0.00750326132401824,
      "learning_rate": 0.0002541176470588235,
      "loss": 0.0703,
      "step": 8820
    },
    {
      "epoch": 28.88888888888889,
      "grad_norm": 8.436212539672852,
      "learning_rate": 0.00025333333333333333,
      "loss": 0.0836,
      "step": 8840
    },
    {
      "epoch": 28.954248366013072,
      "grad_norm": 4.2558817863464355,
      "learning_rate": 0.0002525490196078431,
      "loss": 0.0533,
      "step": 8860
    },
    {
      "epoch": 29.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9134717161200764,
      "eval_f1": 0.9274336283185841,
      "eval_loss": 0.6582983136177063,
      "eval_runtime": 11.9912,
      "eval_samples_per_second": 34.025,
      "eval_steps_per_second": 4.253,
      "step": 8874
    },
    {
      "epoch": 29.019607843137255,
      "grad_norm": 0.039542488753795624,
      "learning_rate": 0.0002517647058823529,
      "loss": 0.0686,
      "step": 8880
    },
    {
      "epoch": 29.084967320261438,
      "grad_norm": 0.497137188911438,
      "learning_rate": 0.00025098039215686274,
      "loss": 0.0028,
      "step": 8900
    },
    {
      "epoch": 29.15032679738562,
      "grad_norm": 0.0009667819831520319,
      "learning_rate": 0.00025019607843137256,
      "loss": 0.0353,
      "step": 8920
    },
    {
      "epoch": 29.215686274509803,
      "grad_norm": 0.001985404873266816,
      "learning_rate": 0.00024941176470588233,
      "loss": 0.0417,
      "step": 8940
    },
    {
      "epoch": 29.281045751633986,
      "grad_norm": 0.01427600160241127,
      "learning_rate": 0.00024862745098039215,
      "loss": 0.0202,
      "step": 8960
    },
    {
      "epoch": 29.34640522875817,
      "grad_norm": 0.001381543930619955,
      "learning_rate": 0.0002478431372549019,
      "loss": 0.0541,
      "step": 8980
    },
    {
      "epoch": 29.41176470588235,
      "grad_norm": 6.2368903160095215,
      "learning_rate": 0.00024705882352941174,
      "loss": 0.0591,
      "step": 9000
    },
    {
      "epoch": 29.477124183006534,
      "grad_norm": 20.74711036682129,
      "learning_rate": 0.00024627450980392157,
      "loss": 0.0924,
      "step": 9020
    },
    {
      "epoch": 29.54248366013072,
      "grad_norm": 2.4457309246063232,
      "learning_rate": 0.00024549019607843133,
      "loss": 0.065,
      "step": 9040
    },
    {
      "epoch": 29.607843137254903,
      "grad_norm": 0.002251603174954653,
      "learning_rate": 0.00024470588235294116,
      "loss": 0.0323,
      "step": 9060
    },
    {
      "epoch": 29.673202614379086,
      "grad_norm": 0.0023650017101317644,
      "learning_rate": 0.00024392156862745095,
      "loss": 0.0232,
      "step": 9080
    },
    {
      "epoch": 29.73856209150327,
      "grad_norm": 0.49053406715393066,
      "learning_rate": 0.00024313725490196077,
      "loss": 0.1343,
      "step": 9100
    },
    {
      "epoch": 29.80392156862745,
      "grad_norm": 18.276329040527344,
      "learning_rate": 0.00024235294117647057,
      "loss": 0.0762,
      "step": 9120
    },
    {
      "epoch": 29.869281045751634,
      "grad_norm": 3.669510841369629,
      "learning_rate": 0.0002415686274509804,
      "loss": 0.0288,
      "step": 9140
    },
    {
      "epoch": 29.934640522875817,
      "grad_norm": 0.0023137035313993692,
      "learning_rate": 0.00024078431372549018,
      "loss": 0.0899,
      "step": 9160
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.09520109742879868,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.0551,
      "step": 9180
    },
    {
      "epoch": 30.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9095183328164307,
      "eval_f1": 0.9244288224956063,
      "eval_loss": 0.6752269864082336,
      "eval_runtime": 11.9976,
      "eval_samples_per_second": 34.007,
      "eval_steps_per_second": 4.251,
      "step": 9180
    },
    {
      "epoch": 30.065359477124183,
      "grad_norm": 0.01068536564707756,
      "learning_rate": 0.0002392156862745098,
      "loss": 0.0311,
      "step": 9200
    },
    {
      "epoch": 30.130718954248366,
      "grad_norm": 3.2103922367095947,
      "learning_rate": 0.00023843137254901957,
      "loss": 0.0277,
      "step": 9220
    },
    {
      "epoch": 30.19607843137255,
      "grad_norm": 0.530236542224884,
      "learning_rate": 0.0002376470588235294,
      "loss": 0.0198,
      "step": 9240
    },
    {
      "epoch": 30.26143790849673,
      "grad_norm": 0.03488660231232643,
      "learning_rate": 0.00023686274509803919,
      "loss": 0.0508,
      "step": 9260
    },
    {
      "epoch": 30.326797385620914,
      "grad_norm": 0.00785750150680542,
      "learning_rate": 0.00023607843137254898,
      "loss": 0.0481,
      "step": 9280
    },
    {
      "epoch": 30.392156862745097,
      "grad_norm": 0.02434231899678707,
      "learning_rate": 0.0002352941176470588,
      "loss": 0.0298,
      "step": 9300
    },
    {
      "epoch": 30.45751633986928,
      "grad_norm": 0.004772702232003212,
      "learning_rate": 0.0002345098039215686,
      "loss": 0.0239,
      "step": 9320
    },
    {
      "epoch": 30.522875816993466,
      "grad_norm": 0.023723416030406952,
      "learning_rate": 0.00023372549019607842,
      "loss": 0.0098,
      "step": 9340
    },
    {
      "epoch": 30.58823529411765,
      "grad_norm": 9.598917007446289,
      "learning_rate": 0.00023294117647058821,
      "loss": 0.0585,
      "step": 9360
    },
    {
      "epoch": 30.65359477124183,
      "grad_norm": 0.0020868966821581125,
      "learning_rate": 0.00023215686274509804,
      "loss": 0.0765,
      "step": 9380
    },
    {
      "epoch": 30.718954248366014,
      "grad_norm": 0.03359203413128853,
      "learning_rate": 0.00023137254901960783,
      "loss": 0.0608,
      "step": 9400
    },
    {
      "epoch": 30.784313725490197,
      "grad_norm": 0.4970020651817322,
      "learning_rate": 0.00023058823529411763,
      "loss": 0.1064,
      "step": 9420
    },
    {
      "epoch": 30.84967320261438,
      "grad_norm": 0.010244212113320827,
      "learning_rate": 0.00022980392156862745,
      "loss": 0.0642,
      "step": 9440
    },
    {
      "epoch": 30.915032679738562,
      "grad_norm": 0.014393874444067478,
      "learning_rate": 0.00022901960784313722,
      "loss": 0.0154,
      "step": 9460
    },
    {
      "epoch": 30.980392156862745,
      "grad_norm": 6.945219039916992,
      "learning_rate": 0.00022823529411764704,
      "loss": 0.0722,
      "step": 9480
    },
    {
      "epoch": 31.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.9148793091243719,
      "eval_f1": 0.9277978339350181,
      "eval_loss": 0.6269860863685608,
      "eval_runtime": 11.9855,
      "eval_samples_per_second": 34.041,
      "eval_steps_per_second": 4.255,
      "step": 9486
    },
    {
      "epoch": 31.045751633986928,
      "grad_norm": 1.7764266729354858,
      "learning_rate": 0.00022745098039215683,
      "loss": 0.0693,
      "step": 9500
    },
    {
      "epoch": 31.11111111111111,
      "grad_norm": 0.023326968774199486,
      "learning_rate": 0.00022666666666666663,
      "loss": 0.0196,
      "step": 9520
    },
    {
      "epoch": 31.176470588235293,
      "grad_norm": 13.71263313293457,
      "learning_rate": 0.00022588235294117645,
      "loss": 0.0216,
      "step": 9540
    },
    {
      "epoch": 31.241830065359476,
      "grad_norm": 13.786112785339355,
      "learning_rate": 0.00022509803921568625,
      "loss": 0.0308,
      "step": 9560
    },
    {
      "epoch": 31.30718954248366,
      "grad_norm": 3.868027925491333,
      "learning_rate": 0.00022431372549019607,
      "loss": 0.0349,
      "step": 9580
    },
    {
      "epoch": 31.372549019607842,
      "grad_norm": 0.002355781616643071,
      "learning_rate": 0.00022352941176470586,
      "loss": 0.0289,
      "step": 9600
    },
    {
      "epoch": 31.437908496732025,
      "grad_norm": 0.14210541546344757,
      "learning_rate": 0.00022274509803921568,
      "loss": 0.0136,
      "step": 9620
    },
    {
      "epoch": 31.50326797385621,
      "grad_norm": 0.20812349021434784,
      "learning_rate": 0.00022196078431372548,
      "loss": 0.056,
      "step": 9640
    },
    {
      "epoch": 31.568627450980394,
      "grad_norm": 0.0011018752120435238,
      "learning_rate": 0.0002211764705882353,
      "loss": 0.0343,
      "step": 9660
    },
    {
      "epoch": 31.633986928104576,
      "grad_norm": 0.0016550096916034818,
      "learning_rate": 0.0002203921568627451,
      "loss": 0.0289,
      "step": 9680
    },
    {
      "epoch": 31.69934640522876,
      "grad_norm": 13.984548568725586,
      "learning_rate": 0.00021960784313725486,
      "loss": 0.0595,
      "step": 9700
    },
    {
      "epoch": 31.764705882352942,
      "grad_norm": 0.009466595016419888,
      "learning_rate": 0.0002188235294117647,
      "loss": 0.0495,
      "step": 9720
    },
    {
      "epoch": 31.830065359477125,
      "grad_norm": 0.03723776340484619,
      "learning_rate": 0.00021803921568627448,
      "loss": 0.0419,
      "step": 9740
    },
    {
      "epoch": 31.895424836601308,
      "grad_norm": 0.17938190698623657,
      "learning_rate": 0.00021725490196078428,
      "loss": 0.0649,
      "step": 9760
    },
    {
      "epoch": 31.96078431372549,
      "grad_norm": 0.031682807952165604,
      "learning_rate": 0.0002164705882352941,
      "loss": 0.0603,
      "step": 9780
    },
    {
      "epoch": 32.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9047459893048129,
      "eval_f1": 0.9197860962566845,
      "eval_loss": 0.7282391786575317,
      "eval_runtime": 12.0006,
      "eval_samples_per_second": 33.998,
      "eval_steps_per_second": 4.25,
      "step": 9792
    },
    {
      "epoch": 32.02614379084967,
      "grad_norm": 0.00123688206076622,
      "learning_rate": 0.0002156862745098039,
      "loss": 0.044,
      "step": 9800
    },
    {
      "epoch": 32.091503267973856,
      "grad_norm": 0.003084874013438821,
      "learning_rate": 0.00021490196078431372,
      "loss": 0.0099,
      "step": 9820
    },
    {
      "epoch": 32.15686274509804,
      "grad_norm": 6.363887786865234,
      "learning_rate": 0.0002141176470588235,
      "loss": 0.0269,
      "step": 9840
    },
    {
      "epoch": 32.22222222222222,
      "grad_norm": 0.015322425402700901,
      "learning_rate": 0.00021333333333333333,
      "loss": 0.0415,
      "step": 9860
    },
    {
      "epoch": 32.287581699346404,
      "grad_norm": 0.37361592054367065,
      "learning_rate": 0.00021254901960784313,
      "loss": 0.0729,
      "step": 9880
    },
    {
      "epoch": 32.35294117647059,
      "grad_norm": 0.0349886491894722,
      "learning_rate": 0.00021176470588235295,
      "loss": 0.0362,
      "step": 9900
    },
    {
      "epoch": 32.41830065359477,
      "grad_norm": 0.05716468393802643,
      "learning_rate": 0.00021098039215686274,
      "loss": 0.0039,
      "step": 9920
    },
    {
      "epoch": 32.48366013071895,
      "grad_norm": 0.0013016528682783246,
      "learning_rate": 0.0002101960784313725,
      "loss": 0.0336,
      "step": 9940
    },
    {
      "epoch": 32.549019607843135,
      "grad_norm": 0.0003093255509156734,
      "learning_rate": 0.00020941176470588233,
      "loss": 0.0301,
      "step": 9960
    },
    {
      "epoch": 32.61437908496732,
      "grad_norm": 0.0005210348754189909,
      "learning_rate": 0.00020862745098039213,
      "loss": 0.0294,
      "step": 9980
    },
    {
      "epoch": 32.6797385620915,
      "grad_norm": 0.014316009357571602,
      "learning_rate": 0.00020784313725490192,
      "loss": 0.0228,
      "step": 10000
    },
    {
      "epoch": 32.745098039215684,
      "grad_norm": 0.11840751767158508,
      "learning_rate": 0.00020705882352941175,
      "loss": 0.0669,
      "step": 10020
    },
    {
      "epoch": 32.810457516339866,
      "grad_norm": 0.030989617109298706,
      "learning_rate": 0.00020627450980392154,
      "loss": 0.0413,
      "step": 10040
    },
    {
      "epoch": 32.87581699346405,
      "grad_norm": 0.011406800709664822,
      "learning_rate": 0.00020549019607843136,
      "loss": 0.079,
      "step": 10060
    },
    {
      "epoch": 32.94117647058823,
      "grad_norm": 7.350130081176758,
      "learning_rate": 0.00020470588235294116,
      "loss": 0.0425,
      "step": 10080
    },
    {
      "epoch": 33.0,
      "eval_accuracy": 0.8725490196078431,
      "eval_combined_score": 0.8911356209150327,
      "eval_f1": 0.9097222222222222,
      "eval_loss": 0.811176598072052,
      "eval_runtime": 12.0115,
      "eval_samples_per_second": 33.967,
      "eval_steps_per_second": 4.246,
      "step": 10098
    },
    {
      "epoch": 33.00653594771242,
      "grad_norm": 2.0230870246887207,
      "learning_rate": 0.00020392156862745098,
      "loss": 0.0044,
      "step": 10100
    },
    {
      "epoch": 33.071895424836605,
      "grad_norm": 4.394234657287598,
      "learning_rate": 0.00020313725490196078,
      "loss": 0.0189,
      "step": 10120
    },
    {
      "epoch": 33.13725490196079,
      "grad_norm": 0.5841502547264099,
      "learning_rate": 0.0002023529411764706,
      "loss": 0.0546,
      "step": 10140
    },
    {
      "epoch": 33.20261437908497,
      "grad_norm": 0.007289832923561335,
      "learning_rate": 0.0002015686274509804,
      "loss": 0.0157,
      "step": 10160
    },
    {
      "epoch": 33.26797385620915,
      "grad_norm": 0.6165255904197693,
      "learning_rate": 0.00020078431372549016,
      "loss": 0.0205,
      "step": 10180
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 18.859167098999023,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.0634,
      "step": 10200
    },
    {
      "epoch": 33.39869281045752,
      "grad_norm": 0.017813820391893387,
      "learning_rate": 0.00019921568627450978,
      "loss": 0.0299,
      "step": 10220
    },
    {
      "epoch": 33.4640522875817,
      "grad_norm": 0.0054038031958043575,
      "learning_rate": 0.00019843137254901957,
      "loss": 0.0888,
      "step": 10240
    },
    {
      "epoch": 33.529411764705884,
      "grad_norm": 0.010868747718632221,
      "learning_rate": 0.0001976470588235294,
      "loss": 0.0248,
      "step": 10260
    },
    {
      "epoch": 33.59477124183007,
      "grad_norm": 0.3870466649532318,
      "learning_rate": 0.0001968627450980392,
      "loss": 0.0758,
      "step": 10280
    },
    {
      "epoch": 33.66013071895425,
      "grad_norm": 0.012867181561887264,
      "learning_rate": 0.000196078431372549,
      "loss": 0.0235,
      "step": 10300
    },
    {
      "epoch": 33.72549019607843,
      "grad_norm": 0.009927883744239807,
      "learning_rate": 0.0001952941176470588,
      "loss": 0.0287,
      "step": 10320
    },
    {
      "epoch": 33.790849673202615,
      "grad_norm": 0.003079569898545742,
      "learning_rate": 0.00019450980392156863,
      "loss": 0.0257,
      "step": 10340
    },
    {
      "epoch": 33.8562091503268,
      "grad_norm": 0.006659381557255983,
      "learning_rate": 0.00019372549019607842,
      "loss": 0.0683,
      "step": 10360
    },
    {
      "epoch": 33.92156862745098,
      "grad_norm": 0.08114565163850784,
      "learning_rate": 0.00019294117647058825,
      "loss": 0.1076,
      "step": 10380
    },
    {
      "epoch": 33.98692810457516,
      "grad_norm": 3.2611281871795654,
      "learning_rate": 0.000192156862745098,
      "loss": 0.0191,
      "step": 10400
    },
    {
      "epoch": 34.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8986232790988735,
      "eval_f1": 0.9148936170212766,
      "eval_loss": 0.7735298275947571,
      "eval_runtime": 12.0032,
      "eval_samples_per_second": 33.991,
      "eval_steps_per_second": 4.249,
      "step": 10404
    },
    {
      "epoch": 34.052287581699346,
      "grad_norm": 0.07411973178386688,
      "learning_rate": 0.0001913725490196078,
      "loss": 0.0498,
      "step": 10420
    },
    {
      "epoch": 34.11764705882353,
      "grad_norm": 0.0021266660187393427,
      "learning_rate": 0.00019058823529411763,
      "loss": 0.0654,
      "step": 10440
    },
    {
      "epoch": 34.18300653594771,
      "grad_norm": 0.030442295596003532,
      "learning_rate": 0.00018980392156862743,
      "loss": 0.0257,
      "step": 10460
    },
    {
      "epoch": 34.248366013071895,
      "grad_norm": 0.011513087898492813,
      "learning_rate": 0.00018901960784313722,
      "loss": 0.025,
      "step": 10480
    },
    {
      "epoch": 34.31372549019608,
      "grad_norm": 0.008895662613213062,
      "learning_rate": 0.00018823529411764704,
      "loss": 0.0033,
      "step": 10500
    },
    {
      "epoch": 34.37908496732026,
      "grad_norm": 2.4380106925964355,
      "learning_rate": 0.00018745098039215684,
      "loss": 0.024,
      "step": 10520
    },
    {
      "epoch": 34.44444444444444,
      "grad_norm": 0.0013092606095597148,
      "learning_rate": 0.00018666666666666666,
      "loss": 0.0491,
      "step": 10540
    },
    {
      "epoch": 34.509803921568626,
      "grad_norm": 0.0018807768356055021,
      "learning_rate": 0.00018588235294117645,
      "loss": 0.0292,
      "step": 10560
    },
    {
      "epoch": 34.57516339869281,
      "grad_norm": 0.028735900297760963,
      "learning_rate": 0.00018509803921568628,
      "loss": 0.0182,
      "step": 10580
    },
    {
      "epoch": 34.64052287581699,
      "grad_norm": 0.05273665860295296,
      "learning_rate": 0.00018431372549019607,
      "loss": 0.0005,
      "step": 10600
    },
    {
      "epoch": 34.705882352941174,
      "grad_norm": 0.03913336992263794,
      "learning_rate": 0.0001835294117647059,
      "loss": 0.0638,
      "step": 10620
    },
    {
      "epoch": 34.77124183006536,
      "grad_norm": 3.682347536087036,
      "learning_rate": 0.00018274509803921566,
      "loss": 0.0376,
      "step": 10640
    },
    {
      "epoch": 34.83660130718954,
      "grad_norm": 1.3287274837493896,
      "learning_rate": 0.00018196078431372546,
      "loss": 0.0578,
      "step": 10660
    },
    {
      "epoch": 34.90196078431372,
      "grad_norm": 0.05907914415001869,
      "learning_rate": 0.00018117647058823528,
      "loss": 0.0764,
      "step": 10680
    },
    {
      "epoch": 34.967320261437905,
      "grad_norm": 0.03907959163188934,
      "learning_rate": 0.00018039215686274507,
      "loss": 0.005,
      "step": 10700
    },
    {
      "epoch": 35.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9132130124777184,
      "eval_f1": 0.9269162210338681,
      "eval_loss": 0.7185994982719421,
      "eval_runtime": 11.9875,
      "eval_samples_per_second": 34.035,
      "eval_steps_per_second": 4.254,
      "step": 10710
    },
    {
      "epoch": 35.032679738562095,
      "grad_norm": 0.0055607943795621395,
      "learning_rate": 0.00017960784313725487,
      "loss": 0.0356,
      "step": 10720
    },
    {
      "epoch": 35.09803921568628,
      "grad_norm": 0.019560569897294044,
      "learning_rate": 0.0001788235294117647,
      "loss": 0.0973,
      "step": 10740
    },
    {
      "epoch": 35.16339869281046,
      "grad_norm": 16.977909088134766,
      "learning_rate": 0.00017803921568627449,
      "loss": 0.0336,
      "step": 10760
    },
    {
      "epoch": 35.22875816993464,
      "grad_norm": 0.22344210743904114,
      "learning_rate": 0.0001772549019607843,
      "loss": 0.0554,
      "step": 10780
    },
    {
      "epoch": 35.294117647058826,
      "grad_norm": 2.036310911178589,
      "learning_rate": 0.0001764705882352941,
      "loss": 0.0241,
      "step": 10800
    },
    {
      "epoch": 35.35947712418301,
      "grad_norm": 5.5088019371032715,
      "learning_rate": 0.00017568627450980392,
      "loss": 0.0346,
      "step": 10820
    },
    {
      "epoch": 35.42483660130719,
      "grad_norm": 5.9694294929504395,
      "learning_rate": 0.00017490196078431372,
      "loss": 0.0657,
      "step": 10840
    },
    {
      "epoch": 35.490196078431374,
      "grad_norm": 0.00941168237477541,
      "learning_rate": 0.00017411764705882354,
      "loss": 0.0705,
      "step": 10860
    },
    {
      "epoch": 35.55555555555556,
      "grad_norm": 24.943309783935547,
      "learning_rate": 0.0001733333333333333,
      "loss": 0.0277,
      "step": 10880
    },
    {
      "epoch": 35.62091503267974,
      "grad_norm": 0.6147581338882446,
      "learning_rate": 0.0001725490196078431,
      "loss": 0.0575,
      "step": 10900
    },
    {
      "epoch": 35.68627450980392,
      "grad_norm": 0.050405971705913544,
      "learning_rate": 0.00017176470588235293,
      "loss": 0.0374,
      "step": 10920
    },
    {
      "epoch": 35.751633986928105,
      "grad_norm": 13.863428115844727,
      "learning_rate": 0.00017098039215686272,
      "loss": 0.1073,
      "step": 10940
    },
    {
      "epoch": 35.81699346405229,
      "grad_norm": 0.015267840586602688,
      "learning_rate": 0.00017019607843137252,
      "loss": 0.0076,
      "step": 10960
    },
    {
      "epoch": 35.88235294117647,
      "grad_norm": 0.008260664530098438,
      "learning_rate": 0.00016941176470588234,
      "loss": 0.0743,
      "step": 10980
    },
    {
      "epoch": 35.947712418300654,
      "grad_norm": 13.668479919433594,
      "learning_rate": 0.00016862745098039213,
      "loss": 0.0702,
      "step": 11000
    },
    {
      "epoch": 36.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8948658410732715,
      "eval_f1": 0.912280701754386,
      "eval_loss": 0.7782724499702454,
      "eval_runtime": 11.9998,
      "eval_samples_per_second": 34.001,
      "eval_steps_per_second": 4.25,
      "step": 11016
    },
    {
      "epoch": 36.01307189542484,
      "grad_norm": 0.03880292922258377,
      "learning_rate": 0.00016784313725490196,
      "loss": 0.0382,
      "step": 11020
    },
    {
      "epoch": 36.07843137254902,
      "grad_norm": 0.08596394956111908,
      "learning_rate": 0.00016705882352941175,
      "loss": 0.0238,
      "step": 11040
    },
    {
      "epoch": 36.1437908496732,
      "grad_norm": 0.020947903394699097,
      "learning_rate": 0.00016627450980392157,
      "loss": 0.0318,
      "step": 11060
    },
    {
      "epoch": 36.209150326797385,
      "grad_norm": 3.821126937866211,
      "learning_rate": 0.00016549019607843137,
      "loss": 0.0047,
      "step": 11080
    },
    {
      "epoch": 36.27450980392157,
      "grad_norm": 1.1249099969863892,
      "learning_rate": 0.0001647058823529412,
      "loss": 0.0262,
      "step": 11100
    },
    {
      "epoch": 36.33986928104575,
      "grad_norm": 8.321978569030762,
      "learning_rate": 0.00016392156862745096,
      "loss": 0.0289,
      "step": 11120
    },
    {
      "epoch": 36.40522875816993,
      "grad_norm": 2.3819286823272705,
      "learning_rate": 0.00016313725490196075,
      "loss": 0.0082,
      "step": 11140
    },
    {
      "epoch": 36.470588235294116,
      "grad_norm": 0.25911593437194824,
      "learning_rate": 0.00016235294117647057,
      "loss": 0.0474,
      "step": 11160
    },
    {
      "epoch": 36.5359477124183,
      "grad_norm": 0.0067910198122262955,
      "learning_rate": 0.00016156862745098037,
      "loss": 0.0413,
      "step": 11180
    },
    {
      "epoch": 36.60130718954248,
      "grad_norm": 0.0013846359215676785,
      "learning_rate": 0.00016078431372549016,
      "loss": 0.0005,
      "step": 11200
    },
    {
      "epoch": 36.666666666666664,
      "grad_norm": 0.028200209140777588,
      "learning_rate": 0.00015999999999999999,
      "loss": 0.0912,
      "step": 11220
    },
    {
      "epoch": 36.73202614379085,
      "grad_norm": 0.0012054393300786614,
      "learning_rate": 0.00015921568627450978,
      "loss": 0.0024,
      "step": 11240
    },
    {
      "epoch": 36.79738562091503,
      "grad_norm": 0.006309848744422197,
      "learning_rate": 0.0001584313725490196,
      "loss": 0.0019,
      "step": 11260
    },
    {
      "epoch": 36.86274509803921,
      "grad_norm": 0.025432052090764046,
      "learning_rate": 0.0001576470588235294,
      "loss": 0.0286,
      "step": 11280
    },
    {
      "epoch": 36.928104575163395,
      "grad_norm": 0.03749048709869385,
      "learning_rate": 0.00015686274509803922,
      "loss": 0.0076,
      "step": 11300
    },
    {
      "epoch": 36.99346405228758,
      "grad_norm": 0.006600791122764349,
      "learning_rate": 0.00015607843137254901,
      "loss": 0.0659,
      "step": 11320
    },
    {
      "epoch": 37.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8990712074303405,
      "eval_f1": 0.9157894736842105,
      "eval_loss": 0.9136860966682434,
      "eval_runtime": 12.0156,
      "eval_samples_per_second": 33.956,
      "eval_steps_per_second": 4.244,
      "step": 11322
    },
    {
      "epoch": 37.05882352941177,
      "grad_norm": 0.003952465020120144,
      "learning_rate": 0.00015529411764705884,
      "loss": 0.0354,
      "step": 11340
    },
    {
      "epoch": 37.12418300653595,
      "grad_norm": 0.009438013657927513,
      "learning_rate": 0.0001545098039215686,
      "loss": 0.0458,
      "step": 11360
    },
    {
      "epoch": 37.189542483660134,
      "grad_norm": 0.7044521570205688,
      "learning_rate": 0.0001537254901960784,
      "loss": 0.0232,
      "step": 11380
    },
    {
      "epoch": 37.254901960784316,
      "grad_norm": 0.02807343378663063,
      "learning_rate": 0.00015294117647058822,
      "loss": 0.0168,
      "step": 11400
    },
    {
      "epoch": 37.3202614379085,
      "grad_norm": 0.0017567480681464076,
      "learning_rate": 0.00015215686274509802,
      "loss": 0.0156,
      "step": 11420
    },
    {
      "epoch": 37.38562091503268,
      "grad_norm": 0.0026547410525381565,
      "learning_rate": 0.0001513725490196078,
      "loss": 0.0255,
      "step": 11440
    },
    {
      "epoch": 37.450980392156865,
      "grad_norm": 0.0011854588519781828,
      "learning_rate": 0.00015058823529411763,
      "loss": 0.004,
      "step": 11460
    },
    {
      "epoch": 37.51633986928105,
      "grad_norm": 0.0003061951429117471,
      "learning_rate": 0.00014980392156862743,
      "loss": 0.0135,
      "step": 11480
    },
    {
      "epoch": 37.58169934640523,
      "grad_norm": 0.004650830291211605,
      "learning_rate": 0.00014901960784313725,
      "loss": 0.0349,
      "step": 11500
    },
    {
      "epoch": 37.64705882352941,
      "grad_norm": 0.0012806616723537445,
      "learning_rate": 0.00014823529411764705,
      "loss": 0.0632,
      "step": 11520
    },
    {
      "epoch": 37.712418300653596,
      "grad_norm": 0.0004870025150012225,
      "learning_rate": 0.00014745098039215684,
      "loss": 0.0004,
      "step": 11540
    },
    {
      "epoch": 37.77777777777778,
      "grad_norm": 0.006283299531787634,
      "learning_rate": 0.00014666666666666664,
      "loss": 0.0838,
      "step": 11560
    },
    {
      "epoch": 37.84313725490196,
      "grad_norm": 0.008425690233707428,
      "learning_rate": 0.00014588235294117646,
      "loss": 0.0172,
      "step": 11580
    },
    {
      "epoch": 37.908496732026144,
      "grad_norm": 0.001795462449081242,
      "learning_rate": 0.00014509803921568625,
      "loss": 0.0344,
      "step": 11600
    },
    {
      "epoch": 37.97385620915033,
      "grad_norm": 0.0035706390626728535,
      "learning_rate": 0.00014431372549019607,
      "loss": 0.0088,
      "step": 11620
    },
    {
      "epoch": 38.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9012460938841386,
      "eval_f1": 0.9176882661996497,
      "eval_loss": 0.855586051940918,
      "eval_runtime": 12.0159,
      "eval_samples_per_second": 33.955,
      "eval_steps_per_second": 4.244,
      "step": 11628
    },
    {
      "epoch": 38.03921568627451,
      "grad_norm": 0.0011860092636197805,
      "learning_rate": 0.00014352941176470587,
      "loss": 0.0674,
      "step": 11640
    },
    {
      "epoch": 38.10457516339869,
      "grad_norm": 0.015322857536375523,
      "learning_rate": 0.00014274509803921566,
      "loss": 0.0643,
      "step": 11660
    },
    {
      "epoch": 38.169934640522875,
      "grad_norm": 0.008157795295119286,
      "learning_rate": 0.00014196078431372546,
      "loss": 0.0006,
      "step": 11680
    },
    {
      "epoch": 38.23529411764706,
      "grad_norm": 0.01067617442458868,
      "learning_rate": 0.00014117647058823528,
      "loss": 0.0035,
      "step": 11700
    },
    {
      "epoch": 38.30065359477124,
      "grad_norm": 0.04996981471776962,
      "learning_rate": 0.00014039215686274508,
      "loss": 0.0055,
      "step": 11720
    },
    {
      "epoch": 38.36601307189542,
      "grad_norm": 0.009329662658274174,
      "learning_rate": 0.0001396078431372549,
      "loss": 0.0299,
      "step": 11740
    },
    {
      "epoch": 38.431372549019606,
      "grad_norm": 0.0050108665600419044,
      "learning_rate": 0.0001388235294117647,
      "loss": 0.0223,
      "step": 11760
    },
    {
      "epoch": 38.49673202614379,
      "grad_norm": 0.0059908367693424225,
      "learning_rate": 0.0001380392156862745,
      "loss": 0.0012,
      "step": 11780
    },
    {
      "epoch": 38.56209150326797,
      "grad_norm": 0.003566117724403739,
      "learning_rate": 0.00013725490196078428,
      "loss": 0.0457,
      "step": 11800
    },
    {
      "epoch": 38.627450980392155,
      "grad_norm": 0.004538585897535086,
      "learning_rate": 0.0001364705882352941,
      "loss": 0.0509,
      "step": 11820
    },
    {
      "epoch": 38.69281045751634,
      "grad_norm": 0.7317847013473511,
      "learning_rate": 0.0001356862745098039,
      "loss": 0.0265,
      "step": 11840
    },
    {
      "epoch": 38.75816993464052,
      "grad_norm": 0.0022524860687553883,
      "learning_rate": 0.00013490196078431372,
      "loss": 0.0506,
      "step": 11860
    },
    {
      "epoch": 38.8235294117647,
      "grad_norm": 0.03130611777305603,
      "learning_rate": 0.00013411764705882352,
      "loss": 0.029,
      "step": 11880
    },
    {
      "epoch": 38.888888888888886,
      "grad_norm": 17.324174880981445,
      "learning_rate": 0.0001333333333333333,
      "loss": 0.0762,
      "step": 11900
    },
    {
      "epoch": 38.95424836601307,
      "grad_norm": 10.724264144897461,
      "learning_rate": 0.0001325490196078431,
      "loss": 0.0418,
      "step": 11920
    },
    {
      "epoch": 39.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9053098831799855,
      "eval_f1": 0.9209138840070299,
      "eval_loss": 0.775185227394104,
      "eval_runtime": 12.0157,
      "eval_samples_per_second": 33.956,
      "eval_steps_per_second": 4.244,
      "step": 11934
    },
    {
      "epoch": 39.01960784313726,
      "grad_norm": 0.008471088483929634,
      "learning_rate": 0.00013176470588235293,
      "loss": 0.0335,
      "step": 11940
    },
    {
      "epoch": 39.08496732026144,
      "grad_norm": 0.07391174137592316,
      "learning_rate": 0.00013098039215686272,
      "loss": 0.0016,
      "step": 11960
    },
    {
      "epoch": 39.150326797385624,
      "grad_norm": 0.0029603284783661366,
      "learning_rate": 0.00013019607843137255,
      "loss": 0.0327,
      "step": 11980
    },
    {
      "epoch": 39.21568627450981,
      "grad_norm": 0.06725901365280151,
      "learning_rate": 0.00012941176470588234,
      "loss": 0.0044,
      "step": 12000
    },
    {
      "epoch": 39.28104575163399,
      "grad_norm": 0.0015182013157755136,
      "learning_rate": 0.00012862745098039214,
      "loss": 0.0009,
      "step": 12020
    },
    {
      "epoch": 39.34640522875817,
      "grad_norm": 0.002461310476064682,
      "learning_rate": 0.00012784313725490193,
      "loss": 0.057,
      "step": 12040
    },
    {
      "epoch": 39.411764705882355,
      "grad_norm": 0.060147132724523544,
      "learning_rate": 0.00012705882352941175,
      "loss": 0.0218,
      "step": 12060
    },
    {
      "epoch": 39.47712418300654,
      "grad_norm": 0.0012022998416796327,
      "learning_rate": 0.00012627450980392155,
      "loss": 0.0303,
      "step": 12080
    },
    {
      "epoch": 39.54248366013072,
      "grad_norm": 0.004612680524587631,
      "learning_rate": 0.00012549019607843137,
      "loss": 0.0781,
      "step": 12100
    },
    {
      "epoch": 39.6078431372549,
      "grad_norm": 0.0010487587423995137,
      "learning_rate": 0.00012470588235294117,
      "loss": 0.0401,
      "step": 12120
    },
    {
      "epoch": 39.673202614379086,
      "grad_norm": 0.14129246771335602,
      "learning_rate": 0.00012392156862745096,
      "loss": 0.0007,
      "step": 12140
    },
    {
      "epoch": 39.73856209150327,
      "grad_norm": 0.00923753622919321,
      "learning_rate": 0.00012313725490196078,
      "loss": 0.0366,
      "step": 12160
    },
    {
      "epoch": 39.80392156862745,
      "grad_norm": 0.24252493679523468,
      "learning_rate": 0.00012235294117647058,
      "loss": 0.0399,
      "step": 12180
    },
    {
      "epoch": 39.869281045751634,
      "grad_norm": 0.005963262170553207,
      "learning_rate": 0.00012156862745098039,
      "loss": 0.0403,
      "step": 12200
    },
    {
      "epoch": 39.93464052287582,
      "grad_norm": 0.22681176662445068,
      "learning_rate": 0.0001207843137254902,
      "loss": 0.0376,
      "step": 12220
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.005251907743513584,
      "learning_rate": 0.00011999999999999999,
      "loss": 0.0016,
      "step": 12240
    },
    {
      "epoch": 40.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9069325238992394,
      "eval_f1": 0.9217081850533807,
      "eval_loss": 0.7939047813415527,
      "eval_runtime": 12.0202,
      "eval_samples_per_second": 33.943,
      "eval_steps_per_second": 4.243,
      "step": 12240
    },
    {
      "epoch": 40.06535947712418,
      "grad_norm": 0.008715108036994934,
      "learning_rate": 0.00011921568627450978,
      "loss": 0.0339,
      "step": 12260
    },
    {
      "epoch": 40.130718954248366,
      "grad_norm": 22.261341094970703,
      "learning_rate": 0.00011843137254901959,
      "loss": 0.0138,
      "step": 12280
    },
    {
      "epoch": 40.19607843137255,
      "grad_norm": 0.002509787678718567,
      "learning_rate": 0.0001176470588235294,
      "loss": 0.0309,
      "step": 12300
    },
    {
      "epoch": 40.26143790849673,
      "grad_norm": 17.805051803588867,
      "learning_rate": 0.00011686274509803921,
      "loss": 0.0374,
      "step": 12320
    },
    {
      "epoch": 40.326797385620914,
      "grad_norm": 0.13505147397518158,
      "learning_rate": 0.00011607843137254902,
      "loss": 0.0005,
      "step": 12340
    },
    {
      "epoch": 40.3921568627451,
      "grad_norm": 0.0024378166999667883,
      "learning_rate": 0.00011529411764705881,
      "loss": 0.0381,
      "step": 12360
    },
    {
      "epoch": 40.45751633986928,
      "grad_norm": 0.0035523036494851112,
      "learning_rate": 0.00011450980392156861,
      "loss": 0.0482,
      "step": 12380
    },
    {
      "epoch": 40.52287581699346,
      "grad_norm": 0.004899564664810896,
      "learning_rate": 0.00011372549019607842,
      "loss": 0.0073,
      "step": 12400
    },
    {
      "epoch": 40.588235294117645,
      "grad_norm": 0.0004574346530716866,
      "learning_rate": 0.00011294117647058823,
      "loss": 0.041,
      "step": 12420
    },
    {
      "epoch": 40.65359477124183,
      "grad_norm": 0.002244582399725914,
      "learning_rate": 0.00011215686274509803,
      "loss": 0.0162,
      "step": 12440
    },
    {
      "epoch": 40.71895424836601,
      "grad_norm": 0.023113537579774857,
      "learning_rate": 0.00011137254901960784,
      "loss": 0.0738,
      "step": 12460
    },
    {
      "epoch": 40.78431372549019,
      "grad_norm": 0.005311340559273958,
      "learning_rate": 0.00011058823529411765,
      "loss": 0.0326,
      "step": 12480
    },
    {
      "epoch": 40.849673202614376,
      "grad_norm": 0.04850431904196739,
      "learning_rate": 0.00010980392156862743,
      "loss": 0.0054,
      "step": 12500
    },
    {
      "epoch": 40.91503267973856,
      "grad_norm": 15.276747703552246,
      "learning_rate": 0.00010901960784313724,
      "loss": 0.0438,
      "step": 12520
    },
    {
      "epoch": 40.98039215686274,
      "grad_norm": 0.02536921575665474,
      "learning_rate": 0.00010823529411764705,
      "loss": 0.0453,
      "step": 12540
    },
    {
      "epoch": 41.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9031344932339133,
      "eval_f1": 0.9190140845070423,
      "eval_loss": 0.8086125254631042,
      "eval_runtime": 12.0075,
      "eval_samples_per_second": 33.979,
      "eval_steps_per_second": 4.247,
      "step": 12546
    },
    {
      "epoch": 41.04575163398693,
      "grad_norm": 0.00920095480978489,
      "learning_rate": 0.00010745098039215686,
      "loss": 0.0599,
      "step": 12560
    },
    {
      "epoch": 41.111111111111114,
      "grad_norm": 0.005745685193687677,
      "learning_rate": 0.00010666666666666667,
      "loss": 0.0277,
      "step": 12580
    },
    {
      "epoch": 41.1764705882353,
      "grad_norm": 0.006539508700370789,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.0775,
      "step": 12600
    },
    {
      "epoch": 41.24183006535948,
      "grad_norm": 0.0013951188884675503,
      "learning_rate": 0.00010509803921568626,
      "loss": 0.0382,
      "step": 12620
    },
    {
      "epoch": 41.30718954248366,
      "grad_norm": 6.926145076751709,
      "learning_rate": 0.00010431372549019606,
      "loss": 0.036,
      "step": 12640
    },
    {
      "epoch": 41.372549019607845,
      "grad_norm": 0.0024005293380469084,
      "learning_rate": 0.00010352941176470587,
      "loss": 0.0145,
      "step": 12660
    },
    {
      "epoch": 41.43790849673203,
      "grad_norm": 0.010927188210189342,
      "learning_rate": 0.00010274509803921568,
      "loss": 0.0258,
      "step": 12680
    },
    {
      "epoch": 41.50326797385621,
      "grad_norm": 4.0781402587890625,
      "learning_rate": 0.00010196078431372549,
      "loss": 0.0094,
      "step": 12700
    },
    {
      "epoch": 41.568627450980394,
      "grad_norm": 0.04150167480111122,
      "learning_rate": 0.0001011764705882353,
      "loss": 0.0074,
      "step": 12720
    },
    {
      "epoch": 41.63398692810458,
      "grad_norm": 11.467419624328613,
      "learning_rate": 0.00010039215686274508,
      "loss": 0.0503,
      "step": 12740
    },
    {
      "epoch": 41.69934640522876,
      "grad_norm": 0.009463032707571983,
      "learning_rate": 9.960784313725489e-05,
      "loss": 0.0001,
      "step": 12760
    },
    {
      "epoch": 41.76470588235294,
      "grad_norm": 0.0028812768869102,
      "learning_rate": 9.88235294117647e-05,
      "loss": 0.0154,
      "step": 12780
    },
    {
      "epoch": 41.830065359477125,
      "grad_norm": 0.06382673978805542,
      "learning_rate": 9.80392156862745e-05,
      "loss": 0.0075,
      "step": 12800
    },
    {
      "epoch": 41.89542483660131,
      "grad_norm": 0.0006243017269298434,
      "learning_rate": 9.725490196078431e-05,
      "loss": 0.0437,
      "step": 12820
    },
    {
      "epoch": 41.96078431372549,
      "grad_norm": 0.0004670910129789263,
      "learning_rate": 9.647058823529412e-05,
      "loss": 0.0282,
      "step": 12840
    },
    {
      "epoch": 42.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9051704014939308,
      "eval_f1": 0.9206349206349206,
      "eval_loss": 0.8442879319190979,
      "eval_runtime": 12.0034,
      "eval_samples_per_second": 33.99,
      "eval_steps_per_second": 4.249,
      "step": 12852
    },
    {
      "epoch": 42.02614379084967,
      "grad_norm": 0.10631930828094482,
      "learning_rate": 9.56862745098039e-05,
      "loss": 0.0619,
      "step": 12860
    },
    {
      "epoch": 42.091503267973856,
      "grad_norm": 0.014079145155847073,
      "learning_rate": 9.490196078431371e-05,
      "loss": 0.0067,
      "step": 12880
    },
    {
      "epoch": 42.15686274509804,
      "grad_norm": 0.0009753727936185896,
      "learning_rate": 9.411764705882352e-05,
      "loss": 0.0221,
      "step": 12900
    },
    {
      "epoch": 42.22222222222222,
      "grad_norm": 0.003041790798306465,
      "learning_rate": 9.333333333333333e-05,
      "loss": 0.0318,
      "step": 12920
    },
    {
      "epoch": 42.287581699346404,
      "grad_norm": 0.06354819238185883,
      "learning_rate": 9.254901960784314e-05,
      "loss": 0.0091,
      "step": 12940
    },
    {
      "epoch": 42.35294117647059,
      "grad_norm": 0.0137392058968544,
      "learning_rate": 9.176470588235295e-05,
      "loss": 0.0101,
      "step": 12960
    },
    {
      "epoch": 42.41830065359477,
      "grad_norm": 22.442182540893555,
      "learning_rate": 9.098039215686273e-05,
      "loss": 0.0475,
      "step": 12980
    },
    {
      "epoch": 42.48366013071895,
      "grad_norm": 0.0010363621404394507,
      "learning_rate": 9.019607843137254e-05,
      "loss": 0.0438,
      "step": 13000
    },
    {
      "epoch": 42.549019607843135,
      "grad_norm": 0.0017101987032219768,
      "learning_rate": 8.941176470588235e-05,
      "loss": 0.0226,
      "step": 13020
    },
    {
      "epoch": 42.61437908496732,
      "grad_norm": 0.005821059457957745,
      "learning_rate": 8.862745098039215e-05,
      "loss": 0.0325,
      "step": 13040
    },
    {
      "epoch": 42.6797385620915,
      "grad_norm": 0.5014206171035767,
      "learning_rate": 8.784313725490196e-05,
      "loss": 0.0052,
      "step": 13060
    },
    {
      "epoch": 42.745098039215684,
      "grad_norm": 0.0007988262223079801,
      "learning_rate": 8.705882352941177e-05,
      "loss": 0.0053,
      "step": 13080
    },
    {
      "epoch": 42.810457516339866,
      "grad_norm": 0.0004439474723767489,
      "learning_rate": 8.627450980392155e-05,
      "loss": 0.0034,
      "step": 13100
    },
    {
      "epoch": 42.87581699346405,
      "grad_norm": 0.0005699064349755645,
      "learning_rate": 8.549019607843136e-05,
      "loss": 0.0011,
      "step": 13120
    },
    {
      "epoch": 42.94117647058823,
      "grad_norm": 0.0023188516497612,
      "learning_rate": 8.470588235294117e-05,
      "loss": 0.0223,
      "step": 13140
    },
    {
      "epoch": 43.0,
      "eval_accuracy": 0.9044117647058824,
      "eval_combined_score": 0.9173221614227086,
      "eval_f1": 0.9302325581395349,
      "eval_loss": 0.8887246251106262,
      "eval_runtime": 11.9998,
      "eval_samples_per_second": 34.0,
      "eval_steps_per_second": 4.25,
      "step": 13158
    },
    {
      "epoch": 43.00653594771242,
      "grad_norm": 26.741992950439453,
      "learning_rate": 8.392156862745098e-05,
      "loss": 0.0165,
      "step": 13160
    },
    {
      "epoch": 43.071895424836605,
      "grad_norm": 0.00016351061640307307,
      "learning_rate": 8.313725490196079e-05,
      "loss": 0.056,
      "step": 13180
    },
    {
      "epoch": 43.13725490196079,
      "grad_norm": 14.125733375549316,
      "learning_rate": 8.23529411764706e-05,
      "loss": 0.0259,
      "step": 13200
    },
    {
      "epoch": 43.20261437908497,
      "grad_norm": 0.00023561625857837498,
      "learning_rate": 8.156862745098038e-05,
      "loss": 0.0114,
      "step": 13220
    },
    {
      "epoch": 43.26797385620915,
      "grad_norm": 0.14441248774528503,
      "learning_rate": 8.078431372549018e-05,
      "loss": 0.0115,
      "step": 13240
    },
    {
      "epoch": 43.333333333333336,
      "grad_norm": 0.00013861741172149777,
      "learning_rate": 7.999999999999999e-05,
      "loss": 0.0292,
      "step": 13260
    },
    {
      "epoch": 43.39869281045752,
      "grad_norm": 17.148468017578125,
      "learning_rate": 7.92156862745098e-05,
      "loss": 0.045,
      "step": 13280
    },
    {
      "epoch": 43.4640522875817,
      "grad_norm": 0.02142764814198017,
      "learning_rate": 7.843137254901961e-05,
      "loss": 0.0233,
      "step": 13300
    },
    {
      "epoch": 43.529411764705884,
      "grad_norm": 0.1238461285829544,
      "learning_rate": 7.764705882352942e-05,
      "loss": 0.0292,
      "step": 13320
    },
    {
      "epoch": 43.59477124183007,
      "grad_norm": 0.018938297405838966,
      "learning_rate": 7.68627450980392e-05,
      "loss": 0.0441,
      "step": 13340
    },
    {
      "epoch": 43.66013071895425,
      "grad_norm": 0.0009758250671438873,
      "learning_rate": 7.607843137254901e-05,
      "loss": 0.0422,
      "step": 13360
    },
    {
      "epoch": 43.72549019607843,
      "grad_norm": 0.005212064366787672,
      "learning_rate": 7.529411764705882e-05,
      "loss": 0.0328,
      "step": 13380
    },
    {
      "epoch": 43.790849673202615,
      "grad_norm": 0.0015294081531465054,
      "learning_rate": 7.450980392156863e-05,
      "loss": 0.003,
      "step": 13400
    },
    {
      "epoch": 43.8562091503268,
      "grad_norm": 0.00021617852326016873,
      "learning_rate": 7.372549019607842e-05,
      "loss": 0.0413,
      "step": 13420
    },
    {
      "epoch": 43.92156862745098,
      "grad_norm": 0.001040665665641427,
      "learning_rate": 7.294117647058823e-05,
      "loss": 0.0126,
      "step": 13440
    },
    {
      "epoch": 43.98692810457516,
      "grad_norm": 0.0008516125380992889,
      "learning_rate": 7.215686274509804e-05,
      "loss": 0.0321,
      "step": 13460
    },
    {
      "epoch": 44.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9130822722648988,
      "eval_f1": 0.9266547406082289,
      "eval_loss": 0.8685121536254883,
      "eval_runtime": 12.0093,
      "eval_samples_per_second": 33.974,
      "eval_steps_per_second": 4.247,
      "step": 13464
    },
    {
      "epoch": 44.052287581699346,
      "grad_norm": 0.0010382791515439749,
      "learning_rate": 7.137254901960783e-05,
      "loss": 0.047,
      "step": 13480
    },
    {
      "epoch": 44.11764705882353,
      "grad_norm": 0.0022696414962410927,
      "learning_rate": 7.058823529411764e-05,
      "loss": 0.0128,
      "step": 13500
    },
    {
      "epoch": 44.18300653594771,
      "grad_norm": 0.00016812537796795368,
      "learning_rate": 6.980392156862745e-05,
      "loss": 0.0004,
      "step": 13520
    },
    {
      "epoch": 44.248366013071895,
      "grad_norm": 0.6702955365180969,
      "learning_rate": 6.901960784313724e-05,
      "loss": 0.0697,
      "step": 13540
    },
    {
      "epoch": 44.31372549019608,
      "grad_norm": 0.0037113239523023367,
      "learning_rate": 6.823529411764705e-05,
      "loss": 0.0195,
      "step": 13560
    },
    {
      "epoch": 44.37908496732026,
      "grad_norm": 9.668734550476074,
      "learning_rate": 6.745098039215686e-05,
      "loss": 0.0241,
      "step": 13580
    },
    {
      "epoch": 44.44444444444444,
      "grad_norm": 0.003622929099947214,
      "learning_rate": 6.666666666666666e-05,
      "loss": 0.0061,
      "step": 13600
    },
    {
      "epoch": 44.509803921568626,
      "grad_norm": 0.0005844589322805405,
      "learning_rate": 6.588235294117646e-05,
      "loss": 0.0717,
      "step": 13620
    },
    {
      "epoch": 44.57516339869281,
      "grad_norm": 0.0017556867096573114,
      "learning_rate": 6.509803921568627e-05,
      "loss": 0.0292,
      "step": 13640
    },
    {
      "epoch": 44.64052287581699,
      "grad_norm": 0.0010264088632538915,
      "learning_rate": 6.431372549019607e-05,
      "loss": 0.0207,
      "step": 13660
    },
    {
      "epoch": 44.705882352941174,
      "grad_norm": 0.009578632190823555,
      "learning_rate": 6.352941176470588e-05,
      "loss": 0.0345,
      "step": 13680
    },
    {
      "epoch": 44.77124183006536,
      "grad_norm": 0.24931050837039948,
      "learning_rate": 6.274509803921569e-05,
      "loss": 0.0029,
      "step": 13700
    },
    {
      "epoch": 44.83660130718954,
      "grad_norm": 0.000827188603579998,
      "learning_rate": 6.196078431372548e-05,
      "loss": 0.0006,
      "step": 13720
    },
    {
      "epoch": 44.90196078431372,
      "grad_norm": 0.0005107025499455631,
      "learning_rate": 6.117647058823529e-05,
      "loss": 0.0253,
      "step": 13740
    },
    {
      "epoch": 44.967320261437905,
      "grad_norm": 0.0009958295850083232,
      "learning_rate": 6.03921568627451e-05,
      "loss": 0.0002,
      "step": 13760
    },
    {
      "epoch": 45.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9050299323269131,
      "eval_f1": 0.9203539823008849,
      "eval_loss": 0.8938458561897278,
      "eval_runtime": 12.011,
      "eval_samples_per_second": 33.969,
      "eval_steps_per_second": 4.246,
      "step": 13770
    },
    {
      "epoch": 45.032679738562095,
      "grad_norm": 6.550017356872559,
      "learning_rate": 5.960784313725489e-05,
      "loss": 0.0596,
      "step": 13780
    },
    {
      "epoch": 45.09803921568628,
      "grad_norm": 0.014376808889210224,
      "learning_rate": 5.88235294117647e-05,
      "loss": 0.0104,
      "step": 13800
    },
    {
      "epoch": 45.16339869281046,
      "grad_norm": 0.2917715013027191,
      "learning_rate": 5.803921568627451e-05,
      "loss": 0.0319,
      "step": 13820
    },
    {
      "epoch": 45.22875816993464,
      "grad_norm": 0.03411724418401718,
      "learning_rate": 5.7254901960784304e-05,
      "loss": 0.0138,
      "step": 13840
    },
    {
      "epoch": 45.294117647058826,
      "grad_norm": 0.019728342071175575,
      "learning_rate": 5.647058823529411e-05,
      "loss": 0.0177,
      "step": 13860
    },
    {
      "epoch": 45.35947712418301,
      "grad_norm": 0.3196159601211548,
      "learning_rate": 5.568627450980392e-05,
      "loss": 0.0203,
      "step": 13880
    },
    {
      "epoch": 45.42483660130719,
      "grad_norm": 0.00116392457857728,
      "learning_rate": 5.4901960784313716e-05,
      "loss": 0.0106,
      "step": 13900
    },
    {
      "epoch": 45.490196078431374,
      "grad_norm": 0.005020946729928255,
      "learning_rate": 5.4117647058823525e-05,
      "loss": 0.0233,
      "step": 13920
    },
    {
      "epoch": 45.55555555555556,
      "grad_norm": 0.007490407209843397,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.0393,
      "step": 13940
    },
    {
      "epoch": 45.62091503267974,
      "grad_norm": 0.00040515311411581933,
      "learning_rate": 5.254901960784313e-05,
      "loss": 0.0677,
      "step": 13960
    },
    {
      "epoch": 45.68627450980392,
      "grad_norm": 0.0005686065414920449,
      "learning_rate": 5.176470588235294e-05,
      "loss": 0.0368,
      "step": 13980
    },
    {
      "epoch": 45.751633986928105,
      "grad_norm": 0.0020725876092910767,
      "learning_rate": 5.0980392156862745e-05,
      "loss": 0.0005,
      "step": 14000
    },
    {
      "epoch": 45.81699346405229,
      "grad_norm": 0.0008246844517998397,
      "learning_rate": 5.019607843137254e-05,
      "loss": 0.0297,
      "step": 14020
    },
    {
      "epoch": 45.88235294117647,
      "grad_norm": 0.0015217262553051114,
      "learning_rate": 4.941176470588235e-05,
      "loss": 0.0339,
      "step": 14040
    },
    {
      "epoch": 45.947712418300654,
      "grad_norm": 0.012197713367640972,
      "learning_rate": 4.862745098039216e-05,
      "loss": 0.0813,
      "step": 14060
    },
    {
      "epoch": 46.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8990712074303405,
      "eval_f1": 0.9157894736842105,
      "eval_loss": 0.8794887065887451,
      "eval_runtime": 12.0107,
      "eval_samples_per_second": 33.97,
      "eval_steps_per_second": 4.246,
      "step": 14076
    },
    {
      "epoch": 46.01307189542484,
      "grad_norm": 0.0009254644392058253,
      "learning_rate": 4.784313725490195e-05,
      "loss": 0.0389,
      "step": 14080
    },
    {
      "epoch": 46.07843137254902,
      "grad_norm": 0.0017302149208262563,
      "learning_rate": 4.705882352941176e-05,
      "loss": 0.0221,
      "step": 14100
    },
    {
      "epoch": 46.1437908496732,
      "grad_norm": 0.02764674834907055,
      "learning_rate": 4.627450980392157e-05,
      "loss": 0.0365,
      "step": 14120
    },
    {
      "epoch": 46.209150326797385,
      "grad_norm": 0.009241664782166481,
      "learning_rate": 4.5490196078431364e-05,
      "loss": 0.0015,
      "step": 14140
    },
    {
      "epoch": 46.27450980392157,
      "grad_norm": 0.0006282345857471228,
      "learning_rate": 4.470588235294117e-05,
      "loss": 0.0187,
      "step": 14160
    },
    {
      "epoch": 46.33986928104575,
      "grad_norm": 0.0009652095614001155,
      "learning_rate": 4.392156862745098e-05,
      "loss": 0.0064,
      "step": 14180
    },
    {
      "epoch": 46.40522875816993,
      "grad_norm": 0.3701876401901245,
      "learning_rate": 4.3137254901960776e-05,
      "loss": 0.0109,
      "step": 14200
    },
    {
      "epoch": 46.470588235294116,
      "grad_norm": 0.23774453997612,
      "learning_rate": 4.2352941176470585e-05,
      "loss": 0.0167,
      "step": 14220
    },
    {
      "epoch": 46.5359477124183,
      "grad_norm": 8.945098876953125,
      "learning_rate": 4.156862745098039e-05,
      "loss": 0.0424,
      "step": 14240
    },
    {
      "epoch": 46.60130718954248,
      "grad_norm": 0.004712235182523727,
      "learning_rate": 4.078431372549019e-05,
      "loss": 0.0403,
      "step": 14260
    },
    {
      "epoch": 46.666666666666664,
      "grad_norm": 0.025230608880519867,
      "learning_rate": 3.9999999999999996e-05,
      "loss": 0.0986,
      "step": 14280
    },
    {
      "epoch": 46.73202614379085,
      "grad_norm": 0.0018348345765843987,
      "learning_rate": 3.9215686274509805e-05,
      "loss": 0.0061,
      "step": 14300
    },
    {
      "epoch": 46.79738562091503,
      "grad_norm": 0.7603010535240173,
      "learning_rate": 3.84313725490196e-05,
      "loss": 0.0057,
      "step": 14320
    },
    {
      "epoch": 46.86274509803921,
      "grad_norm": 0.0007393034757114947,
      "learning_rate": 3.764705882352941e-05,
      "loss": 0.0005,
      "step": 14340
    },
    {
      "epoch": 46.928104575163395,
      "grad_norm": 0.001695216167718172,
      "learning_rate": 3.686274509803921e-05,
      "loss": 0.0224,
      "step": 14360
    },
    {
      "epoch": 46.99346405228758,
      "grad_norm": 20.906003952026367,
      "learning_rate": 3.607843137254902e-05,
      "loss": 0.0525,
      "step": 14380
    },
    {
      "epoch": 47.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9092508242234947,
      "eval_f1": 0.9238938053097344,
      "eval_loss": 0.82686448097229,
      "eval_runtime": 12.3359,
      "eval_samples_per_second": 33.074,
      "eval_steps_per_second": 4.134,
      "step": 14382
    },
    {
      "epoch": 47.05882352941177,
      "grad_norm": 0.00179568724706769,
      "learning_rate": 3.529411764705882e-05,
      "loss": 0.0006,
      "step": 14400
    },
    {
      "epoch": 47.12418300653595,
      "grad_norm": 0.0003884349134750664,
      "learning_rate": 3.450980392156862e-05,
      "loss": 0.029,
      "step": 14420
    },
    {
      "epoch": 47.189542483660134,
      "grad_norm": 0.001880308729596436,
      "learning_rate": 3.372549019607843e-05,
      "loss": 0.0124,
      "step": 14440
    },
    {
      "epoch": 47.254901960784316,
      "grad_norm": 0.004924935754388571,
      "learning_rate": 3.294117647058823e-05,
      "loss": 0.0004,
      "step": 14460
    },
    {
      "epoch": 47.3202614379085,
      "grad_norm": 0.0009634375455789268,
      "learning_rate": 3.2156862745098034e-05,
      "loss": 0.001,
      "step": 14480
    },
    {
      "epoch": 47.38562091503268,
      "grad_norm": 0.0010563160758465528,
      "learning_rate": 3.137254901960784e-05,
      "loss": 0.0173,
      "step": 14500
    },
    {
      "epoch": 47.450980392156865,
      "grad_norm": 0.005309364292770624,
      "learning_rate": 3.0588235294117644e-05,
      "loss": 0.0004,
      "step": 14520
    },
    {
      "epoch": 47.51633986928105,
      "grad_norm": 0.0009476281702518463,
      "learning_rate": 2.9803921568627446e-05,
      "loss": 0.0694,
      "step": 14540
    },
    {
      "epoch": 47.58169934640523,
      "grad_norm": 1.9019148349761963,
      "learning_rate": 2.9019607843137255e-05,
      "loss": 0.0008,
      "step": 14560
    },
    {
      "epoch": 47.64705882352941,
      "grad_norm": 0.094279445707798,
      "learning_rate": 2.8235294117647056e-05,
      "loss": 0.0022,
      "step": 14580
    },
    {
      "epoch": 47.712418300653596,
      "grad_norm": 0.4616418480873108,
      "learning_rate": 2.7450980392156858e-05,
      "loss": 0.0022,
      "step": 14600
    },
    {
      "epoch": 47.77777777777778,
      "grad_norm": 1.494964599609375,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0493,
      "step": 14620
    },
    {
      "epoch": 47.84313725490196,
      "grad_norm": 0.0031326559837907553,
      "learning_rate": 2.588235294117647e-05,
      "loss": 0.0435,
      "step": 14640
    },
    {
      "epoch": 47.908496732026144,
      "grad_norm": 0.00231986865401268,
      "learning_rate": 2.509803921568627e-05,
      "loss": 0.0446,
      "step": 14660
    },
    {
      "epoch": 47.97385620915033,
      "grad_norm": 0.0015110387466847897,
      "learning_rate": 2.431372549019608e-05,
      "loss": 0.0081,
      "step": 14680
    },
    {
      "epoch": 48.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.907209173422019,
      "eval_f1": 0.9222614840989399,
      "eval_loss": 0.8295633792877197,
      "eval_runtime": 12.0271,
      "eval_samples_per_second": 33.923,
      "eval_steps_per_second": 4.24,
      "step": 14688
    },
    {
      "epoch": 48.03921568627451,
      "grad_norm": 0.0004067156696692109,
      "learning_rate": 2.352941176470588e-05,
      "loss": 0.0055,
      "step": 14700
    },
    {
      "epoch": 48.10457516339869,
      "grad_norm": 0.14735010266304016,
      "learning_rate": 2.2745098039215682e-05,
      "loss": 0.0005,
      "step": 14720
    },
    {
      "epoch": 48.169934640522875,
      "grad_norm": 0.0011654938571155071,
      "learning_rate": 2.196078431372549e-05,
      "loss": 0.0092,
      "step": 14740
    },
    {
      "epoch": 48.23529411764706,
      "grad_norm": 0.00735058868303895,
      "learning_rate": 2.1176470588235292e-05,
      "loss": 0.0012,
      "step": 14760
    },
    {
      "epoch": 48.30065359477124,
      "grad_norm": 0.0006431961664929986,
      "learning_rate": 2.0392156862745094e-05,
      "loss": 0.0057,
      "step": 14780
    },
    {
      "epoch": 48.36601307189542,
      "grad_norm": 15.831217765808105,
      "learning_rate": 1.9607843137254903e-05,
      "loss": 0.0187,
      "step": 14800
    },
    {
      "epoch": 48.431372549019606,
      "grad_norm": 0.001336332643404603,
      "learning_rate": 1.8823529411764704e-05,
      "loss": 0.0234,
      "step": 14820
    },
    {
      "epoch": 48.49673202614379,
      "grad_norm": 0.04281329736113548,
      "learning_rate": 1.803921568627451e-05,
      "loss": 0.0002,
      "step": 14840
    },
    {
      "epoch": 48.56209150326797,
      "grad_norm": 0.0008774677407927811,
      "learning_rate": 1.725490196078431e-05,
      "loss": 0.0012,
      "step": 14860
    },
    {
      "epoch": 48.627450980392155,
      "grad_norm": 0.001394734368659556,
      "learning_rate": 1.6470588235294116e-05,
      "loss": 0.0049,
      "step": 14880
    },
    {
      "epoch": 48.69281045751634,
      "grad_norm": 0.0005807669367641211,
      "learning_rate": 1.568627450980392e-05,
      "loss": 0.0004,
      "step": 14900
    },
    {
      "epoch": 48.75816993464052,
      "grad_norm": 0.0027556084096431732,
      "learning_rate": 1.4901960784313723e-05,
      "loss": 0.0419,
      "step": 14920
    },
    {
      "epoch": 48.8235294117647,
      "grad_norm": 0.00050412054406479,
      "learning_rate": 1.4117647058823528e-05,
      "loss": 0.0529,
      "step": 14940
    },
    {
      "epoch": 48.888888888888886,
      "grad_norm": 0.007072983775287867,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0011,
      "step": 14960
    },
    {
      "epoch": 48.95424836601307,
      "grad_norm": 0.3848828077316284,
      "learning_rate": 1.2549019607843135e-05,
      "loss": 0.0232,
      "step": 14980
    },
    {
      "epoch": 49.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9091156444815938,
      "eval_f1": 0.9236234458259325,
      "eval_loss": 0.8142993450164795,
      "eval_runtime": 12.2041,
      "eval_samples_per_second": 33.431,
      "eval_steps_per_second": 4.179,
      "step": 14994
    },
    {
      "epoch": 49.01960784313726,
      "grad_norm": 4.784307956695557,
      "learning_rate": 1.176470588235294e-05,
      "loss": 0.0058,
      "step": 15000
    },
    {
      "epoch": 49.08496732026144,
      "grad_norm": 0.2316409796476364,
      "learning_rate": 1.0980392156862745e-05,
      "loss": 0.0055,
      "step": 15020
    },
    {
      "epoch": 49.150326797385624,
      "grad_norm": 0.022559011355042458,
      "learning_rate": 1.0196078431372547e-05,
      "loss": 0.0002,
      "step": 15040
    },
    {
      "epoch": 49.21568627450981,
      "grad_norm": 0.0009607343818061054,
      "learning_rate": 9.411764705882352e-06,
      "loss": 0.0043,
      "step": 15060
    },
    {
      "epoch": 49.28104575163399,
      "grad_norm": 0.0133336978033185,
      "learning_rate": 8.627450980392156e-06,
      "loss": 0.0031,
      "step": 15080
    },
    {
      "epoch": 49.34640522875817,
      "grad_norm": 11.69113540649414,
      "learning_rate": 7.84313725490196e-06,
      "loss": 0.0148,
      "step": 15100
    },
    {
      "epoch": 49.411764705882355,
      "grad_norm": 0.0005082230782136321,
      "learning_rate": 7.058823529411764e-06,
      "loss": 0.0411,
      "step": 15120
    },
    {
      "epoch": 49.47712418300654,
      "grad_norm": 0.0026093320921063423,
      "learning_rate": 6.2745098039215675e-06,
      "loss": 0.0459,
      "step": 15140
    },
    {
      "epoch": 49.54248366013072,
      "grad_norm": 0.006090481765568256,
      "learning_rate": 5.490196078431373e-06,
      "loss": 0.0698,
      "step": 15160
    },
    {
      "epoch": 49.6078431372549,
      "grad_norm": 0.0030487836338579655,
      "learning_rate": 4.705882352941176e-06,
      "loss": 0.0497,
      "step": 15180
    },
    {
      "epoch": 49.673202614379086,
      "grad_norm": 0.0018378024687990546,
      "learning_rate": 3.92156862745098e-06,
      "loss": 0.0002,
      "step": 15200
    },
    {
      "epoch": 49.73856209150327,
      "grad_norm": 0.007816622965037823,
      "learning_rate": 3.1372549019607838e-06,
      "loss": 0.0442,
      "step": 15220
    },
    {
      "epoch": 49.80392156862745,
      "grad_norm": 0.0015108861261978745,
      "learning_rate": 2.352941176470588e-06,
      "loss": 0.0351,
      "step": 15240
    },
    {
      "epoch": 49.869281045751634,
      "grad_norm": 0.0015960767632350326,
      "learning_rate": 1.5686274509803919e-06,
      "loss": 0.0343,
      "step": 15260
    },
    {
      "epoch": 49.93464052287582,
      "grad_norm": 0.1423763781785965,
      "learning_rate": 7.843137254901959e-07,
      "loss": 0.0028,
      "step": 15280
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.005329051520675421,
      "learning_rate": 0.0,
      "loss": 0.0284,
      "step": 15300
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.9152661064425771,
      "eval_f1": 0.9285714285714286,
      "eval_loss": 0.8101961612701416,
      "eval_runtime": 12.3197,
      "eval_samples_per_second": 33.118,
      "eval_steps_per_second": 4.14,
      "step": 15300
    },
    {
      "epoch": 50.0,
      "step": 15300,
      "total_flos": 4.38375589951488e+16,
      "train_loss": 0.09845351290035372,
      "train_runtime": 12191.8637,
      "train_samples_per_second": 15.043,
      "train_steps_per_second": 1.255
    }
  ],
  "logging_steps": 20,
  "max_steps": 15300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": -15300,
  "total_flos": 4.38375589951488e+16,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
