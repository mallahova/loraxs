{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 70.0,
  "eval_steps": 500,
  "global_step": 21420,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 3.585618257522583,
      "learning_rate": 0.0005994397759103641,
      "loss": 0.6159,
      "step": 20
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 2.7937023639678955,
      "learning_rate": 0.0005988795518207283,
      "loss": 0.5896,
      "step": 40
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 7.088360786437988,
      "learning_rate": 0.0005983193277310924,
      "loss": 0.5881,
      "step": 60
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 5.249622344970703,
      "learning_rate": 0.0005977591036414565,
      "loss": 0.5002,
      "step": 80
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 10.917210578918457,
      "learning_rate": 0.0005971988795518207,
      "loss": 0.538,
      "step": 100
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 5.186783313751221,
      "learning_rate": 0.0005966386554621849,
      "loss": 0.5257,
      "step": 120
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 3.8063595294952393,
      "learning_rate": 0.000596078431372549,
      "loss": 0.4672,
      "step": 140
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 3.8667163848876953,
      "learning_rate": 0.0005955182072829131,
      "loss": 0.4402,
      "step": 160
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 2.7559049129486084,
      "learning_rate": 0.0005949579831932772,
      "loss": 0.4879,
      "step": 180
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 3.045539140701294,
      "learning_rate": 0.0005943977591036415,
      "loss": 0.5802,
      "step": 200
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 2.581965684890747,
      "learning_rate": 0.0005938375350140056,
      "loss": 0.4347,
      "step": 220
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 3.315674066543579,
      "learning_rate": 0.0005932773109243697,
      "loss": 0.4286,
      "step": 240
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 6.981908321380615,
      "learning_rate": 0.0005927170868347338,
      "loss": 0.4086,
      "step": 260
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 7.187566757202148,
      "learning_rate": 0.0005921568627450981,
      "loss": 0.4329,
      "step": 280
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 10.677309036254883,
      "learning_rate": 0.0005915966386554622,
      "loss": 0.4096,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8308823529411765,
      "eval_combined_score": 0.8582272461223296,
      "eval_f1": 0.8855721393034827,
      "eval_loss": 0.4233096241950989,
      "eval_runtime": 13.329,
      "eval_samples_per_second": 30.61,
      "eval_steps_per_second": 3.826,
      "step": 306
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 1.9400279521942139,
      "learning_rate": 0.0005910364145658263,
      "loss": 0.312,
      "step": 320
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 2.537776231765747,
      "learning_rate": 0.0005904761904761904,
      "loss": 0.4405,
      "step": 340
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 3.54352068901062,
      "learning_rate": 0.0005899159663865545,
      "loss": 0.3552,
      "step": 360
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 1.6282672882080078,
      "learning_rate": 0.0005893557422969187,
      "loss": 0.2647,
      "step": 380
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 5.90822696685791,
      "learning_rate": 0.0005887955182072829,
      "loss": 0.4708,
      "step": 400
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 4.423151016235352,
      "learning_rate": 0.000588235294117647,
      "loss": 0.3198,
      "step": 420
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 1.078329086303711,
      "learning_rate": 0.0005876750700280111,
      "loss": 0.2339,
      "step": 440
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 4.7705793380737305,
      "learning_rate": 0.0005871148459383752,
      "loss": 0.4016,
      "step": 460
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 99.19279479980469,
      "learning_rate": 0.0005865546218487395,
      "loss": 0.4185,
      "step": 480
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 5.763175964355469,
      "learning_rate": 0.0005859943977591036,
      "loss": 0.41,
      "step": 500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 1.8725459575653076,
      "learning_rate": 0.0005854341736694677,
      "loss": 0.3324,
      "step": 520
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.989696741104126,
      "learning_rate": 0.0005848739495798318,
      "loss": 0.3464,
      "step": 540
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 2.2079524993896484,
      "learning_rate": 0.0005843137254901961,
      "loss": 0.3359,
      "step": 560
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 4.714328765869141,
      "learning_rate": 0.0005837535014005602,
      "loss": 0.3033,
      "step": 580
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 3.973498582839966,
      "learning_rate": 0.0005831932773109243,
      "loss": 0.285,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8700980392156863,
      "eval_combined_score": 0.8860656554673626,
      "eval_f1": 0.9020332717190389,
      "eval_loss": 0.32426178455352783,
      "eval_runtime": 13.3333,
      "eval_samples_per_second": 30.6,
      "eval_steps_per_second": 3.825,
      "step": 612
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 2.5481836795806885,
      "learning_rate": 0.0005826330532212884,
      "loss": 0.3883,
      "step": 620
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 5.090386867523193,
      "learning_rate": 0.0005820728291316527,
      "loss": 0.2641,
      "step": 640
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 1.755879282951355,
      "learning_rate": 0.0005815126050420168,
      "loss": 0.3288,
      "step": 660
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 3.3379063606262207,
      "learning_rate": 0.0005809523809523809,
      "loss": 0.2612,
      "step": 680
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 2.6729021072387695,
      "learning_rate": 0.000580392156862745,
      "loss": 0.3108,
      "step": 700
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 3.806239604949951,
      "learning_rate": 0.0005798319327731092,
      "loss": 0.3404,
      "step": 720
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 6.225550174713135,
      "learning_rate": 0.0005792717086834734,
      "loss": 0.2221,
      "step": 740
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 2.349825143814087,
      "learning_rate": 0.0005787114845938375,
      "loss": 0.259,
      "step": 760
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 0.7094648480415344,
      "learning_rate": 0.0005781512605042016,
      "loss": 0.2425,
      "step": 780
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 5.736843585968018,
      "learning_rate": 0.0005775910364145658,
      "loss": 0.3813,
      "step": 800
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 0.6537067294120789,
      "learning_rate": 0.00057703081232493,
      "loss": 0.3015,
      "step": 820
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 4.74227237701416,
      "learning_rate": 0.0005764705882352941,
      "loss": 0.2565,
      "step": 840
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 5.798854827880859,
      "learning_rate": 0.0005759103641456582,
      "loss": 0.325,
      "step": 860
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 4.008552074432373,
      "learning_rate": 0.0005753501400560224,
      "loss": 0.3464,
      "step": 880
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 2.022268056869507,
      "learning_rate": 0.0005747899159663865,
      "loss": 0.2897,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9060784313725491,
      "eval_f1": 0.92,
      "eval_loss": 0.3627774715423584,
      "eval_runtime": 12.712,
      "eval_samples_per_second": 32.096,
      "eval_steps_per_second": 4.012,
      "step": 918
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 3.569141387939453,
      "learning_rate": 0.0005742296918767507,
      "loss": 0.3433,
      "step": 920
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 1.812792420387268,
      "learning_rate": 0.0005736694677871148,
      "loss": 0.2981,
      "step": 940
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 4.831901550292969,
      "learning_rate": 0.000573109243697479,
      "loss": 0.2949,
      "step": 960
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 3.4335315227508545,
      "learning_rate": 0.0005725490196078431,
      "loss": 0.2633,
      "step": 980
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 5.909806728363037,
      "learning_rate": 0.0005719887955182072,
      "loss": 0.3688,
      "step": 1000
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 1.6332944631576538,
      "learning_rate": 0.0005714285714285714,
      "loss": 0.2973,
      "step": 1020
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 1.7984974384307861,
      "learning_rate": 0.0005708683473389355,
      "loss": 0.165,
      "step": 1040
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 4.799921989440918,
      "learning_rate": 0.0005703081232492996,
      "loss": 0.2908,
      "step": 1060
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 5.696170330047607,
      "learning_rate": 0.0005697478991596638,
      "loss": 0.3853,
      "step": 1080
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 3.756570816040039,
      "learning_rate": 0.000569187675070028,
      "loss": 0.3307,
      "step": 1100
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 1.6331658363342285,
      "learning_rate": 0.0005686274509803921,
      "loss": 0.1923,
      "step": 1120
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 3.0997531414031982,
      "learning_rate": 0.0005680672268907562,
      "loss": 0.3668,
      "step": 1140
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 2.0452511310577393,
      "learning_rate": 0.0005675070028011204,
      "loss": 0.2699,
      "step": 1160
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 2.8139357566833496,
      "learning_rate": 0.0005669467787114845,
      "loss": 0.2308,
      "step": 1180
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 1.8429635763168335,
      "learning_rate": 0.0005663865546218487,
      "loss": 0.3188,
      "step": 1200
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 0.9408382177352905,
      "learning_rate": 0.0005658263305322128,
      "loss": 0.2099,
      "step": 1220
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9070713391739675,
      "eval_f1": 0.9219858156028369,
      "eval_loss": 0.38753658533096313,
      "eval_runtime": 12.5004,
      "eval_samples_per_second": 32.639,
      "eval_steps_per_second": 4.08,
      "step": 1224
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 6.589274883270264,
      "learning_rate": 0.000565266106442577,
      "loss": 0.2843,
      "step": 1240
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 3.2496635913848877,
      "learning_rate": 0.0005647058823529411,
      "loss": 0.1994,
      "step": 1260
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 6.028162002563477,
      "learning_rate": 0.0005641456582633052,
      "loss": 0.2085,
      "step": 1280
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 2.00740122795105,
      "learning_rate": 0.0005635854341736694,
      "loss": 0.29,
      "step": 1300
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 3.38348388671875,
      "learning_rate": 0.0005630252100840336,
      "loss": 0.206,
      "step": 1320
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 0.9097682237625122,
      "learning_rate": 0.0005624649859943977,
      "loss": 0.1861,
      "step": 1340
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 2.7218058109283447,
      "learning_rate": 0.0005619047619047618,
      "loss": 0.3002,
      "step": 1360
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 1.5601335763931274,
      "learning_rate": 0.000561344537815126,
      "loss": 0.1753,
      "step": 1380
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 5.956111431121826,
      "learning_rate": 0.0005607843137254902,
      "loss": 0.2746,
      "step": 1400
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 0.9347491264343262,
      "learning_rate": 0.0005602240896358543,
      "loss": 0.2413,
      "step": 1420
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.49671030044555664,
      "learning_rate": 0.0005596638655462184,
      "loss": 0.2142,
      "step": 1440
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 2.3159408569335938,
      "learning_rate": 0.0005591036414565825,
      "loss": 0.2089,
      "step": 1460
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 0.12861958146095276,
      "learning_rate": 0.0005585434173669468,
      "loss": 0.2752,
      "step": 1480
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 4.279187202453613,
      "learning_rate": 0.0005579831932773109,
      "loss": 0.3092,
      "step": 1500
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 0.7804276347160339,
      "learning_rate": 0.000557422969187675,
      "loss": 0.2226,
      "step": 1520
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9134717161200764,
      "eval_f1": 0.9274336283185841,
      "eval_loss": 0.337788462638855,
      "eval_runtime": 12.485,
      "eval_samples_per_second": 32.679,
      "eval_steps_per_second": 4.085,
      "step": 1530
    },
    {
      "epoch": 5.032679738562091,
      "grad_norm": 0.9773188829421997,
      "learning_rate": 0.0005568627450980392,
      "loss": 0.2272,
      "step": 1540
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 0.5507391095161438,
      "learning_rate": 0.0005563025210084034,
      "loss": 0.1331,
      "step": 1560
    },
    {
      "epoch": 5.163398692810458,
      "grad_norm": 5.129703044891357,
      "learning_rate": 0.0005557422969187675,
      "loss": 0.28,
      "step": 1580
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 4.235655307769775,
      "learning_rate": 0.0005551820728291316,
      "loss": 0.1499,
      "step": 1600
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 2.5662691593170166,
      "learning_rate": 0.0005546218487394958,
      "loss": 0.2063,
      "step": 1620
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 2.572842836380005,
      "learning_rate": 0.00055406162464986,
      "loss": 0.2288,
      "step": 1640
    },
    {
      "epoch": 5.42483660130719,
      "grad_norm": 1.3084121942520142,
      "learning_rate": 0.0005535014005602241,
      "loss": 0.1609,
      "step": 1660
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 1.0519492626190186,
      "learning_rate": 0.0005529411764705882,
      "loss": 0.1798,
      "step": 1680
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 4.733180522918701,
      "learning_rate": 0.0005523809523809523,
      "loss": 0.1131,
      "step": 1700
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 2.929436206817627,
      "learning_rate": 0.0005518207282913164,
      "loss": 0.3829,
      "step": 1720
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 3.3082213401794434,
      "learning_rate": 0.0005512605042016805,
      "loss": 0.2226,
      "step": 1740
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 1.175597906112671,
      "learning_rate": 0.0005507002801120448,
      "loss": 0.3152,
      "step": 1760
    },
    {
      "epoch": 5.816993464052287,
      "grad_norm": 4.079764366149902,
      "learning_rate": 0.0005501400560224089,
      "loss": 0.2129,
      "step": 1780
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.5983713865280151,
      "learning_rate": 0.000549579831932773,
      "loss": 0.2779,
      "step": 1800
    },
    {
      "epoch": 5.947712418300654,
      "grad_norm": 1.5031229257583618,
      "learning_rate": 0.0005490196078431371,
      "loss": 0.2417,
      "step": 1820
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9137267824528758,
      "eval_f1": 0.9279437609841829,
      "eval_loss": 0.32826852798461914,
      "eval_runtime": 12.7115,
      "eval_samples_per_second": 32.097,
      "eval_steps_per_second": 4.012,
      "step": 1836
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 3.842005729675293,
      "learning_rate": 0.0005484593837535014,
      "loss": 0.3349,
      "step": 1840
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 2.0476114749908447,
      "learning_rate": 0.0005478991596638655,
      "loss": 0.18,
      "step": 1860
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 1.7351888418197632,
      "learning_rate": 0.0005473389355742296,
      "loss": 0.1933,
      "step": 1880
    },
    {
      "epoch": 6.209150326797386,
      "grad_norm": 2.1779465675354004,
      "learning_rate": 0.0005467787114845938,
      "loss": 0.2372,
      "step": 1900
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 5.348252296447754,
      "learning_rate": 0.000546218487394958,
      "loss": 0.1455,
      "step": 1920
    },
    {
      "epoch": 6.339869281045751,
      "grad_norm": 1.9416221380233765,
      "learning_rate": 0.0005456582633053221,
      "loss": 0.1509,
      "step": 1940
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 4.648884296417236,
      "learning_rate": 0.0005450980392156862,
      "loss": 0.2806,
      "step": 1960
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 3.5878541469573975,
      "learning_rate": 0.0005445378151260504,
      "loss": 0.1699,
      "step": 1980
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 3.809302806854248,
      "learning_rate": 0.0005439775910364145,
      "loss": 0.2249,
      "step": 2000
    },
    {
      "epoch": 6.601307189542483,
      "grad_norm": 0.9790915250778198,
      "learning_rate": 0.0005434173669467787,
      "loss": 0.1845,
      "step": 2020
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 1.7851178646087646,
      "learning_rate": 0.0005428571428571428,
      "loss": 0.2878,
      "step": 2040
    },
    {
      "epoch": 6.73202614379085,
      "grad_norm": 1.615307092666626,
      "learning_rate": 0.000542296918767507,
      "loss": 0.1724,
      "step": 2060
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 3.0443520545959473,
      "learning_rate": 0.0005417366946778711,
      "loss": 0.2296,
      "step": 2080
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 1.1549865007400513,
      "learning_rate": 0.0005411764705882352,
      "loss": 0.1852,
      "step": 2100
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 4.344547748565674,
      "learning_rate": 0.0005406162464985994,
      "loss": 0.2237,
      "step": 2120
    },
    {
      "epoch": 6.993464052287582,
      "grad_norm": 0.5088146328926086,
      "learning_rate": 0.0005400560224089636,
      "loss": 0.1577,
      "step": 2140
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.9002208391889179,
      "eval_f1": 0.9180887372013652,
      "eval_loss": 0.4571606516838074,
      "eval_runtime": 12.6566,
      "eval_samples_per_second": 32.236,
      "eval_steps_per_second": 4.03,
      "step": 2142
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 4.489296913146973,
      "learning_rate": 0.0005394957983193277,
      "loss": 0.187,
      "step": 2160
    },
    {
      "epoch": 7.124183006535947,
      "grad_norm": 6.535711765289307,
      "learning_rate": 0.0005389355742296918,
      "loss": 0.2591,
      "step": 2180
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 3.0750033855438232,
      "learning_rate": 0.000538375350140056,
      "loss": 0.1844,
      "step": 2200
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 0.2933691442012787,
      "learning_rate": 0.0005378151260504202,
      "loss": 0.1445,
      "step": 2220
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 0.20981353521347046,
      "learning_rate": 0.0005372549019607843,
      "loss": 0.1908,
      "step": 2240
    },
    {
      "epoch": 7.38562091503268,
      "grad_norm": 2.935185670852661,
      "learning_rate": 0.0005366946778711484,
      "loss": 0.2398,
      "step": 2260
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 3.1447787284851074,
      "learning_rate": 0.0005361344537815125,
      "loss": 0.1621,
      "step": 2280
    },
    {
      "epoch": 7.516339869281046,
      "grad_norm": 1.3537585735321045,
      "learning_rate": 0.0005355742296918768,
      "loss": 0.0806,
      "step": 2300
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 2.3727526664733887,
      "learning_rate": 0.0005350140056022409,
      "loss": 0.2007,
      "step": 2320
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 7.4309210777282715,
      "learning_rate": 0.000534453781512605,
      "loss": 0.2653,
      "step": 2340
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 0.14290200173854828,
      "learning_rate": 0.0005338935574229691,
      "loss": 0.1461,
      "step": 2360
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 11.545135498046875,
      "learning_rate": 0.0005333333333333333,
      "loss": 0.1543,
      "step": 2380
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 4.359585285186768,
      "learning_rate": 0.0005327731092436974,
      "loss": 0.2667,
      "step": 2400
    },
    {
      "epoch": 7.908496732026144,
      "grad_norm": 1.2454187870025635,
      "learning_rate": 0.0005322128851540616,
      "loss": 0.1653,
      "step": 2420
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 4.311819076538086,
      "learning_rate": 0.0005316526610644257,
      "loss": 0.2108,
      "step": 2440
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9059928375495276,
      "eval_f1": 0.922279792746114,
      "eval_loss": 0.37612634897232056,
      "eval_runtime": 12.6371,
      "eval_samples_per_second": 32.286,
      "eval_steps_per_second": 4.036,
      "step": 2448
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 11.63045883178711,
      "learning_rate": 0.0005310924369747898,
      "loss": 0.1562,
      "step": 2460
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 0.5195901393890381,
      "learning_rate": 0.000530532212885154,
      "loss": 0.0576,
      "step": 2480
    },
    {
      "epoch": 8.169934640522875,
      "grad_norm": 0.0810428261756897,
      "learning_rate": 0.0005299719887955182,
      "loss": 0.1073,
      "step": 2500
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 6.155176639556885,
      "learning_rate": 0.0005294117647058823,
      "loss": 0.2054,
      "step": 2520
    },
    {
      "epoch": 8.300653594771243,
      "grad_norm": 6.201213359832764,
      "learning_rate": 0.0005288515406162464,
      "loss": 0.1491,
      "step": 2540
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 0.18392838537693024,
      "learning_rate": 0.0005282913165266105,
      "loss": 0.1897,
      "step": 2560
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.3251318633556366,
      "learning_rate": 0.0005277310924369748,
      "loss": 0.2052,
      "step": 2580
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 1.0108908414840698,
      "learning_rate": 0.0005271708683473389,
      "loss": 0.154,
      "step": 2600
    },
    {
      "epoch": 8.562091503267974,
      "grad_norm": 0.15343528985977173,
      "learning_rate": 0.000526610644257703,
      "loss": 0.1039,
      "step": 2620
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 0.43833041191101074,
      "learning_rate": 0.0005260504201680671,
      "loss": 0.1666,
      "step": 2640
    },
    {
      "epoch": 8.69281045751634,
      "grad_norm": 8.516595840454102,
      "learning_rate": 0.0005254901960784314,
      "loss": 0.1886,
      "step": 2660
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 6.002397537231445,
      "learning_rate": 0.0005249299719887955,
      "loss": 0.1731,
      "step": 2680
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 2.592012643814087,
      "learning_rate": 0.0005243697478991596,
      "loss": 0.1733,
      "step": 2700
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 3.005944013595581,
      "learning_rate": 0.0005238095238095237,
      "loss": 0.268,
      "step": 2720
    },
    {
      "epoch": 8.954248366013072,
      "grad_norm": 3.0366642475128174,
      "learning_rate": 0.000523249299719888,
      "loss": 0.2206,
      "step": 2740
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9031344932339133,
      "eval_f1": 0.9190140845070423,
      "eval_loss": 0.42056170105934143,
      "eval_runtime": 12.6715,
      "eval_samples_per_second": 32.198,
      "eval_steps_per_second": 4.025,
      "step": 2754
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 3.7555980682373047,
      "learning_rate": 0.0005226890756302521,
      "loss": 0.2122,
      "step": 2760
    },
    {
      "epoch": 9.084967320261438,
      "grad_norm": 3.780106782913208,
      "learning_rate": 0.0005221288515406162,
      "loss": 0.1231,
      "step": 2780
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 4.731170177459717,
      "learning_rate": 0.0005215686274509803,
      "loss": 0.1793,
      "step": 2800
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 11.771282196044922,
      "learning_rate": 0.0005210084033613445,
      "loss": 0.1668,
      "step": 2820
    },
    {
      "epoch": 9.281045751633988,
      "grad_norm": 0.47969362139701843,
      "learning_rate": 0.0005204481792717087,
      "loss": 0.1456,
      "step": 2840
    },
    {
      "epoch": 9.34640522875817,
      "grad_norm": 7.851489543914795,
      "learning_rate": 0.0005198879551820728,
      "loss": 0.0674,
      "step": 2860
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 6.603188514709473,
      "learning_rate": 0.0005193277310924369,
      "loss": 0.1116,
      "step": 2880
    },
    {
      "epoch": 9.477124183006536,
      "grad_norm": 3.406428337097168,
      "learning_rate": 0.0005187675070028011,
      "loss": 0.1576,
      "step": 2900
    },
    {
      "epoch": 9.542483660130719,
      "grad_norm": 1.4662262201309204,
      "learning_rate": 0.0005182072829131652,
      "loss": 0.3072,
      "step": 2920
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 3.4831762313842773,
      "learning_rate": 0.0005176470588235294,
      "loss": 0.1364,
      "step": 2940
    },
    {
      "epoch": 9.673202614379084,
      "grad_norm": 0.2563211917877197,
      "learning_rate": 0.0005170868347338935,
      "loss": 0.1384,
      "step": 2960
    },
    {
      "epoch": 9.738562091503269,
      "grad_norm": 4.426374435424805,
      "learning_rate": 0.0005165266106442577,
      "loss": 0.1763,
      "step": 2980
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 4.748472213745117,
      "learning_rate": 0.0005159663865546218,
      "loss": 0.1808,
      "step": 3000
    },
    {
      "epoch": 9.869281045751634,
      "grad_norm": 8.709171295166016,
      "learning_rate": 0.000515406162464986,
      "loss": 0.2002,
      "step": 3020
    },
    {
      "epoch": 9.934640522875817,
      "grad_norm": 1.6305006742477417,
      "learning_rate": 0.0005148459383753501,
      "loss": 0.159,
      "step": 3040
    },
    {
      "epoch": 10.0,
      "grad_norm": 7.911212921142578,
      "learning_rate": 0.0005142857142857142,
      "loss": 0.1006,
      "step": 3060
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9111628637220013,
      "eval_f1": 0.9252669039145908,
      "eval_loss": 0.40479129552841187,
      "eval_runtime": 12.5358,
      "eval_samples_per_second": 32.547,
      "eval_steps_per_second": 4.068,
      "step": 3060
    },
    {
      "epoch": 10.065359477124183,
      "grad_norm": 0.08384454250335693,
      "learning_rate": 0.0005137254901960783,
      "loss": 0.1265,
      "step": 3080
    },
    {
      "epoch": 10.130718954248366,
      "grad_norm": 0.3411586284637451,
      "learning_rate": 0.0005131652661064425,
      "loss": 0.1165,
      "step": 3100
    },
    {
      "epoch": 10.196078431372548,
      "grad_norm": 3.7782082557678223,
      "learning_rate": 0.0005126050420168067,
      "loss": 0.1349,
      "step": 3120
    },
    {
      "epoch": 10.261437908496733,
      "grad_norm": 7.116649150848389,
      "learning_rate": 0.0005120448179271708,
      "loss": 0.1784,
      "step": 3140
    },
    {
      "epoch": 10.326797385620916,
      "grad_norm": 6.952834129333496,
      "learning_rate": 0.0005114845938375349,
      "loss": 0.1126,
      "step": 3160
    },
    {
      "epoch": 10.392156862745098,
      "grad_norm": 5.455621242523193,
      "learning_rate": 0.0005109243697478991,
      "loss": 0.1065,
      "step": 3180
    },
    {
      "epoch": 10.457516339869281,
      "grad_norm": 6.711389064788818,
      "learning_rate": 0.0005103641456582633,
      "loss": 0.2162,
      "step": 3200
    },
    {
      "epoch": 10.522875816993464,
      "grad_norm": 0.3626708686351776,
      "learning_rate": 0.0005098039215686274,
      "loss": 0.1658,
      "step": 3220
    },
    {
      "epoch": 10.588235294117647,
      "grad_norm": 4.823735237121582,
      "learning_rate": 0.0005092436974789915,
      "loss": 0.1916,
      "step": 3240
    },
    {
      "epoch": 10.65359477124183,
      "grad_norm": 6.818560600280762,
      "learning_rate": 0.0005086834733893557,
      "loss": 0.1393,
      "step": 3260
    },
    {
      "epoch": 10.718954248366012,
      "grad_norm": 3.475848913192749,
      "learning_rate": 0.0005081232492997198,
      "loss": 0.2055,
      "step": 3280
    },
    {
      "epoch": 10.784313725490197,
      "grad_norm": 2.384965658187866,
      "learning_rate": 0.000507563025210084,
      "loss": 0.1291,
      "step": 3300
    },
    {
      "epoch": 10.84967320261438,
      "grad_norm": 0.03480428084731102,
      "learning_rate": 0.0005070028011204481,
      "loss": 0.096,
      "step": 3320
    },
    {
      "epoch": 10.915032679738562,
      "grad_norm": 5.454732418060303,
      "learning_rate": 0.0005064425770308123,
      "loss": 0.1767,
      "step": 3340
    },
    {
      "epoch": 10.980392156862745,
      "grad_norm": 0.9699437022209167,
      "learning_rate": 0.0005058823529411764,
      "loss": 0.1504,
      "step": 3360
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9132130124777184,
      "eval_f1": 0.9269162210338681,
      "eval_loss": 0.4265846312046051,
      "eval_runtime": 12.7116,
      "eval_samples_per_second": 32.097,
      "eval_steps_per_second": 4.012,
      "step": 3366
    },
    {
      "epoch": 11.045751633986928,
      "grad_norm": 0.08979959785938263,
      "learning_rate": 0.0005053221288515405,
      "loss": 0.1038,
      "step": 3380
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 14.550654411315918,
      "learning_rate": 0.0005047619047619048,
      "loss": 0.2471,
      "step": 3400
    },
    {
      "epoch": 11.176470588235293,
      "grad_norm": 14.751594543457031,
      "learning_rate": 0.0005042016806722689,
      "loss": 0.1055,
      "step": 3420
    },
    {
      "epoch": 11.241830065359476,
      "grad_norm": 8.338476181030273,
      "learning_rate": 0.000503641456582633,
      "loss": 0.1265,
      "step": 3440
    },
    {
      "epoch": 11.30718954248366,
      "grad_norm": 3.377598762512207,
      "learning_rate": 0.0005030812324929971,
      "loss": 0.1823,
      "step": 3460
    },
    {
      "epoch": 11.372549019607844,
      "grad_norm": 4.470123291015625,
      "learning_rate": 0.0005025210084033614,
      "loss": 0.1386,
      "step": 3480
    },
    {
      "epoch": 11.437908496732026,
      "grad_norm": 0.6204366683959961,
      "learning_rate": 0.0005019607843137255,
      "loss": 0.0249,
      "step": 3500
    },
    {
      "epoch": 11.50326797385621,
      "grad_norm": 0.023891236633062363,
      "learning_rate": 0.0005014005602240896,
      "loss": 0.1231,
      "step": 3520
    },
    {
      "epoch": 11.568627450980392,
      "grad_norm": 4.860443592071533,
      "learning_rate": 0.0005008403361344537,
      "loss": 0.1718,
      "step": 3540
    },
    {
      "epoch": 11.633986928104575,
      "grad_norm": 1.6822134256362915,
      "learning_rate": 0.000500280112044818,
      "loss": 0.1486,
      "step": 3560
    },
    {
      "epoch": 11.699346405228757,
      "grad_norm": 2.304021120071411,
      "learning_rate": 0.0004997198879551821,
      "loss": 0.0722,
      "step": 3580
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 3.0949902534484863,
      "learning_rate": 0.0004991596638655462,
      "loss": 0.0739,
      "step": 3600
    },
    {
      "epoch": 11.830065359477125,
      "grad_norm": 0.0540551021695137,
      "learning_rate": 0.0004985994397759103,
      "loss": 0.1815,
      "step": 3620
    },
    {
      "epoch": 11.895424836601308,
      "grad_norm": 18.76803970336914,
      "learning_rate": 0.0004980392156862745,
      "loss": 0.0963,
      "step": 3640
    },
    {
      "epoch": 11.96078431372549,
      "grad_norm": 10.735114097595215,
      "learning_rate": 0.0004974789915966387,
      "loss": 0.1906,
      "step": 3660
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9129505931636568,
      "eval_f1": 0.926391382405745,
      "eval_loss": 0.48287901282310486,
      "eval_runtime": 12.518,
      "eval_samples_per_second": 32.593,
      "eval_steps_per_second": 4.074,
      "step": 3672
    },
    {
      "epoch": 12.026143790849673,
      "grad_norm": 1.3882575035095215,
      "learning_rate": 0.0004969187675070028,
      "loss": 0.1262,
      "step": 3680
    },
    {
      "epoch": 12.091503267973856,
      "grad_norm": 0.5284724235534668,
      "learning_rate": 0.0004963585434173669,
      "loss": 0.1506,
      "step": 3700
    },
    {
      "epoch": 12.156862745098039,
      "grad_norm": 0.15427441895008087,
      "learning_rate": 0.000495798319327731,
      "loss": 0.1008,
      "step": 3720
    },
    {
      "epoch": 12.222222222222221,
      "grad_norm": 0.6846757531166077,
      "learning_rate": 0.0004952380952380951,
      "loss": 0.1205,
      "step": 3740
    },
    {
      "epoch": 12.287581699346406,
      "grad_norm": 5.033295154571533,
      "learning_rate": 0.0004946778711484594,
      "loss": 0.1426,
      "step": 3760
    },
    {
      "epoch": 12.352941176470589,
      "grad_norm": 1.0720576047897339,
      "learning_rate": 0.0004941176470588235,
      "loss": 0.1032,
      "step": 3780
    },
    {
      "epoch": 12.418300653594772,
      "grad_norm": 10.26672077178955,
      "learning_rate": 0.0004935574229691876,
      "loss": 0.1067,
      "step": 3800
    },
    {
      "epoch": 12.483660130718954,
      "grad_norm": 0.10082211345434189,
      "learning_rate": 0.0004929971988795517,
      "loss": 0.1725,
      "step": 3820
    },
    {
      "epoch": 12.549019607843137,
      "grad_norm": 0.45340338349342346,
      "learning_rate": 0.000492436974789916,
      "loss": 0.1566,
      "step": 3840
    },
    {
      "epoch": 12.61437908496732,
      "grad_norm": 7.291535377502441,
      "learning_rate": 0.0004918767507002801,
      "loss": 0.1031,
      "step": 3860
    },
    {
      "epoch": 12.679738562091503,
      "grad_norm": 9.506664276123047,
      "learning_rate": 0.0004913165266106442,
      "loss": 0.2908,
      "step": 3880
    },
    {
      "epoch": 12.745098039215687,
      "grad_norm": 6.3677077293396,
      "learning_rate": 0.0004907563025210083,
      "loss": 0.1485,
      "step": 3900
    },
    {
      "epoch": 12.81045751633987,
      "grad_norm": 0.34574711322784424,
      "learning_rate": 0.0004901960784313725,
      "loss": 0.0739,
      "step": 3920
    },
    {
      "epoch": 12.875816993464053,
      "grad_norm": 9.276168823242188,
      "learning_rate": 0.0004896358543417367,
      "loss": 0.065,
      "step": 3940
    },
    {
      "epoch": 12.941176470588236,
      "grad_norm": 0.026825645938515663,
      "learning_rate": 0.0004890756302521008,
      "loss": 0.1172,
      "step": 3960
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9036968954248366,
      "eval_f1": 0.9201388888888888,
      "eval_loss": 0.4222005307674408,
      "eval_runtime": 12.5747,
      "eval_samples_per_second": 32.446,
      "eval_steps_per_second": 4.056,
      "step": 3978
    },
    {
      "epoch": 13.006535947712418,
      "grad_norm": 5.5482587814331055,
      "learning_rate": 0.0004885154061624649,
      "loss": 0.1478,
      "step": 3980
    },
    {
      "epoch": 13.071895424836601,
      "grad_norm": 8.174558639526367,
      "learning_rate": 0.0004879551820728291,
      "loss": 0.1083,
      "step": 4000
    },
    {
      "epoch": 13.137254901960784,
      "grad_norm": 0.03742043673992157,
      "learning_rate": 0.00048739495798319325,
      "loss": 0.0984,
      "step": 4020
    },
    {
      "epoch": 13.202614379084967,
      "grad_norm": 6.086636543273926,
      "learning_rate": 0.00048683473389355737,
      "loss": 0.1625,
      "step": 4040
    },
    {
      "epoch": 13.267973856209151,
      "grad_norm": 6.778184413909912,
      "learning_rate": 0.00048627450980392154,
      "loss": 0.0842,
      "step": 4060
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 2.451927900314331,
      "learning_rate": 0.00048571428571428566,
      "loss": 0.1508,
      "step": 4080
    },
    {
      "epoch": 13.398692810457517,
      "grad_norm": 51.72550582885742,
      "learning_rate": 0.00048515406162464984,
      "loss": 0.1582,
      "step": 4100
    },
    {
      "epoch": 13.4640522875817,
      "grad_norm": 8.310206413269043,
      "learning_rate": 0.00048459383753501396,
      "loss": 0.1082,
      "step": 4120
    },
    {
      "epoch": 13.529411764705882,
      "grad_norm": 0.3526671528816223,
      "learning_rate": 0.00048403361344537813,
      "loss": 0.1534,
      "step": 4140
    },
    {
      "epoch": 13.594771241830065,
      "grad_norm": 3.7002170085906982,
      "learning_rate": 0.00048347338935574225,
      "loss": 0.2192,
      "step": 4160
    },
    {
      "epoch": 13.660130718954248,
      "grad_norm": 0.2089008241891861,
      "learning_rate": 0.0004829131652661064,
      "loss": 0.1203,
      "step": 4180
    },
    {
      "epoch": 13.72549019607843,
      "grad_norm": 0.9024898409843445,
      "learning_rate": 0.00048235294117647055,
      "loss": 0.116,
      "step": 4200
    },
    {
      "epoch": 13.790849673202615,
      "grad_norm": 7.559174537658691,
      "learning_rate": 0.0004817927170868347,
      "loss": 0.0955,
      "step": 4220
    },
    {
      "epoch": 13.856209150326798,
      "grad_norm": 5.795255661010742,
      "learning_rate": 0.00048123249299719884,
      "loss": 0.1118,
      "step": 4240
    },
    {
      "epoch": 13.92156862745098,
      "grad_norm": 7.656655788421631,
      "learning_rate": 0.000480672268907563,
      "loss": 0.1364,
      "step": 4260
    },
    {
      "epoch": 13.986928104575163,
      "grad_norm": 0.014640708453953266,
      "learning_rate": 0.00048011204481792713,
      "loss": 0.0952,
      "step": 4280
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9093850503164229,
      "eval_f1": 0.9241622574955909,
      "eval_loss": 0.4989241063594818,
      "eval_runtime": 12.6641,
      "eval_samples_per_second": 32.217,
      "eval_steps_per_second": 4.027,
      "step": 4284
    },
    {
      "epoch": 14.052287581699346,
      "grad_norm": 6.644800662994385,
      "learning_rate": 0.0004795518207282913,
      "loss": 0.1113,
      "step": 4300
    },
    {
      "epoch": 14.117647058823529,
      "grad_norm": 0.06904881447553635,
      "learning_rate": 0.00047899159663865543,
      "loss": 0.1793,
      "step": 4320
    },
    {
      "epoch": 14.183006535947712,
      "grad_norm": 3.113990545272827,
      "learning_rate": 0.0004784313725490196,
      "loss": 0.0793,
      "step": 4340
    },
    {
      "epoch": 14.248366013071895,
      "grad_norm": 3.0245344638824463,
      "learning_rate": 0.00047787114845938367,
      "loss": 0.1325,
      "step": 4360
    },
    {
      "epoch": 14.313725490196079,
      "grad_norm": 0.10041403025388718,
      "learning_rate": 0.00047731092436974784,
      "loss": 0.1047,
      "step": 4380
    },
    {
      "epoch": 14.379084967320262,
      "grad_norm": 0.5871803760528564,
      "learning_rate": 0.00047675070028011196,
      "loss": 0.1083,
      "step": 4400
    },
    {
      "epoch": 14.444444444444445,
      "grad_norm": 0.7359200119972229,
      "learning_rate": 0.00047619047619047614,
      "loss": 0.0867,
      "step": 4420
    },
    {
      "epoch": 14.509803921568627,
      "grad_norm": 19.557252883911133,
      "learning_rate": 0.00047563025210084026,
      "loss": 0.2087,
      "step": 4440
    },
    {
      "epoch": 14.57516339869281,
      "grad_norm": 1.4663499593734741,
      "learning_rate": 0.00047507002801120443,
      "loss": 0.0594,
      "step": 4460
    },
    {
      "epoch": 14.640522875816993,
      "grad_norm": 0.12499132007360458,
      "learning_rate": 0.00047450980392156855,
      "loss": 0.1729,
      "step": 4480
    },
    {
      "epoch": 14.705882352941176,
      "grad_norm": 1.6405149698257446,
      "learning_rate": 0.0004739495798319327,
      "loss": 0.2008,
      "step": 4500
    },
    {
      "epoch": 14.77124183006536,
      "grad_norm": 6.539224147796631,
      "learning_rate": 0.00047338935574229684,
      "loss": 0.0663,
      "step": 4520
    },
    {
      "epoch": 14.836601307189543,
      "grad_norm": 2.2502694129943848,
      "learning_rate": 0.000472829131652661,
      "loss": 0.0965,
      "step": 4540
    },
    {
      "epoch": 14.901960784313726,
      "grad_norm": 1.0066972970962524,
      "learning_rate": 0.00047226890756302514,
      "loss": 0.0777,
      "step": 4560
    },
    {
      "epoch": 14.967320261437909,
      "grad_norm": 16.885421752929688,
      "learning_rate": 0.0004717086834733893,
      "loss": 0.1482,
      "step": 4580
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.897855170949246,
      "eval_f1": 0.9133574007220215,
      "eval_loss": 0.5619252324104309,
      "eval_runtime": 12.4116,
      "eval_samples_per_second": 32.872,
      "eval_steps_per_second": 4.109,
      "step": 4590
    },
    {
      "epoch": 15.032679738562091,
      "grad_norm": 1.747275948524475,
      "learning_rate": 0.00047114845938375343,
      "loss": 0.092,
      "step": 4600
    },
    {
      "epoch": 15.098039215686274,
      "grad_norm": 0.09362901747226715,
      "learning_rate": 0.0004705882352941176,
      "loss": 0.0824,
      "step": 4620
    },
    {
      "epoch": 15.163398692810457,
      "grad_norm": 0.006633480079472065,
      "learning_rate": 0.0004700280112044817,
      "loss": 0.0392,
      "step": 4640
    },
    {
      "epoch": 15.22875816993464,
      "grad_norm": 0.0075337388552725315,
      "learning_rate": 0.0004694677871148459,
      "loss": 0.0366,
      "step": 4660
    },
    {
      "epoch": 15.294117647058824,
      "grad_norm": 9.620691299438477,
      "learning_rate": 0.00046890756302521,
      "loss": 0.0637,
      "step": 4680
    },
    {
      "epoch": 15.359477124183007,
      "grad_norm": 0.20245304703712463,
      "learning_rate": 0.0004683473389355742,
      "loss": 0.2187,
      "step": 4700
    },
    {
      "epoch": 15.42483660130719,
      "grad_norm": 0.04638662934303284,
      "learning_rate": 0.0004677871148459383,
      "loss": 0.0968,
      "step": 4720
    },
    {
      "epoch": 15.490196078431373,
      "grad_norm": 7.996844291687012,
      "learning_rate": 0.0004672268907563025,
      "loss": 0.057,
      "step": 4740
    },
    {
      "epoch": 15.555555555555555,
      "grad_norm": 0.1910923570394516,
      "learning_rate": 0.0004666666666666666,
      "loss": 0.1148,
      "step": 4760
    },
    {
      "epoch": 15.620915032679738,
      "grad_norm": 0.1346183866262436,
      "learning_rate": 0.0004661064425770308,
      "loss": 0.0596,
      "step": 4780
    },
    {
      "epoch": 15.686274509803921,
      "grad_norm": 0.19479912519454956,
      "learning_rate": 0.0004655462184873949,
      "loss": 0.1549,
      "step": 4800
    },
    {
      "epoch": 15.751633986928105,
      "grad_norm": 0.1334979236125946,
      "learning_rate": 0.0004649859943977591,
      "loss": 0.0677,
      "step": 4820
    },
    {
      "epoch": 15.816993464052288,
      "grad_norm": 4.174920082092285,
      "learning_rate": 0.00046442577030812325,
      "loss": 0.1179,
      "step": 4840
    },
    {
      "epoch": 15.882352941176471,
      "grad_norm": 0.05695229396224022,
      "learning_rate": 0.00046386554621848737,
      "loss": 0.1199,
      "step": 4860
    },
    {
      "epoch": 15.947712418300654,
      "grad_norm": 4.522861957550049,
      "learning_rate": 0.00046330532212885154,
      "loss": 0.2109,
      "step": 4880
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.8964341065022812,
      "eval_f1": 0.9129662522202486,
      "eval_loss": 0.5235623121261597,
      "eval_runtime": 12.6026,
      "eval_samples_per_second": 32.374,
      "eval_steps_per_second": 4.047,
      "step": 4896
    },
    {
      "epoch": 16.013071895424837,
      "grad_norm": 2.0776023864746094,
      "learning_rate": 0.00046274509803921566,
      "loss": 0.0944,
      "step": 4900
    },
    {
      "epoch": 16.07843137254902,
      "grad_norm": 0.16738973557949066,
      "learning_rate": 0.00046218487394957984,
      "loss": 0.0868,
      "step": 4920
    },
    {
      "epoch": 16.143790849673202,
      "grad_norm": 0.2544907033443451,
      "learning_rate": 0.00046162464985994396,
      "loss": 0.0812,
      "step": 4940
    },
    {
      "epoch": 16.209150326797385,
      "grad_norm": 3.8374814987182617,
      "learning_rate": 0.00046106442577030813,
      "loss": 0.1706,
      "step": 4960
    },
    {
      "epoch": 16.274509803921568,
      "grad_norm": 5.629056930541992,
      "learning_rate": 0.00046050420168067225,
      "loss": 0.1018,
      "step": 4980
    },
    {
      "epoch": 16.33986928104575,
      "grad_norm": 5.47295618057251,
      "learning_rate": 0.0004599439775910364,
      "loss": 0.096,
      "step": 5000
    },
    {
      "epoch": 16.405228758169933,
      "grad_norm": 1.977933406829834,
      "learning_rate": 0.00045938375350140055,
      "loss": 0.1331,
      "step": 5020
    },
    {
      "epoch": 16.470588235294116,
      "grad_norm": 0.1345818191766739,
      "learning_rate": 0.0004588235294117646,
      "loss": 0.0694,
      "step": 5040
    },
    {
      "epoch": 16.535947712418302,
      "grad_norm": 9.602892875671387,
      "learning_rate": 0.0004582633053221288,
      "loss": 0.0744,
      "step": 5060
    },
    {
      "epoch": 16.601307189542485,
      "grad_norm": 9.530579566955566,
      "learning_rate": 0.0004577030812324929,
      "loss": 0.1105,
      "step": 5080
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.005269231274724007,
      "learning_rate": 0.0004571428571428571,
      "loss": 0.0771,
      "step": 5100
    },
    {
      "epoch": 16.73202614379085,
      "grad_norm": 8.509693145751953,
      "learning_rate": 0.0004565826330532212,
      "loss": 0.1182,
      "step": 5120
    },
    {
      "epoch": 16.797385620915033,
      "grad_norm": 0.0608350895345211,
      "learning_rate": 0.0004560224089635854,
      "loss": 0.1152,
      "step": 5140
    },
    {
      "epoch": 16.862745098039216,
      "grad_norm": 9.182117462158203,
      "learning_rate": 0.0004554621848739495,
      "loss": 0.1052,
      "step": 5160
    },
    {
      "epoch": 16.9281045751634,
      "grad_norm": 1.3047680854797363,
      "learning_rate": 0.00045490196078431367,
      "loss": 0.0732,
      "step": 5180
    },
    {
      "epoch": 16.99346405228758,
      "grad_norm": 0.13608793914318085,
      "learning_rate": 0.00045434173669467784,
      "loss": 0.1484,
      "step": 5200
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.897342284739983,
      "eval_f1": 0.9147826086956522,
      "eval_loss": 0.6278610229492188,
      "eval_runtime": 13.1596,
      "eval_samples_per_second": 31.004,
      "eval_steps_per_second": 3.876,
      "step": 5202
    },
    {
      "epoch": 17.058823529411764,
      "grad_norm": 6.647702693939209,
      "learning_rate": 0.00045378151260504196,
      "loss": 0.1451,
      "step": 5220
    },
    {
      "epoch": 17.124183006535947,
      "grad_norm": 5.746811866760254,
      "learning_rate": 0.00045322128851540614,
      "loss": 0.068,
      "step": 5240
    },
    {
      "epoch": 17.18954248366013,
      "grad_norm": 11.666946411132812,
      "learning_rate": 0.00045266106442577026,
      "loss": 0.1344,
      "step": 5260
    },
    {
      "epoch": 17.254901960784313,
      "grad_norm": 0.6921539306640625,
      "learning_rate": 0.00045210084033613443,
      "loss": 0.082,
      "step": 5280
    },
    {
      "epoch": 17.320261437908496,
      "grad_norm": 0.43239912390708923,
      "learning_rate": 0.00045154061624649855,
      "loss": 0.0843,
      "step": 5300
    },
    {
      "epoch": 17.38562091503268,
      "grad_norm": 2.0389180183410645,
      "learning_rate": 0.0004509803921568627,
      "loss": 0.0815,
      "step": 5320
    },
    {
      "epoch": 17.45098039215686,
      "grad_norm": 3.304185628890991,
      "learning_rate": 0.00045042016806722684,
      "loss": 0.0684,
      "step": 5340
    },
    {
      "epoch": 17.516339869281047,
      "grad_norm": 0.16363532841205597,
      "learning_rate": 0.000449859943977591,
      "loss": 0.013,
      "step": 5360
    },
    {
      "epoch": 17.58169934640523,
      "grad_norm": 7.954092979431152,
      "learning_rate": 0.00044929971988795514,
      "loss": 0.2562,
      "step": 5380
    },
    {
      "epoch": 17.647058823529413,
      "grad_norm": 0.024036874994635582,
      "learning_rate": 0.0004487394957983193,
      "loss": 0.035,
      "step": 5400
    },
    {
      "epoch": 17.712418300653596,
      "grad_norm": 0.10220569372177124,
      "learning_rate": 0.00044817927170868343,
      "loss": 0.095,
      "step": 5420
    },
    {
      "epoch": 17.77777777777778,
      "grad_norm": 4.418323516845703,
      "learning_rate": 0.0004476190476190476,
      "loss": 0.0892,
      "step": 5440
    },
    {
      "epoch": 17.84313725490196,
      "grad_norm": 0.601460337638855,
      "learning_rate": 0.0004470588235294117,
      "loss": 0.0702,
      "step": 5460
    },
    {
      "epoch": 17.908496732026144,
      "grad_norm": 5.324348449707031,
      "learning_rate": 0.0004464985994397759,
      "loss": 0.0969,
      "step": 5480
    },
    {
      "epoch": 17.973856209150327,
      "grad_norm": 0.0083071980625391,
      "learning_rate": 0.00044593837535014,
      "loss": 0.0776,
      "step": 5500
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.9155193992490613,
      "eval_f1": 0.9290780141843972,
      "eval_loss": 0.5836358666419983,
      "eval_runtime": 13.295,
      "eval_samples_per_second": 30.688,
      "eval_steps_per_second": 3.836,
      "step": 5508
    },
    {
      "epoch": 18.03921568627451,
      "grad_norm": 0.018981847912073135,
      "learning_rate": 0.0004453781512605042,
      "loss": 0.0662,
      "step": 5520
    },
    {
      "epoch": 18.104575163398692,
      "grad_norm": 0.06074346601963043,
      "learning_rate": 0.0004448179271708683,
      "loss": 0.0288,
      "step": 5540
    },
    {
      "epoch": 18.169934640522875,
      "grad_norm": 0.16931399703025818,
      "learning_rate": 0.0004442577030812325,
      "loss": 0.0704,
      "step": 5560
    },
    {
      "epoch": 18.235294117647058,
      "grad_norm": 0.005942641291767359,
      "learning_rate": 0.0004436974789915966,
      "loss": 0.053,
      "step": 5580
    },
    {
      "epoch": 18.30065359477124,
      "grad_norm": 0.01290634460747242,
      "learning_rate": 0.0004431372549019608,
      "loss": 0.0822,
      "step": 5600
    },
    {
      "epoch": 18.366013071895424,
      "grad_norm": 0.32167771458625793,
      "learning_rate": 0.0004425770308123249,
      "loss": 0.1235,
      "step": 5620
    },
    {
      "epoch": 18.431372549019606,
      "grad_norm": 8.944246292114258,
      "learning_rate": 0.0004420168067226891,
      "loss": 0.1361,
      "step": 5640
    },
    {
      "epoch": 18.49673202614379,
      "grad_norm": 2.208324670791626,
      "learning_rate": 0.0004414565826330532,
      "loss": 0.177,
      "step": 5660
    },
    {
      "epoch": 18.562091503267975,
      "grad_norm": 6.282968044281006,
      "learning_rate": 0.00044089635854341737,
      "loss": 0.0326,
      "step": 5680
    },
    {
      "epoch": 18.627450980392158,
      "grad_norm": 4.929278373718262,
      "learning_rate": 0.00044033613445378144,
      "loss": 0.1148,
      "step": 5700
    },
    {
      "epoch": 18.69281045751634,
      "grad_norm": 8.719959259033203,
      "learning_rate": 0.0004397759103641456,
      "loss": 0.0358,
      "step": 5720
    },
    {
      "epoch": 18.758169934640524,
      "grad_norm": 0.0076692672446370125,
      "learning_rate": 0.00043921568627450973,
      "loss": 0.0675,
      "step": 5740
    },
    {
      "epoch": 18.823529411764707,
      "grad_norm": 0.24501168727874756,
      "learning_rate": 0.0004386554621848739,
      "loss": 0.0479,
      "step": 5760
    },
    {
      "epoch": 18.88888888888889,
      "grad_norm": 0.04408096522092819,
      "learning_rate": 0.000438095238095238,
      "loss": 0.1148,
      "step": 5780
    },
    {
      "epoch": 18.954248366013072,
      "grad_norm": 1.5123642683029175,
      "learning_rate": 0.0004375350140056022,
      "loss": 0.0897,
      "step": 5800
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.9156447031109263,
      "eval_f1": 0.9293286219081272,
      "eval_loss": 0.5739628076553345,
      "eval_runtime": 12.5969,
      "eval_samples_per_second": 32.389,
      "eval_steps_per_second": 4.049,
      "step": 5814
    },
    {
      "epoch": 19.019607843137255,
      "grad_norm": 0.060335077345371246,
      "learning_rate": 0.0004369747899159663,
      "loss": 0.0967,
      "step": 5820
    },
    {
      "epoch": 19.084967320261438,
      "grad_norm": 0.12591002881526947,
      "learning_rate": 0.0004364145658263305,
      "loss": 0.089,
      "step": 5840
    },
    {
      "epoch": 19.15032679738562,
      "grad_norm": 0.13530473411083221,
      "learning_rate": 0.0004358543417366946,
      "loss": 0.0431,
      "step": 5860
    },
    {
      "epoch": 19.215686274509803,
      "grad_norm": 0.029857931658625603,
      "learning_rate": 0.0004352941176470588,
      "loss": 0.0348,
      "step": 5880
    },
    {
      "epoch": 19.281045751633986,
      "grad_norm": 0.8490197062492371,
      "learning_rate": 0.0004347338935574229,
      "loss": 0.0481,
      "step": 5900
    },
    {
      "epoch": 19.34640522875817,
      "grad_norm": 0.004441054537892342,
      "learning_rate": 0.0004341736694677871,
      "loss": 0.047,
      "step": 5920
    },
    {
      "epoch": 19.41176470588235,
      "grad_norm": 0.00035129874595440924,
      "learning_rate": 0.0004336134453781512,
      "loss": 0.0471,
      "step": 5940
    },
    {
      "epoch": 19.477124183006534,
      "grad_norm": 0.07416563481092453,
      "learning_rate": 0.0004330532212885154,
      "loss": 0.1604,
      "step": 5960
    },
    {
      "epoch": 19.54248366013072,
      "grad_norm": 0.837480366230011,
      "learning_rate": 0.0004324929971988795,
      "loss": 0.1394,
      "step": 5980
    },
    {
      "epoch": 19.607843137254903,
      "grad_norm": 7.354590892791748,
      "learning_rate": 0.00043193277310924367,
      "loss": 0.1034,
      "step": 6000
    },
    {
      "epoch": 19.673202614379086,
      "grad_norm": 0.005045879166573286,
      "learning_rate": 0.0004313725490196078,
      "loss": 0.0798,
      "step": 6020
    },
    {
      "epoch": 19.73856209150327,
      "grad_norm": 9.138529777526855,
      "learning_rate": 0.00043081232492997196,
      "loss": 0.1389,
      "step": 6040
    },
    {
      "epoch": 19.80392156862745,
      "grad_norm": 0.101137176156044,
      "learning_rate": 0.0004302521008403361,
      "loss": 0.1159,
      "step": 6060
    },
    {
      "epoch": 19.869281045751634,
      "grad_norm": 0.018819676712155342,
      "learning_rate": 0.00042969187675070026,
      "loss": 0.0711,
      "step": 6080
    },
    {
      "epoch": 19.934640522875817,
      "grad_norm": 2.961249828338623,
      "learning_rate": 0.0004291316526610644,
      "loss": 0.0871,
      "step": 6100
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.008113742806017399,
      "learning_rate": 0.00042857142857142855,
      "loss": 0.0974,
      "step": 6120
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9036968954248366,
      "eval_f1": 0.9201388888888888,
      "eval_loss": 0.5806775093078613,
      "eval_runtime": 12.0953,
      "eval_samples_per_second": 33.732,
      "eval_steps_per_second": 4.217,
      "step": 6120
    },
    {
      "epoch": 20.065359477124183,
      "grad_norm": 3.3403615951538086,
      "learning_rate": 0.00042801120448179267,
      "loss": 0.0766,
      "step": 6140
    },
    {
      "epoch": 20.130718954248366,
      "grad_norm": 16.377347946166992,
      "learning_rate": 0.00042745098039215684,
      "loss": 0.12,
      "step": 6160
    },
    {
      "epoch": 20.19607843137255,
      "grad_norm": 0.016299879178404808,
      "learning_rate": 0.00042689075630252096,
      "loss": 0.0455,
      "step": 6180
    },
    {
      "epoch": 20.26143790849673,
      "grad_norm": 0.012399584986269474,
      "learning_rate": 0.00042633053221288514,
      "loss": 0.1056,
      "step": 6200
    },
    {
      "epoch": 20.326797385620914,
      "grad_norm": 1.715680718421936,
      "learning_rate": 0.00042577030812324926,
      "loss": 0.0933,
      "step": 6220
    },
    {
      "epoch": 20.392156862745097,
      "grad_norm": 0.524901807308197,
      "learning_rate": 0.00042521008403361343,
      "loss": 0.0558,
      "step": 6240
    },
    {
      "epoch": 20.45751633986928,
      "grad_norm": 0.0480928048491478,
      "learning_rate": 0.00042464985994397755,
      "loss": 0.0261,
      "step": 6260
    },
    {
      "epoch": 20.522875816993466,
      "grad_norm": 12.40799331665039,
      "learning_rate": 0.0004240896358543417,
      "loss": 0.1071,
      "step": 6280
    },
    {
      "epoch": 20.58823529411765,
      "grad_norm": 0.034252848476171494,
      "learning_rate": 0.0004235294117647059,
      "loss": 0.0582,
      "step": 6300
    },
    {
      "epoch": 20.65359477124183,
      "grad_norm": 0.041424501687288284,
      "learning_rate": 0.00042296918767507,
      "loss": 0.021,
      "step": 6320
    },
    {
      "epoch": 20.718954248366014,
      "grad_norm": 2.51981782913208,
      "learning_rate": 0.0004224089635854342,
      "loss": 0.0935,
      "step": 6340
    },
    {
      "epoch": 20.784313725490197,
      "grad_norm": 0.01669471338391304,
      "learning_rate": 0.00042184873949579826,
      "loss": 0.0259,
      "step": 6360
    },
    {
      "epoch": 20.84967320261438,
      "grad_norm": 4.012894630432129,
      "learning_rate": 0.0004212885154061624,
      "loss": 0.1395,
      "step": 6380
    },
    {
      "epoch": 20.915032679738562,
      "grad_norm": 10.510788917541504,
      "learning_rate": 0.00042072829131652655,
      "loss": 0.1189,
      "step": 6400
    },
    {
      "epoch": 20.980392156862745,
      "grad_norm": 5.260508060455322,
      "learning_rate": 0.0004201680672268907,
      "loss": 0.0912,
      "step": 6420
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.8651960784313726,
      "eval_combined_score": 0.8860667363392057,
      "eval_f1": 0.9069373942470389,
      "eval_loss": 0.8280636668205261,
      "eval_runtime": 12.2265,
      "eval_samples_per_second": 33.37,
      "eval_steps_per_second": 4.171,
      "step": 6426
    },
    {
      "epoch": 21.045751633986928,
      "grad_norm": 0.13831155002117157,
      "learning_rate": 0.00041960784313725485,
      "loss": 0.1156,
      "step": 6440
    },
    {
      "epoch": 21.11111111111111,
      "grad_norm": 1.6026333570480347,
      "learning_rate": 0.00041904761904761897,
      "loss": 0.0611,
      "step": 6460
    },
    {
      "epoch": 21.176470588235293,
      "grad_norm": 4.70048189163208,
      "learning_rate": 0.00041848739495798314,
      "loss": 0.0885,
      "step": 6480
    },
    {
      "epoch": 21.241830065359476,
      "grad_norm": 0.021490905433893204,
      "learning_rate": 0.00041792717086834726,
      "loss": 0.0886,
      "step": 6500
    },
    {
      "epoch": 21.30718954248366,
      "grad_norm": 7.431694507598877,
      "learning_rate": 0.00041736694677871144,
      "loss": 0.0919,
      "step": 6520
    },
    {
      "epoch": 21.372549019607842,
      "grad_norm": 7.1405229568481445,
      "learning_rate": 0.00041680672268907556,
      "loss": 0.0486,
      "step": 6540
    },
    {
      "epoch": 21.437908496732025,
      "grad_norm": 0.02011912129819393,
      "learning_rate": 0.00041624649859943973,
      "loss": 0.126,
      "step": 6560
    },
    {
      "epoch": 21.50326797385621,
      "grad_norm": 0.30797049403190613,
      "learning_rate": 0.00041568627450980385,
      "loss": 0.0597,
      "step": 6580
    },
    {
      "epoch": 21.568627450980394,
      "grad_norm": 4.124236583709717,
      "learning_rate": 0.000415126050420168,
      "loss": 0.1042,
      "step": 6600
    },
    {
      "epoch": 21.633986928104576,
      "grad_norm": 0.06852250546216965,
      "learning_rate": 0.00041456582633053214,
      "loss": 0.1059,
      "step": 6620
    },
    {
      "epoch": 21.69934640522876,
      "grad_norm": 23.84453582763672,
      "learning_rate": 0.0004140056022408963,
      "loss": 0.0758,
      "step": 6640
    },
    {
      "epoch": 21.764705882352942,
      "grad_norm": 0.03664077818393707,
      "learning_rate": 0.0004134453781512605,
      "loss": 0.1577,
      "step": 6660
    },
    {
      "epoch": 21.830065359477125,
      "grad_norm": 3.8058390617370605,
      "learning_rate": 0.0004128851540616246,
      "loss": 0.0498,
      "step": 6680
    },
    {
      "epoch": 21.895424836601308,
      "grad_norm": 0.03340888023376465,
      "learning_rate": 0.0004123249299719888,
      "loss": 0.0604,
      "step": 6700
    },
    {
      "epoch": 21.96078431372549,
      "grad_norm": 8.41253662109375,
      "learning_rate": 0.0004117647058823529,
      "loss": 0.0452,
      "step": 6720
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9057225063938619,
      "eval_f1": 0.9217391304347826,
      "eval_loss": 0.6501191258430481,
      "eval_runtime": 12.3888,
      "eval_samples_per_second": 32.933,
      "eval_steps_per_second": 4.117,
      "step": 6732
    },
    {
      "epoch": 22.026143790849673,
      "grad_norm": 0.16458909213542938,
      "learning_rate": 0.0004112044817927171,
      "loss": 0.0946,
      "step": 6740
    },
    {
      "epoch": 22.091503267973856,
      "grad_norm": 0.01827961392700672,
      "learning_rate": 0.0004106442577030812,
      "loss": 0.078,
      "step": 6760
    },
    {
      "epoch": 22.15686274509804,
      "grad_norm": 0.02126939408481121,
      "learning_rate": 0.0004100840336134454,
      "loss": 0.0444,
      "step": 6780
    },
    {
      "epoch": 22.22222222222222,
      "grad_norm": 0.12157295644283295,
      "learning_rate": 0.0004095238095238095,
      "loss": 0.0201,
      "step": 6800
    },
    {
      "epoch": 22.287581699346404,
      "grad_norm": 0.0765606090426445,
      "learning_rate": 0.00040896358543417367,
      "loss": 0.0653,
      "step": 6820
    },
    {
      "epoch": 22.352941176470587,
      "grad_norm": 0.03240978345274925,
      "learning_rate": 0.0004084033613445378,
      "loss": 0.0776,
      "step": 6840
    },
    {
      "epoch": 22.41830065359477,
      "grad_norm": 0.04684135690331459,
      "learning_rate": 0.00040784313725490196,
      "loss": 0.0726,
      "step": 6860
    },
    {
      "epoch": 22.483660130718953,
      "grad_norm": 0.11446868628263474,
      "learning_rate": 0.0004072829131652661,
      "loss": 0.0945,
      "step": 6880
    },
    {
      "epoch": 22.54901960784314,
      "grad_norm": 103.05451202392578,
      "learning_rate": 0.00040672268907563026,
      "loss": 0.1561,
      "step": 6900
    },
    {
      "epoch": 22.61437908496732,
      "grad_norm": 8.256967544555664,
      "learning_rate": 0.0004061624649859944,
      "loss": 0.1054,
      "step": 6920
    },
    {
      "epoch": 22.679738562091504,
      "grad_norm": 0.023933157324790955,
      "learning_rate": 0.00040560224089635855,
      "loss": 0.0664,
      "step": 6940
    },
    {
      "epoch": 22.745098039215687,
      "grad_norm": 0.05587753653526306,
      "learning_rate": 0.00040504201680672267,
      "loss": 0.0253,
      "step": 6960
    },
    {
      "epoch": 22.81045751633987,
      "grad_norm": 0.03164387121796608,
      "learning_rate": 0.00040448179271708684,
      "loss": 0.1043,
      "step": 6980
    },
    {
      "epoch": 22.875816993464053,
      "grad_norm": 0.011241039261221886,
      "learning_rate": 0.00040392156862745096,
      "loss": 0.1154,
      "step": 7000
    },
    {
      "epoch": 22.941176470588236,
      "grad_norm": 0.2372254580259323,
      "learning_rate": 0.00040336134453781514,
      "loss": 0.0859,
      "step": 7020
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9057225063938619,
      "eval_f1": 0.9217391304347826,
      "eval_loss": 0.636690616607666,
      "eval_runtime": 12.4075,
      "eval_samples_per_second": 32.883,
      "eval_steps_per_second": 4.11,
      "step": 7038
    },
    {
      "epoch": 23.00653594771242,
      "grad_norm": 0.01584690622985363,
      "learning_rate": 0.0004028011204481792,
      "loss": 0.0115,
      "step": 7040
    },
    {
      "epoch": 23.0718954248366,
      "grad_norm": 0.006076308432966471,
      "learning_rate": 0.0004022408963585434,
      "loss": 0.0113,
      "step": 7060
    },
    {
      "epoch": 23.137254901960784,
      "grad_norm": 0.008566562086343765,
      "learning_rate": 0.0004016806722689075,
      "loss": 0.127,
      "step": 7080
    },
    {
      "epoch": 23.202614379084967,
      "grad_norm": 0.037156879901885986,
      "learning_rate": 0.00040112044817927167,
      "loss": 0.0162,
      "step": 7100
    },
    {
      "epoch": 23.26797385620915,
      "grad_norm": 5.711341857910156,
      "learning_rate": 0.0004005602240896358,
      "loss": 0.1022,
      "step": 7120
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 0.01377831120043993,
      "learning_rate": 0.00039999999999999996,
      "loss": 0.1016,
      "step": 7140
    },
    {
      "epoch": 23.398692810457515,
      "grad_norm": 0.00906338170170784,
      "learning_rate": 0.0003994397759103641,
      "loss": 0.005,
      "step": 7160
    },
    {
      "epoch": 23.464052287581698,
      "grad_norm": 11.891921043395996,
      "learning_rate": 0.00039887955182072826,
      "loss": 0.1026,
      "step": 7180
    },
    {
      "epoch": 23.529411764705884,
      "grad_norm": 0.0185844823718071,
      "learning_rate": 0.0003983193277310924,
      "loss": 0.028,
      "step": 7200
    },
    {
      "epoch": 23.594771241830067,
      "grad_norm": 0.01965697854757309,
      "learning_rate": 0.00039775910364145655,
      "loss": 0.0509,
      "step": 7220
    },
    {
      "epoch": 23.66013071895425,
      "grad_norm": 9.467520713806152,
      "learning_rate": 0.00039719887955182067,
      "loss": 0.047,
      "step": 7240
    },
    {
      "epoch": 23.725490196078432,
      "grad_norm": 0.06205277144908905,
      "learning_rate": 0.00039663865546218485,
      "loss": 0.0368,
      "step": 7260
    },
    {
      "epoch": 23.790849673202615,
      "grad_norm": 0.16624292731285095,
      "learning_rate": 0.00039607843137254897,
      "loss": 0.0676,
      "step": 7280
    },
    {
      "epoch": 23.856209150326798,
      "grad_norm": 17.472736358642578,
      "learning_rate": 0.00039551820728291314,
      "loss": 0.1641,
      "step": 7300
    },
    {
      "epoch": 23.92156862745098,
      "grad_norm": 4.3122758865356445,
      "learning_rate": 0.00039495798319327726,
      "loss": 0.0853,
      "step": 7320
    },
    {
      "epoch": 23.986928104575163,
      "grad_norm": 10.460165977478027,
      "learning_rate": 0.00039439775910364143,
      "loss": 0.0681,
      "step": 7340
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.91500916913528,
      "eval_f1": 0.9280575539568345,
      "eval_loss": 0.5603628158569336,
      "eval_runtime": 12.4307,
      "eval_samples_per_second": 32.822,
      "eval_steps_per_second": 4.103,
      "step": 7344
    },
    {
      "epoch": 24.052287581699346,
      "grad_norm": 6.24386739730835,
      "learning_rate": 0.00039383753501400555,
      "loss": 0.1928,
      "step": 7360
    },
    {
      "epoch": 24.11764705882353,
      "grad_norm": 0.050824157893657684,
      "learning_rate": 0.00039327731092436973,
      "loss": 0.0604,
      "step": 7380
    },
    {
      "epoch": 24.18300653594771,
      "grad_norm": 0.29335808753967285,
      "learning_rate": 0.00039271708683473385,
      "loss": 0.0093,
      "step": 7400
    },
    {
      "epoch": 24.248366013071895,
      "grad_norm": 0.0034132960718125105,
      "learning_rate": 0.000392156862745098,
      "loss": 0.0415,
      "step": 7420
    },
    {
      "epoch": 24.313725490196077,
      "grad_norm": 0.016534743830561638,
      "learning_rate": 0.00039159663865546214,
      "loss": 0.1054,
      "step": 7440
    },
    {
      "epoch": 24.37908496732026,
      "grad_norm": 3.3496975898742676,
      "learning_rate": 0.0003910364145658263,
      "loss": 0.037,
      "step": 7460
    },
    {
      "epoch": 24.444444444444443,
      "grad_norm": 3.013066530227661,
      "learning_rate": 0.00039047619047619044,
      "loss": 0.1125,
      "step": 7480
    },
    {
      "epoch": 24.509803921568626,
      "grad_norm": 0.9350399374961853,
      "learning_rate": 0.0003899159663865546,
      "loss": 0.0656,
      "step": 7500
    },
    {
      "epoch": 24.575163398692812,
      "grad_norm": 0.05646856501698494,
      "learning_rate": 0.00038935574229691873,
      "loss": 0.0534,
      "step": 7520
    },
    {
      "epoch": 24.640522875816995,
      "grad_norm": 0.029296552762389183,
      "learning_rate": 0.0003887955182072829,
      "loss": 0.1331,
      "step": 7540
    },
    {
      "epoch": 24.705882352941178,
      "grad_norm": 0.02970752865076065,
      "learning_rate": 0.000388235294117647,
      "loss": 0.0404,
      "step": 7560
    },
    {
      "epoch": 24.77124183006536,
      "grad_norm": 0.0025742247235029936,
      "learning_rate": 0.0003876750700280112,
      "loss": 0.0932,
      "step": 7580
    },
    {
      "epoch": 24.836601307189543,
      "grad_norm": 0.01948288083076477,
      "learning_rate": 0.0003871148459383753,
      "loss": 0.0319,
      "step": 7600
    },
    {
      "epoch": 24.901960784313726,
      "grad_norm": 0.032088976353406906,
      "learning_rate": 0.0003865546218487395,
      "loss": 0.1324,
      "step": 7620
    },
    {
      "epoch": 24.96732026143791,
      "grad_norm": 0.004649917129427195,
      "learning_rate": 0.0003859943977591036,
      "loss": 0.0287,
      "step": 7640
    },
    {
      "epoch": 25.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.9155193992490613,
      "eval_f1": 0.9290780141843972,
      "eval_loss": 0.5634111762046814,
      "eval_runtime": 12.4684,
      "eval_samples_per_second": 32.723,
      "eval_steps_per_second": 4.09,
      "step": 7650
    },
    {
      "epoch": 25.03267973856209,
      "grad_norm": 0.15686719119548798,
      "learning_rate": 0.0003854341736694678,
      "loss": 0.0447,
      "step": 7660
    },
    {
      "epoch": 25.098039215686274,
      "grad_norm": 0.28922533988952637,
      "learning_rate": 0.0003848739495798319,
      "loss": 0.1307,
      "step": 7680
    },
    {
      "epoch": 25.163398692810457,
      "grad_norm": 0.23151430487632751,
      "learning_rate": 0.000384313725490196,
      "loss": 0.054,
      "step": 7700
    },
    {
      "epoch": 25.22875816993464,
      "grad_norm": 0.02976212278008461,
      "learning_rate": 0.00038375350140056015,
      "loss": 0.0494,
      "step": 7720
    },
    {
      "epoch": 25.294117647058822,
      "grad_norm": 0.02619851939380169,
      "learning_rate": 0.0003831932773109243,
      "loss": 0.1055,
      "step": 7740
    },
    {
      "epoch": 25.359477124183005,
      "grad_norm": 0.4337637424468994,
      "learning_rate": 0.00038263305322128844,
      "loss": 0.1044,
      "step": 7760
    },
    {
      "epoch": 25.424836601307188,
      "grad_norm": 7.10760498046875,
      "learning_rate": 0.0003820728291316526,
      "loss": 0.0404,
      "step": 7780
    },
    {
      "epoch": 25.49019607843137,
      "grad_norm": 0.014145980589091778,
      "learning_rate": 0.00038151260504201673,
      "loss": 0.0472,
      "step": 7800
    },
    {
      "epoch": 25.555555555555557,
      "grad_norm": 0.07756823301315308,
      "learning_rate": 0.0003809523809523809,
      "loss": 0.0685,
      "step": 7820
    },
    {
      "epoch": 25.62091503267974,
      "grad_norm": 0.03223273903131485,
      "learning_rate": 0.00038039215686274503,
      "loss": 0.1085,
      "step": 7840
    },
    {
      "epoch": 25.686274509803923,
      "grad_norm": 0.015821553766727448,
      "learning_rate": 0.0003798319327731092,
      "loss": 0.0399,
      "step": 7860
    },
    {
      "epoch": 25.751633986928105,
      "grad_norm": 1.5755630731582642,
      "learning_rate": 0.0003792717086834733,
      "loss": 0.014,
      "step": 7880
    },
    {
      "epoch": 25.81699346405229,
      "grad_norm": 0.003087894059717655,
      "learning_rate": 0.0003787114845938375,
      "loss": 0.1366,
      "step": 7900
    },
    {
      "epoch": 25.88235294117647,
      "grad_norm": 0.0027428825851529837,
      "learning_rate": 0.0003781512605042016,
      "loss": 0.0905,
      "step": 7920
    },
    {
      "epoch": 25.947712418300654,
      "grad_norm": 12.207701683044434,
      "learning_rate": 0.0003775910364145658,
      "loss": 0.1012,
      "step": 7940
    },
    {
      "epoch": 26.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9088423831070891,
      "eval_f1": 0.9230769230769231,
      "eval_loss": 0.614776074886322,
      "eval_runtime": 12.4154,
      "eval_samples_per_second": 32.862,
      "eval_steps_per_second": 4.108,
      "step": 7956
    },
    {
      "epoch": 26.013071895424837,
      "grad_norm": 0.01761169359087944,
      "learning_rate": 0.0003770308123249299,
      "loss": 0.0223,
      "step": 7960
    },
    {
      "epoch": 26.07843137254902,
      "grad_norm": 0.03868838772177696,
      "learning_rate": 0.0003764705882352941,
      "loss": 0.0868,
      "step": 7980
    },
    {
      "epoch": 26.143790849673202,
      "grad_norm": 0.03445873782038689,
      "learning_rate": 0.0003759103641456582,
      "loss": 0.0445,
      "step": 8000
    },
    {
      "epoch": 26.209150326797385,
      "grad_norm": 0.025105005130171776,
      "learning_rate": 0.0003753501400560224,
      "loss": 0.0272,
      "step": 8020
    },
    {
      "epoch": 26.274509803921568,
      "grad_norm": 0.007985149510204792,
      "learning_rate": 0.0003747899159663865,
      "loss": 0.0193,
      "step": 8040
    },
    {
      "epoch": 26.33986928104575,
      "grad_norm": 0.04429524391889572,
      "learning_rate": 0.00037422969187675067,
      "loss": 0.0013,
      "step": 8060
    },
    {
      "epoch": 26.405228758169933,
      "grad_norm": 0.038170430809259415,
      "learning_rate": 0.0003736694677871148,
      "loss": 0.0345,
      "step": 8080
    },
    {
      "epoch": 26.470588235294116,
      "grad_norm": 6.208868026733398,
      "learning_rate": 0.00037310924369747897,
      "loss": 0.0505,
      "step": 8100
    },
    {
      "epoch": 26.535947712418302,
      "grad_norm": 22.298812866210938,
      "learning_rate": 0.0003725490196078431,
      "loss": 0.1214,
      "step": 8120
    },
    {
      "epoch": 26.601307189542485,
      "grad_norm": 1.0297694206237793,
      "learning_rate": 0.00037198879551820726,
      "loss": 0.0941,
      "step": 8140
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 8.353150367736816,
      "learning_rate": 0.00037142857142857143,
      "loss": 0.0078,
      "step": 8160
    },
    {
      "epoch": 26.73202614379085,
      "grad_norm": 7.9766740798950195,
      "learning_rate": 0.00037086834733893555,
      "loss": 0.0593,
      "step": 8180
    },
    {
      "epoch": 26.797385620915033,
      "grad_norm": 0.11718028783798218,
      "learning_rate": 0.00037030812324929973,
      "loss": 0.0261,
      "step": 8200
    },
    {
      "epoch": 26.862745098039216,
      "grad_norm": 0.0028066057711839676,
      "learning_rate": 0.00036974789915966385,
      "loss": 0.0023,
      "step": 8220
    },
    {
      "epoch": 26.9281045751634,
      "grad_norm": 0.0007942244992591441,
      "learning_rate": 0.000369187675070028,
      "loss": 0.0927,
      "step": 8240
    },
    {
      "epoch": 26.99346405228758,
      "grad_norm": 0.04904206469655037,
      "learning_rate": 0.00036862745098039214,
      "loss": 0.0982,
      "step": 8260
    },
    {
      "epoch": 27.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.9152661064425771,
      "eval_f1": 0.9285714285714286,
      "eval_loss": 0.6739006042480469,
      "eval_runtime": 12.5092,
      "eval_samples_per_second": 32.616,
      "eval_steps_per_second": 4.077,
      "step": 8262
    },
    {
      "epoch": 27.058823529411764,
      "grad_norm": 0.050306230783462524,
      "learning_rate": 0.0003680672268907563,
      "loss": 0.1265,
      "step": 8280
    },
    {
      "epoch": 27.124183006535947,
      "grad_norm": 0.024080272763967514,
      "learning_rate": 0.00036750700280112044,
      "loss": 0.0823,
      "step": 8300
    },
    {
      "epoch": 27.18954248366013,
      "grad_norm": 0.2001924216747284,
      "learning_rate": 0.0003669467787114846,
      "loss": 0.0075,
      "step": 8320
    },
    {
      "epoch": 27.254901960784313,
      "grad_norm": 0.01771419495344162,
      "learning_rate": 0.00036638655462184873,
      "loss": 0.0259,
      "step": 8340
    },
    {
      "epoch": 27.320261437908496,
      "grad_norm": 10.753952026367188,
      "learning_rate": 0.0003658263305322129,
      "loss": 0.0371,
      "step": 8360
    },
    {
      "epoch": 27.38562091503268,
      "grad_norm": 0.05565677955746651,
      "learning_rate": 0.00036526610644257697,
      "loss": 0.0387,
      "step": 8380
    },
    {
      "epoch": 27.45098039215686,
      "grad_norm": 0.0022555547766387463,
      "learning_rate": 0.0003647058823529411,
      "loss": 0.0105,
      "step": 8400
    },
    {
      "epoch": 27.516339869281047,
      "grad_norm": 0.09039970487356186,
      "learning_rate": 0.00036414565826330526,
      "loss": 0.0633,
      "step": 8420
    },
    {
      "epoch": 27.58169934640523,
      "grad_norm": 0.0008098872494883835,
      "learning_rate": 0.0003635854341736694,
      "loss": 0.0077,
      "step": 8440
    },
    {
      "epoch": 27.647058823529413,
      "grad_norm": 8.507594108581543,
      "learning_rate": 0.00036302521008403356,
      "loss": 0.1232,
      "step": 8460
    },
    {
      "epoch": 27.712418300653596,
      "grad_norm": 2.768103837966919,
      "learning_rate": 0.0003624649859943977,
      "loss": 0.0859,
      "step": 8480
    },
    {
      "epoch": 27.77777777777778,
      "grad_norm": 0.002590079791843891,
      "learning_rate": 0.00036190476190476185,
      "loss": 0.0954,
      "step": 8500
    },
    {
      "epoch": 27.84313725490196,
      "grad_norm": 0.0028960718773305416,
      "learning_rate": 0.000361344537815126,
      "loss": 0.0234,
      "step": 8520
    },
    {
      "epoch": 27.908496732026144,
      "grad_norm": 0.9692193269729614,
      "learning_rate": 0.00036078431372549015,
      "loss": 0.1264,
      "step": 8540
    },
    {
      "epoch": 27.973856209150327,
      "grad_norm": 6.202183246612549,
      "learning_rate": 0.0003602240896358543,
      "loss": 0.1175,
      "step": 8560
    },
    {
      "epoch": 28.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9110294117647059,
      "eval_f1": 0.9249999999999999,
      "eval_loss": 0.5161393880844116,
      "eval_runtime": 12.3905,
      "eval_samples_per_second": 32.928,
      "eval_steps_per_second": 4.116,
      "step": 8568
    },
    {
      "epoch": 28.03921568627451,
      "grad_norm": 0.04031006246805191,
      "learning_rate": 0.00035966386554621844,
      "loss": 0.058,
      "step": 8580
    },
    {
      "epoch": 28.104575163398692,
      "grad_norm": 0.05789162218570709,
      "learning_rate": 0.0003591036414565826,
      "loss": 0.0882,
      "step": 8600
    },
    {
      "epoch": 28.169934640522875,
      "grad_norm": 0.007678878027945757,
      "learning_rate": 0.00035854341736694673,
      "loss": 0.1382,
      "step": 8620
    },
    {
      "epoch": 28.235294117647058,
      "grad_norm": 12.294146537780762,
      "learning_rate": 0.0003579831932773109,
      "loss": 0.0702,
      "step": 8640
    },
    {
      "epoch": 28.30065359477124,
      "grad_norm": 0.1432816982269287,
      "learning_rate": 0.00035742296918767503,
      "loss": 0.0665,
      "step": 8660
    },
    {
      "epoch": 28.366013071895424,
      "grad_norm": 0.018970360979437828,
      "learning_rate": 0.0003568627450980392,
      "loss": 0.0448,
      "step": 8680
    },
    {
      "epoch": 28.431372549019606,
      "grad_norm": 0.0057593779638409615,
      "learning_rate": 0.0003563025210084033,
      "loss": 0.0955,
      "step": 8700
    },
    {
      "epoch": 28.49673202614379,
      "grad_norm": 0.010850274935364723,
      "learning_rate": 0.0003557422969187675,
      "loss": 0.0212,
      "step": 8720
    },
    {
      "epoch": 28.562091503267975,
      "grad_norm": 9.143396377563477,
      "learning_rate": 0.0003551820728291316,
      "loss": 0.0381,
      "step": 8740
    },
    {
      "epoch": 28.627450980392158,
      "grad_norm": 0.906040370464325,
      "learning_rate": 0.0003546218487394958,
      "loss": 0.0197,
      "step": 8760
    },
    {
      "epoch": 28.69281045751634,
      "grad_norm": 0.0019525174284353852,
      "learning_rate": 0.0003540616246498599,
      "loss": 0.102,
      "step": 8780
    },
    {
      "epoch": 28.758169934640524,
      "grad_norm": 2.2208662033081055,
      "learning_rate": 0.0003535014005602241,
      "loss": 0.1234,
      "step": 8800
    },
    {
      "epoch": 28.823529411764707,
      "grad_norm": 0.007360268384218216,
      "learning_rate": 0.0003529411764705882,
      "loss": 0.0645,
      "step": 8820
    },
    {
      "epoch": 28.88888888888889,
      "grad_norm": 18.533798217773438,
      "learning_rate": 0.0003523809523809524,
      "loss": 0.1594,
      "step": 8840
    },
    {
      "epoch": 28.954248366013072,
      "grad_norm": 3.8790454864501953,
      "learning_rate": 0.0003518207282913165,
      "loss": 0.053,
      "step": 8860
    },
    {
      "epoch": 29.0,
      "eval_accuracy": 0.875,
      "eval_combined_score": 0.8928415061295972,
      "eval_f1": 0.9106830122591945,
      "eval_loss": 0.699334442615509,
      "eval_runtime": 12.4243,
      "eval_samples_per_second": 32.839,
      "eval_steps_per_second": 4.105,
      "step": 8874
    },
    {
      "epoch": 29.019607843137255,
      "grad_norm": 0.026738932356238365,
      "learning_rate": 0.00035126050420168067,
      "loss": 0.1118,
      "step": 8880
    },
    {
      "epoch": 29.084967320261438,
      "grad_norm": 0.01086887065321207,
      "learning_rate": 0.0003507002801120448,
      "loss": 0.0063,
      "step": 8900
    },
    {
      "epoch": 29.15032679738562,
      "grad_norm": 0.0019834600389003754,
      "learning_rate": 0.00035014005602240897,
      "loss": 0.0607,
      "step": 8920
    },
    {
      "epoch": 29.215686274509803,
      "grad_norm": 0.0015026297187432647,
      "learning_rate": 0.0003495798319327731,
      "loss": 0.0384,
      "step": 8940
    },
    {
      "epoch": 29.281045751633986,
      "grad_norm": 0.296314001083374,
      "learning_rate": 0.00034901960784313726,
      "loss": 0.0099,
      "step": 8960
    },
    {
      "epoch": 29.34640522875817,
      "grad_norm": 0.017215272411704063,
      "learning_rate": 0.0003484593837535014,
      "loss": 0.0193,
      "step": 8980
    },
    {
      "epoch": 29.41176470588235,
      "grad_norm": 5.0567522048950195,
      "learning_rate": 0.00034789915966386555,
      "loss": 0.0327,
      "step": 9000
    },
    {
      "epoch": 29.477124183006534,
      "grad_norm": 0.006450945511460304,
      "learning_rate": 0.0003473389355742297,
      "loss": 0.0312,
      "step": 9020
    },
    {
      "epoch": 29.54248366013072,
      "grad_norm": 0.02761506661772728,
      "learning_rate": 0.0003467787114845938,
      "loss": 0.1277,
      "step": 9040
    },
    {
      "epoch": 29.607843137254903,
      "grad_norm": 0.10986356437206268,
      "learning_rate": 0.0003462184873949579,
      "loss": 0.0504,
      "step": 9060
    },
    {
      "epoch": 29.673202614379086,
      "grad_norm": 22.115638732910156,
      "learning_rate": 0.0003456582633053221,
      "loss": 0.0264,
      "step": 9080
    },
    {
      "epoch": 29.73856209150327,
      "grad_norm": 0.44155651330947876,
      "learning_rate": 0.0003450980392156862,
      "loss": 0.1183,
      "step": 9100
    },
    {
      "epoch": 29.80392156862745,
      "grad_norm": 3.4990885257720947,
      "learning_rate": 0.0003445378151260504,
      "loss": 0.1346,
      "step": 9120
    },
    {
      "epoch": 29.869281045751634,
      "grad_norm": 4.1522698402404785,
      "learning_rate": 0.0003439775910364145,
      "loss": 0.0485,
      "step": 9140
    },
    {
      "epoch": 29.934640522875817,
      "grad_norm": 0.11777827143669128,
      "learning_rate": 0.0003434173669467787,
      "loss": 0.0719,
      "step": 9160
    },
    {
      "epoch": 30.0,
      "grad_norm": 1.6831674575805664,
      "learning_rate": 0.0003428571428571428,
      "loss": 0.0567,
      "step": 9180
    },
    {
      "epoch": 30.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8995098039215687,
      "eval_f1": 0.9166666666666667,
      "eval_loss": 0.6172724962234497,
      "eval_runtime": 12.3556,
      "eval_samples_per_second": 33.022,
      "eval_steps_per_second": 4.128,
      "step": 9180
    },
    {
      "epoch": 30.065359477124183,
      "grad_norm": 0.06045901030302048,
      "learning_rate": 0.00034229691876750697,
      "loss": 0.014,
      "step": 9200
    },
    {
      "epoch": 30.130718954248366,
      "grad_norm": 7.358348369598389,
      "learning_rate": 0.0003417366946778711,
      "loss": 0.0124,
      "step": 9220
    },
    {
      "epoch": 30.19607843137255,
      "grad_norm": 7.492786884307861,
      "learning_rate": 0.00034117647058823526,
      "loss": 0.0359,
      "step": 9240
    },
    {
      "epoch": 30.26143790849673,
      "grad_norm": 0.004609950352460146,
      "learning_rate": 0.0003406162464985994,
      "loss": 0.0792,
      "step": 9260
    },
    {
      "epoch": 30.326797385620914,
      "grad_norm": 0.03025326132774353,
      "learning_rate": 0.00034005602240896356,
      "loss": 0.1231,
      "step": 9280
    },
    {
      "epoch": 30.392156862745097,
      "grad_norm": 9.11066722869873,
      "learning_rate": 0.0003394957983193277,
      "loss": 0.0763,
      "step": 9300
    },
    {
      "epoch": 30.45751633986928,
      "grad_norm": 0.03186720982193947,
      "learning_rate": 0.00033893557422969185,
      "loss": 0.018,
      "step": 9320
    },
    {
      "epoch": 30.522875816993466,
      "grad_norm": 0.05523080378770828,
      "learning_rate": 0.00033837535014005597,
      "loss": 0.0318,
      "step": 9340
    },
    {
      "epoch": 30.58823529411765,
      "grad_norm": 0.037352822721004486,
      "learning_rate": 0.00033781512605042015,
      "loss": 0.0501,
      "step": 9360
    },
    {
      "epoch": 30.65359477124183,
      "grad_norm": 0.017753448337316513,
      "learning_rate": 0.00033725490196078427,
      "loss": 0.0599,
      "step": 9380
    },
    {
      "epoch": 30.718954248366014,
      "grad_norm": 12.456869125366211,
      "learning_rate": 0.00033669467787114844,
      "loss": 0.0974,
      "step": 9400
    },
    {
      "epoch": 30.784313725490197,
      "grad_norm": 0.003108906326815486,
      "learning_rate": 0.00033613445378151256,
      "loss": 0.0461,
      "step": 9420
    },
    {
      "epoch": 30.84967320261438,
      "grad_norm": 0.04424206539988518,
      "learning_rate": 0.00033557422969187673,
      "loss": 0.0691,
      "step": 9440
    },
    {
      "epoch": 30.915032679738562,
      "grad_norm": 0.01597077026963234,
      "learning_rate": 0.00033501400560224085,
      "loss": 0.051,
      "step": 9460
    },
    {
      "epoch": 30.980392156862745,
      "grad_norm": 0.01423607300966978,
      "learning_rate": 0.00033445378151260503,
      "loss": 0.0522,
      "step": 9480
    },
    {
      "epoch": 31.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9132130124777184,
      "eval_f1": 0.9269162210338681,
      "eval_loss": 0.5888276100158691,
      "eval_runtime": 12.6113,
      "eval_samples_per_second": 32.352,
      "eval_steps_per_second": 4.044,
      "step": 9486
    },
    {
      "epoch": 31.045751633986928,
      "grad_norm": 1.4960947036743164,
      "learning_rate": 0.00033389355742296915,
      "loss": 0.0366,
      "step": 9500
    },
    {
      "epoch": 31.11111111111111,
      "grad_norm": 1.9013874530792236,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.0852,
      "step": 9520
    },
    {
      "epoch": 31.176470588235293,
      "grad_norm": 10.817496299743652,
      "learning_rate": 0.00033277310924369744,
      "loss": 0.0332,
      "step": 9540
    },
    {
      "epoch": 31.241830065359476,
      "grad_norm": 0.12578292191028595,
      "learning_rate": 0.0003322128851540616,
      "loss": 0.068,
      "step": 9560
    },
    {
      "epoch": 31.30718954248366,
      "grad_norm": 0.03356890752911568,
      "learning_rate": 0.00033165266106442574,
      "loss": 0.0048,
      "step": 9580
    },
    {
      "epoch": 31.372549019607842,
      "grad_norm": 0.0029273908585309982,
      "learning_rate": 0.0003310924369747899,
      "loss": 0.0109,
      "step": 9600
    },
    {
      "epoch": 31.437908496732025,
      "grad_norm": 0.022632300853729248,
      "learning_rate": 0.0003305322128851541,
      "loss": 0.0246,
      "step": 9620
    },
    {
      "epoch": 31.50326797385621,
      "grad_norm": 0.003330452833324671,
      "learning_rate": 0.0003299719887955182,
      "loss": 0.1634,
      "step": 9640
    },
    {
      "epoch": 31.568627450980394,
      "grad_norm": 0.22608891129493713,
      "learning_rate": 0.0003294117647058824,
      "loss": 0.0287,
      "step": 9660
    },
    {
      "epoch": 31.633986928104576,
      "grad_norm": 0.00940636545419693,
      "learning_rate": 0.0003288515406162465,
      "loss": 0.0153,
      "step": 9680
    },
    {
      "epoch": 31.69934640522876,
      "grad_norm": 12.958115577697754,
      "learning_rate": 0.00032829131652661067,
      "loss": 0.1027,
      "step": 9700
    },
    {
      "epoch": 31.764705882352942,
      "grad_norm": 0.023596463724970818,
      "learning_rate": 0.00032773109243697474,
      "loss": 0.0937,
      "step": 9720
    },
    {
      "epoch": 31.830065359477125,
      "grad_norm": 0.7747402787208557,
      "learning_rate": 0.00032717086834733886,
      "loss": 0.0828,
      "step": 9740
    },
    {
      "epoch": 31.895424836601308,
      "grad_norm": 0.0038628466427326202,
      "learning_rate": 0.00032661064425770303,
      "loss": 0.0238,
      "step": 9760
    },
    {
      "epoch": 31.96078431372549,
      "grad_norm": 0.08703054487705231,
      "learning_rate": 0.00032605042016806715,
      "loss": 0.0308,
      "step": 9780
    },
    {
      "epoch": 32.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9034176607706019,
      "eval_f1": 0.9195804195804195,
      "eval_loss": 0.7587283253669739,
      "eval_runtime": 12.3005,
      "eval_samples_per_second": 33.169,
      "eval_steps_per_second": 4.146,
      "step": 9792
    },
    {
      "epoch": 32.02614379084967,
      "grad_norm": 0.0014215748524293303,
      "learning_rate": 0.0003254901960784313,
      "loss": 0.0842,
      "step": 9800
    },
    {
      "epoch": 32.091503267973856,
      "grad_norm": 0.021090464666485786,
      "learning_rate": 0.00032492997198879545,
      "loss": 0.0152,
      "step": 9820
    },
    {
      "epoch": 32.15686274509804,
      "grad_norm": 3.6517021656036377,
      "learning_rate": 0.0003243697478991596,
      "loss": 0.0499,
      "step": 9840
    },
    {
      "epoch": 32.22222222222222,
      "grad_norm": 9.227838516235352,
      "learning_rate": 0.00032380952380952374,
      "loss": 0.0584,
      "step": 9860
    },
    {
      "epoch": 32.287581699346404,
      "grad_norm": 0.5658406615257263,
      "learning_rate": 0.0003232492997198879,
      "loss": 0.0304,
      "step": 9880
    },
    {
      "epoch": 32.35294117647059,
      "grad_norm": 0.020329652354121208,
      "learning_rate": 0.00032268907563025203,
      "loss": 0.0058,
      "step": 9900
    },
    {
      "epoch": 32.41830065359477,
      "grad_norm": 8.973880767822266,
      "learning_rate": 0.0003221288515406162,
      "loss": 0.0471,
      "step": 9920
    },
    {
      "epoch": 32.48366013071895,
      "grad_norm": 0.0008311182609759271,
      "learning_rate": 0.00032156862745098033,
      "loss": 0.0305,
      "step": 9940
    },
    {
      "epoch": 32.549019607843135,
      "grad_norm": 0.0025942500215023756,
      "learning_rate": 0.0003210084033613445,
      "loss": 0.0515,
      "step": 9960
    },
    {
      "epoch": 32.61437908496732,
      "grad_norm": 0.1922658532857895,
      "learning_rate": 0.0003204481792717087,
      "loss": 0.0312,
      "step": 9980
    },
    {
      "epoch": 32.6797385620915,
      "grad_norm": 4.112779140472412,
      "learning_rate": 0.0003198879551820728,
      "loss": 0.0128,
      "step": 10000
    },
    {
      "epoch": 32.745098039215684,
      "grad_norm": 1.3291089534759521,
      "learning_rate": 0.00031932773109243697,
      "loss": 0.0483,
      "step": 10020
    },
    {
      "epoch": 32.810457516339866,
      "grad_norm": 0.7388720512390137,
      "learning_rate": 0.0003187675070028011,
      "loss": 0.0609,
      "step": 10040
    },
    {
      "epoch": 32.87581699346405,
      "grad_norm": 0.019354522228240967,
      "learning_rate": 0.00031820728291316526,
      "loss": 0.0439,
      "step": 10060
    },
    {
      "epoch": 32.94117647058823,
      "grad_norm": 5.351621627807617,
      "learning_rate": 0.0003176470588235294,
      "loss": 0.1025,
      "step": 10080
    },
    {
      "epoch": 33.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9018147414406177,
      "eval_f1": 0.9188255613126081,
      "eval_loss": 0.6976482272148132,
      "eval_runtime": 12.4536,
      "eval_samples_per_second": 32.762,
      "eval_steps_per_second": 4.095,
      "step": 10098
    },
    {
      "epoch": 33.00653594771242,
      "grad_norm": 12.638652801513672,
      "learning_rate": 0.00031708683473389356,
      "loss": 0.1072,
      "step": 10100
    },
    {
      "epoch": 33.071895424836605,
      "grad_norm": 0.07082442194223404,
      "learning_rate": 0.0003165266106442577,
      "loss": 0.0132,
      "step": 10120
    },
    {
      "epoch": 33.13725490196079,
      "grad_norm": 0.005870202090591192,
      "learning_rate": 0.00031596638655462185,
      "loss": 0.0576,
      "step": 10140
    },
    {
      "epoch": 33.20261437908497,
      "grad_norm": 0.013270246796309948,
      "learning_rate": 0.00031540616246498597,
      "loss": 0.0162,
      "step": 10160
    },
    {
      "epoch": 33.26797385620915,
      "grad_norm": 8.147915840148926,
      "learning_rate": 0.00031484593837535015,
      "loss": 0.066,
      "step": 10180
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 10.486659049987793,
      "learning_rate": 0.00031428571428571427,
      "loss": 0.0514,
      "step": 10200
    },
    {
      "epoch": 33.39869281045752,
      "grad_norm": 0.14607885479927063,
      "learning_rate": 0.00031372549019607844,
      "loss": 0.11,
      "step": 10220
    },
    {
      "epoch": 33.4640522875817,
      "grad_norm": 0.018793528899550438,
      "learning_rate": 0.00031316526610644256,
      "loss": 0.0566,
      "step": 10240
    },
    {
      "epoch": 33.529411764705884,
      "grad_norm": 1.1535301208496094,
      "learning_rate": 0.00031260504201680673,
      "loss": 0.0425,
      "step": 10260
    },
    {
      "epoch": 33.59477124183007,
      "grad_norm": 0.15042747557163239,
      "learning_rate": 0.00031204481792717085,
      "loss": 0.0079,
      "step": 10280
    },
    {
      "epoch": 33.66013071895425,
      "grad_norm": 5.984353542327881,
      "learning_rate": 0.00031148459383753503,
      "loss": 0.0252,
      "step": 10300
    },
    {
      "epoch": 33.72549019607843,
      "grad_norm": 0.0756506472826004,
      "learning_rate": 0.00031092436974789915,
      "loss": 0.0691,
      "step": 10320
    },
    {
      "epoch": 33.790849673202615,
      "grad_norm": 0.020850246772170067,
      "learning_rate": 0.0003103641456582633,
      "loss": 0.0813,
      "step": 10340
    },
    {
      "epoch": 33.8562091503268,
      "grad_norm": 0.03885064646601677,
      "learning_rate": 0.00030980392156862744,
      "loss": 0.0768,
      "step": 10360
    },
    {
      "epoch": 33.92156862745098,
      "grad_norm": 7.968810558319092,
      "learning_rate": 0.00030924369747899156,
      "loss": 0.0911,
      "step": 10380
    },
    {
      "epoch": 33.98692810457516,
      "grad_norm": 5.861424922943115,
      "learning_rate": 0.0003086834733893557,
      "loss": 0.0632,
      "step": 10400
    },
    {
      "epoch": 34.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9092508242234947,
      "eval_f1": 0.9238938053097344,
      "eval_loss": 0.6210324764251709,
      "eval_runtime": 12.7154,
      "eval_samples_per_second": 32.087,
      "eval_steps_per_second": 4.011,
      "step": 10404
    },
    {
      "epoch": 34.052287581699346,
      "grad_norm": 0.03315169736742973,
      "learning_rate": 0.00030812324929971986,
      "loss": 0.0024,
      "step": 10420
    },
    {
      "epoch": 34.11764705882353,
      "grad_norm": 0.0021859072148799896,
      "learning_rate": 0.000307563025210084,
      "loss": 0.0514,
      "step": 10440
    },
    {
      "epoch": 34.18300653594771,
      "grad_norm": 0.003763417014852166,
      "learning_rate": 0.00030700280112044815,
      "loss": 0.0354,
      "step": 10460
    },
    {
      "epoch": 34.248366013071895,
      "grad_norm": 0.001970131415873766,
      "learning_rate": 0.00030644257703081227,
      "loss": 0.0058,
      "step": 10480
    },
    {
      "epoch": 34.31372549019608,
      "grad_norm": 0.003221677616238594,
      "learning_rate": 0.00030588235294117644,
      "loss": 0.0398,
      "step": 10500
    },
    {
      "epoch": 34.37908496732026,
      "grad_norm": 14.684069633483887,
      "learning_rate": 0.00030532212885154056,
      "loss": 0.0485,
      "step": 10520
    },
    {
      "epoch": 34.44444444444444,
      "grad_norm": 0.28798818588256836,
      "learning_rate": 0.00030476190476190474,
      "loss": 0.0762,
      "step": 10540
    },
    {
      "epoch": 34.509803921568626,
      "grad_norm": 0.01111564226448536,
      "learning_rate": 0.00030420168067226886,
      "loss": 0.0083,
      "step": 10560
    },
    {
      "epoch": 34.57516339869281,
      "grad_norm": 0.004300293978303671,
      "learning_rate": 0.00030364145658263303,
      "loss": 0.0327,
      "step": 10580
    },
    {
      "epoch": 34.64052287581699,
      "grad_norm": 3.8926162719726562,
      "learning_rate": 0.00030308123249299715,
      "loss": 0.0439,
      "step": 10600
    },
    {
      "epoch": 34.705882352941174,
      "grad_norm": 11.77673625946045,
      "learning_rate": 0.0003025210084033613,
      "loss": 0.0491,
      "step": 10620
    },
    {
      "epoch": 34.77124183006536,
      "grad_norm": 0.0026900283992290497,
      "learning_rate": 0.00030196078431372545,
      "loss": 0.0447,
      "step": 10640
    },
    {
      "epoch": 34.83660130718954,
      "grad_norm": 0.18233223259449005,
      "learning_rate": 0.0003014005602240896,
      "loss": 0.0885,
      "step": 10660
    },
    {
      "epoch": 34.90196078431372,
      "grad_norm": 0.015058492310345173,
      "learning_rate": 0.00030084033613445374,
      "loss": 0.043,
      "step": 10680
    },
    {
      "epoch": 34.967320261437905,
      "grad_norm": 0.004062789957970381,
      "learning_rate": 0.0003002801120448179,
      "loss": 0.0466,
      "step": 10700
    },
    {
      "epoch": 35.0,
      "eval_accuracy": 0.9044117647058824,
      "eval_combined_score": 0.9175700031344687,
      "eval_f1": 0.9307282415630549,
      "eval_loss": 0.6931464076042175,
      "eval_runtime": 12.3338,
      "eval_samples_per_second": 33.08,
      "eval_steps_per_second": 4.135,
      "step": 10710
    },
    {
      "epoch": 35.032679738562095,
      "grad_norm": 0.09696845710277557,
      "learning_rate": 0.00029971988795518203,
      "loss": 0.005,
      "step": 10720
    },
    {
      "epoch": 35.09803921568628,
      "grad_norm": 0.0030795785132795572,
      "learning_rate": 0.0002991596638655462,
      "loss": 0.0859,
      "step": 10740
    },
    {
      "epoch": 35.16339869281046,
      "grad_norm": 0.011405639350414276,
      "learning_rate": 0.00029859943977591033,
      "loss": 0.0889,
      "step": 10760
    },
    {
      "epoch": 35.22875816993464,
      "grad_norm": 0.07202766835689545,
      "learning_rate": 0.0002980392156862745,
      "loss": 0.0897,
      "step": 10780
    },
    {
      "epoch": 35.294117647058826,
      "grad_norm": 19.90964126586914,
      "learning_rate": 0.0002974789915966386,
      "loss": 0.0393,
      "step": 10800
    },
    {
      "epoch": 35.35947712418301,
      "grad_norm": 2.2171876430511475,
      "learning_rate": 0.0002969187675070028,
      "loss": 0.0199,
      "step": 10820
    },
    {
      "epoch": 35.42483660130719,
      "grad_norm": 0.1479678452014923,
      "learning_rate": 0.0002963585434173669,
      "loss": 0.0435,
      "step": 10840
    },
    {
      "epoch": 35.490196078431374,
      "grad_norm": 0.004582703113555908,
      "learning_rate": 0.0002957983193277311,
      "loss": 0.0828,
      "step": 10860
    },
    {
      "epoch": 35.55555555555556,
      "grad_norm": 15.013189315795898,
      "learning_rate": 0.0002952380952380952,
      "loss": 0.0287,
      "step": 10880
    },
    {
      "epoch": 35.62091503267974,
      "grad_norm": 0.004160111770033836,
      "learning_rate": 0.00029467787114845933,
      "loss": 0.0581,
      "step": 10900
    },
    {
      "epoch": 35.68627450980392,
      "grad_norm": 0.008783312514424324,
      "learning_rate": 0.0002941176470588235,
      "loss": 0.0608,
      "step": 10920
    },
    {
      "epoch": 35.751633986928105,
      "grad_norm": 0.03599100932478905,
      "learning_rate": 0.0002935574229691876,
      "loss": 0.0394,
      "step": 10940
    },
    {
      "epoch": 35.81699346405229,
      "grad_norm": 0.008124632760882378,
      "learning_rate": 0.0002929971988795518,
      "loss": 0.0458,
      "step": 10960
    },
    {
      "epoch": 35.88235294117647,
      "grad_norm": 0.06601749360561371,
      "learning_rate": 0.0002924369747899159,
      "loss": 0.0413,
      "step": 10980
    },
    {
      "epoch": 35.947712418300654,
      "grad_norm": 10.409292221069336,
      "learning_rate": 0.0002918767507002801,
      "loss": 0.0372,
      "step": 11000
    },
    {
      "epoch": 36.0,
      "eval_accuracy": 0.9044117647058824,
      "eval_combined_score": 0.9169436762046591,
      "eval_f1": 0.9294755877034359,
      "eval_loss": 0.738899290561676,
      "eval_runtime": 12.5902,
      "eval_samples_per_second": 32.406,
      "eval_steps_per_second": 4.051,
      "step": 11016
    },
    {
      "epoch": 36.01307189542484,
      "grad_norm": 0.007994125597178936,
      "learning_rate": 0.0002913165266106442,
      "loss": 0.0549,
      "step": 11020
    },
    {
      "epoch": 36.07843137254902,
      "grad_norm": 0.1886541247367859,
      "learning_rate": 0.0002907563025210084,
      "loss": 0.0231,
      "step": 11040
    },
    {
      "epoch": 36.1437908496732,
      "grad_norm": 0.0006501265452243388,
      "learning_rate": 0.0002901960784313725,
      "loss": 0.034,
      "step": 11060
    },
    {
      "epoch": 36.209150326797385,
      "grad_norm": 0.06061219051480293,
      "learning_rate": 0.0002896358543417367,
      "loss": 0.0042,
      "step": 11080
    },
    {
      "epoch": 36.27450980392157,
      "grad_norm": 8.937301635742188,
      "learning_rate": 0.0002890756302521008,
      "loss": 0.0575,
      "step": 11100
    },
    {
      "epoch": 36.33986928104575,
      "grad_norm": 0.00640352675691247,
      "learning_rate": 0.000288515406162465,
      "loss": 0.0899,
      "step": 11120
    },
    {
      "epoch": 36.40522875816993,
      "grad_norm": 0.0027000962290912867,
      "learning_rate": 0.0002879551820728291,
      "loss": 0.0532,
      "step": 11140
    },
    {
      "epoch": 36.470588235294116,
      "grad_norm": 0.03042053058743477,
      "learning_rate": 0.00028739495798319327,
      "loss": 0.0141,
      "step": 11160
    },
    {
      "epoch": 36.5359477124183,
      "grad_norm": 0.01680663228034973,
      "learning_rate": 0.0002868347338935574,
      "loss": 0.0025,
      "step": 11180
    },
    {
      "epoch": 36.60130718954248,
      "grad_norm": 0.014143073931336403,
      "learning_rate": 0.00028627450980392156,
      "loss": 0.0027,
      "step": 11200
    },
    {
      "epoch": 36.666666666666664,
      "grad_norm": 0.008263565599918365,
      "learning_rate": 0.0002857142857142857,
      "loss": 0.0961,
      "step": 11220
    },
    {
      "epoch": 36.73202614379085,
      "grad_norm": 0.0041096825152635574,
      "learning_rate": 0.0002851540616246498,
      "loss": 0.0017,
      "step": 11240
    },
    {
      "epoch": 36.79738562091503,
      "grad_norm": 0.02826995588839054,
      "learning_rate": 0.000284593837535014,
      "loss": 0.0247,
      "step": 11260
    },
    {
      "epoch": 36.86274509803921,
      "grad_norm": 0.07281415164470673,
      "learning_rate": 0.0002840336134453781,
      "loss": 0.0879,
      "step": 11280
    },
    {
      "epoch": 36.928104575163395,
      "grad_norm": 0.07033932954072952,
      "learning_rate": 0.00028347338935574227,
      "loss": 0.0503,
      "step": 11300
    },
    {
      "epoch": 36.99346405228758,
      "grad_norm": 0.01474193949252367,
      "learning_rate": 0.0002829131652661064,
      "loss": 0.0788,
      "step": 11320
    },
    {
      "epoch": 37.0,
      "eval_accuracy": 0.9068627450980392,
      "eval_combined_score": 0.9196235433675249,
      "eval_f1": 0.9323843416370107,
      "eval_loss": 0.5791587829589844,
      "eval_runtime": 12.3603,
      "eval_samples_per_second": 33.009,
      "eval_steps_per_second": 4.126,
      "step": 11322
    },
    {
      "epoch": 37.05882352941177,
      "grad_norm": 0.03718598559498787,
      "learning_rate": 0.00028235294117647056,
      "loss": 0.0183,
      "step": 11340
    },
    {
      "epoch": 37.12418300653595,
      "grad_norm": 0.005111518781632185,
      "learning_rate": 0.0002817927170868347,
      "loss": 0.0089,
      "step": 11360
    },
    {
      "epoch": 37.189542483660134,
      "grad_norm": 0.12335511296987534,
      "learning_rate": 0.00028123249299719886,
      "loss": 0.0147,
      "step": 11380
    },
    {
      "epoch": 37.254901960784316,
      "grad_norm": 1.1175389289855957,
      "learning_rate": 0.000280672268907563,
      "loss": 0.008,
      "step": 11400
    },
    {
      "epoch": 37.3202614379085,
      "grad_norm": 0.00507553294301033,
      "learning_rate": 0.00028011204481792715,
      "loss": 0.0196,
      "step": 11420
    },
    {
      "epoch": 37.38562091503268,
      "grad_norm": 0.0005898918607272208,
      "learning_rate": 0.00027955182072829127,
      "loss": 0.0597,
      "step": 11440
    },
    {
      "epoch": 37.450980392156865,
      "grad_norm": 16.245887756347656,
      "learning_rate": 0.00027899159663865545,
      "loss": 0.0023,
      "step": 11460
    },
    {
      "epoch": 37.51633986928105,
      "grad_norm": 0.03939679265022278,
      "learning_rate": 0.0002784313725490196,
      "loss": 0.0121,
      "step": 11480
    },
    {
      "epoch": 37.58169934640523,
      "grad_norm": 0.0006959743332117796,
      "learning_rate": 0.00027787114845938374,
      "loss": 0.0107,
      "step": 11500
    },
    {
      "epoch": 37.64705882352941,
      "grad_norm": 0.07022179663181305,
      "learning_rate": 0.0002773109243697479,
      "loss": 0.0402,
      "step": 11520
    },
    {
      "epoch": 37.712418300653596,
      "grad_norm": 0.017042560502886772,
      "learning_rate": 0.00027675070028011203,
      "loss": 0.014,
      "step": 11540
    },
    {
      "epoch": 37.77777777777778,
      "grad_norm": 0.008608673699200153,
      "learning_rate": 0.00027619047619047615,
      "loss": 0.1007,
      "step": 11560
    },
    {
      "epoch": 37.84313725490196,
      "grad_norm": 0.015232422389090061,
      "learning_rate": 0.0002756302521008403,
      "loss": 0.0546,
      "step": 11580
    },
    {
      "epoch": 37.908496732026144,
      "grad_norm": 0.0015677151968702674,
      "learning_rate": 0.00027507002801120445,
      "loss": 0.0098,
      "step": 11600
    },
    {
      "epoch": 37.97385620915033,
      "grad_norm": 7.053820610046387,
      "learning_rate": 0.00027450980392156857,
      "loss": 0.1542,
      "step": 11620
    },
    {
      "epoch": 38.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9112953692115144,
      "eval_f1": 0.925531914893617,
      "eval_loss": 0.6911869645118713,
      "eval_runtime": 12.4175,
      "eval_samples_per_second": 32.857,
      "eval_steps_per_second": 4.107,
      "step": 11628
    },
    {
      "epoch": 38.03921568627451,
      "grad_norm": 0.703888475894928,
      "learning_rate": 0.00027394957983193274,
      "loss": 0.0939,
      "step": 11640
    },
    {
      "epoch": 38.10457516339869,
      "grad_norm": 0.0029432489536702633,
      "learning_rate": 0.0002733893557422969,
      "loss": 0.0236,
      "step": 11660
    },
    {
      "epoch": 38.169934640522875,
      "grad_norm": 0.045889873057603836,
      "learning_rate": 0.00027282913165266104,
      "loss": 0.03,
      "step": 11680
    },
    {
      "epoch": 38.23529411764706,
      "grad_norm": 0.037683695554733276,
      "learning_rate": 0.0002722689075630252,
      "loss": 0.0224,
      "step": 11700
    },
    {
      "epoch": 38.30065359477124,
      "grad_norm": 0.0040013850666582584,
      "learning_rate": 0.00027170868347338933,
      "loss": 0.0008,
      "step": 11720
    },
    {
      "epoch": 38.36601307189542,
      "grad_norm": 0.022164361551404,
      "learning_rate": 0.0002711484593837535,
      "loss": 0.0263,
      "step": 11740
    },
    {
      "epoch": 38.431372549019606,
      "grad_norm": 0.0027250084094703197,
      "learning_rate": 0.0002705882352941176,
      "loss": 0.0381,
      "step": 11760
    },
    {
      "epoch": 38.49673202614379,
      "grad_norm": 0.004258866887539625,
      "learning_rate": 0.0002700280112044818,
      "loss": 0.0073,
      "step": 11780
    },
    {
      "epoch": 38.56209150326797,
      "grad_norm": 0.000948968343436718,
      "learning_rate": 0.0002694677871148459,
      "loss": 0.0436,
      "step": 11800
    },
    {
      "epoch": 38.627450980392155,
      "grad_norm": 0.005279156845062971,
      "learning_rate": 0.0002689075630252101,
      "loss": 0.031,
      "step": 11820
    },
    {
      "epoch": 38.69281045751634,
      "grad_norm": 0.010835593566298485,
      "learning_rate": 0.0002683473389355742,
      "loss": 0.1041,
      "step": 11840
    },
    {
      "epoch": 38.75816993464052,
      "grad_norm": 0.006888631731271744,
      "learning_rate": 0.0002677871148459384,
      "loss": 0.0086,
      "step": 11860
    },
    {
      "epoch": 38.8235294117647,
      "grad_norm": 0.025990959256887436,
      "learning_rate": 0.0002672268907563025,
      "loss": 0.021,
      "step": 11880
    },
    {
      "epoch": 38.888888888888886,
      "grad_norm": 16.110395431518555,
      "learning_rate": 0.0002666666666666666,
      "loss": 0.0446,
      "step": 11900
    },
    {
      "epoch": 38.95424836601307,
      "grad_norm": 5.713061809539795,
      "learning_rate": 0.0002661064425770308,
      "loss": 0.0689,
      "step": 11920
    },
    {
      "epoch": 39.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9091156444815938,
      "eval_f1": 0.9236234458259325,
      "eval_loss": 0.6293396353721619,
      "eval_runtime": 12.4006,
      "eval_samples_per_second": 32.902,
      "eval_steps_per_second": 4.113,
      "step": 11934
    },
    {
      "epoch": 39.01960784313726,
      "grad_norm": 0.006230537313967943,
      "learning_rate": 0.0002655462184873949,
      "loss": 0.008,
      "step": 11940
    },
    {
      "epoch": 39.08496732026144,
      "grad_norm": 0.00852932594716549,
      "learning_rate": 0.0002649859943977591,
      "loss": 0.0263,
      "step": 11960
    },
    {
      "epoch": 39.150326797385624,
      "grad_norm": 0.15936674177646637,
      "learning_rate": 0.0002644257703081232,
      "loss": 0.0043,
      "step": 11980
    },
    {
      "epoch": 39.21568627450981,
      "grad_norm": 12.13491153717041,
      "learning_rate": 0.0002638655462184874,
      "loss": 0.0897,
      "step": 12000
    },
    {
      "epoch": 39.28104575163399,
      "grad_norm": 0.004270248115062714,
      "learning_rate": 0.0002633053221288515,
      "loss": 0.0027,
      "step": 12020
    },
    {
      "epoch": 39.34640522875817,
      "grad_norm": 0.0013669041218236089,
      "learning_rate": 0.0002627450980392157,
      "loss": 0.014,
      "step": 12040
    },
    {
      "epoch": 39.411764705882355,
      "grad_norm": 0.42437949776649475,
      "learning_rate": 0.0002621848739495798,
      "loss": 0.0043,
      "step": 12060
    },
    {
      "epoch": 39.47712418300654,
      "grad_norm": 0.001731307478621602,
      "learning_rate": 0.000261624649859944,
      "loss": 0.0351,
      "step": 12080
    },
    {
      "epoch": 39.54248366013072,
      "grad_norm": 0.17007818818092346,
      "learning_rate": 0.0002610644257703081,
      "loss": 0.0983,
      "step": 12100
    },
    {
      "epoch": 39.6078431372549,
      "grad_norm": 1.1427125930786133,
      "learning_rate": 0.00026050420168067227,
      "loss": 0.0611,
      "step": 12120
    },
    {
      "epoch": 39.673202614379086,
      "grad_norm": 0.004479925148189068,
      "learning_rate": 0.0002599439775910364,
      "loss": 0.0185,
      "step": 12140
    },
    {
      "epoch": 39.73856209150327,
      "grad_norm": 0.0019493978470563889,
      "learning_rate": 0.00025938375350140056,
      "loss": 0.0427,
      "step": 12160
    },
    {
      "epoch": 39.80392156862745,
      "grad_norm": 0.02413944900035858,
      "learning_rate": 0.0002588235294117647,
      "loss": 0.0243,
      "step": 12180
    },
    {
      "epoch": 39.869281045751634,
      "grad_norm": 0.0010933034354820848,
      "learning_rate": 0.00025826330532212886,
      "loss": 0.0533,
      "step": 12200
    },
    {
      "epoch": 39.93464052287582,
      "grad_norm": 7.12307071685791,
      "learning_rate": 0.000257703081232493,
      "loss": 0.0492,
      "step": 12220
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.00838142167776823,
      "learning_rate": 0.0002571428571428571,
      "loss": 0.0183,
      "step": 12240
    },
    {
      "epoch": 40.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9118161250514192,
      "eval_f1": 0.9265734265734265,
      "eval_loss": 0.8007652163505554,
      "eval_runtime": 12.3875,
      "eval_samples_per_second": 32.936,
      "eval_steps_per_second": 4.117,
      "step": 12240
    },
    {
      "epoch": 40.06535947712418,
      "grad_norm": 0.0007958913338370621,
      "learning_rate": 0.00025658263305322127,
      "loss": 0.0025,
      "step": 12260
    },
    {
      "epoch": 40.130718954248366,
      "grad_norm": 0.002117726719006896,
      "learning_rate": 0.0002560224089635854,
      "loss": 0.0334,
      "step": 12280
    },
    {
      "epoch": 40.19607843137255,
      "grad_norm": 0.0018369716126471758,
      "learning_rate": 0.00025546218487394957,
      "loss": 0.0522,
      "step": 12300
    },
    {
      "epoch": 40.26143790849673,
      "grad_norm": 12.384235382080078,
      "learning_rate": 0.0002549019607843137,
      "loss": 0.031,
      "step": 12320
    },
    {
      "epoch": 40.326797385620914,
      "grad_norm": 4.2729058265686035,
      "learning_rate": 0.00025434173669467786,
      "loss": 0.0222,
      "step": 12340
    },
    {
      "epoch": 40.3921568627451,
      "grad_norm": 0.05741003528237343,
      "learning_rate": 0.000253781512605042,
      "loss": 0.0303,
      "step": 12360
    },
    {
      "epoch": 40.45751633986928,
      "grad_norm": 0.001825373969040811,
      "learning_rate": 0.00025322128851540615,
      "loss": 0.079,
      "step": 12380
    },
    {
      "epoch": 40.52287581699346,
      "grad_norm": 0.0025956351310014725,
      "learning_rate": 0.0002526610644257703,
      "loss": 0.0432,
      "step": 12400
    },
    {
      "epoch": 40.588235294117645,
      "grad_norm": 0.003275812603533268,
      "learning_rate": 0.00025210084033613445,
      "loss": 0.0211,
      "step": 12420
    },
    {
      "epoch": 40.65359477124183,
      "grad_norm": 0.0023691821843385696,
      "learning_rate": 0.00025154061624649857,
      "loss": 0.0099,
      "step": 12440
    },
    {
      "epoch": 40.71895424836601,
      "grad_norm": 0.004394425544887781,
      "learning_rate": 0.00025098039215686274,
      "loss": 0.0691,
      "step": 12460
    },
    {
      "epoch": 40.78431372549019,
      "grad_norm": 0.004614831879734993,
      "learning_rate": 0.00025042016806722686,
      "loss": 0.0006,
      "step": 12480
    },
    {
      "epoch": 40.849673202614376,
      "grad_norm": 0.01905323565006256,
      "learning_rate": 0.00024985994397759104,
      "loss": 0.0162,
      "step": 12500
    },
    {
      "epoch": 40.91503267973856,
      "grad_norm": 0.0061989231035113335,
      "learning_rate": 0.00024929971988795516,
      "loss": 0.0863,
      "step": 12520
    },
    {
      "epoch": 40.98039215686274,
      "grad_norm": 0.04000864177942276,
      "learning_rate": 0.00024873949579831933,
      "loss": 0.0016,
      "step": 12540
    },
    {
      "epoch": 41.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9057225063938619,
      "eval_f1": 0.9217391304347826,
      "eval_loss": 0.8029773235321045,
      "eval_runtime": 12.3365,
      "eval_samples_per_second": 33.073,
      "eval_steps_per_second": 4.134,
      "step": 12546
    },
    {
      "epoch": 41.04575163398693,
      "grad_norm": 0.0067576514557003975,
      "learning_rate": 0.00024817927170868345,
      "loss": 0.0887,
      "step": 12560
    },
    {
      "epoch": 41.111111111111114,
      "grad_norm": 1.4105204343795776,
      "learning_rate": 0.00024761904761904757,
      "loss": 0.0781,
      "step": 12580
    },
    {
      "epoch": 41.1764705882353,
      "grad_norm": 11.646848678588867,
      "learning_rate": 0.00024705882352941174,
      "loss": 0.0433,
      "step": 12600
    },
    {
      "epoch": 41.24183006535948,
      "grad_norm": 0.029901454225182533,
      "learning_rate": 0.00024649859943977586,
      "loss": 0.0257,
      "step": 12620
    },
    {
      "epoch": 41.30718954248366,
      "grad_norm": 0.04896656051278114,
      "learning_rate": 0.00024593837535014004,
      "loss": 0.0073,
      "step": 12640
    },
    {
      "epoch": 41.372549019607845,
      "grad_norm": 0.3355482220649719,
      "learning_rate": 0.00024537815126050416,
      "loss": 0.0292,
      "step": 12660
    },
    {
      "epoch": 41.43790849673203,
      "grad_norm": 0.22762812674045563,
      "learning_rate": 0.00024481792717086833,
      "loss": 0.0111,
      "step": 12680
    },
    {
      "epoch": 41.50326797385621,
      "grad_norm": 0.00842493586242199,
      "learning_rate": 0.00024425770308123245,
      "loss": 0.037,
      "step": 12700
    },
    {
      "epoch": 41.568627450980394,
      "grad_norm": 1.3685815334320068,
      "learning_rate": 0.00024369747899159663,
      "loss": 0.0905,
      "step": 12720
    },
    {
      "epoch": 41.63398692810458,
      "grad_norm": 0.09044725447893143,
      "learning_rate": 0.00024313725490196077,
      "loss": 0.0067,
      "step": 12740
    },
    {
      "epoch": 41.69934640522876,
      "grad_norm": 0.0028935137670487165,
      "learning_rate": 0.00024257703081232492,
      "loss": 0.0132,
      "step": 12760
    },
    {
      "epoch": 41.76470588235294,
      "grad_norm": 0.0026818462647497654,
      "learning_rate": 0.00024201680672268907,
      "loss": 0.0278,
      "step": 12780
    },
    {
      "epoch": 41.830065359477125,
      "grad_norm": 0.794924795627594,
      "learning_rate": 0.0002414565826330532,
      "loss": 0.0027,
      "step": 12800
    },
    {
      "epoch": 41.89542483660131,
      "grad_norm": 0.04952750355005264,
      "learning_rate": 0.00024089635854341736,
      "loss": 0.0681,
      "step": 12820
    },
    {
      "epoch": 41.96078431372549,
      "grad_norm": 0.0010517438640818,
      "learning_rate": 0.0002403361344537815,
      "loss": 0.0307,
      "step": 12840
    },
    {
      "epoch": 42.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9035577645692423,
      "eval_f1": 0.9198606271777002,
      "eval_loss": 0.8474571108818054,
      "eval_runtime": 12.2424,
      "eval_samples_per_second": 33.327,
      "eval_steps_per_second": 4.166,
      "step": 12852
    },
    {
      "epoch": 42.02614379084967,
      "grad_norm": 6.86024284362793,
      "learning_rate": 0.00023977591036414565,
      "loss": 0.0617,
      "step": 12860
    },
    {
      "epoch": 42.091503267973856,
      "grad_norm": 0.40652745962142944,
      "learning_rate": 0.0002392156862745098,
      "loss": 0.0205,
      "step": 12880
    },
    {
      "epoch": 42.15686274509804,
      "grad_norm": 0.010530725121498108,
      "learning_rate": 0.00023865546218487392,
      "loss": 0.0039,
      "step": 12900
    },
    {
      "epoch": 42.22222222222222,
      "grad_norm": 0.00129234348423779,
      "learning_rate": 0.00023809523809523807,
      "loss": 0.0525,
      "step": 12920
    },
    {
      "epoch": 42.287581699346404,
      "grad_norm": 0.018618356436491013,
      "learning_rate": 0.00023753501400560221,
      "loss": 0.0375,
      "step": 12940
    },
    {
      "epoch": 42.35294117647059,
      "grad_norm": 0.3007170259952545,
      "learning_rate": 0.00023697478991596636,
      "loss": 0.0771,
      "step": 12960
    },
    {
      "epoch": 42.41830065359477,
      "grad_norm": 1.0583823919296265,
      "learning_rate": 0.0002364145658263305,
      "loss": 0.0242,
      "step": 12980
    },
    {
      "epoch": 42.48366013071895,
      "grad_norm": 0.000720449723303318,
      "learning_rate": 0.00023585434173669466,
      "loss": 0.0221,
      "step": 13000
    },
    {
      "epoch": 42.549019607843135,
      "grad_norm": 0.001626211917027831,
      "learning_rate": 0.0002352941176470588,
      "loss": 0.023,
      "step": 13020
    },
    {
      "epoch": 42.61437908496732,
      "grad_norm": 0.03314921259880066,
      "learning_rate": 0.00023473389355742295,
      "loss": 0.0154,
      "step": 13040
    },
    {
      "epoch": 42.6797385620915,
      "grad_norm": 0.0010072947479784489,
      "learning_rate": 0.0002341736694677871,
      "loss": 0.0309,
      "step": 13060
    },
    {
      "epoch": 42.745098039215684,
      "grad_norm": 0.06880562007427216,
      "learning_rate": 0.00023361344537815124,
      "loss": 0.0007,
      "step": 13080
    },
    {
      "epoch": 42.810457516339866,
      "grad_norm": 0.033834800124168396,
      "learning_rate": 0.0002330532212885154,
      "loss": 0.0488,
      "step": 13100
    },
    {
      "epoch": 42.87581699346405,
      "grad_norm": 0.00040343208820559084,
      "learning_rate": 0.00023249299719887954,
      "loss": 0.0282,
      "step": 13120
    },
    {
      "epoch": 42.94117647058823,
      "grad_norm": 0.0031874263659119606,
      "learning_rate": 0.00023193277310924368,
      "loss": 0.0315,
      "step": 13140
    },
    {
      "epoch": 43.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9111628637220013,
      "eval_f1": 0.9252669039145908,
      "eval_loss": 0.8335652947425842,
      "eval_runtime": 12.3587,
      "eval_samples_per_second": 33.013,
      "eval_steps_per_second": 4.127,
      "step": 13158
    },
    {
      "epoch": 43.00653594771242,
      "grad_norm": 3.5114848613739014,
      "learning_rate": 0.00023137254901960783,
      "loss": 0.0375,
      "step": 13160
    },
    {
      "epoch": 43.071895424836605,
      "grad_norm": 0.004867427982389927,
      "learning_rate": 0.00023081232492997198,
      "loss": 0.0368,
      "step": 13180
    },
    {
      "epoch": 43.13725490196079,
      "grad_norm": 0.01601102389395237,
      "learning_rate": 0.00023025210084033613,
      "loss": 0.0122,
      "step": 13200
    },
    {
      "epoch": 43.20261437908497,
      "grad_norm": 0.00042339335777796805,
      "learning_rate": 0.00022969187675070027,
      "loss": 0.0372,
      "step": 13220
    },
    {
      "epoch": 43.26797385620915,
      "grad_norm": 0.012341439723968506,
      "learning_rate": 0.0002291316526610644,
      "loss": 0.0009,
      "step": 13240
    },
    {
      "epoch": 43.333333333333336,
      "grad_norm": 0.0005008032894693315,
      "learning_rate": 0.00022857142857142854,
      "loss": 0.0332,
      "step": 13260
    },
    {
      "epoch": 43.39869281045752,
      "grad_norm": 0.009839968755841255,
      "learning_rate": 0.0002280112044817927,
      "loss": 0.0707,
      "step": 13280
    },
    {
      "epoch": 43.4640522875817,
      "grad_norm": 0.11660931259393692,
      "learning_rate": 0.00022745098039215683,
      "loss": 0.065,
      "step": 13300
    },
    {
      "epoch": 43.529411764705884,
      "grad_norm": 0.007134022191166878,
      "learning_rate": 0.00022689075630252098,
      "loss": 0.0413,
      "step": 13320
    },
    {
      "epoch": 43.59477124183007,
      "grad_norm": 0.023795701563358307,
      "learning_rate": 0.00022633053221288513,
      "loss": 0.0597,
      "step": 13340
    },
    {
      "epoch": 43.66013071895425,
      "grad_norm": 0.02767886593937874,
      "learning_rate": 0.00022577030812324927,
      "loss": 0.0403,
      "step": 13360
    },
    {
      "epoch": 43.72549019607843,
      "grad_norm": 0.002561485394835472,
      "learning_rate": 0.00022521008403361342,
      "loss": 0.0609,
      "step": 13380
    },
    {
      "epoch": 43.790849673202615,
      "grad_norm": 0.13459084928035736,
      "learning_rate": 0.00022464985994397757,
      "loss": 0.0307,
      "step": 13400
    },
    {
      "epoch": 43.8562091503268,
      "grad_norm": 3.322734832763672,
      "learning_rate": 0.00022408963585434172,
      "loss": 0.0542,
      "step": 13420
    },
    {
      "epoch": 43.92156862745098,
      "grad_norm": 0.01765974424779415,
      "learning_rate": 0.00022352941176470586,
      "loss": 0.0662,
      "step": 13440
    },
    {
      "epoch": 43.98692810457516,
      "grad_norm": 0.002084332285448909,
      "learning_rate": 0.00022296918767507,
      "loss": 0.0428,
      "step": 13460
    },
    {
      "epoch": 44.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9133428238080312,
      "eval_f1": 0.9271758436944938,
      "eval_loss": 0.7149940729141235,
      "eval_runtime": 12.3611,
      "eval_samples_per_second": 33.007,
      "eval_steps_per_second": 4.126,
      "step": 13464
    },
    {
      "epoch": 44.052287581699346,
      "grad_norm": 0.01560102216899395,
      "learning_rate": 0.00022240896358543416,
      "loss": 0.0435,
      "step": 13480
    },
    {
      "epoch": 44.11764705882353,
      "grad_norm": 0.002982418518513441,
      "learning_rate": 0.0002218487394957983,
      "loss": 0.0581,
      "step": 13500
    },
    {
      "epoch": 44.18300653594771,
      "grad_norm": 0.001590744243003428,
      "learning_rate": 0.00022128851540616245,
      "loss": 0.0236,
      "step": 13520
    },
    {
      "epoch": 44.248366013071895,
      "grad_norm": 3.1619327068328857,
      "learning_rate": 0.0002207282913165266,
      "loss": 0.0452,
      "step": 13540
    },
    {
      "epoch": 44.31372549019608,
      "grad_norm": 0.008742046542465687,
      "learning_rate": 0.00022016806722689072,
      "loss": 0.0171,
      "step": 13560
    },
    {
      "epoch": 44.37908496732026,
      "grad_norm": 0.025326870381832123,
      "learning_rate": 0.00021960784313725486,
      "loss": 0.0325,
      "step": 13580
    },
    {
      "epoch": 44.44444444444444,
      "grad_norm": 0.001969017321243882,
      "learning_rate": 0.000219047619047619,
      "loss": 0.0029,
      "step": 13600
    },
    {
      "epoch": 44.509803921568626,
      "grad_norm": 0.00602400116622448,
      "learning_rate": 0.00021848739495798316,
      "loss": 0.0381,
      "step": 13620
    },
    {
      "epoch": 44.57516339869281,
      "grad_norm": 0.0031690422911196947,
      "learning_rate": 0.0002179271708683473,
      "loss": 0.004,
      "step": 13640
    },
    {
      "epoch": 44.64052287581699,
      "grad_norm": 0.6063952445983887,
      "learning_rate": 0.00021736694677871145,
      "loss": 0.0044,
      "step": 13660
    },
    {
      "epoch": 44.705882352941174,
      "grad_norm": 0.0003528044617269188,
      "learning_rate": 0.0002168067226890756,
      "loss": 0.032,
      "step": 13680
    },
    {
      "epoch": 44.77124183006536,
      "grad_norm": 0.00176091562025249,
      "learning_rate": 0.00021624649859943975,
      "loss": 0.0258,
      "step": 13700
    },
    {
      "epoch": 44.83660130718954,
      "grad_norm": 0.0005333949229680002,
      "learning_rate": 0.0002156862745098039,
      "loss": 0.0089,
      "step": 13720
    },
    {
      "epoch": 44.90196078431372,
      "grad_norm": 31.2468204498291,
      "learning_rate": 0.00021512605042016804,
      "loss": 0.0441,
      "step": 13740
    },
    {
      "epoch": 44.967320261437905,
      "grad_norm": 0.00014092148921918124,
      "learning_rate": 0.0002145658263305322,
      "loss": 0.001,
      "step": 13760
    },
    {
      "epoch": 45.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.9155193992490613,
      "eval_f1": 0.9290780141843972,
      "eval_loss": 0.840379536151886,
      "eval_runtime": 12.2672,
      "eval_samples_per_second": 33.259,
      "eval_steps_per_second": 4.157,
      "step": 13770
    },
    {
      "epoch": 45.032679738562095,
      "grad_norm": 0.0020344143267720938,
      "learning_rate": 0.00021400560224089633,
      "loss": 0.0264,
      "step": 13780
    },
    {
      "epoch": 45.09803921568628,
      "grad_norm": 0.0008167903288267553,
      "learning_rate": 0.00021344537815126048,
      "loss": 0.0251,
      "step": 13800
    },
    {
      "epoch": 45.16339869281046,
      "grad_norm": 0.004192938096821308,
      "learning_rate": 0.00021288515406162463,
      "loss": 0.0532,
      "step": 13820
    },
    {
      "epoch": 45.22875816993464,
      "grad_norm": 0.0008655627607367933,
      "learning_rate": 0.00021232492997198878,
      "loss": 0.0044,
      "step": 13840
    },
    {
      "epoch": 45.294117647058826,
      "grad_norm": 0.13148275017738342,
      "learning_rate": 0.00021176470588235295,
      "loss": 0.0243,
      "step": 13860
    },
    {
      "epoch": 45.35947712418301,
      "grad_norm": 0.009386865422129631,
      "learning_rate": 0.0002112044817927171,
      "loss": 0.0574,
      "step": 13880
    },
    {
      "epoch": 45.42483660130719,
      "grad_norm": 0.0625213086605072,
      "learning_rate": 0.0002106442577030812,
      "loss": 0.0211,
      "step": 13900
    },
    {
      "epoch": 45.490196078431374,
      "grad_norm": 0.0002138260897481814,
      "learning_rate": 0.00021008403361344534,
      "loss": 0.0316,
      "step": 13920
    },
    {
      "epoch": 45.55555555555556,
      "grad_norm": 0.0004601883701980114,
      "learning_rate": 0.00020952380952380948,
      "loss": 0.0493,
      "step": 13940
    },
    {
      "epoch": 45.62091503267974,
      "grad_norm": 0.000521898502483964,
      "learning_rate": 0.00020896358543417363,
      "loss": 0.0365,
      "step": 13960
    },
    {
      "epoch": 45.68627450980392,
      "grad_norm": 0.0007432774291373789,
      "learning_rate": 0.00020840336134453778,
      "loss": 0.0592,
      "step": 13980
    },
    {
      "epoch": 45.751633986928105,
      "grad_norm": 0.01647387631237507,
      "learning_rate": 0.00020784313725490192,
      "loss": 0.0146,
      "step": 14000
    },
    {
      "epoch": 45.81699346405229,
      "grad_norm": 0.0010645606089383364,
      "learning_rate": 0.00020728291316526607,
      "loss": 0.0317,
      "step": 14020
    },
    {
      "epoch": 45.88235294117647,
      "grad_norm": 0.01950625516474247,
      "learning_rate": 0.00020672268907563025,
      "loss": 0.0235,
      "step": 14040
    },
    {
      "epoch": 45.947712418300654,
      "grad_norm": 0.08668242394924164,
      "learning_rate": 0.0002061624649859944,
      "loss": 0.0207,
      "step": 14060
    },
    {
      "epoch": 46.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9118161250514192,
      "eval_f1": 0.9265734265734265,
      "eval_loss": 0.7868338227272034,
      "eval_runtime": 12.5201,
      "eval_samples_per_second": 32.588,
      "eval_steps_per_second": 4.073,
      "step": 14076
    },
    {
      "epoch": 46.01307189542484,
      "grad_norm": 0.0004044131201226264,
      "learning_rate": 0.00020560224089635854,
      "loss": 0.0005,
      "step": 14080
    },
    {
      "epoch": 46.07843137254902,
      "grad_norm": 0.0021493248641490936,
      "learning_rate": 0.0002050420168067227,
      "loss": 0.0234,
      "step": 14100
    },
    {
      "epoch": 46.1437908496732,
      "grad_norm": 0.03285013884305954,
      "learning_rate": 0.00020448179271708683,
      "loss": 0.0876,
      "step": 14120
    },
    {
      "epoch": 46.209150326797385,
      "grad_norm": 0.0012189061380922794,
      "learning_rate": 0.00020392156862745098,
      "loss": 0.04,
      "step": 14140
    },
    {
      "epoch": 46.27450980392157,
      "grad_norm": 0.002583083463832736,
      "learning_rate": 0.00020336134453781513,
      "loss": 0.0167,
      "step": 14160
    },
    {
      "epoch": 46.33986928104575,
      "grad_norm": 0.0038987239822745323,
      "learning_rate": 0.00020280112044817927,
      "loss": 0.0145,
      "step": 14180
    },
    {
      "epoch": 46.40522875816993,
      "grad_norm": 0.011217077262699604,
      "learning_rate": 0.00020224089635854342,
      "loss": 0.0328,
      "step": 14200
    },
    {
      "epoch": 46.470588235294116,
      "grad_norm": 0.09509297460317612,
      "learning_rate": 0.00020168067226890757,
      "loss": 0.0114,
      "step": 14220
    },
    {
      "epoch": 46.5359477124183,
      "grad_norm": 0.00412270613014698,
      "learning_rate": 0.0002011204481792717,
      "loss": 0.0477,
      "step": 14240
    },
    {
      "epoch": 46.60130718954248,
      "grad_norm": 0.3957548141479492,
      "learning_rate": 0.00020056022408963584,
      "loss": 0.0372,
      "step": 14260
    },
    {
      "epoch": 46.666666666666664,
      "grad_norm": 9.793730735778809,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.0647,
      "step": 14280
    },
    {
      "epoch": 46.73202614379085,
      "grad_norm": 0.000905677501577884,
      "learning_rate": 0.00019943977591036413,
      "loss": 0.0003,
      "step": 14300
    },
    {
      "epoch": 46.79738562091503,
      "grad_norm": 6.496179580688477,
      "learning_rate": 0.00019887955182072828,
      "loss": 0.0301,
      "step": 14320
    },
    {
      "epoch": 46.86274509803921,
      "grad_norm": 0.0008586057811044157,
      "learning_rate": 0.00019831932773109242,
      "loss": 0.0496,
      "step": 14340
    },
    {
      "epoch": 46.928104575163395,
      "grad_norm": 0.0024355442728847265,
      "learning_rate": 0.00019775910364145657,
      "loss": 0.0216,
      "step": 14360
    },
    {
      "epoch": 46.99346405228758,
      "grad_norm": 0.009140660986304283,
      "learning_rate": 0.00019719887955182072,
      "loss": 0.0035,
      "step": 14380
    },
    {
      "epoch": 47.0,
      "eval_accuracy": 0.9044117647058824,
      "eval_combined_score": 0.9176926080166581,
      "eval_f1": 0.9309734513274337,
      "eval_loss": 0.7807421088218689,
      "eval_runtime": 12.2858,
      "eval_samples_per_second": 33.209,
      "eval_steps_per_second": 4.151,
      "step": 14382
    },
    {
      "epoch": 47.05882352941177,
      "grad_norm": 0.0011369169224053621,
      "learning_rate": 0.00019663865546218486,
      "loss": 0.0271,
      "step": 14400
    },
    {
      "epoch": 47.12418300653595,
      "grad_norm": 0.0007725941250100732,
      "learning_rate": 0.000196078431372549,
      "loss": 0.0096,
      "step": 14420
    },
    {
      "epoch": 47.189542483660134,
      "grad_norm": 0.0024241877254098654,
      "learning_rate": 0.00019551820728291316,
      "loss": 0.022,
      "step": 14440
    },
    {
      "epoch": 47.254901960784316,
      "grad_norm": 0.002073021838441491,
      "learning_rate": 0.0001949579831932773,
      "loss": 0.0036,
      "step": 14460
    },
    {
      "epoch": 47.3202614379085,
      "grad_norm": 0.0008179516298696399,
      "learning_rate": 0.00019439775910364145,
      "loss": 0.0316,
      "step": 14480
    },
    {
      "epoch": 47.38562091503268,
      "grad_norm": 0.0014115729136392474,
      "learning_rate": 0.0001938375350140056,
      "loss": 0.0408,
      "step": 14500
    },
    {
      "epoch": 47.450980392156865,
      "grad_norm": 0.000540594628546387,
      "learning_rate": 0.00019327731092436975,
      "loss": 0.016,
      "step": 14520
    },
    {
      "epoch": 47.51633986928105,
      "grad_norm": 0.004349259659647942,
      "learning_rate": 0.0001927170868347339,
      "loss": 0.009,
      "step": 14540
    },
    {
      "epoch": 47.58169934640523,
      "grad_norm": 0.0010200286051258445,
      "learning_rate": 0.000192156862745098,
      "loss": 0.0004,
      "step": 14560
    },
    {
      "epoch": 47.64705882352941,
      "grad_norm": 0.0015476690605282784,
      "learning_rate": 0.00019159663865546216,
      "loss": 0.0011,
      "step": 14580
    },
    {
      "epoch": 47.712418300653596,
      "grad_norm": 0.0010267364559695125,
      "learning_rate": 0.0001910364145658263,
      "loss": 0.0188,
      "step": 14600
    },
    {
      "epoch": 47.77777777777778,
      "grad_norm": 0.00017916287470143288,
      "learning_rate": 0.00019047619047619045,
      "loss": 0.0431,
      "step": 14620
    },
    {
      "epoch": 47.84313725490196,
      "grad_norm": 0.004485159646719694,
      "learning_rate": 0.0001899159663865546,
      "loss": 0.0003,
      "step": 14640
    },
    {
      "epoch": 47.908496732026144,
      "grad_norm": 7.9208446550183e-05,
      "learning_rate": 0.00018935574229691875,
      "loss": 0.0014,
      "step": 14660
    },
    {
      "epoch": 47.97385620915033,
      "grad_norm": 0.0007693094667047262,
      "learning_rate": 0.0001887955182072829,
      "loss": 0.0011,
      "step": 14680
    },
    {
      "epoch": 48.0,
      "eval_accuracy": 0.9068627450980392,
      "eval_combined_score": 0.9195028011204482,
      "eval_f1": 0.9321428571428573,
      "eval_loss": 0.9113229513168335,
      "eval_runtime": 12.2413,
      "eval_samples_per_second": 33.33,
      "eval_steps_per_second": 4.166,
      "step": 14688
    },
    {
      "epoch": 48.03921568627451,
      "grad_norm": 0.000603357155341655,
      "learning_rate": 0.00018823529411764704,
      "loss": 0.0017,
      "step": 14700
    },
    {
      "epoch": 48.10457516339869,
      "grad_norm": 0.00014061653928365558,
      "learning_rate": 0.0001876750700280112,
      "loss": 0.0341,
      "step": 14720
    },
    {
      "epoch": 48.169934640522875,
      "grad_norm": 7.468034164048731e-05,
      "learning_rate": 0.00018711484593837534,
      "loss": 0.004,
      "step": 14740
    },
    {
      "epoch": 48.23529411764706,
      "grad_norm": 0.00019758316921070218,
      "learning_rate": 0.00018655462184873948,
      "loss": 0.0424,
      "step": 14760
    },
    {
      "epoch": 48.30065359477124,
      "grad_norm": 0.00011050805915147066,
      "learning_rate": 0.00018599439775910363,
      "loss": 0.0187,
      "step": 14780
    },
    {
      "epoch": 48.36601307189542,
      "grad_norm": 0.0001397978630848229,
      "learning_rate": 0.00018543417366946778,
      "loss": 0.054,
      "step": 14800
    },
    {
      "epoch": 48.431372549019606,
      "grad_norm": 0.0022105886600911617,
      "learning_rate": 0.00018487394957983192,
      "loss": 0.0431,
      "step": 14820
    },
    {
      "epoch": 48.49673202614379,
      "grad_norm": 0.0005945133161731064,
      "learning_rate": 0.00018431372549019607,
      "loss": 0.0349,
      "step": 14840
    },
    {
      "epoch": 48.56209150326797,
      "grad_norm": 0.0011895153438672423,
      "learning_rate": 0.00018375350140056022,
      "loss": 0.0003,
      "step": 14860
    },
    {
      "epoch": 48.627450980392155,
      "grad_norm": 0.0003462944005150348,
      "learning_rate": 0.00018319327731092437,
      "loss": 0.0303,
      "step": 14880
    },
    {
      "epoch": 48.69281045751634,
      "grad_norm": 0.00012928117939736694,
      "learning_rate": 0.00018263305322128849,
      "loss": 0.0069,
      "step": 14900
    },
    {
      "epoch": 48.75816993464052,
      "grad_norm": 0.0008820311049930751,
      "learning_rate": 0.00018207282913165263,
      "loss": 0.0787,
      "step": 14920
    },
    {
      "epoch": 48.8235294117647,
      "grad_norm": 0.001041634357534349,
      "learning_rate": 0.00018151260504201678,
      "loss": 0.0436,
      "step": 14940
    },
    {
      "epoch": 48.888888888888886,
      "grad_norm": 0.0016210053581744432,
      "learning_rate": 0.00018095238095238093,
      "loss": 0.0089,
      "step": 14960
    },
    {
      "epoch": 48.95424836601307,
      "grad_norm": 2.4897210597991943,
      "learning_rate": 0.00018039215686274507,
      "loss": 0.013,
      "step": 14980
    },
    {
      "epoch": 49.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9115575807787903,
      "eval_f1": 0.926056338028169,
      "eval_loss": 0.8694767951965332,
      "eval_runtime": 12.3597,
      "eval_samples_per_second": 33.01,
      "eval_steps_per_second": 4.126,
      "step": 14994
    },
    {
      "epoch": 49.01960784313726,
      "grad_norm": 0.001589747378602624,
      "learning_rate": 0.00017983193277310922,
      "loss": 0.0011,
      "step": 15000
    },
    {
      "epoch": 49.08496732026144,
      "grad_norm": 0.0010895556770265102,
      "learning_rate": 0.00017927170868347337,
      "loss": 0.0248,
      "step": 15020
    },
    {
      "epoch": 49.150326797385624,
      "grad_norm": 0.0010549657745286822,
      "learning_rate": 0.00017871148459383751,
      "loss": 0.0276,
      "step": 15040
    },
    {
      "epoch": 49.21568627450981,
      "grad_norm": 0.0038519534282386303,
      "learning_rate": 0.00017815126050420166,
      "loss": 0.0002,
      "step": 15060
    },
    {
      "epoch": 49.28104575163399,
      "grad_norm": 0.007900441996753216,
      "learning_rate": 0.0001775910364145658,
      "loss": 0.0347,
      "step": 15080
    },
    {
      "epoch": 49.34640522875817,
      "grad_norm": 0.028900014236569405,
      "learning_rate": 0.00017703081232492996,
      "loss": 0.05,
      "step": 15100
    },
    {
      "epoch": 49.411764705882355,
      "grad_norm": 0.0002230034879175946,
      "learning_rate": 0.0001764705882352941,
      "loss": 0.0125,
      "step": 15120
    },
    {
      "epoch": 49.47712418300654,
      "grad_norm": 0.001910155639052391,
      "learning_rate": 0.00017591036414565825,
      "loss": 0.0465,
      "step": 15140
    },
    {
      "epoch": 49.54248366013072,
      "grad_norm": 0.09964968264102936,
      "learning_rate": 0.0001753501400560224,
      "loss": 0.007,
      "step": 15160
    },
    {
      "epoch": 49.6078431372549,
      "grad_norm": 0.051048506051301956,
      "learning_rate": 0.00017478991596638654,
      "loss": 0.0716,
      "step": 15180
    },
    {
      "epoch": 49.673202614379086,
      "grad_norm": 0.0016116818878799677,
      "learning_rate": 0.0001742296918767507,
      "loss": 0.0098,
      "step": 15200
    },
    {
      "epoch": 49.73856209150327,
      "grad_norm": 1.1143062114715576,
      "learning_rate": 0.00017366946778711484,
      "loss": 0.0108,
      "step": 15220
    },
    {
      "epoch": 49.80392156862745,
      "grad_norm": 0.0006070597446523607,
      "learning_rate": 0.00017310924369747896,
      "loss": 0.0091,
      "step": 15240
    },
    {
      "epoch": 49.869281045751634,
      "grad_norm": 0.00036034444929100573,
      "learning_rate": 0.0001725490196078431,
      "loss": 0.0001,
      "step": 15260
    },
    {
      "epoch": 49.93464052287582,
      "grad_norm": 0.010253408923745155,
      "learning_rate": 0.00017198879551820725,
      "loss": 0.0251,
      "step": 15280
    },
    {
      "epoch": 50.0,
      "grad_norm": 1.581405520439148,
      "learning_rate": 0.0001714285714285714,
      "loss": 0.0236,
      "step": 15300
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.91500916913528,
      "eval_f1": 0.9280575539568345,
      "eval_loss": 0.8910980820655823,
      "eval_runtime": 11.9767,
      "eval_samples_per_second": 34.066,
      "eval_steps_per_second": 4.258,
      "step": 15300
    },
    {
      "epoch": 50.06535947712418,
      "grad_norm": 1.8289841413497925,
      "learning_rate": 0.00017086834733893555,
      "loss": 0.008,
      "step": 15320
    },
    {
      "epoch": 50.130718954248366,
      "grad_norm": 0.00028663116972893476,
      "learning_rate": 0.0001703081232492997,
      "loss": 0.0103,
      "step": 15340
    },
    {
      "epoch": 50.19607843137255,
      "grad_norm": 0.056840695440769196,
      "learning_rate": 0.00016974789915966384,
      "loss": 0.0285,
      "step": 15360
    },
    {
      "epoch": 50.26143790849673,
      "grad_norm": 0.000599495368078351,
      "learning_rate": 0.00016918767507002799,
      "loss": 0.0042,
      "step": 15380
    },
    {
      "epoch": 50.326797385620914,
      "grad_norm": 0.00022647799050901085,
      "learning_rate": 0.00016862745098039213,
      "loss": 0.0001,
      "step": 15400
    },
    {
      "epoch": 50.3921568627451,
      "grad_norm": 0.00011421587987570092,
      "learning_rate": 0.00016806722689075628,
      "loss": 0.0123,
      "step": 15420
    },
    {
      "epoch": 50.45751633986928,
      "grad_norm": 0.0005959346890449524,
      "learning_rate": 0.00016750700280112043,
      "loss": 0.0197,
      "step": 15440
    },
    {
      "epoch": 50.52287581699346,
      "grad_norm": 8.286019146908075e-05,
      "learning_rate": 0.00016694677871148457,
      "loss": 0.0849,
      "step": 15460
    },
    {
      "epoch": 50.588235294117645,
      "grad_norm": 0.0008045541471801698,
      "learning_rate": 0.00016638655462184872,
      "loss": 0.0015,
      "step": 15480
    },
    {
      "epoch": 50.65359477124183,
      "grad_norm": 0.0019594619516283274,
      "learning_rate": 0.00016582633053221287,
      "loss": 0.0308,
      "step": 15500
    },
    {
      "epoch": 50.71895424836601,
      "grad_norm": 0.05032402649521828,
      "learning_rate": 0.00016526610644257704,
      "loss": 0.0458,
      "step": 15520
    },
    {
      "epoch": 50.78431372549019,
      "grad_norm": 0.05526356399059296,
      "learning_rate": 0.0001647058823529412,
      "loss": 0.0429,
      "step": 15540
    },
    {
      "epoch": 50.849673202614376,
      "grad_norm": 0.00023175374371930957,
      "learning_rate": 0.00016414565826330534,
      "loss": 0.0385,
      "step": 15560
    },
    {
      "epoch": 50.91503267973856,
      "grad_norm": 0.0005395162152126431,
      "learning_rate": 0.00016358543417366943,
      "loss": 0.0256,
      "step": 15580
    },
    {
      "epoch": 50.98039215686274,
      "grad_norm": 0.0007504785899072886,
      "learning_rate": 0.00016302521008403358,
      "loss": 0.0736,
      "step": 15600
    },
    {
      "epoch": 51.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9070713391739675,
      "eval_f1": 0.9219858156028369,
      "eval_loss": 0.861558735370636,
      "eval_runtime": 12.0513,
      "eval_samples_per_second": 33.855,
      "eval_steps_per_second": 4.232,
      "step": 15606
    },
    {
      "epoch": 51.04575163398693,
      "grad_norm": 0.0005101235001347959,
      "learning_rate": 0.00016246498599439772,
      "loss": 0.0471,
      "step": 15620
    },
    {
      "epoch": 51.111111111111114,
      "grad_norm": 0.008364942856132984,
      "learning_rate": 0.00016190476190476187,
      "loss": 0.0112,
      "step": 15640
    },
    {
      "epoch": 51.1764705882353,
      "grad_norm": 0.0008706427761353552,
      "learning_rate": 0.00016134453781512602,
      "loss": 0.0191,
      "step": 15660
    },
    {
      "epoch": 51.24183006535948,
      "grad_norm": 0.0647929385304451,
      "learning_rate": 0.00016078431372549016,
      "loss": 0.0017,
      "step": 15680
    },
    {
      "epoch": 51.30718954248366,
      "grad_norm": 0.0011778157204389572,
      "learning_rate": 0.00016022408963585434,
      "loss": 0.0344,
      "step": 15700
    },
    {
      "epoch": 51.372549019607845,
      "grad_norm": 0.000548379379324615,
      "learning_rate": 0.00015966386554621849,
      "loss": 0.0234,
      "step": 15720
    },
    {
      "epoch": 51.43790849673203,
      "grad_norm": 0.0007898643962107599,
      "learning_rate": 0.00015910364145658263,
      "loss": 0.0588,
      "step": 15740
    },
    {
      "epoch": 51.50326797385621,
      "grad_norm": 0.01524751540273428,
      "learning_rate": 0.00015854341736694678,
      "loss": 0.0135,
      "step": 15760
    },
    {
      "epoch": 51.568627450980394,
      "grad_norm": 0.0015604414511471987,
      "learning_rate": 0.00015798319327731093,
      "loss": 0.0007,
      "step": 15780
    },
    {
      "epoch": 51.63398692810458,
      "grad_norm": 0.06050322949886322,
      "learning_rate": 0.00015742296918767507,
      "loss": 0.0006,
      "step": 15800
    },
    {
      "epoch": 51.69934640522876,
      "grad_norm": 0.003317144699394703,
      "learning_rate": 0.00015686274509803922,
      "loss": 0.0132,
      "step": 15820
    },
    {
      "epoch": 51.76470588235294,
      "grad_norm": 0.0014751694398000836,
      "learning_rate": 0.00015630252100840337,
      "loss": 0.0014,
      "step": 15840
    },
    {
      "epoch": 51.830065359477125,
      "grad_norm": 0.0007467318791896105,
      "learning_rate": 0.00015574229691876751,
      "loss": 0.0025,
      "step": 15860
    },
    {
      "epoch": 51.89542483660131,
      "grad_norm": 0.25993242859840393,
      "learning_rate": 0.00015518207282913166,
      "loss": 0.0403,
      "step": 15880
    },
    {
      "epoch": 51.96078431372549,
      "grad_norm": 0.005959471687674522,
      "learning_rate": 0.00015462184873949578,
      "loss": 0.0037,
      "step": 15900
    },
    {
      "epoch": 52.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9074819401444789,
      "eval_f1": 0.9228070175438596,
      "eval_loss": 0.8151089549064636,
      "eval_runtime": 12.0393,
      "eval_samples_per_second": 33.889,
      "eval_steps_per_second": 4.236,
      "step": 15912
    },
    {
      "epoch": 52.02614379084967,
      "grad_norm": 0.23927177488803864,
      "learning_rate": 0.00015406162464985993,
      "loss": 0.0198,
      "step": 15920
    },
    {
      "epoch": 52.091503267973856,
      "grad_norm": 0.002463051350787282,
      "learning_rate": 0.00015350140056022407,
      "loss": 0.0376,
      "step": 15940
    },
    {
      "epoch": 52.15686274509804,
      "grad_norm": 0.0024233374278992414,
      "learning_rate": 0.00015294117647058822,
      "loss": 0.0006,
      "step": 15960
    },
    {
      "epoch": 52.22222222222222,
      "grad_norm": 0.002445477293804288,
      "learning_rate": 0.00015238095238095237,
      "loss": 0.0435,
      "step": 15980
    },
    {
      "epoch": 52.287581699346404,
      "grad_norm": 0.004001928027719259,
      "learning_rate": 0.00015182072829131652,
      "loss": 0.0002,
      "step": 16000
    },
    {
      "epoch": 52.35294117647059,
      "grad_norm": 0.02047874964773655,
      "learning_rate": 0.00015126050420168066,
      "loss": 0.0002,
      "step": 16020
    },
    {
      "epoch": 52.41830065359477,
      "grad_norm": 0.011915132403373718,
      "learning_rate": 0.0001507002801120448,
      "loss": 0.0008,
      "step": 16040
    },
    {
      "epoch": 52.48366013071895,
      "grad_norm": 16.645782470703125,
      "learning_rate": 0.00015014005602240896,
      "loss": 0.0753,
      "step": 16060
    },
    {
      "epoch": 52.549019607843135,
      "grad_norm": 0.6423539519309998,
      "learning_rate": 0.0001495798319327731,
      "loss": 0.0244,
      "step": 16080
    },
    {
      "epoch": 52.61437908496732,
      "grad_norm": 0.002888732822611928,
      "learning_rate": 0.00014901960784313725,
      "loss": 0.0892,
      "step": 16100
    },
    {
      "epoch": 52.6797385620915,
      "grad_norm": 0.016055352985858917,
      "learning_rate": 0.0001484593837535014,
      "loss": 0.0005,
      "step": 16120
    },
    {
      "epoch": 52.745098039215684,
      "grad_norm": 0.025733133777976036,
      "learning_rate": 0.00014789915966386554,
      "loss": 0.0004,
      "step": 16140
    },
    {
      "epoch": 52.810457516339866,
      "grad_norm": 0.047372713685035706,
      "learning_rate": 0.00014733893557422966,
      "loss": 0.0072,
      "step": 16160
    },
    {
      "epoch": 52.87581699346405,
      "grad_norm": 11.194083213806152,
      "learning_rate": 0.0001467787114845938,
      "loss": 0.0557,
      "step": 16180
    },
    {
      "epoch": 52.94117647058823,
      "grad_norm": 0.003067316021770239,
      "learning_rate": 0.00014621848739495796,
      "loss": 0.001,
      "step": 16200
    },
    {
      "epoch": 53.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9077509052401449,
      "eval_f1": 0.9233449477351917,
      "eval_loss": 0.7987006902694702,
      "eval_runtime": 12.0696,
      "eval_samples_per_second": 33.804,
      "eval_steps_per_second": 4.225,
      "step": 16218
    },
    {
      "epoch": 53.00653594771242,
      "grad_norm": 0.13428206741809845,
      "learning_rate": 0.0001456582633053221,
      "loss": 0.0025,
      "step": 16220
    },
    {
      "epoch": 53.071895424836605,
      "grad_norm": 0.0014897180953994393,
      "learning_rate": 0.00014509803921568625,
      "loss": 0.0053,
      "step": 16240
    },
    {
      "epoch": 53.13725490196079,
      "grad_norm": 0.0031845462508499622,
      "learning_rate": 0.0001445378151260504,
      "loss": 0.0004,
      "step": 16260
    },
    {
      "epoch": 53.20261437908497,
      "grad_norm": 0.10073868930339813,
      "learning_rate": 0.00014397759103641455,
      "loss": 0.0012,
      "step": 16280
    },
    {
      "epoch": 53.26797385620915,
      "grad_norm": 0.001727348193526268,
      "learning_rate": 0.0001434173669467787,
      "loss": 0.0037,
      "step": 16300
    },
    {
      "epoch": 53.333333333333336,
      "grad_norm": 0.00029948135488666594,
      "learning_rate": 0.00014285714285714284,
      "loss": 0.0022,
      "step": 16320
    },
    {
      "epoch": 53.39869281045752,
      "grad_norm": 0.0010264067677780986,
      "learning_rate": 0.000142296918767507,
      "loss": 0.0176,
      "step": 16340
    },
    {
      "epoch": 53.4640522875817,
      "grad_norm": 0.0011192865204066038,
      "learning_rate": 0.00014173669467787113,
      "loss": 0.0181,
      "step": 16360
    },
    {
      "epoch": 53.529411764705884,
      "grad_norm": 0.0007282055448740721,
      "learning_rate": 0.00014117647058823528,
      "loss": 0.0671,
      "step": 16380
    },
    {
      "epoch": 53.59477124183007,
      "grad_norm": 0.010003315284848213,
      "learning_rate": 0.00014061624649859943,
      "loss": 0.0164,
      "step": 16400
    },
    {
      "epoch": 53.66013071895425,
      "grad_norm": 0.007791411597281694,
      "learning_rate": 0.00014005602240896358,
      "loss": 0.0335,
      "step": 16420
    },
    {
      "epoch": 53.72549019607843,
      "grad_norm": 7.3243536949157715,
      "learning_rate": 0.00013949579831932772,
      "loss": 0.0378,
      "step": 16440
    },
    {
      "epoch": 53.790849673202615,
      "grad_norm": 0.005399094894528389,
      "learning_rate": 0.00013893557422969187,
      "loss": 0.008,
      "step": 16460
    },
    {
      "epoch": 53.8562091503268,
      "grad_norm": 0.00099927035626024,
      "learning_rate": 0.00013837535014005602,
      "loss": 0.0001,
      "step": 16480
    },
    {
      "epoch": 53.92156862745098,
      "grad_norm": 0.07697581499814987,
      "learning_rate": 0.00013781512605042014,
      "loss": 0.0004,
      "step": 16500
    },
    {
      "epoch": 53.98692810457516,
      "grad_norm": 0.0015703708631917834,
      "learning_rate": 0.00013725490196078428,
      "loss": 0.0214,
      "step": 16520
    },
    {
      "epoch": 54.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9003626047914693,
      "eval_f1": 0.9159212880143113,
      "eval_loss": 0.8565528988838196,
      "eval_runtime": 12.0603,
      "eval_samples_per_second": 33.83,
      "eval_steps_per_second": 4.229,
      "step": 16524
    },
    {
      "epoch": 54.052287581699346,
      "grad_norm": 0.042250603437423706,
      "learning_rate": 0.00013669467787114846,
      "loss": 0.0008,
      "step": 16540
    },
    {
      "epoch": 54.11764705882353,
      "grad_norm": 0.00858149491250515,
      "learning_rate": 0.0001361344537815126,
      "loss": 0.0002,
      "step": 16560
    },
    {
      "epoch": 54.18300653594771,
      "grad_norm": 0.010533717460930347,
      "learning_rate": 0.00013557422969187675,
      "loss": 0.0004,
      "step": 16580
    },
    {
      "epoch": 54.248366013071895,
      "grad_norm": 0.0007062352960929275,
      "learning_rate": 0.0001350140056022409,
      "loss": 0.0456,
      "step": 16600
    },
    {
      "epoch": 54.31372549019608,
      "grad_norm": 0.003672870574519038,
      "learning_rate": 0.00013445378151260505,
      "loss": 0.0543,
      "step": 16620
    },
    {
      "epoch": 54.37908496732026,
      "grad_norm": 0.0018041454022750258,
      "learning_rate": 0.0001338935574229692,
      "loss": 0.0014,
      "step": 16640
    },
    {
      "epoch": 54.44444444444444,
      "grad_norm": 40.02228546142578,
      "learning_rate": 0.0001333333333333333,
      "loss": 0.0431,
      "step": 16660
    },
    {
      "epoch": 54.509803921568626,
      "grad_norm": 0.27711430191993713,
      "learning_rate": 0.00013277310924369746,
      "loss": 0.0154,
      "step": 16680
    },
    {
      "epoch": 54.57516339869281,
      "grad_norm": 0.001357495435513556,
      "learning_rate": 0.0001322128851540616,
      "loss": 0.0162,
      "step": 16700
    },
    {
      "epoch": 54.64052287581699,
      "grad_norm": 0.0010420928010717034,
      "learning_rate": 0.00013165266106442575,
      "loss": 0.0012,
      "step": 16720
    },
    {
      "epoch": 54.705882352941174,
      "grad_norm": 0.013760481029748917,
      "learning_rate": 0.0001310924369747899,
      "loss": 0.0271,
      "step": 16740
    },
    {
      "epoch": 54.77124183006536,
      "grad_norm": 0.0007629005121998489,
      "learning_rate": 0.00013053221288515405,
      "loss": 0.0133,
      "step": 16760
    },
    {
      "epoch": 54.83660130718954,
      "grad_norm": 0.0006560348556376994,
      "learning_rate": 0.0001299719887955182,
      "loss": 0.0613,
      "step": 16780
    },
    {
      "epoch": 54.90196078431372,
      "grad_norm": 0.0031493697315454483,
      "learning_rate": 0.00012941176470588234,
      "loss": 0.0277,
      "step": 16800
    },
    {
      "epoch": 54.967320261437905,
      "grad_norm": 0.005667045712471008,
      "learning_rate": 0.0001288515406162465,
      "loss": 0.0089,
      "step": 16820
    },
    {
      "epoch": 55.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9130822722648988,
      "eval_f1": 0.9266547406082289,
      "eval_loss": 0.7733103632926941,
      "eval_runtime": 12.069,
      "eval_samples_per_second": 33.806,
      "eval_steps_per_second": 4.226,
      "step": 16830
    },
    {
      "epoch": 55.032679738562095,
      "grad_norm": 0.0012119720922783017,
      "learning_rate": 0.00012829131652661064,
      "loss": 0.0065,
      "step": 16840
    },
    {
      "epoch": 55.09803921568628,
      "grad_norm": 0.0016767499037086964,
      "learning_rate": 0.00012773109243697478,
      "loss": 0.0334,
      "step": 16860
    },
    {
      "epoch": 55.16339869281046,
      "grad_norm": 0.026512254029512405,
      "learning_rate": 0.00012717086834733893,
      "loss": 0.0006,
      "step": 16880
    },
    {
      "epoch": 55.22875816993464,
      "grad_norm": 0.012298406101763248,
      "learning_rate": 0.00012661064425770308,
      "loss": 0.0001,
      "step": 16900
    },
    {
      "epoch": 55.294117647058826,
      "grad_norm": 0.009507338516414165,
      "learning_rate": 0.00012605042016806722,
      "loss": 0.0002,
      "step": 16920
    },
    {
      "epoch": 55.35947712418301,
      "grad_norm": 0.0165095217525959,
      "learning_rate": 0.00012549019607843137,
      "loss": 0.023,
      "step": 16940
    },
    {
      "epoch": 55.42483660130719,
      "grad_norm": 0.014270467683672905,
      "learning_rate": 0.00012492997198879552,
      "loss": 0.0287,
      "step": 16960
    },
    {
      "epoch": 55.490196078431374,
      "grad_norm": 0.030470233410596848,
      "learning_rate": 0.00012436974789915966,
      "loss": 0.0005,
      "step": 16980
    },
    {
      "epoch": 55.55555555555556,
      "grad_norm": 7.508101463317871,
      "learning_rate": 0.00012380952380952378,
      "loss": 0.0257,
      "step": 17000
    },
    {
      "epoch": 55.62091503267974,
      "grad_norm": 3.8324220180511475,
      "learning_rate": 0.00012324929971988793,
      "loss": 0.0269,
      "step": 17020
    },
    {
      "epoch": 55.68627450980392,
      "grad_norm": 40.263187408447266,
      "learning_rate": 0.00012268907563025208,
      "loss": 0.0336,
      "step": 17040
    },
    {
      "epoch": 55.751633986928105,
      "grad_norm": 0.0004264532180968672,
      "learning_rate": 0.00012212885154061623,
      "loss": 0.0403,
      "step": 17060
    },
    {
      "epoch": 55.81699346405229,
      "grad_norm": 0.0027279581408947706,
      "learning_rate": 0.00012156862745098039,
      "loss": 0.065,
      "step": 17080
    },
    {
      "epoch": 55.88235294117647,
      "grad_norm": 0.00861216988414526,
      "learning_rate": 0.00012100840336134453,
      "loss": 0.064,
      "step": 17100
    },
    {
      "epoch": 55.947712418300654,
      "grad_norm": 0.0008945575682446361,
      "learning_rate": 0.00012044817927170868,
      "loss": 0.0188,
      "step": 17120
    },
    {
      "epoch": 56.0,
      "eval_accuracy": 0.9044117647058824,
      "eval_combined_score": 0.9174465240641712,
      "eval_f1": 0.9304812834224598,
      "eval_loss": 0.7736191153526306,
      "eval_runtime": 12.1356,
      "eval_samples_per_second": 33.62,
      "eval_steps_per_second": 4.203,
      "step": 17136
    },
    {
      "epoch": 56.01307189542484,
      "grad_norm": 0.00140372384339571,
      "learning_rate": 0.00011988795518207283,
      "loss": 0.012,
      "step": 17140
    },
    {
      "epoch": 56.07843137254902,
      "grad_norm": 22.99773406982422,
      "learning_rate": 0.00011932773109243696,
      "loss": 0.007,
      "step": 17160
    },
    {
      "epoch": 56.1437908496732,
      "grad_norm": 0.0024098840076476336,
      "learning_rate": 0.00011876750700280111,
      "loss": 0.0005,
      "step": 17180
    },
    {
      "epoch": 56.209150326797385,
      "grad_norm": 0.3322261571884155,
      "learning_rate": 0.00011820728291316525,
      "loss": 0.0196,
      "step": 17200
    },
    {
      "epoch": 56.27450980392157,
      "grad_norm": 0.0020491096656769514,
      "learning_rate": 0.0001176470588235294,
      "loss": 0.0307,
      "step": 17220
    },
    {
      "epoch": 56.33986928104575,
      "grad_norm": 0.0008266392396762967,
      "learning_rate": 0.00011708683473389355,
      "loss": 0.0101,
      "step": 17240
    },
    {
      "epoch": 56.40522875816993,
      "grad_norm": 21.05661964416504,
      "learning_rate": 0.0001165266106442577,
      "loss": 0.0293,
      "step": 17260
    },
    {
      "epoch": 56.470588235294116,
      "grad_norm": 0.0035107857547700405,
      "learning_rate": 0.00011596638655462184,
      "loss": 0.0022,
      "step": 17280
    },
    {
      "epoch": 56.5359477124183,
      "grad_norm": 13.408519744873047,
      "learning_rate": 0.00011540616246498599,
      "loss": 0.0138,
      "step": 17300
    },
    {
      "epoch": 56.60130718954248,
      "grad_norm": 0.0006739313248544931,
      "learning_rate": 0.00011484593837535014,
      "loss": 0.0001,
      "step": 17320
    },
    {
      "epoch": 56.666666666666664,
      "grad_norm": 0.0008246212964877486,
      "learning_rate": 0.00011428571428571427,
      "loss": 0.0007,
      "step": 17340
    },
    {
      "epoch": 56.73202614379085,
      "grad_norm": 0.0014015724882483482,
      "learning_rate": 0.00011372549019607842,
      "loss": 0.0712,
      "step": 17360
    },
    {
      "epoch": 56.79738562091503,
      "grad_norm": 0.5844427347183228,
      "learning_rate": 0.00011316526610644256,
      "loss": 0.0273,
      "step": 17380
    },
    {
      "epoch": 56.86274509803921,
      "grad_norm": 0.0008150259964168072,
      "learning_rate": 0.00011260504201680671,
      "loss": 0.0357,
      "step": 17400
    },
    {
      "epoch": 56.928104575163395,
      "grad_norm": 0.0017353580333292484,
      "learning_rate": 0.00011204481792717086,
      "loss": 0.0041,
      "step": 17420
    },
    {
      "epoch": 56.99346405228758,
      "grad_norm": 0.01571769267320633,
      "learning_rate": 0.000111484593837535,
      "loss": 0.0217,
      "step": 17440
    },
    {
      "epoch": 57.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.907209173422019,
      "eval_f1": 0.9222614840989399,
      "eval_loss": 0.7946009635925293,
      "eval_runtime": 12.1297,
      "eval_samples_per_second": 33.637,
      "eval_steps_per_second": 4.205,
      "step": 17442
    },
    {
      "epoch": 57.05882352941177,
      "grad_norm": 0.006401591002941132,
      "learning_rate": 0.00011092436974789915,
      "loss": 0.0002,
      "step": 17460
    },
    {
      "epoch": 57.12418300653595,
      "grad_norm": 18.765737533569336,
      "learning_rate": 0.0001103641456582633,
      "loss": 0.0111,
      "step": 17480
    },
    {
      "epoch": 57.189542483660134,
      "grad_norm": 0.0009713669423945248,
      "learning_rate": 0.00010980392156862743,
      "loss": 0.0687,
      "step": 17500
    },
    {
      "epoch": 57.254901960784316,
      "grad_norm": 0.00047642216668464243,
      "learning_rate": 0.00010924369747899158,
      "loss": 0.0213,
      "step": 17520
    },
    {
      "epoch": 57.3202614379085,
      "grad_norm": 0.001250149216502905,
      "learning_rate": 0.00010868347338935573,
      "loss": 0.0278,
      "step": 17540
    },
    {
      "epoch": 57.38562091503268,
      "grad_norm": 0.001844719983637333,
      "learning_rate": 0.00010812324929971987,
      "loss": 0.0256,
      "step": 17560
    },
    {
      "epoch": 57.450980392156865,
      "grad_norm": 0.003978674300014973,
      "learning_rate": 0.00010756302521008402,
      "loss": 0.0146,
      "step": 17580
    },
    {
      "epoch": 57.51633986928105,
      "grad_norm": 0.008935573510825634,
      "learning_rate": 0.00010700280112044817,
      "loss": 0.1007,
      "step": 17600
    },
    {
      "epoch": 57.58169934640523,
      "grad_norm": 0.004604559391736984,
      "learning_rate": 0.00010644257703081231,
      "loss": 0.0236,
      "step": 17620
    },
    {
      "epoch": 57.64705882352941,
      "grad_norm": 0.014308295212686062,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.0135,
      "step": 17640
    },
    {
      "epoch": 57.712418300653596,
      "grad_norm": 0.009010553359985352,
      "learning_rate": 0.0001053221288515406,
      "loss": 0.0403,
      "step": 17660
    },
    {
      "epoch": 57.77777777777778,
      "grad_norm": 0.06869222968816757,
      "learning_rate": 0.00010476190476190474,
      "loss": 0.0003,
      "step": 17680
    },
    {
      "epoch": 57.84313725490196,
      "grad_norm": 0.18022672832012177,
      "learning_rate": 0.00010420168067226889,
      "loss": 0.0607,
      "step": 17700
    },
    {
      "epoch": 57.908496732026144,
      "grad_norm": 0.0028716977685689926,
      "learning_rate": 0.00010364145658263304,
      "loss": 0.0014,
      "step": 17720
    },
    {
      "epoch": 57.97385620915033,
      "grad_norm": 0.0015899616992101073,
      "learning_rate": 0.0001030812324929972,
      "loss": 0.0061,
      "step": 17740
    },
    {
      "epoch": 58.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9069325238992394,
      "eval_f1": 0.9217081850533807,
      "eval_loss": 0.8207355737686157,
      "eval_runtime": 12.2428,
      "eval_samples_per_second": 33.326,
      "eval_steps_per_second": 4.166,
      "step": 17748
    },
    {
      "epoch": 58.03921568627451,
      "grad_norm": 9.306296348571777,
      "learning_rate": 0.00010252100840336134,
      "loss": 0.11,
      "step": 17760
    },
    {
      "epoch": 58.10457516339869,
      "grad_norm": 0.09185529500246048,
      "learning_rate": 0.00010196078431372549,
      "loss": 0.0007,
      "step": 17780
    },
    {
      "epoch": 58.169934640522875,
      "grad_norm": 0.000863045803271234,
      "learning_rate": 0.00010140056022408964,
      "loss": 0.0322,
      "step": 17800
    },
    {
      "epoch": 58.23529411764706,
      "grad_norm": 0.002449404215440154,
      "learning_rate": 0.00010084033613445378,
      "loss": 0.0223,
      "step": 17820
    },
    {
      "epoch": 58.30065359477124,
      "grad_norm": 0.01221825834363699,
      "learning_rate": 0.00010028011204481792,
      "loss": 0.0005,
      "step": 17840
    },
    {
      "epoch": 58.36601307189542,
      "grad_norm": 0.04816674068570137,
      "learning_rate": 9.971988795518206e-05,
      "loss": 0.0145,
      "step": 17860
    },
    {
      "epoch": 58.431372549019606,
      "grad_norm": 0.018549425527453423,
      "learning_rate": 9.915966386554621e-05,
      "loss": 0.0006,
      "step": 17880
    },
    {
      "epoch": 58.49673202614379,
      "grad_norm": 0.013721111230552197,
      "learning_rate": 9.859943977591036e-05,
      "loss": 0.001,
      "step": 17900
    },
    {
      "epoch": 58.56209150326797,
      "grad_norm": 0.014751539565622807,
      "learning_rate": 9.80392156862745e-05,
      "loss": 0.0486,
      "step": 17920
    },
    {
      "epoch": 58.627450980392155,
      "grad_norm": 0.020367372781038284,
      "learning_rate": 9.747899159663865e-05,
      "loss": 0.0017,
      "step": 17940
    },
    {
      "epoch": 58.69281045751634,
      "grad_norm": 0.0017648967914283276,
      "learning_rate": 9.69187675070028e-05,
      "loss": 0.0183,
      "step": 17960
    },
    {
      "epoch": 58.75816993464052,
      "grad_norm": 0.01863028109073639,
      "learning_rate": 9.635854341736695e-05,
      "loss": 0.0276,
      "step": 17980
    },
    {
      "epoch": 58.8235294117647,
      "grad_norm": 0.000417175266193226,
      "learning_rate": 9.579831932773108e-05,
      "loss": 0.0169,
      "step": 18000
    },
    {
      "epoch": 58.888888888888886,
      "grad_norm": 0.0005947098252363503,
      "learning_rate": 9.523809523809523e-05,
      "loss": 0.0042,
      "step": 18020
    },
    {
      "epoch": 58.95424836601307,
      "grad_norm": 0.0024229581467807293,
      "learning_rate": 9.467787114845937e-05,
      "loss": 0.0238,
      "step": 18040
    },
    {
      "epoch": 59.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9050299323269131,
      "eval_f1": 0.9203539823008849,
      "eval_loss": 0.8521023988723755,
      "eval_runtime": 12.3621,
      "eval_samples_per_second": 33.004,
      "eval_steps_per_second": 4.126,
      "step": 18054
    },
    {
      "epoch": 59.01960784313726,
      "grad_norm": 0.0005329968989826739,
      "learning_rate": 9.411764705882352e-05,
      "loss": 0.0195,
      "step": 18060
    },
    {
      "epoch": 59.08496732026144,
      "grad_norm": 0.0007067388505674899,
      "learning_rate": 9.355742296918767e-05,
      "loss": 0.0304,
      "step": 18080
    },
    {
      "epoch": 59.150326797385624,
      "grad_norm": 0.13819530606269836,
      "learning_rate": 9.299719887955182e-05,
      "loss": 0.0007,
      "step": 18100
    },
    {
      "epoch": 59.21568627450981,
      "grad_norm": 0.00123685656581074,
      "learning_rate": 9.243697478991596e-05,
      "loss": 0.0019,
      "step": 18120
    },
    {
      "epoch": 59.28104575163399,
      "grad_norm": 5.510479927062988,
      "learning_rate": 9.187675070028011e-05,
      "loss": 0.0221,
      "step": 18140
    },
    {
      "epoch": 59.34640522875817,
      "grad_norm": 0.22554472088813782,
      "learning_rate": 9.131652661064424e-05,
      "loss": 0.0202,
      "step": 18160
    },
    {
      "epoch": 59.411764705882355,
      "grad_norm": 0.001280306838452816,
      "learning_rate": 9.075630252100839e-05,
      "loss": 0.0001,
      "step": 18180
    },
    {
      "epoch": 59.47712418300654,
      "grad_norm": 0.0009800372645258904,
      "learning_rate": 9.019607843137254e-05,
      "loss": 0.0009,
      "step": 18200
    },
    {
      "epoch": 59.54248366013072,
      "grad_norm": 0.003639365779235959,
      "learning_rate": 8.963585434173668e-05,
      "loss": 0.0002,
      "step": 18220
    },
    {
      "epoch": 59.6078431372549,
      "grad_norm": 0.0005703569622710347,
      "learning_rate": 8.907563025210083e-05,
      "loss": 0.0197,
      "step": 18240
    },
    {
      "epoch": 59.673202614379086,
      "grad_norm": 0.006427829619497061,
      "learning_rate": 8.851540616246498e-05,
      "loss": 0.0189,
      "step": 18260
    },
    {
      "epoch": 59.73856209150327,
      "grad_norm": 0.006849481258541346,
      "learning_rate": 8.795518207282912e-05,
      "loss": 0.022,
      "step": 18280
    },
    {
      "epoch": 59.80392156862745,
      "grad_norm": 0.002404684666544199,
      "learning_rate": 8.739495798319327e-05,
      "loss": 0.0073,
      "step": 18300
    },
    {
      "epoch": 59.869281045751634,
      "grad_norm": 0.002377711469307542,
      "learning_rate": 8.683473389355742e-05,
      "loss": 0.0002,
      "step": 18320
    },
    {
      "epoch": 59.93464052287582,
      "grad_norm": 0.0009612999856472015,
      "learning_rate": 8.627450980392155e-05,
      "loss": 0.0303,
      "step": 18340
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.2649792432785034,
      "learning_rate": 8.57142857142857e-05,
      "loss": 0.0002,
      "step": 18360
    },
    {
      "epoch": 60.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9050299323269131,
      "eval_f1": 0.9203539823008849,
      "eval_loss": 0.8367879390716553,
      "eval_runtime": 12.1738,
      "eval_samples_per_second": 33.515,
      "eval_steps_per_second": 4.189,
      "step": 18360
    },
    {
      "epoch": 60.06535947712418,
      "grad_norm": 0.0036691746208816767,
      "learning_rate": 8.515406162464985e-05,
      "loss": 0.0244,
      "step": 18380
    },
    {
      "epoch": 60.130718954248366,
      "grad_norm": 0.02083653211593628,
      "learning_rate": 8.459383753501399e-05,
      "loss": 0.0352,
      "step": 18400
    },
    {
      "epoch": 60.19607843137255,
      "grad_norm": 17.145936965942383,
      "learning_rate": 8.403361344537814e-05,
      "loss": 0.0317,
      "step": 18420
    },
    {
      "epoch": 60.26143790849673,
      "grad_norm": 0.04096338152885437,
      "learning_rate": 8.347338935574229e-05,
      "loss": 0.0498,
      "step": 18440
    },
    {
      "epoch": 60.326797385620914,
      "grad_norm": 0.6198139190673828,
      "learning_rate": 8.291316526610643e-05,
      "loss": 0.0135,
      "step": 18460
    },
    {
      "epoch": 60.3921568627451,
      "grad_norm": 0.0005452241748571396,
      "learning_rate": 8.23529411764706e-05,
      "loss": 0.0342,
      "step": 18480
    },
    {
      "epoch": 60.45751633986928,
      "grad_norm": 0.0015522593166679144,
      "learning_rate": 8.179271708683471e-05,
      "loss": 0.0001,
      "step": 18500
    },
    {
      "epoch": 60.52287581699346,
      "grad_norm": 0.0009576789452694356,
      "learning_rate": 8.123249299719886e-05,
      "loss": 0.0043,
      "step": 18520
    },
    {
      "epoch": 60.588235294117645,
      "grad_norm": 0.0022618118673563004,
      "learning_rate": 8.067226890756301e-05,
      "loss": 0.0434,
      "step": 18540
    },
    {
      "epoch": 60.65359477124183,
      "grad_norm": 0.7002926468849182,
      "learning_rate": 8.011204481792717e-05,
      "loss": 0.0339,
      "step": 18560
    },
    {
      "epoch": 60.71895424836601,
      "grad_norm": 0.0011974694207310677,
      "learning_rate": 7.955182072829132e-05,
      "loss": 0.0006,
      "step": 18580
    },
    {
      "epoch": 60.78431372549019,
      "grad_norm": 0.0009566065273247659,
      "learning_rate": 7.899159663865546e-05,
      "loss": 0.0111,
      "step": 18600
    },
    {
      "epoch": 60.849673202614376,
      "grad_norm": 0.0026316598523408175,
      "learning_rate": 7.843137254901961e-05,
      "loss": 0.0042,
      "step": 18620
    },
    {
      "epoch": 60.91503267973856,
      "grad_norm": 0.0007325237966142595,
      "learning_rate": 7.787114845938376e-05,
      "loss": 0.0003,
      "step": 18640
    },
    {
      "epoch": 60.98039215686274,
      "grad_norm": 0.001396929961629212,
      "learning_rate": 7.731092436974789e-05,
      "loss": 0.0002,
      "step": 18660
    },
    {
      "epoch": 61.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9091156444815938,
      "eval_f1": 0.9236234458259325,
      "eval_loss": 0.8636161684989929,
      "eval_runtime": 12.0611,
      "eval_samples_per_second": 33.828,
      "eval_steps_per_second": 4.228,
      "step": 18666
    },
    {
      "epoch": 61.04575163398693,
      "grad_norm": 0.0013964326353743672,
      "learning_rate": 7.675070028011204e-05,
      "loss": 0.0328,
      "step": 18680
    },
    {
      "epoch": 61.111111111111114,
      "grad_norm": 0.0010700618149712682,
      "learning_rate": 7.619047619047618e-05,
      "loss": 0.0386,
      "step": 18700
    },
    {
      "epoch": 61.1764705882353,
      "grad_norm": 0.01194717176258564,
      "learning_rate": 7.563025210084033e-05,
      "loss": 0.0322,
      "step": 18720
    },
    {
      "epoch": 61.24183006535948,
      "grad_norm": 0.00028780451975762844,
      "learning_rate": 7.507002801120448e-05,
      "loss": 0.0006,
      "step": 18740
    },
    {
      "epoch": 61.30718954248366,
      "grad_norm": 0.0013598472578451037,
      "learning_rate": 7.450980392156863e-05,
      "loss": 0.0159,
      "step": 18760
    },
    {
      "epoch": 61.372549019607845,
      "grad_norm": 22.416826248168945,
      "learning_rate": 7.394957983193277e-05,
      "loss": 0.0509,
      "step": 18780
    },
    {
      "epoch": 61.43790849673203,
      "grad_norm": 0.0032447061967104673,
      "learning_rate": 7.33893557422969e-05,
      "loss": 0.0205,
      "step": 18800
    },
    {
      "epoch": 61.50326797385621,
      "grad_norm": 0.506908118724823,
      "learning_rate": 7.282913165266105e-05,
      "loss": 0.0015,
      "step": 18820
    },
    {
      "epoch": 61.568627450980394,
      "grad_norm": 0.0046769785694777966,
      "learning_rate": 7.22689075630252e-05,
      "loss": 0.0019,
      "step": 18840
    },
    {
      "epoch": 61.63398692810458,
      "grad_norm": 0.006964960601180792,
      "learning_rate": 7.170868347338935e-05,
      "loss": 0.0002,
      "step": 18860
    },
    {
      "epoch": 61.69934640522876,
      "grad_norm": 0.0006845207535661757,
      "learning_rate": 7.11484593837535e-05,
      "loss": 0.0001,
      "step": 18880
    },
    {
      "epoch": 61.76470588235294,
      "grad_norm": 0.0044765654020011425,
      "learning_rate": 7.058823529411764e-05,
      "loss": 0.0003,
      "step": 18900
    },
    {
      "epoch": 61.830065359477125,
      "grad_norm": 0.007544323801994324,
      "learning_rate": 7.002801120448179e-05,
      "loss": 0.0003,
      "step": 18920
    },
    {
      "epoch": 61.89542483660131,
      "grad_norm": 22.685466766357422,
      "learning_rate": 6.946778711484593e-05,
      "loss": 0.0048,
      "step": 18940
    },
    {
      "epoch": 61.96078431372549,
      "grad_norm": 18.205665588378906,
      "learning_rate": 6.890756302521007e-05,
      "loss": 0.042,
      "step": 18960
    },
    {
      "epoch": 62.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.907209173422019,
      "eval_f1": 0.9222614840989399,
      "eval_loss": 0.8542779684066772,
      "eval_runtime": 12.1065,
      "eval_samples_per_second": 33.701,
      "eval_steps_per_second": 4.213,
      "step": 18972
    },
    {
      "epoch": 62.02614379084967,
      "grad_norm": 0.0006878251442685723,
      "learning_rate": 6.834733893557423e-05,
      "loss": 0.0229,
      "step": 18980
    },
    {
      "epoch": 62.091503267973856,
      "grad_norm": 0.0007357948343269527,
      "learning_rate": 6.778711484593838e-05,
      "loss": 0.0001,
      "step": 19000
    },
    {
      "epoch": 62.15686274509804,
      "grad_norm": 0.0005246761138550937,
      "learning_rate": 6.722689075630252e-05,
      "loss": 0.0057,
      "step": 19020
    },
    {
      "epoch": 62.22222222222222,
      "grad_norm": 0.00182187685277313,
      "learning_rate": 6.666666666666666e-05,
      "loss": 0.0006,
      "step": 19040
    },
    {
      "epoch": 62.287581699346404,
      "grad_norm": 0.001290582469664514,
      "learning_rate": 6.61064425770308e-05,
      "loss": 0.0384,
      "step": 19060
    },
    {
      "epoch": 62.35294117647059,
      "grad_norm": 0.0008664522902108729,
      "learning_rate": 6.554621848739495e-05,
      "loss": 0.0031,
      "step": 19080
    },
    {
      "epoch": 62.41830065359477,
      "grad_norm": 0.0004218656977172941,
      "learning_rate": 6.49859943977591e-05,
      "loss": 0.0146,
      "step": 19100
    },
    {
      "epoch": 62.48366013071895,
      "grad_norm": 0.0006556941079907119,
      "learning_rate": 6.442577030812324e-05,
      "loss": 0.0018,
      "step": 19120
    },
    {
      "epoch": 62.549019607843135,
      "grad_norm": 20.958311080932617,
      "learning_rate": 6.386554621848739e-05,
      "loss": 0.0102,
      "step": 19140
    },
    {
      "epoch": 62.61437908496732,
      "grad_norm": 0.0005944108124822378,
      "learning_rate": 6.330532212885154e-05,
      "loss": 0.0263,
      "step": 19160
    },
    {
      "epoch": 62.6797385620915,
      "grad_norm": 0.0023011774756014347,
      "learning_rate": 6.274509803921569e-05,
      "loss": 0.0004,
      "step": 19180
    },
    {
      "epoch": 62.745098039215684,
      "grad_norm": 0.002217100467532873,
      "learning_rate": 6.218487394957983e-05,
      "loss": 0.036,
      "step": 19200
    },
    {
      "epoch": 62.810457516339866,
      "grad_norm": 0.01858195848762989,
      "learning_rate": 6.162464985994397e-05,
      "loss": 0.0012,
      "step": 19220
    },
    {
      "epoch": 62.87581699346405,
      "grad_norm": 0.019401615485548973,
      "learning_rate": 6.106442577030811e-05,
      "loss": 0.027,
      "step": 19240
    },
    {
      "epoch": 62.94117647058823,
      "grad_norm": 0.0007601219695061445,
      "learning_rate": 6.0504201680672267e-05,
      "loss": 0.0018,
      "step": 19260
    },
    {
      "epoch": 63.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.907209173422019,
      "eval_f1": 0.9222614840989399,
      "eval_loss": 0.8445072770118713,
      "eval_runtime": 12.1974,
      "eval_samples_per_second": 33.45,
      "eval_steps_per_second": 4.181,
      "step": 19278
    },
    {
      "epoch": 63.00653594771242,
      "grad_norm": 0.0005027664010412991,
      "learning_rate": 5.9943977591036414e-05,
      "loss": 0.0017,
      "step": 19280
    },
    {
      "epoch": 63.071895424836605,
      "grad_norm": 0.0005337356706149876,
      "learning_rate": 5.9383753501400554e-05,
      "loss": 0.0372,
      "step": 19300
    },
    {
      "epoch": 63.13725490196079,
      "grad_norm": 0.04533766955137253,
      "learning_rate": 5.88235294117647e-05,
      "loss": 0.0007,
      "step": 19320
    },
    {
      "epoch": 63.20261437908497,
      "grad_norm": 0.00033575997804291546,
      "learning_rate": 5.826330532212885e-05,
      "loss": 0.0171,
      "step": 19340
    },
    {
      "epoch": 63.26797385620915,
      "grad_norm": 0.000996495713479817,
      "learning_rate": 5.7703081232492995e-05,
      "loss": 0.0009,
      "step": 19360
    },
    {
      "epoch": 63.333333333333336,
      "grad_norm": 0.0019002214539796114,
      "learning_rate": 5.7142857142857135e-05,
      "loss": 0.0031,
      "step": 19380
    },
    {
      "epoch": 63.39869281045752,
      "grad_norm": 0.00028538290644064546,
      "learning_rate": 5.658263305322128e-05,
      "loss": 0.0294,
      "step": 19400
    },
    {
      "epoch": 63.4640522875817,
      "grad_norm": 0.0004303067398723215,
      "learning_rate": 5.602240896358543e-05,
      "loss": 0.0017,
      "step": 19420
    },
    {
      "epoch": 63.529411764705884,
      "grad_norm": 15.37497329711914,
      "learning_rate": 5.5462184873949576e-05,
      "loss": 0.0287,
      "step": 19440
    },
    {
      "epoch": 63.59477124183007,
      "grad_norm": 0.1547037661075592,
      "learning_rate": 5.4901960784313716e-05,
      "loss": 0.0003,
      "step": 19460
    },
    {
      "epoch": 63.66013071895425,
      "grad_norm": 0.20417095720767975,
      "learning_rate": 5.434173669467786e-05,
      "loss": 0.0091,
      "step": 19480
    },
    {
      "epoch": 63.72549019607843,
      "grad_norm": 0.07223953306674957,
      "learning_rate": 5.378151260504201e-05,
      "loss": 0.0259,
      "step": 19500
    },
    {
      "epoch": 63.790849673202615,
      "grad_norm": 0.0005270064575597644,
      "learning_rate": 5.322128851540616e-05,
      "loss": 0.0103,
      "step": 19520
    },
    {
      "epoch": 63.8562091503268,
      "grad_norm": 0.34934407472610474,
      "learning_rate": 5.26610644257703e-05,
      "loss": 0.0244,
      "step": 19540
    },
    {
      "epoch": 63.92156862745098,
      "grad_norm": 0.00035970014869235456,
      "learning_rate": 5.2100840336134444e-05,
      "loss": 0.0608,
      "step": 19560
    },
    {
      "epoch": 63.98692810457516,
      "grad_norm": 0.0014256943250074983,
      "learning_rate": 5.15406162464986e-05,
      "loss": 0.0058,
      "step": 19580
    },
    {
      "epoch": 64.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9095183328164307,
      "eval_f1": 0.9244288224956063,
      "eval_loss": 0.87092125415802,
      "eval_runtime": 12.213,
      "eval_samples_per_second": 33.407,
      "eval_steps_per_second": 4.176,
      "step": 19584
    },
    {
      "epoch": 64.05228758169935,
      "grad_norm": 0.0004941889201290905,
      "learning_rate": 5.0980392156862745e-05,
      "loss": 0.0316,
      "step": 19600
    },
    {
      "epoch": 64.11764705882354,
      "grad_norm": 0.0007600078242830932,
      "learning_rate": 5.042016806722689e-05,
      "loss": 0.0258,
      "step": 19620
    },
    {
      "epoch": 64.18300653594771,
      "grad_norm": 0.0024311437737196684,
      "learning_rate": 4.985994397759103e-05,
      "loss": 0.0001,
      "step": 19640
    },
    {
      "epoch": 64.2483660130719,
      "grad_norm": 0.36659687757492065,
      "learning_rate": 4.929971988795518e-05,
      "loss": 0.0034,
      "step": 19660
    },
    {
      "epoch": 64.31372549019608,
      "grad_norm": 0.1794576197862625,
      "learning_rate": 4.8739495798319326e-05,
      "loss": 0.0165,
      "step": 19680
    },
    {
      "epoch": 64.37908496732027,
      "grad_norm": 0.00037311905180104077,
      "learning_rate": 4.817927170868347e-05,
      "loss": 0.0155,
      "step": 19700
    },
    {
      "epoch": 64.44444444444444,
      "grad_norm": 0.002661526668816805,
      "learning_rate": 4.7619047619047614e-05,
      "loss": 0.0087,
      "step": 19720
    },
    {
      "epoch": 64.50980392156863,
      "grad_norm": 0.00034826816408894956,
      "learning_rate": 4.705882352941176e-05,
      "loss": 0.0019,
      "step": 19740
    },
    {
      "epoch": 64.57516339869281,
      "grad_norm": 0.00047311847447417676,
      "learning_rate": 4.649859943977591e-05,
      "loss": 0.0087,
      "step": 19760
    },
    {
      "epoch": 64.640522875817,
      "grad_norm": 0.010988124646246433,
      "learning_rate": 4.5938375350140055e-05,
      "loss": 0.0003,
      "step": 19780
    },
    {
      "epoch": 64.70588235294117,
      "grad_norm": 0.0009591217385604978,
      "learning_rate": 4.5378151260504195e-05,
      "loss": 0.0579,
      "step": 19800
    },
    {
      "epoch": 64.77124183006536,
      "grad_norm": 0.0011011871974915266,
      "learning_rate": 4.481792717086834e-05,
      "loss": 0.009,
      "step": 19820
    },
    {
      "epoch": 64.83660130718954,
      "grad_norm": 0.0012569419341161847,
      "learning_rate": 4.425770308123249e-05,
      "loss": 0.0037,
      "step": 19840
    },
    {
      "epoch": 64.90196078431373,
      "grad_norm": 0.003694510320201516,
      "learning_rate": 4.3697478991596636e-05,
      "loss": 0.015,
      "step": 19860
    },
    {
      "epoch": 64.9673202614379,
      "grad_norm": 0.0029731907416135073,
      "learning_rate": 4.3137254901960776e-05,
      "loss": 0.0003,
      "step": 19880
    },
    {
      "epoch": 65.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9115575807787903,
      "eval_f1": 0.926056338028169,
      "eval_loss": 0.845899760723114,
      "eval_runtime": 12.2152,
      "eval_samples_per_second": 33.401,
      "eval_steps_per_second": 4.175,
      "step": 19890
    },
    {
      "epoch": 65.0326797385621,
      "grad_norm": 9.376993179321289,
      "learning_rate": 4.257703081232492e-05,
      "loss": 0.0013,
      "step": 19900
    },
    {
      "epoch": 65.09803921568627,
      "grad_norm": 2.2676169872283936,
      "learning_rate": 4.201680672268907e-05,
      "loss": 0.005,
      "step": 19920
    },
    {
      "epoch": 65.16339869281046,
      "grad_norm": 0.00027249622507952154,
      "learning_rate": 4.145658263305322e-05,
      "loss": 0.0002,
      "step": 19940
    },
    {
      "epoch": 65.22875816993464,
      "grad_norm": 0.001340082148090005,
      "learning_rate": 4.089635854341736e-05,
      "loss": 0.0049,
      "step": 19960
    },
    {
      "epoch": 65.29411764705883,
      "grad_norm": 4.435636520385742,
      "learning_rate": 4.0336134453781504e-05,
      "loss": 0.0026,
      "step": 19980
    },
    {
      "epoch": 65.359477124183,
      "grad_norm": 0.0008485420839861035,
      "learning_rate": 3.977591036414566e-05,
      "loss": 0.0021,
      "step": 20000
    },
    {
      "epoch": 65.42483660130719,
      "grad_norm": 0.00018274223839398474,
      "learning_rate": 3.9215686274509805e-05,
      "loss": 0.0068,
      "step": 20020
    },
    {
      "epoch": 65.49019607843137,
      "grad_norm": 0.00017846863192971796,
      "learning_rate": 3.8655462184873945e-05,
      "loss": 0.0415,
      "step": 20040
    },
    {
      "epoch": 65.55555555555556,
      "grad_norm": 0.5808264017105103,
      "learning_rate": 3.809523809523809e-05,
      "loss": 0.0145,
      "step": 20060
    },
    {
      "epoch": 65.62091503267973,
      "grad_norm": 0.005416327156126499,
      "learning_rate": 3.753501400560224e-05,
      "loss": 0.0332,
      "step": 20080
    },
    {
      "epoch": 65.68627450980392,
      "grad_norm": 17.896629333496094,
      "learning_rate": 3.6974789915966386e-05,
      "loss": 0.0124,
      "step": 20100
    },
    {
      "epoch": 65.7516339869281,
      "grad_norm": 0.0019996478222310543,
      "learning_rate": 3.6414565826330526e-05,
      "loss": 0.0013,
      "step": 20120
    },
    {
      "epoch": 65.81699346405229,
      "grad_norm": 0.000695047783665359,
      "learning_rate": 3.5854341736694673e-05,
      "loss": 0.0131,
      "step": 20140
    },
    {
      "epoch": 65.88235294117646,
      "grad_norm": 0.0017834953032433987,
      "learning_rate": 3.529411764705882e-05,
      "loss": 0.0045,
      "step": 20160
    },
    {
      "epoch": 65.94771241830065,
      "grad_norm": 0.08163084089756012,
      "learning_rate": 3.473389355742297e-05,
      "loss": 0.0038,
      "step": 20180
    },
    {
      "epoch": 66.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9074819401444789,
      "eval_f1": 0.9228070175438596,
      "eval_loss": 0.9022140502929688,
      "eval_runtime": 12.4316,
      "eval_samples_per_second": 32.82,
      "eval_steps_per_second": 4.102,
      "step": 20196
    },
    {
      "epoch": 66.01307189542484,
      "grad_norm": 0.0008198327268473804,
      "learning_rate": 3.4173669467787114e-05,
      "loss": 0.0069,
      "step": 20200
    },
    {
      "epoch": 66.07843137254902,
      "grad_norm": 0.571125328540802,
      "learning_rate": 3.361344537815126e-05,
      "loss": 0.0407,
      "step": 20220
    },
    {
      "epoch": 66.14379084967321,
      "grad_norm": 9.210001945495605,
      "learning_rate": 3.30532212885154e-05,
      "loss": 0.017,
      "step": 20240
    },
    {
      "epoch": 66.20915032679738,
      "grad_norm": 0.000950068177189678,
      "learning_rate": 3.249299719887955e-05,
      "loss": 0.0,
      "step": 20260
    },
    {
      "epoch": 66.27450980392157,
      "grad_norm": 0.003994825296103954,
      "learning_rate": 3.1932773109243696e-05,
      "loss": 0.0004,
      "step": 20280
    },
    {
      "epoch": 66.33986928104575,
      "grad_norm": 0.0041360994800925255,
      "learning_rate": 3.137254901960784e-05,
      "loss": 0.0608,
      "step": 20300
    },
    {
      "epoch": 66.40522875816994,
      "grad_norm": 0.00036499096313491464,
      "learning_rate": 3.081232492997198e-05,
      "loss": 0.0204,
      "step": 20320
    },
    {
      "epoch": 66.47058823529412,
      "grad_norm": 0.00021469127386808395,
      "learning_rate": 3.0252100840336133e-05,
      "loss": 0.0,
      "step": 20340
    },
    {
      "epoch": 66.5359477124183,
      "grad_norm": 0.00043784090667031705,
      "learning_rate": 2.9691876750700277e-05,
      "loss": 0.0001,
      "step": 20360
    },
    {
      "epoch": 66.60130718954248,
      "grad_norm": 0.005214364733546972,
      "learning_rate": 2.9131652661064424e-05,
      "loss": 0.0576,
      "step": 20380
    },
    {
      "epoch": 66.66666666666667,
      "grad_norm": 0.11980230361223221,
      "learning_rate": 2.8571428571428567e-05,
      "loss": 0.0069,
      "step": 20400
    },
    {
      "epoch": 66.73202614379085,
      "grad_norm": 0.012538020499050617,
      "learning_rate": 2.8011204481792714e-05,
      "loss": 0.0021,
      "step": 20420
    },
    {
      "epoch": 66.79738562091504,
      "grad_norm": 0.0005999522400088608,
      "learning_rate": 2.7450980392156858e-05,
      "loss": 0.0006,
      "step": 20440
    },
    {
      "epoch": 66.86274509803921,
      "grad_norm": 0.013571462593972683,
      "learning_rate": 2.6890756302521005e-05,
      "loss": 0.0172,
      "step": 20460
    },
    {
      "epoch": 66.9281045751634,
      "grad_norm": 0.006367686204612255,
      "learning_rate": 2.633053221288515e-05,
      "loss": 0.0122,
      "step": 20480
    },
    {
      "epoch": 66.99346405228758,
      "grad_norm": 0.0008823638199828565,
      "learning_rate": 2.57703081232493e-05,
      "loss": 0.0029,
      "step": 20500
    },
    {
      "epoch": 67.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9135996991389148,
      "eval_f1": 0.927689594356261,
      "eval_loss": 0.862366795539856,
      "eval_runtime": 12.5995,
      "eval_samples_per_second": 32.382,
      "eval_steps_per_second": 4.048,
      "step": 20502
    },
    {
      "epoch": 67.05882352941177,
      "grad_norm": 0.004245355725288391,
      "learning_rate": 2.5210084033613446e-05,
      "loss": 0.0415,
      "step": 20520
    },
    {
      "epoch": 67.12418300653594,
      "grad_norm": 0.0026729912497103214,
      "learning_rate": 2.464985994397759e-05,
      "loss": 0.0065,
      "step": 20540
    },
    {
      "epoch": 67.18954248366013,
      "grad_norm": 0.09741689264774323,
      "learning_rate": 2.4089635854341737e-05,
      "loss": 0.0179,
      "step": 20560
    },
    {
      "epoch": 67.25490196078431,
      "grad_norm": 0.0003162507782690227,
      "learning_rate": 2.352941176470588e-05,
      "loss": 0.0,
      "step": 20580
    },
    {
      "epoch": 67.3202614379085,
      "grad_norm": 0.0009384609293192625,
      "learning_rate": 2.2969187675070027e-05,
      "loss": 0.0182,
      "step": 20600
    },
    {
      "epoch": 67.38562091503267,
      "grad_norm": 0.0005338819464668632,
      "learning_rate": 2.240896358543417e-05,
      "loss": 0.0,
      "step": 20620
    },
    {
      "epoch": 67.45098039215686,
      "grad_norm": 0.026442574337124825,
      "learning_rate": 2.1848739495798318e-05,
      "loss": 0.0113,
      "step": 20640
    },
    {
      "epoch": 67.51633986928104,
      "grad_norm": 0.026096949353814125,
      "learning_rate": 2.128851540616246e-05,
      "loss": 0.003,
      "step": 20660
    },
    {
      "epoch": 67.58169934640523,
      "grad_norm": 0.001652603386901319,
      "learning_rate": 2.072829131652661e-05,
      "loss": 0.0293,
      "step": 20680
    },
    {
      "epoch": 67.6470588235294,
      "grad_norm": 0.0007611305336467922,
      "learning_rate": 2.0168067226890752e-05,
      "loss": 0.0305,
      "step": 20700
    },
    {
      "epoch": 67.7124183006536,
      "grad_norm": 0.01533195748925209,
      "learning_rate": 1.9607843137254903e-05,
      "loss": 0.0001,
      "step": 20720
    },
    {
      "epoch": 67.77777777777777,
      "grad_norm": 0.00023188907653093338,
      "learning_rate": 1.9047619047619046e-05,
      "loss": 0.0468,
      "step": 20740
    },
    {
      "epoch": 67.84313725490196,
      "grad_norm": 0.010935081169009209,
      "learning_rate": 1.8487394957983193e-05,
      "loss": 0.0426,
      "step": 20760
    },
    {
      "epoch": 67.90849673202614,
      "grad_norm": 0.0008645618217997253,
      "learning_rate": 1.7927170868347337e-05,
      "loss": 0.0027,
      "step": 20780
    },
    {
      "epoch": 67.97385620915033,
      "grad_norm": 0.028491420671343803,
      "learning_rate": 1.7366946778711484e-05,
      "loss": 0.0008,
      "step": 20800
    },
    {
      "epoch": 68.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9135996991389148,
      "eval_f1": 0.927689594356261,
      "eval_loss": 0.8689109683036804,
      "eval_runtime": 12.3088,
      "eval_samples_per_second": 33.147,
      "eval_steps_per_second": 4.143,
      "step": 20808
    },
    {
      "epoch": 68.03921568627452,
      "grad_norm": 0.000551058619748801,
      "learning_rate": 1.680672268907563e-05,
      "loss": 0.0103,
      "step": 20820
    },
    {
      "epoch": 68.10457516339869,
      "grad_norm": 0.011886602267622948,
      "learning_rate": 1.6246498599439774e-05,
      "loss": 0.0007,
      "step": 20840
    },
    {
      "epoch": 68.16993464052288,
      "grad_norm": 0.0024527714122086763,
      "learning_rate": 1.568627450980392e-05,
      "loss": 0.0023,
      "step": 20860
    },
    {
      "epoch": 68.23529411764706,
      "grad_norm": 0.0006873268284834921,
      "learning_rate": 1.5126050420168067e-05,
      "loss": 0.0351,
      "step": 20880
    },
    {
      "epoch": 68.30065359477125,
      "grad_norm": 0.0022385907359421253,
      "learning_rate": 1.4565826330532212e-05,
      "loss": 0.0011,
      "step": 20900
    },
    {
      "epoch": 68.36601307189542,
      "grad_norm": 0.0009687630808912218,
      "learning_rate": 1.4005602240896357e-05,
      "loss": 0.0,
      "step": 20920
    },
    {
      "epoch": 68.43137254901961,
      "grad_norm": 0.018482014536857605,
      "learning_rate": 1.3445378151260503e-05,
      "loss": 0.0118,
      "step": 20940
    },
    {
      "epoch": 68.49673202614379,
      "grad_norm": 0.009006856940686703,
      "learning_rate": 1.288515406162465e-05,
      "loss": 0.0001,
      "step": 20960
    },
    {
      "epoch": 68.56209150326798,
      "grad_norm": 0.00018030291539616883,
      "learning_rate": 1.2324929971988795e-05,
      "loss": 0.0033,
      "step": 20980
    },
    {
      "epoch": 68.62745098039215,
      "grad_norm": 0.10610529035329819,
      "learning_rate": 1.176470588235294e-05,
      "loss": 0.031,
      "step": 21000
    },
    {
      "epoch": 68.69281045751634,
      "grad_norm": 0.41279295086860657,
      "learning_rate": 1.1204481792717085e-05,
      "loss": 0.0048,
      "step": 21020
    },
    {
      "epoch": 68.75816993464052,
      "grad_norm": 0.0004328253271523863,
      "learning_rate": 1.064425770308123e-05,
      "loss": 0.0438,
      "step": 21040
    },
    {
      "epoch": 68.82352941176471,
      "grad_norm": 0.003241034457460046,
      "learning_rate": 1.0084033613445376e-05,
      "loss": 0.0003,
      "step": 21060
    },
    {
      "epoch": 68.88888888888889,
      "grad_norm": 0.001775162760168314,
      "learning_rate": 9.523809523809523e-06,
      "loss": 0.0255,
      "step": 21080
    },
    {
      "epoch": 68.95424836601308,
      "grad_norm": 0.000311604468151927,
      "learning_rate": 8.963585434173668e-06,
      "loss": 0.0058,
      "step": 21100
    },
    {
      "epoch": 69.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9095183328164307,
      "eval_f1": 0.9244288224956063,
      "eval_loss": 0.8869204521179199,
      "eval_runtime": 12.1684,
      "eval_samples_per_second": 33.53,
      "eval_steps_per_second": 4.191,
      "step": 21114
    },
    {
      "epoch": 69.01960784313725,
      "grad_norm": 0.0007707931217737496,
      "learning_rate": 8.403361344537815e-06,
      "loss": 0.0002,
      "step": 21120
    },
    {
      "epoch": 69.08496732026144,
      "grad_norm": 0.005313355475664139,
      "learning_rate": 7.84313725490196e-06,
      "loss": 0.0001,
      "step": 21140
    },
    {
      "epoch": 69.15032679738562,
      "grad_norm": 11.754169464111328,
      "learning_rate": 7.282913165266106e-06,
      "loss": 0.0058,
      "step": 21160
    },
    {
      "epoch": 69.2156862745098,
      "grad_norm": 0.013065263628959656,
      "learning_rate": 6.722689075630251e-06,
      "loss": 0.0001,
      "step": 21180
    },
    {
      "epoch": 69.28104575163398,
      "grad_norm": 0.0010008889948949218,
      "learning_rate": 6.162464985994397e-06,
      "loss": 0.0008,
      "step": 21200
    },
    {
      "epoch": 69.34640522875817,
      "grad_norm": 0.005540900398045778,
      "learning_rate": 5.602240896358543e-06,
      "loss": 0.0018,
      "step": 21220
    },
    {
      "epoch": 69.41176470588235,
      "grad_norm": 0.006008039694279432,
      "learning_rate": 5.042016806722688e-06,
      "loss": 0.0006,
      "step": 21240
    },
    {
      "epoch": 69.47712418300654,
      "grad_norm": 0.00033271292340941727,
      "learning_rate": 4.481792717086834e-06,
      "loss": 0.0218,
      "step": 21260
    },
    {
      "epoch": 69.54248366013071,
      "grad_norm": 0.014725149609148502,
      "learning_rate": 3.92156862745098e-06,
      "loss": 0.0015,
      "step": 21280
    },
    {
      "epoch": 69.6078431372549,
      "grad_norm": 0.00029914735932834446,
      "learning_rate": 3.3613445378151256e-06,
      "loss": 0.013,
      "step": 21300
    },
    {
      "epoch": 69.67320261437908,
      "grad_norm": 0.0004345071210991591,
      "learning_rate": 2.8011204481792714e-06,
      "loss": 0.0381,
      "step": 21320
    },
    {
      "epoch": 69.73856209150327,
      "grad_norm": 0.0008153653470799327,
      "learning_rate": 2.240896358543417e-06,
      "loss": 0.0001,
      "step": 21340
    },
    {
      "epoch": 69.80392156862744,
      "grad_norm": 0.0009143493953160942,
      "learning_rate": 1.6806722689075628e-06,
      "loss": 0.0001,
      "step": 21360
    },
    {
      "epoch": 69.86928104575163,
      "grad_norm": 10.597777366638184,
      "learning_rate": 1.1204481792717085e-06,
      "loss": 0.0107,
      "step": 21380
    },
    {
      "epoch": 69.93464052287581,
      "grad_norm": 0.0002530294004827738,
      "learning_rate": 5.602240896358543e-07,
      "loss": 0.0178,
      "step": 21400
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.00043900974560528994,
      "learning_rate": 0.0,
      "loss": 0.0269,
      "step": 21420
    },
    {
      "epoch": 70.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9115575807787903,
      "eval_f1": 0.926056338028169,
      "eval_loss": 0.8833219408988953,
      "eval_runtime": 12.0782,
      "eval_samples_per_second": 33.78,
      "eval_steps_per_second": 4.222,
      "step": 21420
    },
    {
      "epoch": 70.0,
      "step": 21420,
      "total_flos": 6.137258259320832e+16,
      "train_loss": 0.07937311752511866,
      "train_runtime": 17580.2277,
      "train_samples_per_second": 14.605,
      "train_steps_per_second": 1.218
    }
  ],
  "logging_steps": 20,
  "max_steps": 21420,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 70,
  "save_steps": 1530,
  "total_flos": 6.137258259320832e+16,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
