{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 22950,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04357298474945534,
      "grad_norm": 5.888917922973633,
      "learning_rate": 0.0005994771241830065,
      "loss": 0.7163,
      "step": 20
    },
    {
      "epoch": 0.08714596949891068,
      "grad_norm": 1.9223344326019287,
      "learning_rate": 0.000598954248366013,
      "loss": 0.5653,
      "step": 40
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 4.14576530456543,
      "learning_rate": 0.0005984313725490196,
      "loss": 0.648,
      "step": 60
    },
    {
      "epoch": 0.17429193899782136,
      "grad_norm": 13.176684379577637,
      "learning_rate": 0.000597908496732026,
      "loss": 0.4963,
      "step": 80
    },
    {
      "epoch": 0.2178649237472767,
      "grad_norm": 3.0111300945281982,
      "learning_rate": 0.0005973856209150327,
      "loss": 0.572,
      "step": 100
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 2.1240081787109375,
      "learning_rate": 0.0005968627450980391,
      "loss": 0.3972,
      "step": 120
    },
    {
      "epoch": 0.30501089324618735,
      "grad_norm": 3.837890863418579,
      "learning_rate": 0.0005963398692810457,
      "loss": 0.6037,
      "step": 140
    },
    {
      "epoch": 0.3485838779956427,
      "grad_norm": 6.184067249298096,
      "learning_rate": 0.0005958169934640522,
      "loss": 0.5768,
      "step": 160
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 11.370604515075684,
      "learning_rate": 0.0005952941176470588,
      "loss": 0.5335,
      "step": 180
    },
    {
      "epoch": 0.4357298474945534,
      "grad_norm": 3.749077796936035,
      "learning_rate": 0.0005947712418300653,
      "loss": 0.4678,
      "step": 200
    },
    {
      "epoch": 0.4793028322440087,
      "grad_norm": 4.721167087554932,
      "learning_rate": 0.0005942483660130719,
      "loss": 0.567,
      "step": 220
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 1.8456944227218628,
      "learning_rate": 0.0005937254901960784,
      "loss": 0.3306,
      "step": 240
    },
    {
      "epoch": 0.5664488017429193,
      "grad_norm": 10.716233253479004,
      "learning_rate": 0.000593202614379085,
      "loss": 0.4639,
      "step": 260
    },
    {
      "epoch": 0.6100217864923747,
      "grad_norm": 11.753177642822266,
      "learning_rate": 0.0005926797385620914,
      "loss": 0.4858,
      "step": 280
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 3.127777576446533,
      "learning_rate": 0.0005921568627450981,
      "loss": 0.4666,
      "step": 300
    },
    {
      "epoch": 0.6971677559912854,
      "grad_norm": 7.845574855804443,
      "learning_rate": 0.0005916339869281045,
      "loss": 0.3937,
      "step": 320
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 5.037083625793457,
      "learning_rate": 0.000591111111111111,
      "loss": 0.4471,
      "step": 340
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 2.4500250816345215,
      "learning_rate": 0.0005905882352941176,
      "loss": 0.4339,
      "step": 360
    },
    {
      "epoch": 0.8278867102396514,
      "grad_norm": 0.8148461580276489,
      "learning_rate": 0.0005900653594771241,
      "loss": 0.5135,
      "step": 380
    },
    {
      "epoch": 0.8714596949891068,
      "grad_norm": 2.566650867462158,
      "learning_rate": 0.0005895424836601307,
      "loss": 0.3453,
      "step": 400
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 1.687053918838501,
      "learning_rate": 0.0005890196078431371,
      "loss": 0.3906,
      "step": 420
    },
    {
      "epoch": 0.9586056644880174,
      "grad_norm": 5.517395973205566,
      "learning_rate": 0.0005884967320261438,
      "loss": 0.431,
      "step": 440
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_combined_score": 0.8796018407362944,
      "eval_f1": 0.901360544217687,
      "eval_loss": 0.39453548192977905,
      "eval_runtime": 11.9794,
      "eval_samples_per_second": 34.058,
      "eval_steps_per_second": 4.257,
      "step": 459
    },
    {
      "epoch": 1.0021786492374727,
      "grad_norm": 2.3453891277313232,
      "learning_rate": 0.0005879738562091502,
      "loss": 0.2576,
      "step": 460
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 1.271456003189087,
      "learning_rate": 0.0005874509803921568,
      "loss": 0.3086,
      "step": 480
    },
    {
      "epoch": 1.0893246187363834,
      "grad_norm": 2.582831859588623,
      "learning_rate": 0.0005869281045751633,
      "loss": 0.4471,
      "step": 500
    },
    {
      "epoch": 1.132897603485839,
      "grad_norm": 7.992142677307129,
      "learning_rate": 0.0005864052287581699,
      "loss": 0.4139,
      "step": 520
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 2.225353240966797,
      "learning_rate": 0.0005858823529411764,
      "loss": 0.3293,
      "step": 540
    },
    {
      "epoch": 1.2200435729847494,
      "grad_norm": 5.988617420196533,
      "learning_rate": 0.000585359477124183,
      "loss": 0.3094,
      "step": 560
    },
    {
      "epoch": 1.263616557734205,
      "grad_norm": 6.13852596282959,
      "learning_rate": 0.0005848366013071895,
      "loss": 0.2328,
      "step": 580
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 7.620780944824219,
      "learning_rate": 0.0005843137254901961,
      "loss": 0.4567,
      "step": 600
    },
    {
      "epoch": 1.3507625272331154,
      "grad_norm": 7.600331783294678,
      "learning_rate": 0.0005837908496732025,
      "loss": 0.3389,
      "step": 620
    },
    {
      "epoch": 1.3943355119825709,
      "grad_norm": 0.4988915026187897,
      "learning_rate": 0.0005832679738562092,
      "loss": 0.3532,
      "step": 640
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 5.199068546295166,
      "learning_rate": 0.0005827450980392156,
      "loss": 0.3264,
      "step": 660
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 3.019930362701416,
      "learning_rate": 0.0005822222222222221,
      "loss": 0.2785,
      "step": 680
    },
    {
      "epoch": 1.5250544662309369,
      "grad_norm": 1.229799509048462,
      "learning_rate": 0.0005816993464052287,
      "loss": 0.4436,
      "step": 700
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 7.0600738525390625,
      "learning_rate": 0.0005811764705882352,
      "loss": 0.3839,
      "step": 720
    },
    {
      "epoch": 1.6122004357298474,
      "grad_norm": 4.092292308807373,
      "learning_rate": 0.0005806535947712418,
      "loss": 0.4259,
      "step": 740
    },
    {
      "epoch": 1.6557734204793029,
      "grad_norm": 3.198969841003418,
      "learning_rate": 0.0005801307189542483,
      "loss": 0.392,
      "step": 760
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 0.7725562453269958,
      "learning_rate": 0.0005796078431372549,
      "loss": 0.3673,
      "step": 780
    },
    {
      "epoch": 1.7429193899782134,
      "grad_norm": 6.682016372680664,
      "learning_rate": 0.0005790849673202613,
      "loss": 0.2972,
      "step": 800
    },
    {
      "epoch": 1.7864923747276689,
      "grad_norm": 2.567911386489868,
      "learning_rate": 0.000578562091503268,
      "loss": 0.4124,
      "step": 820
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 6.043787956237793,
      "learning_rate": 0.0005780392156862744,
      "loss": 0.2962,
      "step": 840
    },
    {
      "epoch": 1.8736383442265794,
      "grad_norm": 6.924878120422363,
      "learning_rate": 0.000577516339869281,
      "loss": 0.3271,
      "step": 860
    },
    {
      "epoch": 1.9172113289760349,
      "grad_norm": 1.839590311050415,
      "learning_rate": 0.0005769934640522875,
      "loss": 0.2781,
      "step": 880
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 4.972322463989258,
      "learning_rate": 0.0005764705882352941,
      "loss": 0.381,
      "step": 900
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8627450980392157,
      "eval_combined_score": 0.8811933375500738,
      "eval_f1": 0.899641577060932,
      "eval_loss": 0.3490466773509979,
      "eval_runtime": 11.9712,
      "eval_samples_per_second": 34.082,
      "eval_steps_per_second": 4.26,
      "step": 918
    },
    {
      "epoch": 2.0043572984749454,
      "grad_norm": 2.1552300453186035,
      "learning_rate": 0.0005759477124183006,
      "loss": 0.3858,
      "step": 920
    },
    {
      "epoch": 2.047930283224401,
      "grad_norm": 0.5122661590576172,
      "learning_rate": 0.0005754248366013072,
      "loss": 0.3062,
      "step": 940
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 6.539795875549316,
      "learning_rate": 0.0005749019607843137,
      "loss": 0.3242,
      "step": 960
    },
    {
      "epoch": 2.1350762527233114,
      "grad_norm": 15.312986373901367,
      "learning_rate": 0.0005743790849673203,
      "loss": 0.3694,
      "step": 980
    },
    {
      "epoch": 2.178649237472767,
      "grad_norm": 11.963732719421387,
      "learning_rate": 0.0005738562091503267,
      "loss": 0.2045,
      "step": 1000
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 7.8464436531066895,
      "learning_rate": 0.0005733333333333334,
      "loss": 0.3073,
      "step": 1020
    },
    {
      "epoch": 2.265795206971678,
      "grad_norm": 3.7908284664154053,
      "learning_rate": 0.0005728104575163398,
      "loss": 0.3677,
      "step": 1040
    },
    {
      "epoch": 2.309368191721133,
      "grad_norm": 4.659782886505127,
      "learning_rate": 0.0005722875816993463,
      "loss": 0.4426,
      "step": 1060
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.31244924664497375,
      "learning_rate": 0.0005717647058823529,
      "loss": 0.3621,
      "step": 1080
    },
    {
      "epoch": 2.3965141612200433,
      "grad_norm": 2.2305948734283447,
      "learning_rate": 0.0005712418300653594,
      "loss": 0.1738,
      "step": 1100
    },
    {
      "epoch": 2.440087145969499,
      "grad_norm": 13.154403686523438,
      "learning_rate": 0.000570718954248366,
      "loss": 0.2702,
      "step": 1120
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 4.510670185089111,
      "learning_rate": 0.0005701960784313724,
      "loss": 0.2338,
      "step": 1140
    },
    {
      "epoch": 2.52723311546841,
      "grad_norm": 4.503652572631836,
      "learning_rate": 0.0005696732026143791,
      "loss": 0.386,
      "step": 1160
    },
    {
      "epoch": 2.570806100217865,
      "grad_norm": 3.9933817386627197,
      "learning_rate": 0.0005691503267973855,
      "loss": 0.3672,
      "step": 1180
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 6.100781440734863,
      "learning_rate": 0.0005686274509803921,
      "loss": 0.2733,
      "step": 1200
    },
    {
      "epoch": 2.6579520697167753,
      "grad_norm": 2.604790210723877,
      "learning_rate": 0.0005681045751633986,
      "loss": 0.377,
      "step": 1220
    },
    {
      "epoch": 2.701525054466231,
      "grad_norm": 3.2401251792907715,
      "learning_rate": 0.0005675816993464052,
      "loss": 0.3224,
      "step": 1240
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 4.57866096496582,
      "learning_rate": 0.0005670588235294117,
      "loss": 0.2061,
      "step": 1260
    },
    {
      "epoch": 2.7886710239651418,
      "grad_norm": 6.125765800476074,
      "learning_rate": 0.0005665359477124183,
      "loss": 0.4135,
      "step": 1280
    },
    {
      "epoch": 2.832244008714597,
      "grad_norm": 5.610019207000732,
      "learning_rate": 0.0005660130718954248,
      "loss": 0.3418,
      "step": 1300
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 32.94335174560547,
      "learning_rate": 0.0005654901960784314,
      "loss": 0.3116,
      "step": 1320
    },
    {
      "epoch": 2.9193899782135078,
      "grad_norm": 6.664458751678467,
      "learning_rate": 0.0005649673202614378,
      "loss": 0.3149,
      "step": 1340
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 2.276702880859375,
      "learning_rate": 0.0005644444444444445,
      "loss": 0.3043,
      "step": 1360
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8725490196078431,
      "eval_combined_score": 0.8906604747162024,
      "eval_f1": 0.9087719298245615,
      "eval_loss": 0.3849296569824219,
      "eval_runtime": 11.9668,
      "eval_samples_per_second": 34.094,
      "eval_steps_per_second": 4.262,
      "step": 1377
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 0.18452340364456177,
      "learning_rate": 0.0005639215686274509,
      "loss": 0.4039,
      "step": 1380
    },
    {
      "epoch": 3.0501089324618738,
      "grad_norm": 3.215686082839966,
      "learning_rate": 0.0005633986928104574,
      "loss": 0.3083,
      "step": 1400
    },
    {
      "epoch": 3.093681917211329,
      "grad_norm": 4.2090744972229,
      "learning_rate": 0.000562875816993464,
      "loss": 0.355,
      "step": 1420
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 3.699009418487549,
      "learning_rate": 0.0005623529411764705,
      "loss": 0.1787,
      "step": 1440
    },
    {
      "epoch": 3.1808278867102397,
      "grad_norm": 5.373092174530029,
      "learning_rate": 0.0005618300653594771,
      "loss": 0.3862,
      "step": 1460
    },
    {
      "epoch": 3.224400871459695,
      "grad_norm": 3.327624559402466,
      "learning_rate": 0.0005613071895424836,
      "loss": 0.1856,
      "step": 1480
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 15.192639350891113,
      "learning_rate": 0.0005607843137254902,
      "loss": 0.4501,
      "step": 1500
    },
    {
      "epoch": 3.3115468409586057,
      "grad_norm": 9.207813262939453,
      "learning_rate": 0.0005602614379084966,
      "loss": 0.2765,
      "step": 1520
    },
    {
      "epoch": 3.355119825708061,
      "grad_norm": 2.1353137493133545,
      "learning_rate": 0.0005597385620915033,
      "loss": 0.2045,
      "step": 1540
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 0.22841724753379822,
      "learning_rate": 0.0005592156862745097,
      "loss": 0.2518,
      "step": 1560
    },
    {
      "epoch": 3.4422657952069717,
      "grad_norm": 8.576746940612793,
      "learning_rate": 0.0005586928104575163,
      "loss": 0.3553,
      "step": 1580
    },
    {
      "epoch": 3.4858387799564268,
      "grad_norm": 7.683632850646973,
      "learning_rate": 0.0005581699346405228,
      "loss": 0.248,
      "step": 1600
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 5.785562038421631,
      "learning_rate": 0.0005576470588235294,
      "loss": 0.3387,
      "step": 1620
    },
    {
      "epoch": 3.5729847494553377,
      "grad_norm": 2.631415605545044,
      "learning_rate": 0.0005571241830065359,
      "loss": 0.2726,
      "step": 1640
    },
    {
      "epoch": 3.616557734204793,
      "grad_norm": 0.2768109142780304,
      "learning_rate": 0.0005566013071895425,
      "loss": 0.2069,
      "step": 1660
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 8.944974899291992,
      "learning_rate": 0.000556078431372549,
      "loss": 0.1707,
      "step": 1680
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 4.029865264892578,
      "learning_rate": 0.0005555555555555556,
      "loss": 0.2686,
      "step": 1700
    },
    {
      "epoch": 3.747276688453159,
      "grad_norm": 4.74273157119751,
      "learning_rate": 0.000555032679738562,
      "loss": 0.2791,
      "step": 1720
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 2.745680570602417,
      "learning_rate": 0.0005545098039215687,
      "loss": 0.2642,
      "step": 1740
    },
    {
      "epoch": 3.8344226579520697,
      "grad_norm": 4.027174949645996,
      "learning_rate": 0.0005539869281045751,
      "loss": 0.3206,
      "step": 1760
    },
    {
      "epoch": 3.877995642701525,
      "grad_norm": 2.57289981842041,
      "learning_rate": 0.0005534640522875816,
      "loss": 0.2698,
      "step": 1780
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 0.743431031703949,
      "learning_rate": 0.0005529411764705882,
      "loss": 0.2826,
      "step": 1800
    },
    {
      "epoch": 3.9651416122004357,
      "grad_norm": 1.3756033182144165,
      "learning_rate": 0.0005524183006535947,
      "loss": 0.2826,
      "step": 1820
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8990712074303405,
      "eval_f1": 0.9157894736842105,
      "eval_loss": 0.40518718957901,
      "eval_runtime": 11.9543,
      "eval_samples_per_second": 34.13,
      "eval_steps_per_second": 4.266,
      "step": 1836
    },
    {
      "epoch": 4.008714596949891,
      "grad_norm": 1.6796661615371704,
      "learning_rate": 0.0005518954248366013,
      "loss": 0.1575,
      "step": 1840
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 7.537755489349365,
      "learning_rate": 0.0005513725490196077,
      "loss": 0.3665,
      "step": 1860
    },
    {
      "epoch": 4.095860566448802,
      "grad_norm": 6.805169105529785,
      "learning_rate": 0.0005508496732026144,
      "loss": 0.1812,
      "step": 1880
    },
    {
      "epoch": 4.139433551198257,
      "grad_norm": 0.20459000766277313,
      "learning_rate": 0.0005503267973856208,
      "loss": 0.2139,
      "step": 1900
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 11.756522178649902,
      "learning_rate": 0.0005498039215686274,
      "loss": 0.2378,
      "step": 1920
    },
    {
      "epoch": 4.226579520697168,
      "grad_norm": 7.870934963226318,
      "learning_rate": 0.0005492810457516339,
      "loss": 0.2971,
      "step": 1940
    },
    {
      "epoch": 4.270152505446623,
      "grad_norm": 0.23740310966968536,
      "learning_rate": 0.0005487581699346405,
      "loss": 0.2723,
      "step": 1960
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 4.229461193084717,
      "learning_rate": 0.000548235294117647,
      "loss": 0.1933,
      "step": 1980
    },
    {
      "epoch": 4.357298474945534,
      "grad_norm": 0.2715100347995758,
      "learning_rate": 0.0005477124183006536,
      "loss": 0.2953,
      "step": 2000
    },
    {
      "epoch": 4.400871459694989,
      "grad_norm": 6.448829650878906,
      "learning_rate": 0.0005471895424836601,
      "loss": 0.347,
      "step": 2020
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 16.870479583740234,
      "learning_rate": 0.0005466666666666667,
      "loss": 0.2256,
      "step": 2040
    },
    {
      "epoch": 4.4880174291939,
      "grad_norm": 0.048641473054885864,
      "learning_rate": 0.0005461437908496731,
      "loss": 0.1992,
      "step": 2060
    },
    {
      "epoch": 4.531590413943356,
      "grad_norm": 2.6657493114471436,
      "learning_rate": 0.0005456209150326798,
      "loss": 0.229,
      "step": 2080
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 6.815957546234131,
      "learning_rate": 0.0005450980392156862,
      "loss": 0.2251,
      "step": 2100
    },
    {
      "epoch": 4.618736383442266,
      "grad_norm": 5.651426792144775,
      "learning_rate": 0.0005445751633986927,
      "loss": 0.324,
      "step": 2120
    },
    {
      "epoch": 4.662309368191721,
      "grad_norm": 2.0794737339019775,
      "learning_rate": 0.0005440522875816993,
      "loss": 0.2241,
      "step": 2140
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 6.563268184661865,
      "learning_rate": 0.0005435294117647058,
      "loss": 0.3061,
      "step": 2160
    },
    {
      "epoch": 4.749455337690632,
      "grad_norm": 2.5117619037628174,
      "learning_rate": 0.0005430065359477124,
      "loss": 0.1949,
      "step": 2180
    },
    {
      "epoch": 4.793028322440087,
      "grad_norm": 6.277483940124512,
      "learning_rate": 0.0005424836601307189,
      "loss": 0.2485,
      "step": 2200
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 0.5454664826393127,
      "learning_rate": 0.0005419607843137255,
      "loss": 0.3692,
      "step": 2220
    },
    {
      "epoch": 4.880174291938998,
      "grad_norm": 3.0212085247039795,
      "learning_rate": 0.0005414379084967319,
      "loss": 0.3037,
      "step": 2240
    },
    {
      "epoch": 4.923747276688453,
      "grad_norm": 3.710456609725952,
      "learning_rate": 0.0005409150326797386,
      "loss": 0.3241,
      "step": 2260
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 0.19414280354976654,
      "learning_rate": 0.000540392156862745,
      "loss": 0.161,
      "step": 2280
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9135996991389148,
      "eval_f1": 0.927689594356261,
      "eval_loss": 0.41207054257392883,
      "eval_runtime": 12.0086,
      "eval_samples_per_second": 33.976,
      "eval_steps_per_second": 4.247,
      "step": 2295
    },
    {
      "epoch": 5.010893246187364,
      "grad_norm": 6.661077976226807,
      "learning_rate": 0.0005398692810457516,
      "loss": 0.2247,
      "step": 2300
    },
    {
      "epoch": 5.05446623093682,
      "grad_norm": 6.89249324798584,
      "learning_rate": 0.0005393464052287581,
      "loss": 0.2429,
      "step": 2320
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 0.5363501310348511,
      "learning_rate": 0.0005388235294117647,
      "loss": 0.1656,
      "step": 2340
    },
    {
      "epoch": 5.14161220043573,
      "grad_norm": 5.748373031616211,
      "learning_rate": 0.0005383006535947712,
      "loss": 0.2486,
      "step": 2360
    },
    {
      "epoch": 5.185185185185185,
      "grad_norm": 17.241010665893555,
      "learning_rate": 0.0005377777777777778,
      "loss": 0.2434,
      "step": 2380
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 0.09714964032173157,
      "learning_rate": 0.0005372549019607843,
      "loss": 0.2397,
      "step": 2400
    },
    {
      "epoch": 5.272331154684096,
      "grad_norm": 0.36459097266197205,
      "learning_rate": 0.0005367320261437909,
      "loss": 0.2339,
      "step": 2420
    },
    {
      "epoch": 5.315904139433552,
      "grad_norm": 7.344535827636719,
      "learning_rate": 0.0005362091503267973,
      "loss": 0.159,
      "step": 2440
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 9.563765525817871,
      "learning_rate": 0.000535686274509804,
      "loss": 0.2198,
      "step": 2460
    },
    {
      "epoch": 5.403050108932462,
      "grad_norm": 0.35568368434906006,
      "learning_rate": 0.0005351633986928104,
      "loss": 0.2126,
      "step": 2480
    },
    {
      "epoch": 5.446623093681917,
      "grad_norm": 5.145400047302246,
      "learning_rate": 0.0005346405228758169,
      "loss": 0.2138,
      "step": 2500
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 2.2466888427734375,
      "learning_rate": 0.0005341176470588235,
      "loss": 0.2628,
      "step": 2520
    },
    {
      "epoch": 5.533769063180828,
      "grad_norm": 0.03964567929506302,
      "learning_rate": 0.00053359477124183,
      "loss": 0.1201,
      "step": 2540
    },
    {
      "epoch": 5.5773420479302835,
      "grad_norm": 5.063624858856201,
      "learning_rate": 0.0005330718954248366,
      "loss": 0.3034,
      "step": 2560
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 1.7900290489196777,
      "learning_rate": 0.000532549019607843,
      "loss": 0.2907,
      "step": 2580
    },
    {
      "epoch": 5.664488017429194,
      "grad_norm": 4.218796253204346,
      "learning_rate": 0.0005320261437908497,
      "loss": 0.1763,
      "step": 2600
    },
    {
      "epoch": 5.708061002178649,
      "grad_norm": 3.3048226833343506,
      "learning_rate": 0.0005315032679738561,
      "loss": 0.2912,
      "step": 2620
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 3.135545492172241,
      "learning_rate": 0.0005309803921568627,
      "loss": 0.2803,
      "step": 2640
    },
    {
      "epoch": 5.79520697167756,
      "grad_norm": 1.862522006034851,
      "learning_rate": 0.0005304575163398692,
      "loss": 0.2204,
      "step": 2660
    },
    {
      "epoch": 5.8387799564270155,
      "grad_norm": 1.0440988540649414,
      "learning_rate": 0.0005299346405228758,
      "loss": 0.1917,
      "step": 2680
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.6340382099151611,
      "learning_rate": 0.0005294117647058823,
      "loss": 0.3673,
      "step": 2700
    },
    {
      "epoch": 5.925925925925926,
      "grad_norm": 5.9686737060546875,
      "learning_rate": 0.0005288888888888889,
      "loss": 0.3308,
      "step": 2720
    },
    {
      "epoch": 5.969498910675381,
      "grad_norm": 0.0928221344947815,
      "learning_rate": 0.0005283660130718954,
      "loss": 0.1569,
      "step": 2740
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9015323955669224,
      "eval_f1": 0.9182608695652175,
      "eval_loss": 0.44677090644836426,
      "eval_runtime": 12.3338,
      "eval_samples_per_second": 33.08,
      "eval_steps_per_second": 4.135,
      "step": 2754
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 5.990793704986572,
      "learning_rate": 0.000527843137254902,
      "loss": 0.3676,
      "step": 2760
    },
    {
      "epoch": 6.056644880174292,
      "grad_norm": 3.0400381088256836,
      "learning_rate": 0.0005273202614379084,
      "loss": 0.2272,
      "step": 2780
    },
    {
      "epoch": 6.1002178649237475,
      "grad_norm": 5.24409818649292,
      "learning_rate": 0.000526797385620915,
      "loss": 0.2132,
      "step": 2800
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 0.7538501024246216,
      "learning_rate": 0.0005262745098039215,
      "loss": 0.1539,
      "step": 2820
    },
    {
      "epoch": 6.187363834422658,
      "grad_norm": 1.10017728805542,
      "learning_rate": 0.000525751633986928,
      "loss": 0.2236,
      "step": 2840
    },
    {
      "epoch": 6.230936819172113,
      "grad_norm": 13.682820320129395,
      "learning_rate": 0.0005252287581699346,
      "loss": 0.3894,
      "step": 2860
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 10.678509712219238,
      "learning_rate": 0.0005247058823529411,
      "loss": 0.1718,
      "step": 2880
    },
    {
      "epoch": 6.318082788671024,
      "grad_norm": 8.025229454040527,
      "learning_rate": 0.0005241830065359477,
      "loss": 0.1346,
      "step": 2900
    },
    {
      "epoch": 6.3616557734204795,
      "grad_norm": 10.961299896240234,
      "learning_rate": 0.0005236601307189542,
      "loss": 0.2447,
      "step": 2920
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 0.7380819916725159,
      "learning_rate": 0.0005231372549019608,
      "loss": 0.2617,
      "step": 2940
    },
    {
      "epoch": 6.44880174291939,
      "grad_norm": 4.213951587677002,
      "learning_rate": 0.0005226143790849672,
      "loss": 0.3082,
      "step": 2960
    },
    {
      "epoch": 6.492374727668845,
      "grad_norm": 7.049993991851807,
      "learning_rate": 0.0005220915032679739,
      "loss": 0.2698,
      "step": 2980
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 7.537693500518799,
      "learning_rate": 0.0005215686274509803,
      "loss": 0.0942,
      "step": 3000
    },
    {
      "epoch": 6.579520697167756,
      "grad_norm": 23.951265335083008,
      "learning_rate": 0.0005210457516339869,
      "loss": 0.2666,
      "step": 3020
    },
    {
      "epoch": 6.6230936819172115,
      "grad_norm": 15.051050186157227,
      "learning_rate": 0.0005205228758169934,
      "loss": 0.1504,
      "step": 3040
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 3.551003932952881,
      "learning_rate": 0.00052,
      "loss": 0.3526,
      "step": 3060
    },
    {
      "epoch": 6.710239651416122,
      "grad_norm": 3.416536569595337,
      "learning_rate": 0.0005194771241830065,
      "loss": 0.19,
      "step": 3080
    },
    {
      "epoch": 6.753812636165577,
      "grad_norm": 3.818127393722534,
      "learning_rate": 0.000518954248366013,
      "loss": 0.1897,
      "step": 3100
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 3.5704641342163086,
      "learning_rate": 0.0005184313725490196,
      "loss": 0.2446,
      "step": 3120
    },
    {
      "epoch": 6.840958605664488,
      "grad_norm": 0.382352352142334,
      "learning_rate": 0.0005179084967320261,
      "loss": 0.2518,
      "step": 3140
    },
    {
      "epoch": 6.8845315904139435,
      "grad_norm": 4.841144561767578,
      "learning_rate": 0.0005173856209150326,
      "loss": 0.2657,
      "step": 3160
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 0.1099632978439331,
      "learning_rate": 0.0005168627450980392,
      "loss": 0.1075,
      "step": 3180
    },
    {
      "epoch": 6.9716775599128535,
      "grad_norm": 14.037602424621582,
      "learning_rate": 0.0005163398692810457,
      "loss": 0.1722,
      "step": 3200
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9013897443794272,
      "eval_f1": 0.917975567190227,
      "eval_loss": 0.5435502529144287,
      "eval_runtime": 11.9975,
      "eval_samples_per_second": 34.007,
      "eval_steps_per_second": 4.251,
      "step": 3213
    },
    {
      "epoch": 7.015250544662309,
      "grad_norm": 0.047099675983190536,
      "learning_rate": 0.0005158169934640522,
      "loss": 0.1888,
      "step": 3220
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 6.290064334869385,
      "learning_rate": 0.0005152941176470588,
      "loss": 0.1767,
      "step": 3240
    },
    {
      "epoch": 7.10239651416122,
      "grad_norm": 0.6579235792160034,
      "learning_rate": 0.0005147712418300653,
      "loss": 0.3517,
      "step": 3260
    },
    {
      "epoch": 7.1459694989106755,
      "grad_norm": 4.67439603805542,
      "learning_rate": 0.0005142483660130719,
      "loss": 0.3335,
      "step": 3280
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 6.9527435302734375,
      "learning_rate": 0.0005137254901960783,
      "loss": 0.1994,
      "step": 3300
    },
    {
      "epoch": 7.233115468409586,
      "grad_norm": 1.5091848373413086,
      "learning_rate": 0.000513202614379085,
      "loss": 0.0846,
      "step": 3320
    },
    {
      "epoch": 7.276688453159041,
      "grad_norm": 0.06303345412015915,
      "learning_rate": 0.0005126797385620914,
      "loss": 0.1723,
      "step": 3340
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 8.478666305541992,
      "learning_rate": 0.000512156862745098,
      "loss": 0.1986,
      "step": 3360
    },
    {
      "epoch": 7.363834422657952,
      "grad_norm": 4.301301002502441,
      "learning_rate": 0.0005116339869281045,
      "loss": 0.3134,
      "step": 3380
    },
    {
      "epoch": 7.407407407407407,
      "grad_norm": 12.907830238342285,
      "learning_rate": 0.0005111111111111111,
      "loss": 0.1333,
      "step": 3400
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 0.19467131793498993,
      "learning_rate": 0.0005105882352941176,
      "loss": 0.1415,
      "step": 3420
    },
    {
      "epoch": 7.494553376906318,
      "grad_norm": 10.163829803466797,
      "learning_rate": 0.0005100653594771242,
      "loss": 0.1849,
      "step": 3440
    },
    {
      "epoch": 7.538126361655774,
      "grad_norm": 0.943200409412384,
      "learning_rate": 0.0005095424836601307,
      "loss": 0.188,
      "step": 3460
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 0.07650001347064972,
      "learning_rate": 0.0005090196078431372,
      "loss": 0.2253,
      "step": 3480
    },
    {
      "epoch": 7.625272331154684,
      "grad_norm": 8.93347454071045,
      "learning_rate": 0.0005084967320261437,
      "loss": 0.2848,
      "step": 3500
    },
    {
      "epoch": 7.668845315904139,
      "grad_norm": 0.6590211987495422,
      "learning_rate": 0.0005079738562091503,
      "loss": 0.2769,
      "step": 3520
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 0.16285686194896698,
      "learning_rate": 0.0005074509803921568,
      "loss": 0.1554,
      "step": 3540
    },
    {
      "epoch": 7.75599128540305,
      "grad_norm": 6.205111026763916,
      "learning_rate": 0.0005069281045751633,
      "loss": 0.1812,
      "step": 3560
    },
    {
      "epoch": 7.799564270152505,
      "grad_norm": 6.667943000793457,
      "learning_rate": 0.0005064052287581699,
      "loss": 0.2115,
      "step": 3580
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 0.38577091693878174,
      "learning_rate": 0.0005058823529411764,
      "loss": 0.4548,
      "step": 3600
    },
    {
      "epoch": 7.886710239651416,
      "grad_norm": 2.189573287963867,
      "learning_rate": 0.000505359477124183,
      "loss": 0.1253,
      "step": 3620
    },
    {
      "epoch": 7.930283224400871,
      "grad_norm": 0.0932752937078476,
      "learning_rate": 0.0005048366013071895,
      "loss": 0.2609,
      "step": 3640
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 8.31521987915039,
      "learning_rate": 0.0005043137254901961,
      "loss": 0.2378,
      "step": 3660
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9055859254696643,
      "eval_f1": 0.9214659685863874,
      "eval_loss": 0.39256539940834045,
      "eval_runtime": 12.057,
      "eval_samples_per_second": 33.839,
      "eval_steps_per_second": 4.23,
      "step": 3672
    },
    {
      "epoch": 8.017429193899781,
      "grad_norm": 0.13446994125843048,
      "learning_rate": 0.0005037908496732025,
      "loss": 0.1719,
      "step": 3680
    },
    {
      "epoch": 8.061002178649238,
      "grad_norm": 0.11095286160707474,
      "learning_rate": 0.0005032679738562092,
      "loss": 0.1387,
      "step": 3700
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 1.0003817081451416,
      "learning_rate": 0.0005027450980392156,
      "loss": 0.1698,
      "step": 3720
    },
    {
      "epoch": 8.148148148148149,
      "grad_norm": 4.021989345550537,
      "learning_rate": 0.0005022222222222222,
      "loss": 0.1176,
      "step": 3740
    },
    {
      "epoch": 8.191721132897603,
      "grad_norm": 10.694220542907715,
      "learning_rate": 0.0005016993464052287,
      "loss": 0.1933,
      "step": 3760
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 0.28851574659347534,
      "learning_rate": 0.0005011764705882353,
      "loss": 0.2122,
      "step": 3780
    },
    {
      "epoch": 8.278867102396514,
      "grad_norm": 7.885209560394287,
      "learning_rate": 0.0005006535947712418,
      "loss": 0.16,
      "step": 3800
    },
    {
      "epoch": 8.322440087145969,
      "grad_norm": 43.4297981262207,
      "learning_rate": 0.0005001307189542483,
      "loss": 0.304,
      "step": 3820
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 4.331015586853027,
      "learning_rate": 0.0004996078431372549,
      "loss": 0.1596,
      "step": 3840
    },
    {
      "epoch": 8.40958605664488,
      "grad_norm": 4.744446754455566,
      "learning_rate": 0.0004990849673202614,
      "loss": 0.2259,
      "step": 3860
    },
    {
      "epoch": 8.453159041394336,
      "grad_norm": 1.7868292331695557,
      "learning_rate": 0.0004985620915032679,
      "loss": 0.1718,
      "step": 3880
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 3.227083921432495,
      "learning_rate": 0.0004980392156862745,
      "loss": 0.1413,
      "step": 3900
    },
    {
      "epoch": 8.540305010893245,
      "grad_norm": 8.68746280670166,
      "learning_rate": 0.000497516339869281,
      "loss": 0.1215,
      "step": 3920
    },
    {
      "epoch": 8.583877995642702,
      "grad_norm": 81.55307006835938,
      "learning_rate": 0.0004969934640522875,
      "loss": 0.3199,
      "step": 3940
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 9.271875381469727,
      "learning_rate": 0.0004964705882352941,
      "loss": 0.1932,
      "step": 3960
    },
    {
      "epoch": 8.671023965141613,
      "grad_norm": 6.0061259269714355,
      "learning_rate": 0.0004959477124183006,
      "loss": 0.1672,
      "step": 3980
    },
    {
      "epoch": 8.714596949891067,
      "grad_norm": 0.23764435946941376,
      "learning_rate": 0.0004954248366013072,
      "loss": 0.2613,
      "step": 4000
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 5.538139820098877,
      "learning_rate": 0.0004949019607843136,
      "loss": 0.1553,
      "step": 4020
    },
    {
      "epoch": 8.801742919389978,
      "grad_norm": 4.172910690307617,
      "learning_rate": 0.0004943790849673203,
      "loss": 0.1313,
      "step": 4040
    },
    {
      "epoch": 8.845315904139433,
      "grad_norm": 0.05873139575123787,
      "learning_rate": 0.0004938562091503267,
      "loss": 0.1789,
      "step": 4060
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 3.8023998737335205,
      "learning_rate": 0.0004933333333333333,
      "loss": 0.1658,
      "step": 4080
    },
    {
      "epoch": 8.932461873638344,
      "grad_norm": 8.380210876464844,
      "learning_rate": 0.0004928104575163398,
      "loss": 0.1332,
      "step": 4100
    },
    {
      "epoch": 8.9760348583878,
      "grad_norm": 0.4968448579311371,
      "learning_rate": 0.0004922875816993464,
      "loss": 0.1326,
      "step": 4120
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9104859335038363,
      "eval_f1": 0.9239130434782609,
      "eval_loss": 0.47218161821365356,
      "eval_runtime": 12.7566,
      "eval_samples_per_second": 31.983,
      "eval_steps_per_second": 3.998,
      "step": 4131
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 0.4461901783943176,
      "learning_rate": 0.0004917647058823529,
      "loss": 0.2669,
      "step": 4140
    },
    {
      "epoch": 9.06318082788671,
      "grad_norm": 5.570210933685303,
      "learning_rate": 0.0004912418300653594,
      "loss": 0.12,
      "step": 4160
    },
    {
      "epoch": 9.106753812636166,
      "grad_norm": 0.7416980266571045,
      "learning_rate": 0.000490718954248366,
      "loss": 0.0606,
      "step": 4180
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 7.769497394561768,
      "learning_rate": 0.0004901960784313725,
      "loss": 0.1614,
      "step": 4200
    },
    {
      "epoch": 9.193899782135077,
      "grad_norm": 6.775843620300293,
      "learning_rate": 0.000489673202614379,
      "loss": 0.1475,
      "step": 4220
    },
    {
      "epoch": 9.237472766884531,
      "grad_norm": 0.02209126017987728,
      "learning_rate": 0.0004891503267973856,
      "loss": 0.0836,
      "step": 4240
    },
    {
      "epoch": 9.281045751633988,
      "grad_norm": 0.38885176181793213,
      "learning_rate": 0.0004886274509803921,
      "loss": 0.3023,
      "step": 4260
    },
    {
      "epoch": 9.324618736383442,
      "grad_norm": 11.866134643554688,
      "learning_rate": 0.0004881045751633986,
      "loss": 0.1644,
      "step": 4280
    },
    {
      "epoch": 9.368191721132897,
      "grad_norm": 11.204216003417969,
      "learning_rate": 0.00048758169934640523,
      "loss": 0.178,
      "step": 4300
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 0.11202286928892136,
      "learning_rate": 0.0004870588235294117,
      "loss": 0.1371,
      "step": 4320
    },
    {
      "epoch": 9.455337690631808,
      "grad_norm": 13.744277954101562,
      "learning_rate": 0.0004865359477124182,
      "loss": 0.253,
      "step": 4340
    },
    {
      "epoch": 9.498910675381264,
      "grad_norm": 0.08537064492702484,
      "learning_rate": 0.0004860130718954248,
      "loss": 0.1735,
      "step": 4360
    },
    {
      "epoch": 9.542483660130719,
      "grad_norm": 0.28270164132118225,
      "learning_rate": 0.0004854901960784313,
      "loss": 0.2628,
      "step": 4380
    },
    {
      "epoch": 9.586056644880173,
      "grad_norm": 0.8511550426483154,
      "learning_rate": 0.00048496732026143786,
      "loss": 0.1877,
      "step": 4400
    },
    {
      "epoch": 9.62962962962963,
      "grad_norm": 2.1711173057556152,
      "learning_rate": 0.0004844444444444444,
      "loss": 0.2368,
      "step": 4420
    },
    {
      "epoch": 9.673202614379084,
      "grad_norm": 1.2649999856948853,
      "learning_rate": 0.00048392156862745096,
      "loss": 0.1696,
      "step": 4440
    },
    {
      "epoch": 9.71677559912854,
      "grad_norm": 2.6188254356384277,
      "learning_rate": 0.00048339869281045745,
      "loss": 0.2666,
      "step": 4460
    },
    {
      "epoch": 9.760348583877995,
      "grad_norm": 0.6246312260627747,
      "learning_rate": 0.000482875816993464,
      "loss": 0.2875,
      "step": 4480
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 0.43505293130874634,
      "learning_rate": 0.00048235294117647055,
      "loss": 0.1722,
      "step": 4500
    },
    {
      "epoch": 9.847494553376906,
      "grad_norm": 0.05832755193114281,
      "learning_rate": 0.0004818300653594771,
      "loss": 0.1427,
      "step": 4520
    },
    {
      "epoch": 9.89106753812636,
      "grad_norm": 10.381994247436523,
      "learning_rate": 0.0004813071895424836,
      "loss": 0.1275,
      "step": 4540
    },
    {
      "epoch": 9.934640522875817,
      "grad_norm": 0.34629026055336,
      "learning_rate": 0.0004807843137254902,
      "loss": 0.1643,
      "step": 4560
    },
    {
      "epoch": 9.978213507625272,
      "grad_norm": 2.8304286003112793,
      "learning_rate": 0.0004802614379084967,
      "loss": 0.2359,
      "step": 4580
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9006612858287186,
      "eval_f1": 0.91651865008881,
      "eval_loss": 0.48771122097969055,
      "eval_runtime": 12.4506,
      "eval_samples_per_second": 32.769,
      "eval_steps_per_second": 4.096,
      "step": 4590
    },
    {
      "epoch": 10.021786492374728,
      "grad_norm": 0.12231180816888809,
      "learning_rate": 0.00047973856209150323,
      "loss": 0.1186,
      "step": 4600
    },
    {
      "epoch": 10.065359477124183,
      "grad_norm": 0.12299074232578278,
      "learning_rate": 0.0004792156862745098,
      "loss": 0.1153,
      "step": 4620
    },
    {
      "epoch": 10.10893246187364,
      "grad_norm": 0.06811118125915527,
      "learning_rate": 0.00047869281045751633,
      "loss": 0.226,
      "step": 4640
    },
    {
      "epoch": 10.152505446623094,
      "grad_norm": 5.073714256286621,
      "learning_rate": 0.0004781699346405228,
      "loss": 0.0454,
      "step": 4660
    },
    {
      "epoch": 10.196078431372548,
      "grad_norm": 0.006242758594453335,
      "learning_rate": 0.0004776470588235293,
      "loss": 0.0845,
      "step": 4680
    },
    {
      "epoch": 10.239651416122005,
      "grad_norm": 0.3880242109298706,
      "learning_rate": 0.0004771241830065359,
      "loss": 0.1869,
      "step": 4700
    },
    {
      "epoch": 10.28322440087146,
      "grad_norm": 26.866455078125,
      "learning_rate": 0.0004766013071895424,
      "loss": 0.1842,
      "step": 4720
    },
    {
      "epoch": 10.326797385620916,
      "grad_norm": 12.361231803894043,
      "learning_rate": 0.00047607843137254896,
      "loss": 0.1178,
      "step": 4740
    },
    {
      "epoch": 10.37037037037037,
      "grad_norm": 11.128989219665527,
      "learning_rate": 0.0004755555555555555,
      "loss": 0.1995,
      "step": 4760
    },
    {
      "epoch": 10.413943355119827,
      "grad_norm": 4.626397132873535,
      "learning_rate": 0.00047503267973856206,
      "loss": 0.1713,
      "step": 4780
    },
    {
      "epoch": 10.457516339869281,
      "grad_norm": 0.8179218769073486,
      "learning_rate": 0.00047450980392156855,
      "loss": 0.0905,
      "step": 4800
    },
    {
      "epoch": 10.501089324618736,
      "grad_norm": 0.3040502667427063,
      "learning_rate": 0.00047398692810457515,
      "loss": 0.1371,
      "step": 4820
    },
    {
      "epoch": 10.544662309368192,
      "grad_norm": 12.010820388793945,
      "learning_rate": 0.00047346405228758165,
      "loss": 0.2101,
      "step": 4840
    },
    {
      "epoch": 10.588235294117647,
      "grad_norm": 6.757755756378174,
      "learning_rate": 0.0004729411764705882,
      "loss": 0.1148,
      "step": 4860
    },
    {
      "epoch": 10.631808278867103,
      "grad_norm": 0.1978214532136917,
      "learning_rate": 0.00047241830065359474,
      "loss": 0.1354,
      "step": 4880
    },
    {
      "epoch": 10.675381263616558,
      "grad_norm": 7.381426811218262,
      "learning_rate": 0.0004718954248366013,
      "loss": 0.1572,
      "step": 4900
    },
    {
      "epoch": 10.718954248366012,
      "grad_norm": 0.11688445508480072,
      "learning_rate": 0.0004713725490196078,
      "loss": 0.2269,
      "step": 4920
    },
    {
      "epoch": 10.762527233115469,
      "grad_norm": 4.316389560699463,
      "learning_rate": 0.00047084967320261433,
      "loss": 0.1089,
      "step": 4940
    },
    {
      "epoch": 10.806100217864923,
      "grad_norm": 14.721762657165527,
      "learning_rate": 0.0004703267973856209,
      "loss": 0.1312,
      "step": 4960
    },
    {
      "epoch": 10.84967320261438,
      "grad_norm": 0.04961659386754036,
      "learning_rate": 0.00046980392156862743,
      "loss": 0.1533,
      "step": 4980
    },
    {
      "epoch": 10.893246187363834,
      "grad_norm": 0.11958657205104828,
      "learning_rate": 0.0004692810457516339,
      "loss": 0.1798,
      "step": 5000
    },
    {
      "epoch": 10.93681917211329,
      "grad_norm": 0.15953505039215088,
      "learning_rate": 0.0004687581699346405,
      "loss": 0.2054,
      "step": 5020
    },
    {
      "epoch": 10.980392156862745,
      "grad_norm": 0.8575449585914612,
      "learning_rate": 0.000468235294117647,
      "loss": 0.1706,
      "step": 5040
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.897855170949246,
      "eval_f1": 0.9133574007220215,
      "eval_loss": 0.47355738282203674,
      "eval_runtime": 12.8692,
      "eval_samples_per_second": 31.704,
      "eval_steps_per_second": 3.963,
      "step": 5049
    },
    {
      "epoch": 11.0239651416122,
      "grad_norm": 0.016225388273596764,
      "learning_rate": 0.0004677124183006535,
      "loss": 0.1428,
      "step": 5060
    },
    {
      "epoch": 11.067538126361656,
      "grad_norm": 1.0684289932250977,
      "learning_rate": 0.0004671895424836601,
      "loss": 0.1868,
      "step": 5080
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 0.358536958694458,
      "learning_rate": 0.0004666666666666666,
      "loss": 0.1497,
      "step": 5100
    },
    {
      "epoch": 11.154684095860567,
      "grad_norm": 0.12850284576416016,
      "learning_rate": 0.00046614379084967316,
      "loss": 0.0758,
      "step": 5120
    },
    {
      "epoch": 11.198257080610022,
      "grad_norm": 0.0940089300274849,
      "learning_rate": 0.00046562091503267965,
      "loss": 0.0842,
      "step": 5140
    },
    {
      "epoch": 11.241830065359476,
      "grad_norm": 7.028655052185059,
      "learning_rate": 0.00046509803921568625,
      "loss": 0.108,
      "step": 5160
    },
    {
      "epoch": 11.285403050108933,
      "grad_norm": 3.162475824356079,
      "learning_rate": 0.00046457516339869275,
      "loss": 0.1518,
      "step": 5180
    },
    {
      "epoch": 11.328976034858387,
      "grad_norm": 0.5093872547149658,
      "learning_rate": 0.0004640522875816993,
      "loss": 0.2132,
      "step": 5200
    },
    {
      "epoch": 11.372549019607844,
      "grad_norm": 13.23704719543457,
      "learning_rate": 0.00046352941176470584,
      "loss": 0.1972,
      "step": 5220
    },
    {
      "epoch": 11.416122004357298,
      "grad_norm": 13.218170166015625,
      "learning_rate": 0.0004630065359477124,
      "loss": 0.1358,
      "step": 5240
    },
    {
      "epoch": 11.459694989106755,
      "grad_norm": 0.07779049128293991,
      "learning_rate": 0.0004624836601307189,
      "loss": 0.0787,
      "step": 5260
    },
    {
      "epoch": 11.50326797385621,
      "grad_norm": 5.807723045349121,
      "learning_rate": 0.0004619607843137255,
      "loss": 0.1144,
      "step": 5280
    },
    {
      "epoch": 11.546840958605664,
      "grad_norm": 0.028822997584939003,
      "learning_rate": 0.000461437908496732,
      "loss": 0.1552,
      "step": 5300
    },
    {
      "epoch": 11.59041394335512,
      "grad_norm": 0.015308722853660583,
      "learning_rate": 0.00046091503267973853,
      "loss": 0.1123,
      "step": 5320
    },
    {
      "epoch": 11.633986928104575,
      "grad_norm": 0.056573182344436646,
      "learning_rate": 0.0004603921568627451,
      "loss": 0.129,
      "step": 5340
    },
    {
      "epoch": 11.677559912854031,
      "grad_norm": 10.476828575134277,
      "learning_rate": 0.0004598692810457516,
      "loss": 0.2395,
      "step": 5360
    },
    {
      "epoch": 11.721132897603486,
      "grad_norm": 0.02459532953798771,
      "learning_rate": 0.0004593464052287581,
      "loss": 0.1316,
      "step": 5380
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 6.130714416503906,
      "learning_rate": 0.0004588235294117646,
      "loss": 0.1209,
      "step": 5400
    },
    {
      "epoch": 11.808278867102397,
      "grad_norm": 102.55172729492188,
      "learning_rate": 0.0004583006535947712,
      "loss": 0.2518,
      "step": 5420
    },
    {
      "epoch": 11.851851851851851,
      "grad_norm": 5.103644371032715,
      "learning_rate": 0.0004577777777777777,
      "loss": 0.1122,
      "step": 5440
    },
    {
      "epoch": 11.895424836601308,
      "grad_norm": 26.811687469482422,
      "learning_rate": 0.00045725490196078426,
      "loss": 0.2254,
      "step": 5460
    },
    {
      "epoch": 11.938997821350762,
      "grad_norm": 0.07708007097244263,
      "learning_rate": 0.0004567320261437908,
      "loss": 0.1863,
      "step": 5480
    },
    {
      "epoch": 11.982570806100219,
      "grad_norm": 0.15289466083049774,
      "learning_rate": 0.00045620915032679735,
      "loss": 0.2184,
      "step": 5500
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9021112054930275,
      "eval_f1": 0.9169675090252707,
      "eval_loss": 0.5041700005531311,
      "eval_runtime": 12.4551,
      "eval_samples_per_second": 32.758,
      "eval_steps_per_second": 4.095,
      "step": 5508
    },
    {
      "epoch": 12.026143790849673,
      "grad_norm": 11.152361869812012,
      "learning_rate": 0.00045568627450980385,
      "loss": 0.171,
      "step": 5520
    },
    {
      "epoch": 12.069716775599128,
      "grad_norm": 9.487841606140137,
      "learning_rate": 0.00045516339869281045,
      "loss": 0.1545,
      "step": 5540
    },
    {
      "epoch": 12.113289760348584,
      "grad_norm": 8.627288818359375,
      "learning_rate": 0.00045464052287581694,
      "loss": 0.1386,
      "step": 5560
    },
    {
      "epoch": 12.156862745098039,
      "grad_norm": 0.5694680213928223,
      "learning_rate": 0.0004541176470588235,
      "loss": 0.1302,
      "step": 5580
    },
    {
      "epoch": 12.200435729847495,
      "grad_norm": 0.009171349927783012,
      "learning_rate": 0.00045359477124183004,
      "loss": 0.0953,
      "step": 5600
    },
    {
      "epoch": 12.24400871459695,
      "grad_norm": 15.50103759765625,
      "learning_rate": 0.0004530718954248366,
      "loss": 0.0981,
      "step": 5620
    },
    {
      "epoch": 12.287581699346406,
      "grad_norm": 7.371367931365967,
      "learning_rate": 0.0004525490196078431,
      "loss": 0.2666,
      "step": 5640
    },
    {
      "epoch": 12.33115468409586,
      "grad_norm": 0.14369215071201324,
      "learning_rate": 0.00045202614379084963,
      "loss": 0.096,
      "step": 5660
    },
    {
      "epoch": 12.374727668845315,
      "grad_norm": 11.746489524841309,
      "learning_rate": 0.0004515032679738562,
      "loss": 0.2299,
      "step": 5680
    },
    {
      "epoch": 12.418300653594772,
      "grad_norm": 0.8861033320426941,
      "learning_rate": 0.0004509803921568627,
      "loss": 0.1455,
      "step": 5700
    },
    {
      "epoch": 12.461873638344226,
      "grad_norm": 0.053002096712589264,
      "learning_rate": 0.0004504575163398692,
      "loss": 0.0505,
      "step": 5720
    },
    {
      "epoch": 12.505446623093682,
      "grad_norm": 3.8874289989471436,
      "learning_rate": 0.0004499346405228758,
      "loss": 0.0899,
      "step": 5740
    },
    {
      "epoch": 12.549019607843137,
      "grad_norm": 12.51738166809082,
      "learning_rate": 0.0004494117647058823,
      "loss": 0.193,
      "step": 5760
    },
    {
      "epoch": 12.592592592592592,
      "grad_norm": 13.058488845825195,
      "learning_rate": 0.0004488888888888888,
      "loss": 0.1826,
      "step": 5780
    },
    {
      "epoch": 12.636165577342048,
      "grad_norm": 11.371400833129883,
      "learning_rate": 0.0004483660130718954,
      "loss": 0.2456,
      "step": 5800
    },
    {
      "epoch": 12.679738562091503,
      "grad_norm": 2.4569976329803467,
      "learning_rate": 0.0004478431372549019,
      "loss": 0.1508,
      "step": 5820
    },
    {
      "epoch": 12.723311546840959,
      "grad_norm": 3.3245861530303955,
      "learning_rate": 0.00044732026143790845,
      "loss": 0.1518,
      "step": 5840
    },
    {
      "epoch": 12.766884531590414,
      "grad_norm": 0.11968481540679932,
      "learning_rate": 0.00044679738562091495,
      "loss": 0.0465,
      "step": 5860
    },
    {
      "epoch": 12.81045751633987,
      "grad_norm": 26.768381118774414,
      "learning_rate": 0.00044627450980392155,
      "loss": 0.1649,
      "step": 5880
    },
    {
      "epoch": 12.854030501089325,
      "grad_norm": 0.021398203447461128,
      "learning_rate": 0.00044575163398692804,
      "loss": 0.1162,
      "step": 5900
    },
    {
      "epoch": 12.89760348583878,
      "grad_norm": 8.913738250732422,
      "learning_rate": 0.0004452287581699346,
      "loss": 0.1589,
      "step": 5920
    },
    {
      "epoch": 12.941176470588236,
      "grad_norm": 1.8139814138412476,
      "learning_rate": 0.00044470588235294114,
      "loss": 0.188,
      "step": 5940
    },
    {
      "epoch": 12.98474945533769,
      "grad_norm": 0.7122898697853088,
      "learning_rate": 0.0004441830065359477,
      "loss": 0.0844,
      "step": 5960
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9009557526714389,
      "eval_f1": 0.9171075837742505,
      "eval_loss": 0.6462270021438599,
      "eval_runtime": 12.896,
      "eval_samples_per_second": 31.638,
      "eval_steps_per_second": 3.955,
      "step": 5967
    },
    {
      "epoch": 13.028322440087146,
      "grad_norm": 0.06798892468214035,
      "learning_rate": 0.0004436601307189542,
      "loss": 0.1182,
      "step": 5980
    },
    {
      "epoch": 13.071895424836601,
      "grad_norm": 0.03234942629933357,
      "learning_rate": 0.0004431372549019608,
      "loss": 0.2142,
      "step": 6000
    },
    {
      "epoch": 13.115468409586057,
      "grad_norm": 0.15299434959888458,
      "learning_rate": 0.0004426143790849673,
      "loss": 0.1287,
      "step": 6020
    },
    {
      "epoch": 13.159041394335512,
      "grad_norm": 15.74412727355957,
      "learning_rate": 0.0004420915032679738,
      "loss": 0.1028,
      "step": 6040
    },
    {
      "epoch": 13.202614379084967,
      "grad_norm": 5.6635050773620605,
      "learning_rate": 0.00044156862745098037,
      "loss": 0.2328,
      "step": 6060
    },
    {
      "epoch": 13.246187363834423,
      "grad_norm": 0.05437427759170532,
      "learning_rate": 0.0004410457516339869,
      "loss": 0.0226,
      "step": 6080
    },
    {
      "epoch": 13.289760348583878,
      "grad_norm": 0.08106885105371475,
      "learning_rate": 0.0004405228758169934,
      "loss": 0.0677,
      "step": 6100
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 11.42782211303711,
      "learning_rate": 0.0004399999999999999,
      "loss": 0.1592,
      "step": 6120
    },
    {
      "epoch": 13.376906318082789,
      "grad_norm": 0.1190841943025589,
      "learning_rate": 0.0004394771241830065,
      "loss": 0.0241,
      "step": 6140
    },
    {
      "epoch": 13.420479302832245,
      "grad_norm": 0.017587827518582344,
      "learning_rate": 0.000438954248366013,
      "loss": 0.2469,
      "step": 6160
    },
    {
      "epoch": 13.4640522875817,
      "grad_norm": 7.427029609680176,
      "learning_rate": 0.00043843137254901955,
      "loss": 0.2151,
      "step": 6180
    },
    {
      "epoch": 13.507625272331154,
      "grad_norm": 8.772491455078125,
      "learning_rate": 0.0004379084967320261,
      "loss": 0.3112,
      "step": 6200
    },
    {
      "epoch": 13.55119825708061,
      "grad_norm": 7.797123432159424,
      "learning_rate": 0.00043738562091503265,
      "loss": 0.1773,
      "step": 6220
    },
    {
      "epoch": 13.594771241830065,
      "grad_norm": 0.0200488418340683,
      "learning_rate": 0.00043686274509803914,
      "loss": 0.0783,
      "step": 6240
    },
    {
      "epoch": 13.638344226579521,
      "grad_norm": 0.13844579458236694,
      "learning_rate": 0.00043633986928104574,
      "loss": 0.2043,
      "step": 6260
    },
    {
      "epoch": 13.681917211328976,
      "grad_norm": 0.061499226838350296,
      "learning_rate": 0.00043581699346405224,
      "loss": 0.1073,
      "step": 6280
    },
    {
      "epoch": 13.72549019607843,
      "grad_norm": 0.14148226380348206,
      "learning_rate": 0.0004352941176470588,
      "loss": 0.2028,
      "step": 6300
    },
    {
      "epoch": 13.769063180827887,
      "grad_norm": 0.6918255090713501,
      "learning_rate": 0.00043477124183006533,
      "loss": 0.1148,
      "step": 6320
    },
    {
      "epoch": 13.812636165577342,
      "grad_norm": 0.7174221873283386,
      "learning_rate": 0.0004342483660130719,
      "loss": 0.2159,
      "step": 6340
    },
    {
      "epoch": 13.856209150326798,
      "grad_norm": 0.1985653042793274,
      "learning_rate": 0.0004337254901960784,
      "loss": 0.093,
      "step": 6360
    },
    {
      "epoch": 13.899782135076252,
      "grad_norm": 0.011704586446285248,
      "learning_rate": 0.0004332026143790849,
      "loss": 0.1508,
      "step": 6380
    },
    {
      "epoch": 13.943355119825709,
      "grad_norm": 18.92978286743164,
      "learning_rate": 0.00043267973856209147,
      "loss": 0.1998,
      "step": 6400
    },
    {
      "epoch": 13.986928104575163,
      "grad_norm": 0.17086230218410492,
      "learning_rate": 0.000432156862745098,
      "loss": 0.1258,
      "step": 6420
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.910759627592044,
      "eval_f1": 0.9244604316546762,
      "eval_loss": 0.49109581112861633,
      "eval_runtime": 12.8601,
      "eval_samples_per_second": 31.726,
      "eval_steps_per_second": 3.966,
      "step": 6426
    },
    {
      "epoch": 14.030501089324618,
      "grad_norm": 0.850560188293457,
      "learning_rate": 0.0004316339869281045,
      "loss": 0.0382,
      "step": 6440
    },
    {
      "epoch": 14.074074074074074,
      "grad_norm": 1.8794407844543457,
      "learning_rate": 0.0004311111111111111,
      "loss": 0.1926,
      "step": 6460
    },
    {
      "epoch": 14.117647058823529,
      "grad_norm": 0.03152720257639885,
      "learning_rate": 0.0004305882352941176,
      "loss": 0.0338,
      "step": 6480
    },
    {
      "epoch": 14.161220043572985,
      "grad_norm": 1.8992469310760498,
      "learning_rate": 0.0004300653594771241,
      "loss": 0.1131,
      "step": 6500
    },
    {
      "epoch": 14.20479302832244,
      "grad_norm": 12.100132942199707,
      "learning_rate": 0.0004295424836601307,
      "loss": 0.1219,
      "step": 6520
    },
    {
      "epoch": 14.248366013071895,
      "grad_norm": 0.027089525014162064,
      "learning_rate": 0.0004290196078431372,
      "loss": 0.0342,
      "step": 6540
    },
    {
      "epoch": 14.291938997821351,
      "grad_norm": 0.06221069023013115,
      "learning_rate": 0.00042849673202614375,
      "loss": 0.1336,
      "step": 6560
    },
    {
      "epoch": 14.335511982570806,
      "grad_norm": 3.0398619174957275,
      "learning_rate": 0.00042797385620915024,
      "loss": 0.2418,
      "step": 6580
    },
    {
      "epoch": 14.379084967320262,
      "grad_norm": 8.118483543395996,
      "learning_rate": 0.00042745098039215684,
      "loss": 0.0924,
      "step": 6600
    },
    {
      "epoch": 14.422657952069716,
      "grad_norm": 13.891546249389648,
      "learning_rate": 0.00042692810457516334,
      "loss": 0.101,
      "step": 6620
    },
    {
      "epoch": 14.466230936819173,
      "grad_norm": 0.02255254238843918,
      "learning_rate": 0.0004264052287581699,
      "loss": 0.1715,
      "step": 6640
    },
    {
      "epoch": 14.509803921568627,
      "grad_norm": 33.927791595458984,
      "learning_rate": 0.00042588235294117643,
      "loss": 0.1227,
      "step": 6660
    },
    {
      "epoch": 14.553376906318082,
      "grad_norm": 6.374330520629883,
      "learning_rate": 0.000425359477124183,
      "loss": 0.0913,
      "step": 6680
    },
    {
      "epoch": 14.596949891067538,
      "grad_norm": 0.018598483875393867,
      "learning_rate": 0.0004248366013071895,
      "loss": 0.1139,
      "step": 6700
    },
    {
      "epoch": 14.640522875816993,
      "grad_norm": 0.13584589958190918,
      "learning_rate": 0.0004243137254901961,
      "loss": 0.1651,
      "step": 6720
    },
    {
      "epoch": 14.68409586056645,
      "grad_norm": 5.423623561859131,
      "learning_rate": 0.00042379084967320257,
      "loss": 0.1711,
      "step": 6740
    },
    {
      "epoch": 14.727668845315904,
      "grad_norm": 0.04061659425497055,
      "learning_rate": 0.0004232679738562091,
      "loss": 0.107,
      "step": 6760
    },
    {
      "epoch": 14.77124183006536,
      "grad_norm": 0.2491106241941452,
      "learning_rate": 0.00042274509803921567,
      "loss": 0.1123,
      "step": 6780
    },
    {
      "epoch": 14.814814814814815,
      "grad_norm": 0.5789620280265808,
      "learning_rate": 0.0004222222222222222,
      "loss": 0.1279,
      "step": 6800
    },
    {
      "epoch": 14.85838779956427,
      "grad_norm": 0.03601686283946037,
      "learning_rate": 0.0004216993464052287,
      "loss": 0.0701,
      "step": 6820
    },
    {
      "epoch": 14.901960784313726,
      "grad_norm": 0.003779015503823757,
      "learning_rate": 0.0004211764705882352,
      "loss": 0.0969,
      "step": 6840
    },
    {
      "epoch": 14.94553376906318,
      "grad_norm": 10.49934196472168,
      "learning_rate": 0.0004206535947712418,
      "loss": 0.187,
      "step": 6860
    },
    {
      "epoch": 14.989106753812637,
      "grad_norm": 0.14649797976016998,
      "learning_rate": 0.0004201307189542483,
      "loss": 0.1675,
      "step": 6880
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9130822722648988,
      "eval_f1": 0.9266547406082289,
      "eval_loss": 0.47460728883743286,
      "eval_runtime": 12.8733,
      "eval_samples_per_second": 31.693,
      "eval_steps_per_second": 3.962,
      "step": 6885
    },
    {
      "epoch": 15.032679738562091,
      "grad_norm": 14.212237358093262,
      "learning_rate": 0.00041960784313725485,
      "loss": 0.2285,
      "step": 6900
    },
    {
      "epoch": 15.076252723311546,
      "grad_norm": 9.634539604187012,
      "learning_rate": 0.0004190849673202614,
      "loss": 0.0791,
      "step": 6920
    },
    {
      "epoch": 15.119825708061002,
      "grad_norm": 3.1937944889068604,
      "learning_rate": 0.00041856209150326794,
      "loss": 0.1485,
      "step": 6940
    },
    {
      "epoch": 15.163398692810457,
      "grad_norm": 0.007820882834494114,
      "learning_rate": 0.00041803921568627444,
      "loss": 0.1027,
      "step": 6960
    },
    {
      "epoch": 15.206971677559913,
      "grad_norm": 0.6861315369606018,
      "learning_rate": 0.00041751633986928104,
      "loss": 0.0727,
      "step": 6980
    },
    {
      "epoch": 15.250544662309368,
      "grad_norm": 0.41481906175613403,
      "learning_rate": 0.00041699346405228753,
      "loss": 0.0473,
      "step": 7000
    },
    {
      "epoch": 15.294117647058824,
      "grad_norm": 9.309385299682617,
      "learning_rate": 0.0004164705882352941,
      "loss": 0.3194,
      "step": 7020
    },
    {
      "epoch": 15.337690631808279,
      "grad_norm": 0.4738454222679138,
      "learning_rate": 0.00041594771241830063,
      "loss": 0.1262,
      "step": 7040
    },
    {
      "epoch": 15.381263616557733,
      "grad_norm": 0.04212431237101555,
      "learning_rate": 0.0004154248366013072,
      "loss": 0.1149,
      "step": 7060
    },
    {
      "epoch": 15.42483660130719,
      "grad_norm": 0.029888389632105827,
      "learning_rate": 0.00041490196078431367,
      "loss": 0.02,
      "step": 7080
    },
    {
      "epoch": 15.468409586056644,
      "grad_norm": 22.14297866821289,
      "learning_rate": 0.0004143790849673202,
      "loss": 0.0163,
      "step": 7100
    },
    {
      "epoch": 15.5119825708061,
      "grad_norm": 0.024845842272043228,
      "learning_rate": 0.00041385620915032677,
      "loss": 0.1944,
      "step": 7120
    },
    {
      "epoch": 15.555555555555555,
      "grad_norm": 0.05458363518118858,
      "learning_rate": 0.0004133333333333333,
      "loss": 0.2069,
      "step": 7140
    },
    {
      "epoch": 15.599128540305012,
      "grad_norm": 0.29508042335510254,
      "learning_rate": 0.0004128104575163398,
      "loss": 0.0565,
      "step": 7160
    },
    {
      "epoch": 15.642701525054466,
      "grad_norm": 17.423521041870117,
      "learning_rate": 0.0004122875816993464,
      "loss": 0.1136,
      "step": 7180
    },
    {
      "epoch": 15.686274509803921,
      "grad_norm": 0.11984232068061829,
      "learning_rate": 0.0004117647058823529,
      "loss": 0.2256,
      "step": 7200
    },
    {
      "epoch": 15.729847494553377,
      "grad_norm": 0.2801680862903595,
      "learning_rate": 0.0004112418300653594,
      "loss": 0.0963,
      "step": 7220
    },
    {
      "epoch": 15.773420479302832,
      "grad_norm": 0.3314935266971588,
      "learning_rate": 0.000410718954248366,
      "loss": 0.0927,
      "step": 7240
    },
    {
      "epoch": 15.816993464052288,
      "grad_norm": 0.06538200378417969,
      "learning_rate": 0.0004101960784313725,
      "loss": 0.1301,
      "step": 7260
    },
    {
      "epoch": 15.860566448801743,
      "grad_norm": 0.021592266857624054,
      "learning_rate": 0.00040967320261437904,
      "loss": 0.0801,
      "step": 7280
    },
    {
      "epoch": 15.904139433551197,
      "grad_norm": 11.84164047241211,
      "learning_rate": 0.00040915032679738554,
      "loss": 0.2212,
      "step": 7300
    },
    {
      "epoch": 15.947712418300654,
      "grad_norm": 5.4929327964782715,
      "learning_rate": 0.00040862745098039214,
      "loss": 0.2196,
      "step": 7320
    },
    {
      "epoch": 15.991285403050108,
      "grad_norm": 0.273262619972229,
      "learning_rate": 0.00040810457516339863,
      "loss": 0.1655,
      "step": 7340
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9097821065599014,
      "eval_f1": 0.9249563699825479,
      "eval_loss": 0.6030611991882324,
      "eval_runtime": 13.0208,
      "eval_samples_per_second": 31.335,
      "eval_steps_per_second": 3.917,
      "step": 7344
    },
    {
      "epoch": 16.034858387799563,
      "grad_norm": 0.05215844884514809,
      "learning_rate": 0.0004075816993464052,
      "loss": 0.0112,
      "step": 7360
    },
    {
      "epoch": 16.07843137254902,
      "grad_norm": 0.0010212205816060305,
      "learning_rate": 0.00040705882352941173,
      "loss": 0.0994,
      "step": 7380
    },
    {
      "epoch": 16.122004357298476,
      "grad_norm": 32.0935173034668,
      "learning_rate": 0.0004065359477124183,
      "loss": 0.101,
      "step": 7400
    },
    {
      "epoch": 16.165577342047932,
      "grad_norm": 0.4010341465473175,
      "learning_rate": 0.00040601307189542477,
      "loss": 0.152,
      "step": 7420
    },
    {
      "epoch": 16.209150326797385,
      "grad_norm": 0.024104932323098183,
      "learning_rate": 0.0004054901960784314,
      "loss": 0.0676,
      "step": 7440
    },
    {
      "epoch": 16.25272331154684,
      "grad_norm": 11.201407432556152,
      "learning_rate": 0.00040496732026143787,
      "loss": 0.0404,
      "step": 7460
    },
    {
      "epoch": 16.296296296296298,
      "grad_norm": 0.013307375833392143,
      "learning_rate": 0.0004044444444444444,
      "loss": 0.2439,
      "step": 7480
    },
    {
      "epoch": 16.33986928104575,
      "grad_norm": 0.10369928926229477,
      "learning_rate": 0.00040392156862745096,
      "loss": 0.1158,
      "step": 7500
    },
    {
      "epoch": 16.383442265795207,
      "grad_norm": 0.029015209525823593,
      "learning_rate": 0.0004033986928104575,
      "loss": 0.1316,
      "step": 7520
    },
    {
      "epoch": 16.427015250544663,
      "grad_norm": 0.041623517870903015,
      "learning_rate": 0.000402875816993464,
      "loss": 0.1339,
      "step": 7540
    },
    {
      "epoch": 16.470588235294116,
      "grad_norm": 1.1774410009384155,
      "learning_rate": 0.0004023529411764705,
      "loss": 0.1092,
      "step": 7560
    },
    {
      "epoch": 16.514161220043572,
      "grad_norm": 0.029439987614750862,
      "learning_rate": 0.0004018300653594771,
      "loss": 0.0629,
      "step": 7580
    },
    {
      "epoch": 16.55773420479303,
      "grad_norm": 0.2557946443557739,
      "learning_rate": 0.0004013071895424836,
      "loss": 0.1084,
      "step": 7600
    },
    {
      "epoch": 16.601307189542485,
      "grad_norm": 27.862192153930664,
      "learning_rate": 0.00040078431372549014,
      "loss": 0.1804,
      "step": 7620
    },
    {
      "epoch": 16.644880174291938,
      "grad_norm": 0.11556956171989441,
      "learning_rate": 0.00040026143790849675,
      "loss": 0.0986,
      "step": 7640
    },
    {
      "epoch": 16.688453159041394,
      "grad_norm": 1.608934998512268,
      "learning_rate": 0.00039973856209150324,
      "loss": 0.1123,
      "step": 7660
    },
    {
      "epoch": 16.73202614379085,
      "grad_norm": 4.999493598937988,
      "learning_rate": 0.00039921568627450973,
      "loss": 0.1365,
      "step": 7680
    },
    {
      "epoch": 16.775599128540303,
      "grad_norm": 0.028859782963991165,
      "learning_rate": 0.00039869281045751634,
      "loss": 0.1421,
      "step": 7700
    },
    {
      "epoch": 16.81917211328976,
      "grad_norm": 0.009693803265690804,
      "learning_rate": 0.00039816993464052283,
      "loss": 0.0477,
      "step": 7720
    },
    {
      "epoch": 16.862745098039216,
      "grad_norm": 1.2231615781784058,
      "learning_rate": 0.0003976470588235294,
      "loss": 0.1746,
      "step": 7740
    },
    {
      "epoch": 16.906318082788673,
      "grad_norm": 0.07048287987709045,
      "learning_rate": 0.0003971241830065359,
      "loss": 0.0082,
      "step": 7760
    },
    {
      "epoch": 16.949891067538125,
      "grad_norm": 7.736215591430664,
      "learning_rate": 0.0003966013071895425,
      "loss": 0.1306,
      "step": 7780
    },
    {
      "epoch": 16.99346405228758,
      "grad_norm": 21.112201690673828,
      "learning_rate": 0.00039607843137254897,
      "loss": 0.0414,
      "step": 7800
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8993646238983398,
      "eval_f1": 0.9163763066202091,
      "eval_loss": 0.7572460770606995,
      "eval_runtime": 12.7372,
      "eval_samples_per_second": 32.032,
      "eval_steps_per_second": 4.004,
      "step": 7803
    },
    {
      "epoch": 17.037037037037038,
      "grad_norm": 0.011358481831848621,
      "learning_rate": 0.0003955555555555555,
      "loss": 0.1116,
      "step": 7820
    },
    {
      "epoch": 17.08061002178649,
      "grad_norm": 0.01751616783440113,
      "learning_rate": 0.00039503267973856206,
      "loss": 0.0382,
      "step": 7840
    },
    {
      "epoch": 17.124183006535947,
      "grad_norm": 8.377212524414062,
      "learning_rate": 0.0003945098039215686,
      "loss": 0.0994,
      "step": 7860
    },
    {
      "epoch": 17.167755991285404,
      "grad_norm": 0.013746153563261032,
      "learning_rate": 0.0003939869281045751,
      "loss": 0.0156,
      "step": 7880
    },
    {
      "epoch": 17.21132897603486,
      "grad_norm": 0.0168522447347641,
      "learning_rate": 0.0003934640522875817,
      "loss": 0.2357,
      "step": 7900
    },
    {
      "epoch": 17.254901960784313,
      "grad_norm": 0.0315232127904892,
      "learning_rate": 0.0003929411764705882,
      "loss": 0.0194,
      "step": 7920
    },
    {
      "epoch": 17.29847494553377,
      "grad_norm": 12.75782299041748,
      "learning_rate": 0.0003924183006535947,
      "loss": 0.0194,
      "step": 7940
    },
    {
      "epoch": 17.342047930283226,
      "grad_norm": 0.003310750238597393,
      "learning_rate": 0.0003918954248366013,
      "loss": 0.1134,
      "step": 7960
    },
    {
      "epoch": 17.38562091503268,
      "grad_norm": 4.139048099517822,
      "learning_rate": 0.0003913725490196078,
      "loss": 0.2084,
      "step": 7980
    },
    {
      "epoch": 17.429193899782135,
      "grad_norm": 0.1846608817577362,
      "learning_rate": 0.00039084967320261434,
      "loss": 0.1532,
      "step": 8000
    },
    {
      "epoch": 17.47276688453159,
      "grad_norm": 0.10192538797855377,
      "learning_rate": 0.00039032679738562083,
      "loss": 0.0937,
      "step": 8020
    },
    {
      "epoch": 17.516339869281047,
      "grad_norm": 0.38929271697998047,
      "learning_rate": 0.00038980392156862743,
      "loss": 0.0638,
      "step": 8040
    },
    {
      "epoch": 17.5599128540305,
      "grad_norm": 0.015526463277637959,
      "learning_rate": 0.00038928104575163393,
      "loss": 0.1124,
      "step": 8060
    },
    {
      "epoch": 17.603485838779957,
      "grad_norm": 0.07905159890651703,
      "learning_rate": 0.0003887581699346405,
      "loss": 0.1697,
      "step": 8080
    },
    {
      "epoch": 17.647058823529413,
      "grad_norm": 0.030930394306778908,
      "learning_rate": 0.000388235294117647,
      "loss": 0.0214,
      "step": 8100
    },
    {
      "epoch": 17.690631808278866,
      "grad_norm": 0.006631352007389069,
      "learning_rate": 0.00038771241830065357,
      "loss": 0.0545,
      "step": 8120
    },
    {
      "epoch": 17.734204793028322,
      "grad_norm": 0.003357464913278818,
      "learning_rate": 0.00038718954248366007,
      "loss": 0.0928,
      "step": 8140
    },
    {
      "epoch": 17.77777777777778,
      "grad_norm": 17.661640167236328,
      "learning_rate": 0.00038666666666666667,
      "loss": 0.123,
      "step": 8160
    },
    {
      "epoch": 17.82135076252723,
      "grad_norm": 0.013620072975754738,
      "learning_rate": 0.00038614379084967316,
      "loss": 0.1188,
      "step": 8180
    },
    {
      "epoch": 17.864923747276688,
      "grad_norm": 0.018348433077335358,
      "learning_rate": 0.0003856209150326797,
      "loss": 0.0279,
      "step": 8200
    },
    {
      "epoch": 17.908496732026144,
      "grad_norm": 0.7380634546279907,
      "learning_rate": 0.00038509803921568626,
      "loss": 0.0765,
      "step": 8220
    },
    {
      "epoch": 17.9520697167756,
      "grad_norm": 9.355201721191406,
      "learning_rate": 0.0003845751633986928,
      "loss": 0.0243,
      "step": 8240
    },
    {
      "epoch": 17.995642701525053,
      "grad_norm": 19.894716262817383,
      "learning_rate": 0.0003840522875816993,
      "loss": 0.0984,
      "step": 8260
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9053098831799855,
      "eval_f1": 0.9209138840070299,
      "eval_loss": 0.69303297996521,
      "eval_runtime": 13.3269,
      "eval_samples_per_second": 30.615,
      "eval_steps_per_second": 3.827,
      "step": 8262
    },
    {
      "epoch": 18.03921568627451,
      "grad_norm": 0.0570252388715744,
      "learning_rate": 0.0003835294117647058,
      "loss": 0.0675,
      "step": 8280
    },
    {
      "epoch": 18.082788671023966,
      "grad_norm": 0.017934473231434822,
      "learning_rate": 0.0003830065359477124,
      "loss": 0.0762,
      "step": 8300
    },
    {
      "epoch": 18.12636165577342,
      "grad_norm": 0.005746003240346909,
      "learning_rate": 0.0003824836601307189,
      "loss": 0.0087,
      "step": 8320
    },
    {
      "epoch": 18.169934640522875,
      "grad_norm": 0.6365580558776855,
      "learning_rate": 0.00038196078431372544,
      "loss": 0.1102,
      "step": 8340
    },
    {
      "epoch": 18.21350762527233,
      "grad_norm": 0.030911950394511223,
      "learning_rate": 0.00038143790849673204,
      "loss": 0.1149,
      "step": 8360
    },
    {
      "epoch": 18.257080610021788,
      "grad_norm": 0.026822863146662712,
      "learning_rate": 0.00038091503267973853,
      "loss": 0.0449,
      "step": 8380
    },
    {
      "epoch": 18.30065359477124,
      "grad_norm": 9.56584644317627,
      "learning_rate": 0.00038039215686274503,
      "loss": 0.2023,
      "step": 8400
    },
    {
      "epoch": 18.344226579520697,
      "grad_norm": 0.02698950096964836,
      "learning_rate": 0.00037986928104575163,
      "loss": 0.1502,
      "step": 8420
    },
    {
      "epoch": 18.387799564270153,
      "grad_norm": 0.037410520017147064,
      "learning_rate": 0.0003793464052287581,
      "loss": 0.1651,
      "step": 8440
    },
    {
      "epoch": 18.431372549019606,
      "grad_norm": 9.091618537902832,
      "learning_rate": 0.00037882352941176467,
      "loss": 0.1893,
      "step": 8460
    },
    {
      "epoch": 18.474945533769063,
      "grad_norm": 0.2872699201107025,
      "learning_rate": 0.0003783006535947712,
      "loss": 0.0374,
      "step": 8480
    },
    {
      "epoch": 18.51851851851852,
      "grad_norm": 0.05124787241220474,
      "learning_rate": 0.00037777777777777777,
      "loss": 0.1478,
      "step": 8500
    },
    {
      "epoch": 18.562091503267975,
      "grad_norm": 2.7055463790893555,
      "learning_rate": 0.00037725490196078426,
      "loss": 0.107,
      "step": 8520
    },
    {
      "epoch": 18.60566448801743,
      "grad_norm": 0.9249919056892395,
      "learning_rate": 0.0003767320261437908,
      "loss": 0.0538,
      "step": 8540
    },
    {
      "epoch": 18.649237472766885,
      "grad_norm": 9.807500839233398,
      "learning_rate": 0.00037620915032679736,
      "loss": 0.089,
      "step": 8560
    },
    {
      "epoch": 18.69281045751634,
      "grad_norm": 16.270687103271484,
      "learning_rate": 0.0003756862745098039,
      "loss": 0.1409,
      "step": 8580
    },
    {
      "epoch": 18.736383442265794,
      "grad_norm": 0.01596389152109623,
      "learning_rate": 0.0003751633986928104,
      "loss": 0.1048,
      "step": 8600
    },
    {
      "epoch": 18.77995642701525,
      "grad_norm": 1.5851625204086304,
      "learning_rate": 0.000374640522875817,
      "loss": 0.0969,
      "step": 8620
    },
    {
      "epoch": 18.823529411764707,
      "grad_norm": 0.030426809564232826,
      "learning_rate": 0.0003741176470588235,
      "loss": 0.0601,
      "step": 8640
    },
    {
      "epoch": 18.867102396514163,
      "grad_norm": 18.858341217041016,
      "learning_rate": 0.00037359477124183,
      "loss": 0.1988,
      "step": 8660
    },
    {
      "epoch": 18.910675381263616,
      "grad_norm": 0.014208249747753143,
      "learning_rate": 0.0003730718954248366,
      "loss": 0.0791,
      "step": 8680
    },
    {
      "epoch": 18.954248366013072,
      "grad_norm": 2.12343430519104,
      "learning_rate": 0.0003725490196078431,
      "loss": 0.0972,
      "step": 8700
    },
    {
      "epoch": 18.99782135076253,
      "grad_norm": 0.209745392203331,
      "learning_rate": 0.00037202614379084963,
      "loss": 0.0202,
      "step": 8720
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8954728950403692,
      "eval_f1": 0.9134948096885814,
      "eval_loss": 0.7635369896888733,
      "eval_runtime": 13.3101,
      "eval_samples_per_second": 30.653,
      "eval_steps_per_second": 3.832,
      "step": 8721
    },
    {
      "epoch": 19.04139433551198,
      "grad_norm": 0.02969313971698284,
      "learning_rate": 0.00037150326797385613,
      "loss": 0.038,
      "step": 8740
    },
    {
      "epoch": 19.084967320261438,
      "grad_norm": 9.267565727233887,
      "learning_rate": 0.00037098039215686273,
      "loss": 0.0231,
      "step": 8760
    },
    {
      "epoch": 19.128540305010894,
      "grad_norm": 37.51371765136719,
      "learning_rate": 0.0003704575163398692,
      "loss": 0.1803,
      "step": 8780
    },
    {
      "epoch": 19.17211328976035,
      "grad_norm": 1.244098424911499,
      "learning_rate": 0.00036993464052287577,
      "loss": 0.0228,
      "step": 8800
    },
    {
      "epoch": 19.215686274509803,
      "grad_norm": 0.12275808304548264,
      "learning_rate": 0.0003694117647058823,
      "loss": 0.0213,
      "step": 8820
    },
    {
      "epoch": 19.25925925925926,
      "grad_norm": 0.0014738511526957154,
      "learning_rate": 0.00036888888888888887,
      "loss": 0.055,
      "step": 8840
    },
    {
      "epoch": 19.302832244008716,
      "grad_norm": 0.009721921756863594,
      "learning_rate": 0.00036836601307189536,
      "loss": 0.0335,
      "step": 8860
    },
    {
      "epoch": 19.34640522875817,
      "grad_norm": 0.3748680055141449,
      "learning_rate": 0.00036784313725490196,
      "loss": 0.1474,
      "step": 8880
    },
    {
      "epoch": 19.389978213507625,
      "grad_norm": 0.002603841945528984,
      "learning_rate": 0.00036732026143790846,
      "loss": 0.021,
      "step": 8900
    },
    {
      "epoch": 19.43355119825708,
      "grad_norm": 0.00165966444183141,
      "learning_rate": 0.000366797385620915,
      "loss": 0.1281,
      "step": 8920
    },
    {
      "epoch": 19.477124183006534,
      "grad_norm": 0.013089992105960846,
      "learning_rate": 0.00036627450980392155,
      "loss": 0.0935,
      "step": 8940
    },
    {
      "epoch": 19.52069716775599,
      "grad_norm": 0.00782906822860241,
      "learning_rate": 0.0003657516339869281,
      "loss": 0.0373,
      "step": 8960
    },
    {
      "epoch": 19.564270152505447,
      "grad_norm": 0.08087804913520813,
      "learning_rate": 0.0003652287581699346,
      "loss": 0.1532,
      "step": 8980
    },
    {
      "epoch": 19.607843137254903,
      "grad_norm": 0.003946480806916952,
      "learning_rate": 0.0003647058823529411,
      "loss": 0.1102,
      "step": 9000
    },
    {
      "epoch": 19.651416122004356,
      "grad_norm": 0.020185979083180428,
      "learning_rate": 0.0003641830065359477,
      "loss": 0.0037,
      "step": 9020
    },
    {
      "epoch": 19.694989106753813,
      "grad_norm": 2.8610126972198486,
      "learning_rate": 0.0003636601307189542,
      "loss": 0.0054,
      "step": 9040
    },
    {
      "epoch": 19.73856209150327,
      "grad_norm": 0.007783347740769386,
      "learning_rate": 0.00036313725490196073,
      "loss": 0.0654,
      "step": 9060
    },
    {
      "epoch": 19.78213507625272,
      "grad_norm": 0.00399263808503747,
      "learning_rate": 0.00036261437908496734,
      "loss": 0.0864,
      "step": 9080
    },
    {
      "epoch": 19.825708061002178,
      "grad_norm": 0.0639212355017662,
      "learning_rate": 0.00036209150326797383,
      "loss": 0.219,
      "step": 9100
    },
    {
      "epoch": 19.869281045751634,
      "grad_norm": 0.12140566855669022,
      "learning_rate": 0.0003615686274509803,
      "loss": 0.0837,
      "step": 9120
    },
    {
      "epoch": 19.91285403050109,
      "grad_norm": 12.878948211669922,
      "learning_rate": 0.0003610457516339869,
      "loss": 0.0844,
      "step": 9140
    },
    {
      "epoch": 19.956427015250544,
      "grad_norm": 0.030459396541118622,
      "learning_rate": 0.0003605228758169934,
      "loss": 0.1608,
      "step": 9160
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.030336346477270126,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.1331,
      "step": 9180
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9012460938841386,
      "eval_f1": 0.9176882661996497,
      "eval_loss": 0.630936861038208,
      "eval_runtime": 13.038,
      "eval_samples_per_second": 31.293,
      "eval_steps_per_second": 3.912,
      "step": 9180
    },
    {
      "epoch": 20.043572984749456,
      "grad_norm": 0.016928622499108315,
      "learning_rate": 0.0003594771241830065,
      "loss": 0.0478,
      "step": 9200
    },
    {
      "epoch": 20.08714596949891,
      "grad_norm": 0.047720182687044144,
      "learning_rate": 0.00035895424836601306,
      "loss": 0.0292,
      "step": 9220
    },
    {
      "epoch": 20.130718954248366,
      "grad_norm": 0.03535519912838936,
      "learning_rate": 0.00035843137254901956,
      "loss": 0.0223,
      "step": 9240
    },
    {
      "epoch": 20.174291938997822,
      "grad_norm": 16.933353424072266,
      "learning_rate": 0.0003579084967320261,
      "loss": 0.1354,
      "step": 9260
    },
    {
      "epoch": 20.21786492374728,
      "grad_norm": 0.4802026152610779,
      "learning_rate": 0.00035738562091503265,
      "loss": 0.103,
      "step": 9280
    },
    {
      "epoch": 20.26143790849673,
      "grad_norm": 3.7883388996124268,
      "learning_rate": 0.0003568627450980392,
      "loss": 0.1036,
      "step": 9300
    },
    {
      "epoch": 20.305010893246187,
      "grad_norm": 16.71288299560547,
      "learning_rate": 0.0003563398692810457,
      "loss": 0.0285,
      "step": 9320
    },
    {
      "epoch": 20.348583877995644,
      "grad_norm": 21.56116485595703,
      "learning_rate": 0.0003558169934640523,
      "loss": 0.1481,
      "step": 9340
    },
    {
      "epoch": 20.392156862745097,
      "grad_norm": 6.405033111572266,
      "learning_rate": 0.0003552941176470588,
      "loss": 0.1391,
      "step": 9360
    },
    {
      "epoch": 20.435729847494553,
      "grad_norm": 0.11693324148654938,
      "learning_rate": 0.0003547712418300653,
      "loss": 0.0657,
      "step": 9380
    },
    {
      "epoch": 20.47930283224401,
      "grad_norm": 6.860258102416992,
      "learning_rate": 0.0003542483660130719,
      "loss": 0.1104,
      "step": 9400
    },
    {
      "epoch": 20.522875816993466,
      "grad_norm": 1.43409264087677,
      "learning_rate": 0.0003537254901960784,
      "loss": 0.0671,
      "step": 9420
    },
    {
      "epoch": 20.56644880174292,
      "grad_norm": 0.03650853782892227,
      "learning_rate": 0.00035320261437908493,
      "loss": 0.0506,
      "step": 9440
    },
    {
      "epoch": 20.610021786492375,
      "grad_norm": 8.93474292755127,
      "learning_rate": 0.0003526797385620914,
      "loss": 0.0948,
      "step": 9460
    },
    {
      "epoch": 20.65359477124183,
      "grad_norm": 16.171581268310547,
      "learning_rate": 0.000352156862745098,
      "loss": 0.0828,
      "step": 9480
    },
    {
      "epoch": 20.697167755991284,
      "grad_norm": 1.4440932273864746,
      "learning_rate": 0.0003516339869281045,
      "loss": 0.1316,
      "step": 9500
    },
    {
      "epoch": 20.74074074074074,
      "grad_norm": 0.25886204838752747,
      "learning_rate": 0.00035111111111111107,
      "loss": 0.0198,
      "step": 9520
    },
    {
      "epoch": 20.784313725490197,
      "grad_norm": 19.45357322692871,
      "learning_rate": 0.0003505882352941176,
      "loss": 0.1985,
      "step": 9540
    },
    {
      "epoch": 20.827886710239653,
      "grad_norm": 7.603171348571777,
      "learning_rate": 0.00035006535947712416,
      "loss": 0.0985,
      "step": 9560
    },
    {
      "epoch": 20.871459694989106,
      "grad_norm": 0.006920165382325649,
      "learning_rate": 0.00034954248366013066,
      "loss": 0.1436,
      "step": 9580
    },
    {
      "epoch": 20.915032679738562,
      "grad_norm": 9.745953559875488,
      "learning_rate": 0.00034901960784313726,
      "loss": 0.1666,
      "step": 9600
    },
    {
      "epoch": 20.95860566448802,
      "grad_norm": 3.0840158462524414,
      "learning_rate": 0.00034849673202614375,
      "loss": 0.1277,
      "step": 9620
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9051704014939308,
      "eval_f1": 0.9206349206349206,
      "eval_loss": 0.7733187675476074,
      "eval_runtime": 12.8158,
      "eval_samples_per_second": 31.836,
      "eval_steps_per_second": 3.979,
      "step": 9639
    },
    {
      "epoch": 21.00217864923747,
      "grad_norm": 0.0020611609797924757,
      "learning_rate": 0.0003479738562091503,
      "loss": 0.0782,
      "step": 9640
    },
    {
      "epoch": 21.045751633986928,
      "grad_norm": 0.024318715557456017,
      "learning_rate": 0.00034745098039215685,
      "loss": 0.06,
      "step": 9660
    },
    {
      "epoch": 21.089324618736384,
      "grad_norm": 0.0069902571849524975,
      "learning_rate": 0.0003469281045751634,
      "loss": 0.0732,
      "step": 9680
    },
    {
      "epoch": 21.132897603485837,
      "grad_norm": 29.403839111328125,
      "learning_rate": 0.0003464052287581699,
      "loss": 0.1685,
      "step": 9700
    },
    {
      "epoch": 21.176470588235293,
      "grad_norm": 0.0075591434724628925,
      "learning_rate": 0.0003458823529411764,
      "loss": 0.0238,
      "step": 9720
    },
    {
      "epoch": 21.22004357298475,
      "grad_norm": 0.021452022716403008,
      "learning_rate": 0.000345359477124183,
      "loss": 0.0852,
      "step": 9740
    },
    {
      "epoch": 21.263616557734206,
      "grad_norm": 1.0085192918777466,
      "learning_rate": 0.0003448366013071895,
      "loss": 0.1268,
      "step": 9760
    },
    {
      "epoch": 21.30718954248366,
      "grad_norm": 0.03018983080983162,
      "learning_rate": 0.00034431372549019603,
      "loss": 0.0244,
      "step": 9780
    },
    {
      "epoch": 21.350762527233115,
      "grad_norm": 0.0020234528928995132,
      "learning_rate": 0.00034379084967320263,
      "loss": 0.1119,
      "step": 9800
    },
    {
      "epoch": 21.39433551198257,
      "grad_norm": 0.0022511302959173918,
      "learning_rate": 0.0003432679738562091,
      "loss": 0.1162,
      "step": 9820
    },
    {
      "epoch": 21.437908496732025,
      "grad_norm": 17.639873504638672,
      "learning_rate": 0.0003427450980392156,
      "loss": 0.1765,
      "step": 9840
    },
    {
      "epoch": 21.48148148148148,
      "grad_norm": 0.36907315254211426,
      "learning_rate": 0.0003422222222222222,
      "loss": 0.0328,
      "step": 9860
    },
    {
      "epoch": 21.525054466230937,
      "grad_norm": 0.004917248152196407,
      "learning_rate": 0.0003416993464052287,
      "loss": 0.0921,
      "step": 9880
    },
    {
      "epoch": 21.568627450980394,
      "grad_norm": 0.09398198127746582,
      "learning_rate": 0.00034117647058823526,
      "loss": 0.0644,
      "step": 9900
    },
    {
      "epoch": 21.612200435729847,
      "grad_norm": 0.005854290444403887,
      "learning_rate": 0.0003406535947712418,
      "loss": 0.0736,
      "step": 9920
    },
    {
      "epoch": 21.655773420479303,
      "grad_norm": 0.0034533170983195305,
      "learning_rate": 0.00034013071895424836,
      "loss": 0.0653,
      "step": 9940
    },
    {
      "epoch": 21.69934640522876,
      "grad_norm": 0.14323996007442474,
      "learning_rate": 0.00033960784313725485,
      "loss": 0.0953,
      "step": 9960
    },
    {
      "epoch": 21.742919389978212,
      "grad_norm": 0.48171621561050415,
      "learning_rate": 0.0003390849673202614,
      "loss": 0.0666,
      "step": 9980
    },
    {
      "epoch": 21.78649237472767,
      "grad_norm": 0.003863586811348796,
      "learning_rate": 0.00033856209150326795,
      "loss": 0.0639,
      "step": 10000
    },
    {
      "epoch": 21.830065359477125,
      "grad_norm": 9.668853759765625,
      "learning_rate": 0.0003380392156862745,
      "loss": 0.1723,
      "step": 10020
    },
    {
      "epoch": 21.87363834422658,
      "grad_norm": 0.00267363665625453,
      "learning_rate": 0.000337516339869281,
      "loss": 0.0731,
      "step": 10040
    },
    {
      "epoch": 21.917211328976034,
      "grad_norm": 0.015689104795455933,
      "learning_rate": 0.0003369934640522876,
      "loss": 0.0395,
      "step": 10060
    },
    {
      "epoch": 21.96078431372549,
      "grad_norm": 0.3525230586528778,
      "learning_rate": 0.0003364705882352941,
      "loss": 0.0712,
      "step": 10080
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9074819401444789,
      "eval_f1": 0.9228070175438596,
      "eval_loss": 0.7746396660804749,
      "eval_runtime": 12.6153,
      "eval_samples_per_second": 32.342,
      "eval_steps_per_second": 4.043,
      "step": 10098
    },
    {
      "epoch": 22.004357298474947,
      "grad_norm": 0.021530570462346077,
      "learning_rate": 0.0003359477124183006,
      "loss": 0.05,
      "step": 10100
    },
    {
      "epoch": 22.0479302832244,
      "grad_norm": 10.59970760345459,
      "learning_rate": 0.0003354248366013072,
      "loss": 0.0403,
      "step": 10120
    },
    {
      "epoch": 22.091503267973856,
      "grad_norm": 0.0027895509265363216,
      "learning_rate": 0.00033490196078431373,
      "loss": 0.0329,
      "step": 10140
    },
    {
      "epoch": 22.135076252723312,
      "grad_norm": 0.02279876358807087,
      "learning_rate": 0.0003343790849673202,
      "loss": 0.1499,
      "step": 10160
    },
    {
      "epoch": 22.17864923747277,
      "grad_norm": 0.030392961576581,
      "learning_rate": 0.0003338562091503267,
      "loss": 0.1148,
      "step": 10180
    },
    {
      "epoch": 22.22222222222222,
      "grad_norm": 0.004758654627948999,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.0094,
      "step": 10200
    },
    {
      "epoch": 22.265795206971678,
      "grad_norm": 13.350310325622559,
      "learning_rate": 0.0003328104575163398,
      "loss": 0.1335,
      "step": 10220
    },
    {
      "epoch": 22.309368191721134,
      "grad_norm": 6.443027019500732,
      "learning_rate": 0.00033228758169934636,
      "loss": 0.0732,
      "step": 10240
    },
    {
      "epoch": 22.352941176470587,
      "grad_norm": 0.3240128457546234,
      "learning_rate": 0.0003317647058823529,
      "loss": 0.0884,
      "step": 10260
    },
    {
      "epoch": 22.396514161220043,
      "grad_norm": 0.014067430980503559,
      "learning_rate": 0.00033124183006535946,
      "loss": 0.0579,
      "step": 10280
    },
    {
      "epoch": 22.4400871459695,
      "grad_norm": 5.138278007507324,
      "learning_rate": 0.00033071895424836595,
      "loss": 0.1408,
      "step": 10300
    },
    {
      "epoch": 22.483660130718953,
      "grad_norm": 20.164627075195312,
      "learning_rate": 0.00033019607843137256,
      "loss": 0.0831,
      "step": 10320
    },
    {
      "epoch": 22.52723311546841,
      "grad_norm": 7.761573314666748,
      "learning_rate": 0.00032967320261437905,
      "loss": 0.1312,
      "step": 10340
    },
    {
      "epoch": 22.570806100217865,
      "grad_norm": 0.07363509386777878,
      "learning_rate": 0.0003291503267973856,
      "loss": 0.066,
      "step": 10360
    },
    {
      "epoch": 22.61437908496732,
      "grad_norm": 0.013204132206737995,
      "learning_rate": 0.00032862745098039215,
      "loss": 0.0841,
      "step": 10380
    },
    {
      "epoch": 22.657952069716774,
      "grad_norm": 0.09994451701641083,
      "learning_rate": 0.0003281045751633987,
      "loss": 0.0557,
      "step": 10400
    },
    {
      "epoch": 22.70152505446623,
      "grad_norm": 0.07743430882692337,
      "learning_rate": 0.0003275816993464052,
      "loss": 0.1136,
      "step": 10420
    },
    {
      "epoch": 22.745098039215687,
      "grad_norm": 19.060701370239258,
      "learning_rate": 0.0003270588235294117,
      "loss": 0.0793,
      "step": 10440
    },
    {
      "epoch": 22.78867102396514,
      "grad_norm": 0.029315952211618423,
      "learning_rate": 0.0003265359477124183,
      "loss": 0.0917,
      "step": 10460
    },
    {
      "epoch": 22.832244008714596,
      "grad_norm": 0.666783332824707,
      "learning_rate": 0.0003260130718954248,
      "loss": 0.067,
      "step": 10480
    },
    {
      "epoch": 22.875816993464053,
      "grad_norm": 0.0586729496717453,
      "learning_rate": 0.0003254901960784313,
      "loss": 0.0436,
      "step": 10500
    },
    {
      "epoch": 22.91938997821351,
      "grad_norm": 0.05728754773736,
      "learning_rate": 0.00032496732026143793,
      "loss": 0.048,
      "step": 10520
    },
    {
      "epoch": 22.962962962962962,
      "grad_norm": 0.484851211309433,
      "learning_rate": 0.0003244444444444444,
      "loss": 0.0463,
      "step": 10540
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9006612858287186,
      "eval_f1": 0.91651865008881,
      "eval_loss": 0.8920889496803284,
      "eval_runtime": 12.6254,
      "eval_samples_per_second": 32.316,
      "eval_steps_per_second": 4.039,
      "step": 10557
    },
    {
      "epoch": 23.00653594771242,
      "grad_norm": 29.6561222076416,
      "learning_rate": 0.0003239215686274509,
      "loss": 0.0455,
      "step": 10560
    },
    {
      "epoch": 23.050108932461875,
      "grad_norm": 0.0014062679838389158,
      "learning_rate": 0.0003233986928104575,
      "loss": 0.0356,
      "step": 10580
    },
    {
      "epoch": 23.093681917211327,
      "grad_norm": 0.0017137536779046059,
      "learning_rate": 0.000322875816993464,
      "loss": 0.0105,
      "step": 10600
    },
    {
      "epoch": 23.137254901960784,
      "grad_norm": 0.004768565762788057,
      "learning_rate": 0.00032235294117647056,
      "loss": 0.0001,
      "step": 10620
    },
    {
      "epoch": 23.18082788671024,
      "grad_norm": 0.03362305462360382,
      "learning_rate": 0.00032183006535947705,
      "loss": 0.0789,
      "step": 10640
    },
    {
      "epoch": 23.224400871459697,
      "grad_norm": 0.031499024480581284,
      "learning_rate": 0.00032130718954248366,
      "loss": 0.0467,
      "step": 10660
    },
    {
      "epoch": 23.26797385620915,
      "grad_norm": 7.24751091003418,
      "learning_rate": 0.00032078431372549015,
      "loss": 0.147,
      "step": 10680
    },
    {
      "epoch": 23.311546840958606,
      "grad_norm": 0.0013074568705633283,
      "learning_rate": 0.0003202614379084967,
      "loss": 0.048,
      "step": 10700
    },
    {
      "epoch": 23.355119825708062,
      "grad_norm": 0.000987539766356349,
      "learning_rate": 0.00031973856209150325,
      "loss": 0.0336,
      "step": 10720
    },
    {
      "epoch": 23.398692810457515,
      "grad_norm": 0.006914583034813404,
      "learning_rate": 0.0003192156862745098,
      "loss": 0.0027,
      "step": 10740
    },
    {
      "epoch": 23.44226579520697,
      "grad_norm": 0.005601805169135332,
      "learning_rate": 0.0003186928104575163,
      "loss": 0.0795,
      "step": 10760
    },
    {
      "epoch": 23.485838779956428,
      "grad_norm": 16.30849266052246,
      "learning_rate": 0.0003181699346405229,
      "loss": 0.1267,
      "step": 10780
    },
    {
      "epoch": 23.529411764705884,
      "grad_norm": 0.009157813154160976,
      "learning_rate": 0.0003176470588235294,
      "loss": 0.1413,
      "step": 10800
    },
    {
      "epoch": 23.572984749455337,
      "grad_norm": 2.406027317047119,
      "learning_rate": 0.0003171241830065359,
      "loss": 0.0268,
      "step": 10820
    },
    {
      "epoch": 23.616557734204793,
      "grad_norm": 0.03823517635464668,
      "learning_rate": 0.0003166013071895425,
      "loss": 0.0935,
      "step": 10840
    },
    {
      "epoch": 23.66013071895425,
      "grad_norm": 0.08617399632930756,
      "learning_rate": 0.00031607843137254903,
      "loss": 0.0909,
      "step": 10860
    },
    {
      "epoch": 23.703703703703702,
      "grad_norm": 0.019729314371943474,
      "learning_rate": 0.0003155555555555555,
      "loss": 0.1547,
      "step": 10880
    },
    {
      "epoch": 23.74727668845316,
      "grad_norm": 0.03423934429883957,
      "learning_rate": 0.000315032679738562,
      "loss": 0.0155,
      "step": 10900
    },
    {
      "epoch": 23.790849673202615,
      "grad_norm": 16.597450256347656,
      "learning_rate": 0.0003145098039215686,
      "loss": 0.0241,
      "step": 10920
    },
    {
      "epoch": 23.834422657952068,
      "grad_norm": 0.0033032221253961325,
      "learning_rate": 0.0003139869281045751,
      "loss": 0.0981,
      "step": 10940
    },
    {
      "epoch": 23.877995642701524,
      "grad_norm": 6.939140796661377,
      "learning_rate": 0.00031346405228758166,
      "loss": 0.1002,
      "step": 10960
    },
    {
      "epoch": 23.92156862745098,
      "grad_norm": 0.01370904128998518,
      "learning_rate": 0.0003129411764705882,
      "loss": 0.0673,
      "step": 10980
    },
    {
      "epoch": 23.965141612200437,
      "grad_norm": 0.020659999921917915,
      "learning_rate": 0.00031241830065359476,
      "loss": 0.0545,
      "step": 11000
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9051704014939308,
      "eval_f1": 0.9206349206349206,
      "eval_loss": 0.8002134561538696,
      "eval_runtime": 12.24,
      "eval_samples_per_second": 33.333,
      "eval_steps_per_second": 4.167,
      "step": 11016
    },
    {
      "epoch": 24.00871459694989,
      "grad_norm": 0.09708960354328156,
      "learning_rate": 0.00031189542483660125,
      "loss": 0.175,
      "step": 11020
    },
    {
      "epoch": 24.052287581699346,
      "grad_norm": 6.567689418792725,
      "learning_rate": 0.00031137254901960785,
      "loss": 0.1403,
      "step": 11040
    },
    {
      "epoch": 24.095860566448803,
      "grad_norm": 1.872755527496338,
      "learning_rate": 0.00031084967320261435,
      "loss": 0.0516,
      "step": 11060
    },
    {
      "epoch": 24.139433551198255,
      "grad_norm": 0.03897592052817345,
      "learning_rate": 0.0003103267973856209,
      "loss": 0.0142,
      "step": 11080
    },
    {
      "epoch": 24.18300653594771,
      "grad_norm": 0.034276459366083145,
      "learning_rate": 0.00030980392156862744,
      "loss": 0.0857,
      "step": 11100
    },
    {
      "epoch": 24.226579520697168,
      "grad_norm": 0.9495152831077576,
      "learning_rate": 0.000309281045751634,
      "loss": 0.1012,
      "step": 11120
    },
    {
      "epoch": 24.270152505446625,
      "grad_norm": 0.053185392171144485,
      "learning_rate": 0.0003087581699346405,
      "loss": 0.1078,
      "step": 11140
    },
    {
      "epoch": 24.313725490196077,
      "grad_norm": 0.005737046245485544,
      "learning_rate": 0.000308235294117647,
      "loss": 0.0006,
      "step": 11160
    },
    {
      "epoch": 24.357298474945534,
      "grad_norm": 0.005600262898951769,
      "learning_rate": 0.0003077124183006536,
      "loss": 0.1025,
      "step": 11180
    },
    {
      "epoch": 24.40087145969499,
      "grad_norm": 0.002657718490809202,
      "learning_rate": 0.0003071895424836601,
      "loss": 0.0538,
      "step": 11200
    },
    {
      "epoch": 24.444444444444443,
      "grad_norm": 0.0038630967028439045,
      "learning_rate": 0.0003066666666666666,
      "loss": 0.1057,
      "step": 11220
    },
    {
      "epoch": 24.4880174291939,
      "grad_norm": 3.2184295654296875,
      "learning_rate": 0.0003061437908496732,
      "loss": 0.1067,
      "step": 11240
    },
    {
      "epoch": 24.531590413943356,
      "grad_norm": 0.00393503624945879,
      "learning_rate": 0.0003056209150326797,
      "loss": 0.0198,
      "step": 11260
    },
    {
      "epoch": 24.575163398692812,
      "grad_norm": 0.36773669719696045,
      "learning_rate": 0.0003050980392156862,
      "loss": 0.0672,
      "step": 11280
    },
    {
      "epoch": 24.618736383442265,
      "grad_norm": 24.149368286132812,
      "learning_rate": 0.0003045751633986928,
      "loss": 0.0512,
      "step": 11300
    },
    {
      "epoch": 24.66230936819172,
      "grad_norm": 0.0035722660832107067,
      "learning_rate": 0.0003040522875816993,
      "loss": 0.0628,
      "step": 11320
    },
    {
      "epoch": 24.705882352941178,
      "grad_norm": 0.0008335402817465365,
      "learning_rate": 0.00030352941176470586,
      "loss": 0.0606,
      "step": 11340
    },
    {
      "epoch": 24.74945533769063,
      "grad_norm": 0.05589117109775543,
      "learning_rate": 0.00030300653594771235,
      "loss": 0.1047,
      "step": 11360
    },
    {
      "epoch": 24.793028322440087,
      "grad_norm": 0.01150248758494854,
      "learning_rate": 0.00030248366013071895,
      "loss": 0.1987,
      "step": 11380
    },
    {
      "epoch": 24.836601307189543,
      "grad_norm": 0.047694381326436996,
      "learning_rate": 0.00030196078431372545,
      "loss": 0.0624,
      "step": 11400
    },
    {
      "epoch": 24.880174291939,
      "grad_norm": 0.047059640288352966,
      "learning_rate": 0.000301437908496732,
      "loss": 0.1239,
      "step": 11420
    },
    {
      "epoch": 24.923747276688452,
      "grad_norm": 0.06740061193704605,
      "learning_rate": 0.00030091503267973854,
      "loss": 0.051,
      "step": 11440
    },
    {
      "epoch": 24.96732026143791,
      "grad_norm": 21.765722274780273,
      "learning_rate": 0.0003003921568627451,
      "loss": 0.0111,
      "step": 11460
    },
    {
      "epoch": 25.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8987736437331115,
      "eval_f1": 0.9151943462897526,
      "eval_loss": 0.7949898838996887,
      "eval_runtime": 12.5806,
      "eval_samples_per_second": 32.431,
      "eval_steps_per_second": 4.054,
      "step": 11475
    },
    {
      "epoch": 25.010893246187365,
      "grad_norm": 0.0027973398100584745,
      "learning_rate": 0.00029986928104575164,
      "loss": 0.079,
      "step": 11480
    },
    {
      "epoch": 25.054466230936818,
      "grad_norm": 0.021783841773867607,
      "learning_rate": 0.00029934640522875813,
      "loss": 0.0957,
      "step": 11500
    },
    {
      "epoch": 25.098039215686274,
      "grad_norm": 0.016288965940475464,
      "learning_rate": 0.0002988235294117647,
      "loss": 0.0985,
      "step": 11520
    },
    {
      "epoch": 25.14161220043573,
      "grad_norm": 0.0658332109451294,
      "learning_rate": 0.0002983006535947712,
      "loss": 0.0262,
      "step": 11540
    },
    {
      "epoch": 25.185185185185187,
      "grad_norm": 0.014352277852594852,
      "learning_rate": 0.0002977777777777777,
      "loss": 0.0978,
      "step": 11560
    },
    {
      "epoch": 25.22875816993464,
      "grad_norm": 0.007126514799892902,
      "learning_rate": 0.0002972549019607843,
      "loss": 0.0236,
      "step": 11580
    },
    {
      "epoch": 25.272331154684096,
      "grad_norm": 0.0620390847325325,
      "learning_rate": 0.0002967320261437908,
      "loss": 0.0104,
      "step": 11600
    },
    {
      "epoch": 25.315904139433552,
      "grad_norm": 0.12663352489471436,
      "learning_rate": 0.00029620915032679737,
      "loss": 0.0495,
      "step": 11620
    },
    {
      "epoch": 25.359477124183005,
      "grad_norm": 0.1912645697593689,
      "learning_rate": 0.0002956862745098039,
      "loss": 0.1154,
      "step": 11640
    },
    {
      "epoch": 25.40305010893246,
      "grad_norm": 0.0054480647668242455,
      "learning_rate": 0.0002951633986928104,
      "loss": 0.0418,
      "step": 11660
    },
    {
      "epoch": 25.446623093681918,
      "grad_norm": 0.0770886018872261,
      "learning_rate": 0.00029464052287581696,
      "loss": 0.0878,
      "step": 11680
    },
    {
      "epoch": 25.49019607843137,
      "grad_norm": 0.019002769142389297,
      "learning_rate": 0.0002941176470588235,
      "loss": 0.0082,
      "step": 11700
    },
    {
      "epoch": 25.533769063180827,
      "grad_norm": 0.03029152937233448,
      "learning_rate": 0.00029359477124183005,
      "loss": 0.0261,
      "step": 11720
    },
    {
      "epoch": 25.577342047930284,
      "grad_norm": 0.02356400154531002,
      "learning_rate": 0.0002930718954248366,
      "loss": 0.028,
      "step": 11740
    },
    {
      "epoch": 25.62091503267974,
      "grad_norm": 0.004858783911913633,
      "learning_rate": 0.0002925490196078431,
      "loss": 0.0802,
      "step": 11760
    },
    {
      "epoch": 25.664488017429193,
      "grad_norm": 0.010831288993358612,
      "learning_rate": 0.00029202614379084964,
      "loss": 0.1008,
      "step": 11780
    },
    {
      "epoch": 25.70806100217865,
      "grad_norm": 0.08417032659053802,
      "learning_rate": 0.0002915032679738562,
      "loss": 0.0459,
      "step": 11800
    },
    {
      "epoch": 25.751633986928105,
      "grad_norm": 0.007965659722685814,
      "learning_rate": 0.00029098039215686274,
      "loss": 0.025,
      "step": 11820
    },
    {
      "epoch": 25.79520697167756,
      "grad_norm": 0.01018716674298048,
      "learning_rate": 0.0002904575163398693,
      "loss": 0.1366,
      "step": 11840
    },
    {
      "epoch": 25.838779956427015,
      "grad_norm": 12.840643882751465,
      "learning_rate": 0.0002899346405228758,
      "loss": 0.0858,
      "step": 11860
    },
    {
      "epoch": 25.88235294117647,
      "grad_norm": 0.018696123734116554,
      "learning_rate": 0.00028941176470588233,
      "loss": 0.048,
      "step": 11880
    },
    {
      "epoch": 25.925925925925927,
      "grad_norm": 0.03611240163445473,
      "learning_rate": 0.0002888888888888888,
      "loss": 0.1379,
      "step": 11900
    },
    {
      "epoch": 25.96949891067538,
      "grad_norm": 1.8929905891418457,
      "learning_rate": 0.00028836601307189537,
      "loss": 0.1278,
      "step": 11920
    },
    {
      "epoch": 26.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8957701637355973,
      "eval_f1": 0.9140893470790378,
      "eval_loss": 0.6887514591217041,
      "eval_runtime": 12.7898,
      "eval_samples_per_second": 31.901,
      "eval_steps_per_second": 3.988,
      "step": 11934
    },
    {
      "epoch": 26.013071895424837,
      "grad_norm": 0.03025096468627453,
      "learning_rate": 0.00028784313725490197,
      "loss": 0.16,
      "step": 11940
    },
    {
      "epoch": 26.056644880174293,
      "grad_norm": 11.610848426818848,
      "learning_rate": 0.00028732026143790847,
      "loss": 0.0807,
      "step": 11960
    },
    {
      "epoch": 26.100217864923746,
      "grad_norm": 0.0030456152744591236,
      "learning_rate": 0.000286797385620915,
      "loss": 0.0404,
      "step": 11980
    },
    {
      "epoch": 26.143790849673202,
      "grad_norm": 0.00516122579574585,
      "learning_rate": 0.00028627450980392156,
      "loss": 0.0356,
      "step": 12000
    },
    {
      "epoch": 26.18736383442266,
      "grad_norm": 0.08342362940311432,
      "learning_rate": 0.00028575163398692806,
      "loss": 0.0102,
      "step": 12020
    },
    {
      "epoch": 26.230936819172115,
      "grad_norm": 24.718181610107422,
      "learning_rate": 0.0002852287581699346,
      "loss": 0.0985,
      "step": 12040
    },
    {
      "epoch": 26.274509803921568,
      "grad_norm": 0.005937632173299789,
      "learning_rate": 0.00028470588235294115,
      "loss": 0.0913,
      "step": 12060
    },
    {
      "epoch": 26.318082788671024,
      "grad_norm": 0.010378197766840458,
      "learning_rate": 0.0002841830065359477,
      "loss": 0.0789,
      "step": 12080
    },
    {
      "epoch": 26.36165577342048,
      "grad_norm": 0.018890025094151497,
      "learning_rate": 0.00028366013071895425,
      "loss": 0.0698,
      "step": 12100
    },
    {
      "epoch": 26.405228758169933,
      "grad_norm": 1.1612131595611572,
      "learning_rate": 0.00028313725490196074,
      "loss": 0.0289,
      "step": 12120
    },
    {
      "epoch": 26.44880174291939,
      "grad_norm": 0.005695202387869358,
      "learning_rate": 0.0002826143790849673,
      "loss": 0.093,
      "step": 12140
    },
    {
      "epoch": 26.492374727668846,
      "grad_norm": 0.0728224515914917,
      "learning_rate": 0.00028209150326797384,
      "loss": 0.0319,
      "step": 12160
    },
    {
      "epoch": 26.535947712418302,
      "grad_norm": 0.025829583406448364,
      "learning_rate": 0.0002815686274509804,
      "loss": 0.0724,
      "step": 12180
    },
    {
      "epoch": 26.579520697167755,
      "grad_norm": 0.0057995994575321674,
      "learning_rate": 0.00028104575163398693,
      "loss": 0.0337,
      "step": 12200
    },
    {
      "epoch": 26.62309368191721,
      "grad_norm": 0.19752994179725647,
      "learning_rate": 0.00028052287581699343,
      "loss": 0.0364,
      "step": 12220
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 0.030361289158463478,
      "learning_rate": 0.00028,
      "loss": 0.0511,
      "step": 12240
    },
    {
      "epoch": 26.71023965141612,
      "grad_norm": 0.006618967279791832,
      "learning_rate": 0.00027947712418300647,
      "loss": 0.1374,
      "step": 12260
    },
    {
      "epoch": 26.753812636165577,
      "grad_norm": 0.013206977397203445,
      "learning_rate": 0.00027895424836601307,
      "loss": 0.0008,
      "step": 12280
    },
    {
      "epoch": 26.797385620915033,
      "grad_norm": 17.29594612121582,
      "learning_rate": 0.0002784313725490196,
      "loss": 0.0677,
      "step": 12300
    },
    {
      "epoch": 26.84095860566449,
      "grad_norm": 19.480241775512695,
      "learning_rate": 0.0002779084967320261,
      "loss": 0.0803,
      "step": 12320
    },
    {
      "epoch": 26.884531590413943,
      "grad_norm": 0.013582389801740646,
      "learning_rate": 0.00027738562091503266,
      "loss": 0.0872,
      "step": 12340
    },
    {
      "epoch": 26.9281045751634,
      "grad_norm": 0.04048536717891693,
      "learning_rate": 0.0002768627450980392,
      "loss": 0.0925,
      "step": 12360
    },
    {
      "epoch": 26.971677559912855,
      "grad_norm": 0.11217748373746872,
      "learning_rate": 0.0002763398692810457,
      "loss": 0.0563,
      "step": 12380
    },
    {
      "epoch": 27.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9054483877614092,
      "eval_f1": 0.9211908931698775,
      "eval_loss": 0.8079127669334412,
      "eval_runtime": 12.5229,
      "eval_samples_per_second": 32.58,
      "eval_steps_per_second": 4.073,
      "step": 12393
    },
    {
      "epoch": 27.015250544662308,
      "grad_norm": 0.028718940913677216,
      "learning_rate": 0.00027581699346405225,
      "loss": 0.0357,
      "step": 12400
    },
    {
      "epoch": 27.058823529411764,
      "grad_norm": 19.309219360351562,
      "learning_rate": 0.0002752941176470588,
      "loss": 0.1064,
      "step": 12420
    },
    {
      "epoch": 27.10239651416122,
      "grad_norm": 8.332215309143066,
      "learning_rate": 0.00027477124183006535,
      "loss": 0.0826,
      "step": 12440
    },
    {
      "epoch": 27.145969498910674,
      "grad_norm": 0.21258221566677094,
      "learning_rate": 0.0002742483660130719,
      "loss": 0.0747,
      "step": 12460
    },
    {
      "epoch": 27.18954248366013,
      "grad_norm": 0.005136234685778618,
      "learning_rate": 0.0002737254901960784,
      "loss": 0.0405,
      "step": 12480
    },
    {
      "epoch": 27.233115468409586,
      "grad_norm": 0.4805666506290436,
      "learning_rate": 0.00027320261437908494,
      "loss": 0.0464,
      "step": 12500
    },
    {
      "epoch": 27.276688453159043,
      "grad_norm": 0.003952230326831341,
      "learning_rate": 0.0002726797385620915,
      "loss": 0.0198,
      "step": 12520
    },
    {
      "epoch": 27.320261437908496,
      "grad_norm": 0.004295556806027889,
      "learning_rate": 0.00027215686274509803,
      "loss": 0.0261,
      "step": 12540
    },
    {
      "epoch": 27.363834422657952,
      "grad_norm": 0.0509440042078495,
      "learning_rate": 0.0002716339869281046,
      "loss": 0.0195,
      "step": 12560
    },
    {
      "epoch": 27.40740740740741,
      "grad_norm": 0.00766392657533288,
      "learning_rate": 0.0002711111111111111,
      "loss": 0.0471,
      "step": 12580
    },
    {
      "epoch": 27.45098039215686,
      "grad_norm": 0.0013218473177403212,
      "learning_rate": 0.0002705882352941176,
      "loss": 0.0182,
      "step": 12600
    },
    {
      "epoch": 27.494553376906318,
      "grad_norm": 0.30775561928749084,
      "learning_rate": 0.0002700653594771241,
      "loss": 0.0875,
      "step": 12620
    },
    {
      "epoch": 27.538126361655774,
      "grad_norm": 0.002332600299268961,
      "learning_rate": 0.0002695424836601307,
      "loss": 0.0026,
      "step": 12640
    },
    {
      "epoch": 27.58169934640523,
      "grad_norm": 0.11504258215427399,
      "learning_rate": 0.00026901960784313727,
      "loss": 0.0007,
      "step": 12660
    },
    {
      "epoch": 27.625272331154683,
      "grad_norm": 0.04520917683839798,
      "learning_rate": 0.00026849673202614376,
      "loss": 0.0079,
      "step": 12680
    },
    {
      "epoch": 27.66884531590414,
      "grad_norm": 0.020281633362174034,
      "learning_rate": 0.0002679738562091503,
      "loss": 0.0035,
      "step": 12700
    },
    {
      "epoch": 27.712418300653596,
      "grad_norm": 0.001188542926684022,
      "learning_rate": 0.00026745098039215686,
      "loss": 0.0462,
      "step": 12720
    },
    {
      "epoch": 27.75599128540305,
      "grad_norm": 0.0018491854425519705,
      "learning_rate": 0.00026692810457516335,
      "loss": 0.0733,
      "step": 12740
    },
    {
      "epoch": 27.799564270152505,
      "grad_norm": 6.9962968826293945,
      "learning_rate": 0.0002664052287581699,
      "loss": 0.0972,
      "step": 12760
    },
    {
      "epoch": 27.84313725490196,
      "grad_norm": 0.11187070608139038,
      "learning_rate": 0.00026588235294117645,
      "loss": 0.0078,
      "step": 12780
    },
    {
      "epoch": 27.886710239651418,
      "grad_norm": 3.319570541381836,
      "learning_rate": 0.000265359477124183,
      "loss": 0.0405,
      "step": 12800
    },
    {
      "epoch": 27.93028322440087,
      "grad_norm": 0.0009402611176483333,
      "learning_rate": 0.00026483660130718954,
      "loss": 0.005,
      "step": 12820
    },
    {
      "epoch": 27.973856209150327,
      "grad_norm": 0.008459842763841152,
      "learning_rate": 0.00026431372549019604,
      "loss": 0.114,
      "step": 12840
    },
    {
      "epoch": 28.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9092508242234947,
      "eval_f1": 0.9238938053097344,
      "eval_loss": 0.7702904343605042,
      "eval_runtime": 12.218,
      "eval_samples_per_second": 33.393,
      "eval_steps_per_second": 4.174,
      "step": 12852
    },
    {
      "epoch": 28.017429193899783,
      "grad_norm": 0.011845089495182037,
      "learning_rate": 0.0002637908496732026,
      "loss": 0.079,
      "step": 12860
    },
    {
      "epoch": 28.061002178649236,
      "grad_norm": 0.1387493759393692,
      "learning_rate": 0.00026326797385620913,
      "loss": 0.0716,
      "step": 12880
    },
    {
      "epoch": 28.104575163398692,
      "grad_norm": 0.008215143345296383,
      "learning_rate": 0.0002627450980392157,
      "loss": 0.1368,
      "step": 12900
    },
    {
      "epoch": 28.14814814814815,
      "grad_norm": 0.04061167314648628,
      "learning_rate": 0.00026222222222222223,
      "loss": 0.0711,
      "step": 12920
    },
    {
      "epoch": 28.191721132897605,
      "grad_norm": 0.02271057851612568,
      "learning_rate": 0.0002616993464052287,
      "loss": 0.0631,
      "step": 12940
    },
    {
      "epoch": 28.235294117647058,
      "grad_norm": 8.767976760864258,
      "learning_rate": 0.00026117647058823527,
      "loss": 0.0357,
      "step": 12960
    },
    {
      "epoch": 28.278867102396514,
      "grad_norm": 0.00449339346960187,
      "learning_rate": 0.00026065359477124177,
      "loss": 0.0925,
      "step": 12980
    },
    {
      "epoch": 28.32244008714597,
      "grad_norm": 0.18170636892318726,
      "learning_rate": 0.00026013071895424837,
      "loss": 0.1984,
      "step": 13000
    },
    {
      "epoch": 28.366013071895424,
      "grad_norm": 0.030712267383933067,
      "learning_rate": 0.0002596078431372549,
      "loss": 0.0755,
      "step": 13020
    },
    {
      "epoch": 28.40958605664488,
      "grad_norm": 0.021768001839518547,
      "learning_rate": 0.0002590849673202614,
      "loss": 0.0321,
      "step": 13040
    },
    {
      "epoch": 28.453159041394336,
      "grad_norm": 0.03262345492839813,
      "learning_rate": 0.00025856209150326796,
      "loss": 0.017,
      "step": 13060
    },
    {
      "epoch": 28.49673202614379,
      "grad_norm": 0.002206704579293728,
      "learning_rate": 0.0002580392156862745,
      "loss": 0.1191,
      "step": 13080
    },
    {
      "epoch": 28.540305010893245,
      "grad_norm": 0.03734803944826126,
      "learning_rate": 0.000257516339869281,
      "loss": 0.0806,
      "step": 13100
    },
    {
      "epoch": 28.583877995642702,
      "grad_norm": 0.03825085237622261,
      "learning_rate": 0.00025699346405228755,
      "loss": 0.0197,
      "step": 13120
    },
    {
      "epoch": 28.627450980392158,
      "grad_norm": 0.001961279194802046,
      "learning_rate": 0.0002564705882352941,
      "loss": 0.0367,
      "step": 13140
    },
    {
      "epoch": 28.67102396514161,
      "grad_norm": 0.013520816341042519,
      "learning_rate": 0.00025594771241830064,
      "loss": 0.0559,
      "step": 13160
    },
    {
      "epoch": 28.714596949891067,
      "grad_norm": 0.0029840334318578243,
      "learning_rate": 0.0002554248366013072,
      "loss": 0.1254,
      "step": 13180
    },
    {
      "epoch": 28.758169934640524,
      "grad_norm": 0.008906899020075798,
      "learning_rate": 0.0002549019607843137,
      "loss": 0.1606,
      "step": 13200
    },
    {
      "epoch": 28.801742919389977,
      "grad_norm": 10.272760391235352,
      "learning_rate": 0.00025437908496732023,
      "loss": 0.062,
      "step": 13220
    },
    {
      "epoch": 28.845315904139433,
      "grad_norm": 0.03647666424512863,
      "learning_rate": 0.0002538562091503268,
      "loss": 0.0687,
      "step": 13240
    },
    {
      "epoch": 28.88888888888889,
      "grad_norm": 8.96028995513916,
      "learning_rate": 0.00025333333333333333,
      "loss": 0.098,
      "step": 13260
    },
    {
      "epoch": 28.932461873638346,
      "grad_norm": 10.181199073791504,
      "learning_rate": 0.0002528104575163399,
      "loss": 0.0738,
      "step": 13280
    },
    {
      "epoch": 28.9760348583878,
      "grad_norm": 0.017465442419052124,
      "learning_rate": 0.00025228758169934637,
      "loss": 0.0361,
      "step": 13300
    },
    {
      "epoch": 29.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9115575807787903,
      "eval_f1": 0.926056338028169,
      "eval_loss": 0.7714462280273438,
      "eval_runtime": 12.5321,
      "eval_samples_per_second": 32.556,
      "eval_steps_per_second": 4.07,
      "step": 13311
    },
    {
      "epoch": 29.019607843137255,
      "grad_norm": 0.0598471499979496,
      "learning_rate": 0.0002517647058823529,
      "loss": 0.0529,
      "step": 13320
    },
    {
      "epoch": 29.06318082788671,
      "grad_norm": 0.05255415663123131,
      "learning_rate": 0.0002512418300653594,
      "loss": 0.0123,
      "step": 13340
    },
    {
      "epoch": 29.106753812636164,
      "grad_norm": 0.05236464738845825,
      "learning_rate": 0.000250718954248366,
      "loss": 0.0119,
      "step": 13360
    },
    {
      "epoch": 29.15032679738562,
      "grad_norm": 0.0005779736675322056,
      "learning_rate": 0.00025019607843137256,
      "loss": 0.024,
      "step": 13380
    },
    {
      "epoch": 29.193899782135077,
      "grad_norm": 0.0021387662272900343,
      "learning_rate": 0.00024967320261437906,
      "loss": 0.0138,
      "step": 13400
    },
    {
      "epoch": 29.237472766884533,
      "grad_norm": 0.012306202203035355,
      "learning_rate": 0.0002491503267973856,
      "loss": 0.1212,
      "step": 13420
    },
    {
      "epoch": 29.281045751633986,
      "grad_norm": 0.009356392547488213,
      "learning_rate": 0.00024862745098039215,
      "loss": 0.0177,
      "step": 13440
    },
    {
      "epoch": 29.324618736383442,
      "grad_norm": 41.991451263427734,
      "learning_rate": 0.00024810457516339865,
      "loss": 0.0438,
      "step": 13460
    },
    {
      "epoch": 29.3681917211329,
      "grad_norm": 0.00980021059513092,
      "learning_rate": 0.0002475816993464052,
      "loss": 0.0592,
      "step": 13480
    },
    {
      "epoch": 29.41176470588235,
      "grad_norm": 10.65612506866455,
      "learning_rate": 0.00024705882352941174,
      "loss": 0.0424,
      "step": 13500
    },
    {
      "epoch": 29.455337690631808,
      "grad_norm": 0.09168747067451477,
      "learning_rate": 0.0002465359477124183,
      "loss": 0.0616,
      "step": 13520
    },
    {
      "epoch": 29.498910675381264,
      "grad_norm": 0.00622285483404994,
      "learning_rate": 0.00024601307189542484,
      "loss": 0.1323,
      "step": 13540
    },
    {
      "epoch": 29.54248366013072,
      "grad_norm": 16.73431968688965,
      "learning_rate": 0.00024549019607843133,
      "loss": 0.0904,
      "step": 13560
    },
    {
      "epoch": 29.586056644880173,
      "grad_norm": 0.012850778177380562,
      "learning_rate": 0.0002449673202614379,
      "loss": 0.0954,
      "step": 13580
    },
    {
      "epoch": 29.62962962962963,
      "grad_norm": 0.015931623056530952,
      "learning_rate": 0.00024444444444444443,
      "loss": 0.015,
      "step": 13600
    },
    {
      "epoch": 29.673202614379086,
      "grad_norm": 0.00172794156242162,
      "learning_rate": 0.00024392156862745095,
      "loss": 0.0154,
      "step": 13620
    },
    {
      "epoch": 29.71677559912854,
      "grad_norm": 0.003747527254745364,
      "learning_rate": 0.0002433986928104575,
      "loss": 0.0378,
      "step": 13640
    },
    {
      "epoch": 29.760348583877995,
      "grad_norm": 0.1915557086467743,
      "learning_rate": 0.00024287581699346402,
      "loss": 0.0084,
      "step": 13660
    },
    {
      "epoch": 29.80392156862745,
      "grad_norm": 0.37638065218925476,
      "learning_rate": 0.00024235294117647057,
      "loss": 0.0437,
      "step": 13680
    },
    {
      "epoch": 29.847494553376904,
      "grad_norm": 4.788814544677734,
      "learning_rate": 0.0002418300653594771,
      "loss": 0.0177,
      "step": 13700
    },
    {
      "epoch": 29.89106753812636,
      "grad_norm": 0.14045575261116028,
      "learning_rate": 0.00024130718954248364,
      "loss": 0.0214,
      "step": 13720
    },
    {
      "epoch": 29.934640522875817,
      "grad_norm": 0.00010503866360522807,
      "learning_rate": 0.00024078431372549018,
      "loss": 0.0274,
      "step": 13740
    },
    {
      "epoch": 29.978213507625274,
      "grad_norm": 40.479087829589844,
      "learning_rate": 0.0002402614379084967,
      "loss": 0.0838,
      "step": 13760
    },
    {
      "epoch": 30.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9111628637220013,
      "eval_f1": 0.9252669039145908,
      "eval_loss": 0.9591212272644043,
      "eval_runtime": 12.6331,
      "eval_samples_per_second": 32.296,
      "eval_steps_per_second": 4.037,
      "step": 13770
    },
    {
      "epoch": 30.021786492374726,
      "grad_norm": 0.0008217038703151047,
      "learning_rate": 0.00023973856209150325,
      "loss": 0.0347,
      "step": 13780
    },
    {
      "epoch": 30.065359477124183,
      "grad_norm": 0.002051383489742875,
      "learning_rate": 0.0002392156862745098,
      "loss": 0.0425,
      "step": 13800
    },
    {
      "epoch": 30.10893246187364,
      "grad_norm": 0.001409271266311407,
      "learning_rate": 0.00023869281045751632,
      "loss": 0.1121,
      "step": 13820
    },
    {
      "epoch": 30.152505446623092,
      "grad_norm": 0.001843961770646274,
      "learning_rate": 0.00023816993464052287,
      "loss": 0.0363,
      "step": 13840
    },
    {
      "epoch": 30.19607843137255,
      "grad_norm": 0.017755085602402687,
      "learning_rate": 0.0002376470588235294,
      "loss": 0.0758,
      "step": 13860
    },
    {
      "epoch": 30.239651416122005,
      "grad_norm": 0.01996425725519657,
      "learning_rate": 0.00023712418300653594,
      "loss": 0.131,
      "step": 13880
    },
    {
      "epoch": 30.28322440087146,
      "grad_norm": 0.023688575252890587,
      "learning_rate": 0.0002366013071895425,
      "loss": 0.0372,
      "step": 13900
    },
    {
      "epoch": 30.326797385620914,
      "grad_norm": 0.010420359671115875,
      "learning_rate": 0.00023607843137254898,
      "loss": 0.0608,
      "step": 13920
    },
    {
      "epoch": 30.37037037037037,
      "grad_norm": 0.004023731220513582,
      "learning_rate": 0.00023555555555555553,
      "loss": 0.1017,
      "step": 13940
    },
    {
      "epoch": 30.413943355119827,
      "grad_norm": 0.004106251988559961,
      "learning_rate": 0.00023503267973856205,
      "loss": 0.0078,
      "step": 13960
    },
    {
      "epoch": 30.45751633986928,
      "grad_norm": 0.004764968995004892,
      "learning_rate": 0.0002345098039215686,
      "loss": 0.0544,
      "step": 13980
    },
    {
      "epoch": 30.501089324618736,
      "grad_norm": 0.01546934898942709,
      "learning_rate": 0.00023398692810457515,
      "loss": 0.0092,
      "step": 14000
    },
    {
      "epoch": 30.544662309368192,
      "grad_norm": 0.0005935275694355369,
      "learning_rate": 0.00023346405228758167,
      "loss": 0.0219,
      "step": 14020
    },
    {
      "epoch": 30.58823529411765,
      "grad_norm": 0.0029027117416262627,
      "learning_rate": 0.00023294117647058821,
      "loss": 0.0037,
      "step": 14040
    },
    {
      "epoch": 30.6318082788671,
      "grad_norm": 0.01823549158871174,
      "learning_rate": 0.00023241830065359474,
      "loss": 0.0547,
      "step": 14060
    },
    {
      "epoch": 30.675381263616558,
      "grad_norm": 0.0022519310005009174,
      "learning_rate": 0.00023189542483660128,
      "loss": 0.0733,
      "step": 14080
    },
    {
      "epoch": 30.718954248366014,
      "grad_norm": 0.014233332127332687,
      "learning_rate": 0.00023137254901960783,
      "loss": 0.0149,
      "step": 14100
    },
    {
      "epoch": 30.762527233115467,
      "grad_norm": 6.002061367034912,
      "learning_rate": 0.00023084967320261435,
      "loss": 0.0308,
      "step": 14120
    },
    {
      "epoch": 30.806100217864923,
      "grad_norm": 0.0059754932299256325,
      "learning_rate": 0.0002303267973856209,
      "loss": 0.0025,
      "step": 14140
    },
    {
      "epoch": 30.84967320261438,
      "grad_norm": 0.004416184034198523,
      "learning_rate": 0.00022980392156862745,
      "loss": 0.1081,
      "step": 14160
    },
    {
      "epoch": 30.893246187363836,
      "grad_norm": 0.014620860107243061,
      "learning_rate": 0.00022928104575163397,
      "loss": 0.0048,
      "step": 14180
    },
    {
      "epoch": 30.93681917211329,
      "grad_norm": 0.0030198870226740837,
      "learning_rate": 0.00022875816993464052,
      "loss": 0.0868,
      "step": 14200
    },
    {
      "epoch": 30.980392156862745,
      "grad_norm": 0.0023139668628573418,
      "learning_rate": 0.00022823529411764704,
      "loss": 0.068,
      "step": 14220
    },
    {
      "epoch": 31.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9112953692115144,
      "eval_f1": 0.925531914893617,
      "eval_loss": 0.7876688838005066,
      "eval_runtime": 12.7302,
      "eval_samples_per_second": 32.05,
      "eval_steps_per_second": 4.006,
      "step": 14229
    },
    {
      "epoch": 31.0239651416122,
      "grad_norm": 0.14590835571289062,
      "learning_rate": 0.0002277124183006536,
      "loss": 0.0186,
      "step": 14240
    },
    {
      "epoch": 31.067538126361654,
      "grad_norm": 0.05584792420268059,
      "learning_rate": 0.00022718954248366013,
      "loss": 0.0697,
      "step": 14260
    },
    {
      "epoch": 31.11111111111111,
      "grad_norm": 0.0033449886832386255,
      "learning_rate": 0.00022666666666666663,
      "loss": 0.0058,
      "step": 14280
    },
    {
      "epoch": 31.154684095860567,
      "grad_norm": 0.5848329663276672,
      "learning_rate": 0.00022614379084967318,
      "loss": 0.0146,
      "step": 14300
    },
    {
      "epoch": 31.198257080610023,
      "grad_norm": 0.0009256461635231972,
      "learning_rate": 0.0002256209150326797,
      "loss": 0.0303,
      "step": 14320
    },
    {
      "epoch": 31.241830065359476,
      "grad_norm": 0.040169671177864075,
      "learning_rate": 0.00022509803921568625,
      "loss": 0.0946,
      "step": 14340
    },
    {
      "epoch": 31.285403050108933,
      "grad_norm": 0.05122428387403488,
      "learning_rate": 0.0002245751633986928,
      "loss": 0.0147,
      "step": 14360
    },
    {
      "epoch": 31.32897603485839,
      "grad_norm": 0.001335236127488315,
      "learning_rate": 0.00022405228758169931,
      "loss": 0.01,
      "step": 14380
    },
    {
      "epoch": 31.372549019607842,
      "grad_norm": 0.06807105988264084,
      "learning_rate": 0.00022352941176470586,
      "loss": 0.0331,
      "step": 14400
    },
    {
      "epoch": 31.416122004357298,
      "grad_norm": 0.029900336638092995,
      "learning_rate": 0.00022300653594771238,
      "loss": 0.0006,
      "step": 14420
    },
    {
      "epoch": 31.459694989106755,
      "grad_norm": 0.0006971661932766438,
      "learning_rate": 0.00022248366013071893,
      "loss": 0.006,
      "step": 14440
    },
    {
      "epoch": 31.50326797385621,
      "grad_norm": 1.8144659996032715,
      "learning_rate": 0.00022196078431372548,
      "loss": 0.0008,
      "step": 14460
    },
    {
      "epoch": 31.546840958605664,
      "grad_norm": 0.0003181151987519115,
      "learning_rate": 0.000221437908496732,
      "loss": 0.0987,
      "step": 14480
    },
    {
      "epoch": 31.59041394335512,
      "grad_norm": 7.81680965423584,
      "learning_rate": 0.00022091503267973855,
      "loss": 0.0996,
      "step": 14500
    },
    {
      "epoch": 31.633986928104576,
      "grad_norm": 2.1051719188690186,
      "learning_rate": 0.0002203921568627451,
      "loss": 0.0004,
      "step": 14520
    },
    {
      "epoch": 31.67755991285403,
      "grad_norm": 7.15224552154541,
      "learning_rate": 0.00021986928104575162,
      "loss": 0.0389,
      "step": 14540
    },
    {
      "epoch": 31.721132897603486,
      "grad_norm": 0.4297037720680237,
      "learning_rate": 0.00021934640522875817,
      "loss": 0.0077,
      "step": 14560
    },
    {
      "epoch": 31.764705882352942,
      "grad_norm": 0.0007979436195455492,
      "learning_rate": 0.0002188235294117647,
      "loss": 0.0078,
      "step": 14580
    },
    {
      "epoch": 31.808278867102395,
      "grad_norm": 0.003568445798009634,
      "learning_rate": 0.00021830065359477123,
      "loss": 0.0592,
      "step": 14600
    },
    {
      "epoch": 31.85185185185185,
      "grad_norm": 0.0013352318201214075,
      "learning_rate": 0.00021777777777777778,
      "loss": 0.0559,
      "step": 14620
    },
    {
      "epoch": 31.895424836601308,
      "grad_norm": 0.0007613027701154351,
      "learning_rate": 0.00021725490196078428,
      "loss": 0.06,
      "step": 14640
    },
    {
      "epoch": 31.938997821350764,
      "grad_norm": 0.0014129206538200378,
      "learning_rate": 0.00021673202614379082,
      "loss": 0.0909,
      "step": 14660
    },
    {
      "epoch": 31.982570806100217,
      "grad_norm": 0.008810427039861679,
      "learning_rate": 0.00021620915032679735,
      "loss": 0.0353,
      "step": 14680
    },
    {
      "epoch": 32.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.907209173422019,
      "eval_f1": 0.9222614840989399,
      "eval_loss": 0.8786795139312744,
      "eval_runtime": 12.669,
      "eval_samples_per_second": 32.204,
      "eval_steps_per_second": 4.026,
      "step": 14688
    },
    {
      "epoch": 32.02614379084967,
      "grad_norm": 0.0024328723084181547,
      "learning_rate": 0.0002156862745098039,
      "loss": 0.0506,
      "step": 14700
    },
    {
      "epoch": 32.069716775599126,
      "grad_norm": 0.020327558740973473,
      "learning_rate": 0.00021516339869281044,
      "loss": 0.0008,
      "step": 14720
    },
    {
      "epoch": 32.113289760348586,
      "grad_norm": 0.001022988697513938,
      "learning_rate": 0.00021464052287581696,
      "loss": 0.0104,
      "step": 14740
    },
    {
      "epoch": 32.15686274509804,
      "grad_norm": 0.0026896419003605843,
      "learning_rate": 0.0002141176470588235,
      "loss": 0.0031,
      "step": 14760
    },
    {
      "epoch": 32.20043572984749,
      "grad_norm": 0.0008366828551515937,
      "learning_rate": 0.00021359477124183003,
      "loss": 0.1415,
      "step": 14780
    },
    {
      "epoch": 32.24400871459695,
      "grad_norm": 0.006315845530480146,
      "learning_rate": 0.00021307189542483658,
      "loss": 0.0421,
      "step": 14800
    },
    {
      "epoch": 32.287581699346404,
      "grad_norm": 0.025631269440054893,
      "learning_rate": 0.00021254901960784313,
      "loss": 0.0617,
      "step": 14820
    },
    {
      "epoch": 32.331154684095864,
      "grad_norm": 0.02941014990210533,
      "learning_rate": 0.00021202614379084965,
      "loss": 0.0945,
      "step": 14840
    },
    {
      "epoch": 32.37472766884532,
      "grad_norm": 20.289621353149414,
      "learning_rate": 0.0002115032679738562,
      "loss": 0.0525,
      "step": 14860
    },
    {
      "epoch": 32.41830065359477,
      "grad_norm": 3.467428684234619,
      "learning_rate": 0.00021098039215686274,
      "loss": 0.0259,
      "step": 14880
    },
    {
      "epoch": 32.46187363834423,
      "grad_norm": 0.001846746657975018,
      "learning_rate": 0.00021045751633986927,
      "loss": 0.0005,
      "step": 14900
    },
    {
      "epoch": 32.50544662309368,
      "grad_norm": 11.258509635925293,
      "learning_rate": 0.00020993464052287581,
      "loss": 0.0847,
      "step": 14920
    },
    {
      "epoch": 32.549019607843135,
      "grad_norm": 0.0007048334227874875,
      "learning_rate": 0.00020941176470588233,
      "loss": 0.0892,
      "step": 14940
    },
    {
      "epoch": 32.592592592592595,
      "grad_norm": 0.022986363619565964,
      "learning_rate": 0.00020888888888888888,
      "loss": 0.0631,
      "step": 14960
    },
    {
      "epoch": 32.63616557734205,
      "grad_norm": 0.010425649583339691,
      "learning_rate": 0.00020836601307189543,
      "loss": 0.0483,
      "step": 14980
    },
    {
      "epoch": 32.6797385620915,
      "grad_norm": 0.022129077464342117,
      "learning_rate": 0.00020784313725490192,
      "loss": 0.0534,
      "step": 15000
    },
    {
      "epoch": 32.72331154684096,
      "grad_norm": 0.07523844391107559,
      "learning_rate": 0.00020732026143790847,
      "loss": 0.1043,
      "step": 15020
    },
    {
      "epoch": 32.766884531590414,
      "grad_norm": 0.008729607798159122,
      "learning_rate": 0.000206797385620915,
      "loss": 0.0013,
      "step": 15040
    },
    {
      "epoch": 32.810457516339866,
      "grad_norm": 1.8215998411178589,
      "learning_rate": 0.00020627450980392154,
      "loss": 0.0202,
      "step": 15060
    },
    {
      "epoch": 32.854030501089326,
      "grad_norm": 0.004324106499552727,
      "learning_rate": 0.0002057516339869281,
      "loss": 0.0339,
      "step": 15080
    },
    {
      "epoch": 32.89760348583878,
      "grad_norm": 0.002864072099328041,
      "learning_rate": 0.0002052287581699346,
      "loss": 0.0373,
      "step": 15100
    },
    {
      "epoch": 32.94117647058823,
      "grad_norm": 0.0010928979609161615,
      "learning_rate": 0.00020470588235294116,
      "loss": 0.0011,
      "step": 15120
    },
    {
      "epoch": 32.98474945533769,
      "grad_norm": 0.0006349327741190791,
      "learning_rate": 0.00020418300653594768,
      "loss": 0.0034,
      "step": 15140
    },
    {
      "epoch": 33.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9110294117647059,
      "eval_f1": 0.9249999999999999,
      "eval_loss": 0.9352850317955017,
      "eval_runtime": 12.5806,
      "eval_samples_per_second": 32.431,
      "eval_steps_per_second": 4.054,
      "step": 15147
    },
    {
      "epoch": 33.028322440087145,
      "grad_norm": 0.00029584881849586964,
      "learning_rate": 0.00020366013071895423,
      "loss": 0.001,
      "step": 15160
    },
    {
      "epoch": 33.071895424836605,
      "grad_norm": 1.135664463043213,
      "learning_rate": 0.00020313725490196078,
      "loss": 0.0337,
      "step": 15180
    },
    {
      "epoch": 33.11546840958606,
      "grad_norm": 0.007147148251533508,
      "learning_rate": 0.0002026143790849673,
      "loss": 0.0132,
      "step": 15200
    },
    {
      "epoch": 33.15904139433551,
      "grad_norm": 0.004849900957196951,
      "learning_rate": 0.00020209150326797384,
      "loss": 0.0751,
      "step": 15220
    },
    {
      "epoch": 33.20261437908497,
      "grad_norm": 0.0017016794299706817,
      "learning_rate": 0.0002015686274509804,
      "loss": 0.0345,
      "step": 15240
    },
    {
      "epoch": 33.24618736383442,
      "grad_norm": 0.0024465015158057213,
      "learning_rate": 0.0002010457516339869,
      "loss": 0.0128,
      "step": 15260
    },
    {
      "epoch": 33.289760348583876,
      "grad_norm": 0.059485845267772675,
      "learning_rate": 0.00020052287581699346,
      "loss": 0.046,
      "step": 15280
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 0.0026588018517941236,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.0522,
      "step": 15300
    },
    {
      "epoch": 33.37690631808279,
      "grad_norm": 0.0029069725424051285,
      "learning_rate": 0.00019947712418300653,
      "loss": 0.0448,
      "step": 15320
    },
    {
      "epoch": 33.42047930283224,
      "grad_norm": 0.18383470177650452,
      "learning_rate": 0.00019895424836601308,
      "loss": 0.081,
      "step": 15340
    },
    {
      "epoch": 33.4640522875817,
      "grad_norm": 0.06696675717830658,
      "learning_rate": 0.00019843137254901957,
      "loss": 0.0306,
      "step": 15360
    },
    {
      "epoch": 33.507625272331154,
      "grad_norm": 0.0005409162840805948,
      "learning_rate": 0.00019790849673202612,
      "loss": 0.0253,
      "step": 15380
    },
    {
      "epoch": 33.55119825708061,
      "grad_norm": 0.00263051874935627,
      "learning_rate": 0.00019738562091503264,
      "loss": 0.008,
      "step": 15400
    },
    {
      "epoch": 33.59477124183007,
      "grad_norm": 0.015887588262557983,
      "learning_rate": 0.0001968627450980392,
      "loss": 0.0144,
      "step": 15420
    },
    {
      "epoch": 33.63834422657952,
      "grad_norm": 0.00039518444100394845,
      "learning_rate": 0.00019633986928104574,
      "loss": 0.0001,
      "step": 15440
    },
    {
      "epoch": 33.68191721132898,
      "grad_norm": 0.0023090029135346413,
      "learning_rate": 0.00019581699346405226,
      "loss": 0.0518,
      "step": 15460
    },
    {
      "epoch": 33.72549019607843,
      "grad_norm": 0.03123682178556919,
      "learning_rate": 0.0001952941176470588,
      "loss": 0.0003,
      "step": 15480
    },
    {
      "epoch": 33.769063180827885,
      "grad_norm": 0.0018129640957340598,
      "learning_rate": 0.00019477124183006533,
      "loss": 0.0328,
      "step": 15500
    },
    {
      "epoch": 33.812636165577345,
      "grad_norm": 0.0005805114633403718,
      "learning_rate": 0.00019424836601307188,
      "loss": 0.0244,
      "step": 15520
    },
    {
      "epoch": 33.8562091503268,
      "grad_norm": 0.0021564410999417305,
      "learning_rate": 0.00019372549019607842,
      "loss": 0.0366,
      "step": 15540
    },
    {
      "epoch": 33.89978213507625,
      "grad_norm": 12.427529335021973,
      "learning_rate": 0.00019320261437908494,
      "loss": 0.1297,
      "step": 15560
    },
    {
      "epoch": 33.94335511982571,
      "grad_norm": 0.00945666991174221,
      "learning_rate": 0.0001926797385620915,
      "loss": 0.0405,
      "step": 15580
    },
    {
      "epoch": 33.98692810457516,
      "grad_norm": 0.17269845306873322,
      "learning_rate": 0.000192156862745098,
      "loss": 0.0115,
      "step": 15600
    },
    {
      "epoch": 34.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9027021840764775,
      "eval_f1": 0.9181494661921709,
      "eval_loss": 0.8420579433441162,
      "eval_runtime": 12.6222,
      "eval_samples_per_second": 32.324,
      "eval_steps_per_second": 4.04,
      "step": 15606
    },
    {
      "epoch": 34.030501089324616,
      "grad_norm": 1.4102387428283691,
      "learning_rate": 0.00019163398692810456,
      "loss": 0.0996,
      "step": 15620
    },
    {
      "epoch": 34.074074074074076,
      "grad_norm": 0.5592795014381409,
      "learning_rate": 0.0001911111111111111,
      "loss": 0.0282,
      "step": 15640
    },
    {
      "epoch": 34.11764705882353,
      "grad_norm": 0.008343115448951721,
      "learning_rate": 0.00019058823529411763,
      "loss": 0.0387,
      "step": 15660
    },
    {
      "epoch": 34.16122004357298,
      "grad_norm": 0.07060276716947556,
      "learning_rate": 0.00019006535947712418,
      "loss": 0.0482,
      "step": 15680
    },
    {
      "epoch": 34.20479302832244,
      "grad_norm": 36.76689910888672,
      "learning_rate": 0.00018954248366013073,
      "loss": 0.0817,
      "step": 15700
    },
    {
      "epoch": 34.248366013071895,
      "grad_norm": 0.0334990993142128,
      "learning_rate": 0.00018901960784313722,
      "loss": 0.0042,
      "step": 15720
    },
    {
      "epoch": 34.29193899782135,
      "grad_norm": 0.0014448990114033222,
      "learning_rate": 0.0001884967320261438,
      "loss": 0.0242,
      "step": 15740
    },
    {
      "epoch": 34.33551198257081,
      "grad_norm": 0.0003085131465923041,
      "learning_rate": 0.0001879738562091503,
      "loss": 0.0271,
      "step": 15760
    },
    {
      "epoch": 34.37908496732026,
      "grad_norm": 5.392375946044922,
      "learning_rate": 0.00018745098039215684,
      "loss": 0.0342,
      "step": 15780
    },
    {
      "epoch": 34.42265795206972,
      "grad_norm": 7.91786003112793,
      "learning_rate": 0.00018692810457516339,
      "loss": 0.0912,
      "step": 15800
    },
    {
      "epoch": 34.46623093681917,
      "grad_norm": 0.0010814126580953598,
      "learning_rate": 0.0001864052287581699,
      "loss": 0.0024,
      "step": 15820
    },
    {
      "epoch": 34.509803921568626,
      "grad_norm": 0.0005696461303159595,
      "learning_rate": 0.00018588235294117645,
      "loss": 0.113,
      "step": 15840
    },
    {
      "epoch": 34.553376906318086,
      "grad_norm": 0.0004244183946866542,
      "learning_rate": 0.00018535947712418298,
      "loss": 0.0047,
      "step": 15860
    },
    {
      "epoch": 34.59694989106754,
      "grad_norm": 0.007880267687141895,
      "learning_rate": 0.00018483660130718952,
      "loss": 0.0127,
      "step": 15880
    },
    {
      "epoch": 34.64052287581699,
      "grad_norm": 0.7415953278541565,
      "learning_rate": 0.00018431372549019607,
      "loss": 0.0834,
      "step": 15900
    },
    {
      "epoch": 34.68409586056645,
      "grad_norm": 0.0004330268129706383,
      "learning_rate": 0.0001837908496732026,
      "loss": 0.0028,
      "step": 15920
    },
    {
      "epoch": 34.727668845315904,
      "grad_norm": 0.0012190347770228982,
      "learning_rate": 0.00018326797385620914,
      "loss": 0.0087,
      "step": 15940
    },
    {
      "epoch": 34.77124183006536,
      "grad_norm": 7.328620433807373,
      "learning_rate": 0.00018274509803921566,
      "loss": 0.055,
      "step": 15960
    },
    {
      "epoch": 34.81481481481482,
      "grad_norm": 0.0010400546016171575,
      "learning_rate": 0.0001822222222222222,
      "loss": 0.0935,
      "step": 15980
    },
    {
      "epoch": 34.85838779956427,
      "grad_norm": 1.1529709100723267,
      "learning_rate": 0.00018169934640522876,
      "loss": 0.0385,
      "step": 16000
    },
    {
      "epoch": 34.90196078431372,
      "grad_norm": 0.02501765824854374,
      "learning_rate": 0.00018117647058823528,
      "loss": 0.0357,
      "step": 16020
    },
    {
      "epoch": 34.94553376906318,
      "grad_norm": 0.014585654251277447,
      "learning_rate": 0.00018065359477124183,
      "loss": 0.0686,
      "step": 16040
    },
    {
      "epoch": 34.989106753812635,
      "grad_norm": 0.14874733984470367,
      "learning_rate": 0.00018013071895424837,
      "loss": 0.049,
      "step": 16060
    },
    {
      "epoch": 35.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9050299323269131,
      "eval_f1": 0.9203539823008849,
      "eval_loss": 0.7360584139823914,
      "eval_runtime": 12.834,
      "eval_samples_per_second": 31.791,
      "eval_steps_per_second": 3.974,
      "step": 16065
    },
    {
      "epoch": 35.032679738562095,
      "grad_norm": 0.013730491511523724,
      "learning_rate": 0.00017960784313725487,
      "loss": 0.0006,
      "step": 16080
    },
    {
      "epoch": 35.07625272331155,
      "grad_norm": 0.003922554198652506,
      "learning_rate": 0.00017908496732026144,
      "loss": 0.017,
      "step": 16100
    },
    {
      "epoch": 35.119825708061,
      "grad_norm": 0.004270356614142656,
      "learning_rate": 0.00017856209150326794,
      "loss": 0.0104,
      "step": 16120
    },
    {
      "epoch": 35.16339869281046,
      "grad_norm": 0.016235873103141785,
      "learning_rate": 0.00017803921568627449,
      "loss": 0.0002,
      "step": 16140
    },
    {
      "epoch": 35.20697167755991,
      "grad_norm": 0.0020669857040047646,
      "learning_rate": 0.00017751633986928103,
      "loss": 0.0296,
      "step": 16160
    },
    {
      "epoch": 35.250544662309366,
      "grad_norm": 0.001695543061941862,
      "learning_rate": 0.00017699346405228755,
      "loss": 0.0412,
      "step": 16180
    },
    {
      "epoch": 35.294117647058826,
      "grad_norm": 0.04158289358019829,
      "learning_rate": 0.0001764705882352941,
      "loss": 0.0303,
      "step": 16200
    },
    {
      "epoch": 35.33769063180828,
      "grad_norm": 0.005233996547758579,
      "learning_rate": 0.00017594771241830062,
      "loss": 0.065,
      "step": 16220
    },
    {
      "epoch": 35.38126361655773,
      "grad_norm": 0.02592361532151699,
      "learning_rate": 0.00017542483660130717,
      "loss": 0.0375,
      "step": 16240
    },
    {
      "epoch": 35.42483660130719,
      "grad_norm": 0.0011754392180591822,
      "learning_rate": 0.00017490196078431372,
      "loss": 0.0345,
      "step": 16260
    },
    {
      "epoch": 35.468409586056644,
      "grad_norm": 0.0009953479748219252,
      "learning_rate": 0.00017437908496732024,
      "loss": 0.0244,
      "step": 16280
    },
    {
      "epoch": 35.5119825708061,
      "grad_norm": 0.014384905807673931,
      "learning_rate": 0.0001738562091503268,
      "loss": 0.0529,
      "step": 16300
    },
    {
      "epoch": 35.55555555555556,
      "grad_norm": 0.006122971419245005,
      "learning_rate": 0.0001733333333333333,
      "loss": 0.1517,
      "step": 16320
    },
    {
      "epoch": 35.59912854030501,
      "grad_norm": 0.004634889308363199,
      "learning_rate": 0.00017281045751633986,
      "loss": 0.0472,
      "step": 16340
    },
    {
      "epoch": 35.64270152505446,
      "grad_norm": 0.0023166651371866465,
      "learning_rate": 0.0001722875816993464,
      "loss": 0.052,
      "step": 16360
    },
    {
      "epoch": 35.68627450980392,
      "grad_norm": 0.01179228350520134,
      "learning_rate": 0.00017176470588235293,
      "loss": 0.0412,
      "step": 16380
    },
    {
      "epoch": 35.729847494553375,
      "grad_norm": 11.90247917175293,
      "learning_rate": 0.00017124183006535947,
      "loss": 0.017,
      "step": 16400
    },
    {
      "epoch": 35.773420479302835,
      "grad_norm": 0.005600969772785902,
      "learning_rate": 0.00017071895424836602,
      "loss": 0.0405,
      "step": 16420
    },
    {
      "epoch": 35.81699346405229,
      "grad_norm": 0.002981937723234296,
      "learning_rate": 0.00017019607843137252,
      "loss": 0.0018,
      "step": 16440
    },
    {
      "epoch": 35.86056644880174,
      "grad_norm": 25.47518539428711,
      "learning_rate": 0.0001696732026143791,
      "loss": 0.0442,
      "step": 16460
    },
    {
      "epoch": 35.9041394335512,
      "grad_norm": 0.06479838490486145,
      "learning_rate": 0.00016915032679738559,
      "loss": 0.0004,
      "step": 16480
    },
    {
      "epoch": 35.947712418300654,
      "grad_norm": 0.0014938270905986428,
      "learning_rate": 0.00016862745098039213,
      "loss": 0.0461,
      "step": 16500
    },
    {
      "epoch": 35.99128540305011,
      "grad_norm": 0.0018683784874156117,
      "learning_rate": 0.00016810457516339868,
      "loss": 0.0003,
      "step": 16520
    },
    {
      "epoch": 36.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9031344932339133,
      "eval_f1": 0.9190140845070423,
      "eval_loss": 0.988752007484436,
      "eval_runtime": 12.5339,
      "eval_samples_per_second": 32.552,
      "eval_steps_per_second": 4.069,
      "step": 16524
    },
    {
      "epoch": 36.03485838779957,
      "grad_norm": 0.1709124743938446,
      "learning_rate": 0.0001675816993464052,
      "loss": 0.0601,
      "step": 16540
    },
    {
      "epoch": 36.07843137254902,
      "grad_norm": 0.11691129952669144,
      "learning_rate": 0.00016705882352941175,
      "loss": 0.0388,
      "step": 16560
    },
    {
      "epoch": 36.12200435729847,
      "grad_norm": 0.0015267146518453956,
      "learning_rate": 0.00016653594771241827,
      "loss": 0.0926,
      "step": 16580
    },
    {
      "epoch": 36.16557734204793,
      "grad_norm": 0.0023461829405277967,
      "learning_rate": 0.00016601307189542482,
      "loss": 0.0489,
      "step": 16600
    },
    {
      "epoch": 36.209150326797385,
      "grad_norm": 0.0026810842100530863,
      "learning_rate": 0.00016549019607843137,
      "loss": 0.0136,
      "step": 16620
    },
    {
      "epoch": 36.25272331154684,
      "grad_norm": 0.007984914816915989,
      "learning_rate": 0.0001649673202614379,
      "loss": 0.0124,
      "step": 16640
    },
    {
      "epoch": 36.2962962962963,
      "grad_norm": 0.0010018863249570131,
      "learning_rate": 0.00016444444444444444,
      "loss": 0.0151,
      "step": 16660
    },
    {
      "epoch": 36.33986928104575,
      "grad_norm": 0.025451427325606346,
      "learning_rate": 0.00016392156862745096,
      "loss": 0.0881,
      "step": 16680
    },
    {
      "epoch": 36.38344226579521,
      "grad_norm": 0.0021243474911898375,
      "learning_rate": 0.0001633986928104575,
      "loss": 0.0273,
      "step": 16700
    },
    {
      "epoch": 36.42701525054466,
      "grad_norm": 0.038293469697237015,
      "learning_rate": 0.00016287581699346405,
      "loss": 0.0089,
      "step": 16720
    },
    {
      "epoch": 36.470588235294116,
      "grad_norm": 0.0012710214359685779,
      "learning_rate": 0.00016235294117647057,
      "loss": 0.0622,
      "step": 16740
    },
    {
      "epoch": 36.514161220043576,
      "grad_norm": 0.0009081201860681176,
      "learning_rate": 0.00016183006535947712,
      "loss": 0.0063,
      "step": 16760
    },
    {
      "epoch": 36.55773420479303,
      "grad_norm": 0.0003165487723890692,
      "learning_rate": 0.00016130718954248367,
      "loss": 0.0008,
      "step": 16780
    },
    {
      "epoch": 36.60130718954248,
      "grad_norm": 0.3566296100616455,
      "learning_rate": 0.00016078431372549016,
      "loss": 0.0003,
      "step": 16800
    },
    {
      "epoch": 36.64488017429194,
      "grad_norm": 0.0021148642990738153,
      "learning_rate": 0.00016026143790849674,
      "loss": 0.0458,
      "step": 16820
    },
    {
      "epoch": 36.688453159041394,
      "grad_norm": 11.938272476196289,
      "learning_rate": 0.00015973856209150323,
      "loss": 0.1372,
      "step": 16840
    },
    {
      "epoch": 36.73202614379085,
      "grad_norm": 0.004238510504364967,
      "learning_rate": 0.00015921568627450978,
      "loss": 0.0774,
      "step": 16860
    },
    {
      "epoch": 36.77559912854031,
      "grad_norm": 0.324283629655838,
      "learning_rate": 0.00015869281045751633,
      "loss": 0.0464,
      "step": 16880
    },
    {
      "epoch": 36.81917211328976,
      "grad_norm": 8.27441692352295,
      "learning_rate": 0.00015816993464052285,
      "loss": 0.0173,
      "step": 16900
    },
    {
      "epoch": 36.86274509803921,
      "grad_norm": 0.0032318648882210255,
      "learning_rate": 0.0001576470588235294,
      "loss": 0.0358,
      "step": 16920
    },
    {
      "epoch": 36.90631808278867,
      "grad_norm": 0.0060061002150177956,
      "learning_rate": 0.00015712418300653592,
      "loss": 0.0349,
      "step": 16940
    },
    {
      "epoch": 36.949891067538125,
      "grad_norm": 0.0008400760707445443,
      "learning_rate": 0.00015660130718954247,
      "loss": 0.0729,
      "step": 16960
    },
    {
      "epoch": 36.99346405228758,
      "grad_norm": 0.0019965507090091705,
      "learning_rate": 0.00015607843137254901,
      "loss": 0.0005,
      "step": 16980
    },
    {
      "epoch": 37.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9032765737874097,
      "eval_f1": 0.9192982456140351,
      "eval_loss": 0.9544193148612976,
      "eval_runtime": 12.6501,
      "eval_samples_per_second": 32.253,
      "eval_steps_per_second": 4.032,
      "step": 16983
    },
    {
      "epoch": 37.03703703703704,
      "grad_norm": 0.0005455846549011767,
      "learning_rate": 0.00015555555555555554,
      "loss": 0.0004,
      "step": 17000
    },
    {
      "epoch": 37.08061002178649,
      "grad_norm": 1.0319466590881348,
      "learning_rate": 0.00015503267973856208,
      "loss": 0.022,
      "step": 17020
    },
    {
      "epoch": 37.12418300653595,
      "grad_norm": 0.003997421823441982,
      "learning_rate": 0.0001545098039215686,
      "loss": 0.0367,
      "step": 17040
    },
    {
      "epoch": 37.167755991285404,
      "grad_norm": 0.7186359763145447,
      "learning_rate": 0.00015398692810457515,
      "loss": 0.0177,
      "step": 17060
    },
    {
      "epoch": 37.21132897603486,
      "grad_norm": 0.007672574371099472,
      "learning_rate": 0.0001534640522875817,
      "loss": 0.0211,
      "step": 17080
    },
    {
      "epoch": 37.254901960784316,
      "grad_norm": 0.0008848830475471914,
      "learning_rate": 0.00015294117647058822,
      "loss": 0.0075,
      "step": 17100
    },
    {
      "epoch": 37.29847494553377,
      "grad_norm": 0.018666179850697517,
      "learning_rate": 0.00015241830065359477,
      "loss": 0.041,
      "step": 17120
    },
    {
      "epoch": 37.34204793028322,
      "grad_norm": 0.0020481848623603582,
      "learning_rate": 0.00015189542483660132,
      "loss": 0.0221,
      "step": 17140
    },
    {
      "epoch": 37.38562091503268,
      "grad_norm": 0.0016293395310640335,
      "learning_rate": 0.0001513725490196078,
      "loss": 0.0478,
      "step": 17160
    },
    {
      "epoch": 37.429193899782135,
      "grad_norm": 0.004795080982148647,
      "learning_rate": 0.0001508496732026144,
      "loss": 0.037,
      "step": 17180
    },
    {
      "epoch": 37.47276688453159,
      "grad_norm": 0.0006621640059165657,
      "learning_rate": 0.00015032679738562088,
      "loss": 0.0134,
      "step": 17200
    },
    {
      "epoch": 37.51633986928105,
      "grad_norm": 0.00032661878503859043,
      "learning_rate": 0.00014980392156862743,
      "loss": 0.0383,
      "step": 17220
    },
    {
      "epoch": 37.5599128540305,
      "grad_norm": 0.38023287057876587,
      "learning_rate": 0.00014928104575163398,
      "loss": 0.0078,
      "step": 17240
    },
    {
      "epoch": 37.60348583877995,
      "grad_norm": 0.015642335638403893,
      "learning_rate": 0.0001487581699346405,
      "loss": 0.0001,
      "step": 17260
    },
    {
      "epoch": 37.64705882352941,
      "grad_norm": 0.0018568347441032529,
      "learning_rate": 0.00014823529411764705,
      "loss": 0.1302,
      "step": 17280
    },
    {
      "epoch": 37.690631808278866,
      "grad_norm": 0.4904978573322296,
      "learning_rate": 0.0001477124183006536,
      "loss": 0.0724,
      "step": 17300
    },
    {
      "epoch": 37.734204793028326,
      "grad_norm": 0.10077843815088272,
      "learning_rate": 0.00014718954248366011,
      "loss": 0.0471,
      "step": 17320
    },
    {
      "epoch": 37.77777777777778,
      "grad_norm": 0.0004328012000769377,
      "learning_rate": 0.00014666666666666664,
      "loss": 0.0129,
      "step": 17340
    },
    {
      "epoch": 37.82135076252723,
      "grad_norm": 0.0025920860935002565,
      "learning_rate": 0.0001461437908496732,
      "loss": 0.045,
      "step": 17360
    },
    {
      "epoch": 37.86492374727669,
      "grad_norm": 0.011905551888048649,
      "learning_rate": 0.00014562091503267973,
      "loss": 0.0089,
      "step": 17380
    },
    {
      "epoch": 37.908496732026144,
      "grad_norm": 0.0004267209442332387,
      "learning_rate": 0.00014509803921568625,
      "loss": 0.0014,
      "step": 17400
    },
    {
      "epoch": 37.9520697167756,
      "grad_norm": 0.002873850055038929,
      "learning_rate": 0.0001445751633986928,
      "loss": 0.0001,
      "step": 17420
    },
    {
      "epoch": 37.99564270152506,
      "grad_norm": 0.004642813932150602,
      "learning_rate": 0.00014405228758169932,
      "loss": 0.0227,
      "step": 17440
    },
    {
      "epoch": 38.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9048884651551561,
      "eval_f1": 0.9200710479573712,
      "eval_loss": 0.9602434039115906,
      "eval_runtime": 13.2824,
      "eval_samples_per_second": 30.717,
      "eval_steps_per_second": 3.84,
      "step": 17442
    },
    {
      "epoch": 38.03921568627451,
      "grad_norm": 0.0003165407106280327,
      "learning_rate": 0.00014352941176470587,
      "loss": 0.0278,
      "step": 17460
    },
    {
      "epoch": 38.08278867102396,
      "grad_norm": 0.3606679439544678,
      "learning_rate": 0.00014300653594771242,
      "loss": 0.0362,
      "step": 17480
    },
    {
      "epoch": 38.12636165577342,
      "grad_norm": 0.0003992778656538576,
      "learning_rate": 0.00014248366013071894,
      "loss": 0.0282,
      "step": 17500
    },
    {
      "epoch": 38.169934640522875,
      "grad_norm": 0.0006653352756984532,
      "learning_rate": 0.00014196078431372546,
      "loss": 0.0222,
      "step": 17520
    },
    {
      "epoch": 38.21350762527233,
      "grad_norm": 0.00046088933595456183,
      "learning_rate": 0.00014143790849673203,
      "loss": 0.0121,
      "step": 17540
    },
    {
      "epoch": 38.25708061002179,
      "grad_norm": 0.00046308073797263205,
      "learning_rate": 0.00014091503267973856,
      "loss": 0.0481,
      "step": 17560
    },
    {
      "epoch": 38.30065359477124,
      "grad_norm": 4.322265625,
      "learning_rate": 0.00014039215686274508,
      "loss": 0.0426,
      "step": 17580
    },
    {
      "epoch": 38.3442265795207,
      "grad_norm": 0.00020228316134307534,
      "learning_rate": 0.00013986928104575162,
      "loss": 0.0708,
      "step": 17600
    },
    {
      "epoch": 38.38779956427015,
      "grad_norm": 0.011863380670547485,
      "learning_rate": 0.00013934640522875815,
      "loss": 0.0593,
      "step": 17620
    },
    {
      "epoch": 38.431372549019606,
      "grad_norm": 0.007577193900942802,
      "learning_rate": 0.0001388235294117647,
      "loss": 0.0296,
      "step": 17640
    },
    {
      "epoch": 38.474945533769066,
      "grad_norm": 0.042621295899152756,
      "learning_rate": 0.00013830065359477124,
      "loss": 0.0022,
      "step": 17660
    },
    {
      "epoch": 38.51851851851852,
      "grad_norm": 6.4629716873168945,
      "learning_rate": 0.00013777777777777776,
      "loss": 0.0013,
      "step": 17680
    },
    {
      "epoch": 38.56209150326797,
      "grad_norm": 1.7880949974060059,
      "learning_rate": 0.00013725490196078428,
      "loss": 0.0172,
      "step": 17700
    },
    {
      "epoch": 38.60566448801743,
      "grad_norm": 4.230949878692627,
      "learning_rate": 0.00013673202614379086,
      "loss": 0.039,
      "step": 17720
    },
    {
      "epoch": 38.649237472766885,
      "grad_norm": 0.07119037955999374,
      "learning_rate": 0.00013620915032679738,
      "loss": 0.0034,
      "step": 17740
    },
    {
      "epoch": 38.69281045751634,
      "grad_norm": 0.004835746716707945,
      "learning_rate": 0.0001356862745098039,
      "loss": 0.0908,
      "step": 17760
    },
    {
      "epoch": 38.7363834422658,
      "grad_norm": 0.0004535967600531876,
      "learning_rate": 0.00013516339869281045,
      "loss": 0.0002,
      "step": 17780
    },
    {
      "epoch": 38.77995642701525,
      "grad_norm": 0.00012144027277827263,
      "learning_rate": 0.00013464052287581697,
      "loss": 0.0013,
      "step": 17800
    },
    {
      "epoch": 38.8235294117647,
      "grad_norm": 21.224761962890625,
      "learning_rate": 0.00013411764705882352,
      "loss": 0.0282,
      "step": 17820
    },
    {
      "epoch": 38.86710239651416,
      "grad_norm": 0.004762774799019098,
      "learning_rate": 0.00013359477124183007,
      "loss": 0.0239,
      "step": 17840
    },
    {
      "epoch": 38.910675381263616,
      "grad_norm": 0.010438930243253708,
      "learning_rate": 0.0001330718954248366,
      "loss": 0.0258,
      "step": 17860
    },
    {
      "epoch": 38.95424836601307,
      "grad_norm": 0.14449456334114075,
      "learning_rate": 0.0001325490196078431,
      "loss": 0.0033,
      "step": 17880
    },
    {
      "epoch": 38.99782135076253,
      "grad_norm": 0.0019609276205301285,
      "learning_rate": 0.00013202614379084966,
      "loss": 0.0002,
      "step": 17900
    },
    {
      "epoch": 39.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9067927170868348,
      "eval_f1": 0.9214285714285715,
      "eval_loss": 1.0117645263671875,
      "eval_runtime": 13.1453,
      "eval_samples_per_second": 31.038,
      "eval_steps_per_second": 3.88,
      "step": 17901
    },
    {
      "epoch": 39.04139433551198,
      "grad_norm": 47.88030242919922,
      "learning_rate": 0.0001315032679738562,
      "loss": 0.0941,
      "step": 17920
    },
    {
      "epoch": 39.08496732026144,
      "grad_norm": 0.004605734720826149,
      "learning_rate": 0.00013098039215686272,
      "loss": 0.0355,
      "step": 17940
    },
    {
      "epoch": 39.128540305010894,
      "grad_norm": 0.01964309625327587,
      "learning_rate": 0.00013045751633986927,
      "loss": 0.0005,
      "step": 17960
    },
    {
      "epoch": 39.17211328976035,
      "grad_norm": 0.0001626859448151663,
      "learning_rate": 0.0001299346405228758,
      "loss": 0.0005,
      "step": 17980
    },
    {
      "epoch": 39.21568627450981,
      "grad_norm": 9.97052001953125,
      "learning_rate": 0.00012941176470588234,
      "loss": 0.0493,
      "step": 18000
    },
    {
      "epoch": 39.25925925925926,
      "grad_norm": 0.005010932683944702,
      "learning_rate": 0.0001288888888888889,
      "loss": 0.058,
      "step": 18020
    },
    {
      "epoch": 39.30283224400871,
      "grad_norm": 0.0043792203068733215,
      "learning_rate": 0.0001283660130718954,
      "loss": 0.0551,
      "step": 18040
    },
    {
      "epoch": 39.34640522875817,
      "grad_norm": 0.0016690047923475504,
      "learning_rate": 0.00012784313725490193,
      "loss": 0.03,
      "step": 18060
    },
    {
      "epoch": 39.389978213507625,
      "grad_norm": 0.0035457981284707785,
      "learning_rate": 0.00012732026143790848,
      "loss": 0.0282,
      "step": 18080
    },
    {
      "epoch": 39.43355119825708,
      "grad_norm": 0.0028097794856876135,
      "learning_rate": 0.00012679738562091503,
      "loss": 0.0012,
      "step": 18100
    },
    {
      "epoch": 39.47712418300654,
      "grad_norm": 0.006825011223554611,
      "learning_rate": 0.00012627450980392155,
      "loss": 0.0045,
      "step": 18120
    },
    {
      "epoch": 39.52069716775599,
      "grad_norm": 39.750022888183594,
      "learning_rate": 0.0001257516339869281,
      "loss": 0.0291,
      "step": 18140
    },
    {
      "epoch": 39.56427015250544,
      "grad_norm": 0.0009441303554922342,
      "learning_rate": 0.00012522875816993462,
      "loss": 0.0006,
      "step": 18160
    },
    {
      "epoch": 39.6078431372549,
      "grad_norm": 0.00027122595929540694,
      "learning_rate": 0.00012470588235294117,
      "loss": 0.0308,
      "step": 18180
    },
    {
      "epoch": 39.651416122004356,
      "grad_norm": 0.0061135925352573395,
      "learning_rate": 0.00012418300653594771,
      "loss": 0.0003,
      "step": 18200
    },
    {
      "epoch": 39.694989106753816,
      "grad_norm": 9.98872346826829e-05,
      "learning_rate": 0.00012366013071895423,
      "loss": 0.0367,
      "step": 18220
    },
    {
      "epoch": 39.73856209150327,
      "grad_norm": 0.005920860450714827,
      "learning_rate": 0.00012313725490196078,
      "loss": 0.11,
      "step": 18240
    },
    {
      "epoch": 39.78213507625272,
      "grad_norm": 0.00013456036685965955,
      "learning_rate": 0.0001226143790849673,
      "loss": 0.0845,
      "step": 18260
    },
    {
      "epoch": 39.82570806100218,
      "grad_norm": 0.3912019431591034,
      "learning_rate": 0.00012209150326797385,
      "loss": 0.0206,
      "step": 18280
    },
    {
      "epoch": 39.869281045751634,
      "grad_norm": 0.00015417320537380874,
      "learning_rate": 0.00012156862745098039,
      "loss": 0.0021,
      "step": 18300
    },
    {
      "epoch": 39.91285403050109,
      "grad_norm": 0.0007665434386581182,
      "learning_rate": 0.00012104575163398692,
      "loss": 0.0968,
      "step": 18320
    },
    {
      "epoch": 39.95642701525055,
      "grad_norm": 0.0003696322091855109,
      "learning_rate": 0.00012052287581699344,
      "loss": 0.0001,
      "step": 18340
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.00022934129810892045,
      "learning_rate": 0.00011999999999999999,
      "loss": 0.0006,
      "step": 18360
    },
    {
      "epoch": 40.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9031344932339133,
      "eval_f1": 0.9190140845070423,
      "eval_loss": 1.021765947341919,
      "eval_runtime": 13.3177,
      "eval_samples_per_second": 30.636,
      "eval_steps_per_second": 3.829,
      "step": 18360
    },
    {
      "epoch": 40.04357298474945,
      "grad_norm": 0.12446512281894684,
      "learning_rate": 0.00011947712418300652,
      "loss": 0.0685,
      "step": 18380
    },
    {
      "epoch": 40.08714596949891,
      "grad_norm": 0.0018059253925457597,
      "learning_rate": 0.00011895424836601306,
      "loss": 0.0235,
      "step": 18400
    },
    {
      "epoch": 40.130718954248366,
      "grad_norm": 0.03943483531475067,
      "learning_rate": 0.00011843137254901959,
      "loss": 0.0001,
      "step": 18420
    },
    {
      "epoch": 40.17429193899782,
      "grad_norm": 0.0053922091610729694,
      "learning_rate": 0.00011790849673202613,
      "loss": 0.0048,
      "step": 18440
    },
    {
      "epoch": 40.21786492374728,
      "grad_norm": 0.004433267284184694,
      "learning_rate": 0.00011738562091503268,
      "loss": 0.0094,
      "step": 18460
    },
    {
      "epoch": 40.26143790849673,
      "grad_norm": 35.477027893066406,
      "learning_rate": 0.00011686274509803921,
      "loss": 0.0984,
      "step": 18480
    },
    {
      "epoch": 40.305010893246184,
      "grad_norm": 0.33253800868988037,
      "learning_rate": 0.00011633986928104574,
      "loss": 0.062,
      "step": 18500
    },
    {
      "epoch": 40.348583877995644,
      "grad_norm": 0.000998907838948071,
      "learning_rate": 0.00011581699346405227,
      "loss": 0.0001,
      "step": 18520
    },
    {
      "epoch": 40.3921568627451,
      "grad_norm": 17.818784713745117,
      "learning_rate": 0.00011529411764705881,
      "loss": 0.016,
      "step": 18540
    },
    {
      "epoch": 40.43572984749456,
      "grad_norm": 0.0012367271119728684,
      "learning_rate": 0.00011477124183006535,
      "loss": 0.0005,
      "step": 18560
    },
    {
      "epoch": 40.47930283224401,
      "grad_norm": 0.0008722238126210868,
      "learning_rate": 0.00011424836601307188,
      "loss": 0.0329,
      "step": 18580
    },
    {
      "epoch": 40.52287581699346,
      "grad_norm": 0.00041059800423681736,
      "learning_rate": 0.00011372549019607842,
      "loss": 0.0632,
      "step": 18600
    },
    {
      "epoch": 40.56644880174292,
      "grad_norm": 0.76601642370224,
      "learning_rate": 0.00011320261437908495,
      "loss": 0.0036,
      "step": 18620
    },
    {
      "epoch": 40.610021786492375,
      "grad_norm": 0.0008322198991663754,
      "learning_rate": 0.0001126797385620915,
      "loss": 0.0028,
      "step": 18640
    },
    {
      "epoch": 40.65359477124183,
      "grad_norm": 0.00048103267909027636,
      "learning_rate": 0.00011215686274509803,
      "loss": 0.0527,
      "step": 18660
    },
    {
      "epoch": 40.69716775599129,
      "grad_norm": 0.8118064999580383,
      "learning_rate": 0.00011163398692810457,
      "loss": 0.0599,
      "step": 18680
    },
    {
      "epoch": 40.74074074074074,
      "grad_norm": 0.0005926932208240032,
      "learning_rate": 0.00011111111111111109,
      "loss": 0.0,
      "step": 18700
    },
    {
      "epoch": 40.78431372549019,
      "grad_norm": 0.02206679806113243,
      "learning_rate": 0.00011058823529411765,
      "loss": 0.0051,
      "step": 18720
    },
    {
      "epoch": 40.82788671023965,
      "grad_norm": 0.001882385928183794,
      "learning_rate": 0.00011006535947712417,
      "loss": 0.0023,
      "step": 18740
    },
    {
      "epoch": 40.871459694989106,
      "grad_norm": 0.00021047762129455805,
      "learning_rate": 0.0001095424836601307,
      "loss": 0.0284,
      "step": 18760
    },
    {
      "epoch": 40.91503267973856,
      "grad_norm": 0.0006807681056670845,
      "learning_rate": 0.00010901960784313724,
      "loss": 0.0199,
      "step": 18780
    },
    {
      "epoch": 40.95860566448802,
      "grad_norm": 0.0006660119397565722,
      "learning_rate": 0.00010849673202614378,
      "loss": 0.0326,
      "step": 18800
    },
    {
      "epoch": 41.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8989229494614748,
      "eval_f1": 0.915492957746479,
      "eval_loss": 0.9874167442321777,
      "eval_runtime": 13.3157,
      "eval_samples_per_second": 30.641,
      "eval_steps_per_second": 3.83,
      "step": 18819
    },
    {
      "epoch": 41.00217864923747,
      "grad_norm": 0.0020518696401268244,
      "learning_rate": 0.00010797385620915032,
      "loss": 0.1778,
      "step": 18820
    },
    {
      "epoch": 41.04575163398693,
      "grad_norm": 0.001155880163423717,
      "learning_rate": 0.00010745098039215686,
      "loss": 0.0271,
      "step": 18840
    },
    {
      "epoch": 41.089324618736384,
      "grad_norm": 12.081568717956543,
      "learning_rate": 0.00010692810457516339,
      "loss": 0.0458,
      "step": 18860
    },
    {
      "epoch": 41.13289760348584,
      "grad_norm": 0.0018366167787462473,
      "learning_rate": 0.00010640522875816991,
      "loss": 0.0001,
      "step": 18880
    },
    {
      "epoch": 41.1764705882353,
      "grad_norm": 0.03341252729296684,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.1305,
      "step": 18900
    },
    {
      "epoch": 41.22004357298475,
      "grad_norm": 24.480466842651367,
      "learning_rate": 0.000105359477124183,
      "loss": 0.0341,
      "step": 18920
    },
    {
      "epoch": 41.2636165577342,
      "grad_norm": 0.11075459420681,
      "learning_rate": 0.00010483660130718953,
      "loss": 0.0299,
      "step": 18940
    },
    {
      "epoch": 41.30718954248366,
      "grad_norm": 0.48968321084976196,
      "learning_rate": 0.00010431372549019606,
      "loss": 0.0638,
      "step": 18960
    },
    {
      "epoch": 41.350762527233115,
      "grad_norm": 0.0010985725093632936,
      "learning_rate": 0.0001037908496732026,
      "loss": 0.003,
      "step": 18980
    },
    {
      "epoch": 41.39433551198257,
      "grad_norm": 6.276528358459473,
      "learning_rate": 0.00010326797385620915,
      "loss": 0.0337,
      "step": 19000
    },
    {
      "epoch": 41.43790849673203,
      "grad_norm": 0.010600722394883633,
      "learning_rate": 0.00010274509803921568,
      "loss": 0.0552,
      "step": 19020
    },
    {
      "epoch": 41.48148148148148,
      "grad_norm": 0.007361565250903368,
      "learning_rate": 0.00010222222222222222,
      "loss": 0.0066,
      "step": 19040
    },
    {
      "epoch": 41.525054466230934,
      "grad_norm": 39.9346809387207,
      "learning_rate": 0.00010169934640522874,
      "loss": 0.087,
      "step": 19060
    },
    {
      "epoch": 41.568627450980394,
      "grad_norm": 0.0024749203585088253,
      "learning_rate": 0.0001011764705882353,
      "loss": 0.0304,
      "step": 19080
    },
    {
      "epoch": 41.61220043572985,
      "grad_norm": 0.001023275894112885,
      "learning_rate": 0.00010065359477124182,
      "loss": 0.0021,
      "step": 19100
    },
    {
      "epoch": 41.655773420479306,
      "grad_norm": 0.0013487599790096283,
      "learning_rate": 0.00010013071895424835,
      "loss": 0.0489,
      "step": 19120
    },
    {
      "epoch": 41.69934640522876,
      "grad_norm": 0.0063069541938602924,
      "learning_rate": 9.960784313725489e-05,
      "loss": 0.0021,
      "step": 19140
    },
    {
      "epoch": 41.74291938997821,
      "grad_norm": 0.00267209904268384,
      "learning_rate": 9.908496732026142e-05,
      "loss": 0.0082,
      "step": 19160
    },
    {
      "epoch": 41.78649237472767,
      "grad_norm": 0.003286242252215743,
      "learning_rate": 9.856209150326797e-05,
      "loss": 0.0384,
      "step": 19180
    },
    {
      "epoch": 41.830065359477125,
      "grad_norm": 8.125187873840332,
      "learning_rate": 9.80392156862745e-05,
      "loss": 0.0545,
      "step": 19200
    },
    {
      "epoch": 41.87363834422658,
      "grad_norm": 0.003469337709248066,
      "learning_rate": 9.751633986928104e-05,
      "loss": 0.0336,
      "step": 19220
    },
    {
      "epoch": 41.91721132897604,
      "grad_norm": 14.526869773864746,
      "learning_rate": 9.699346405228756e-05,
      "loss": 0.005,
      "step": 19240
    },
    {
      "epoch": 41.96078431372549,
      "grad_norm": 0.0008634939440526068,
      "learning_rate": 9.647058823529412e-05,
      "loss": 0.0001,
      "step": 19260
    },
    {
      "epoch": 42.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9048884651551561,
      "eval_f1": 0.9200710479573712,
      "eval_loss": 0.8561720252037048,
      "eval_runtime": 13.317,
      "eval_samples_per_second": 30.637,
      "eval_steps_per_second": 3.83,
      "step": 19278
    },
    {
      "epoch": 42.00435729847494,
      "grad_norm": 69.91690826416016,
      "learning_rate": 9.594771241830064e-05,
      "loss": 0.077,
      "step": 19280
    },
    {
      "epoch": 42.0479302832244,
      "grad_norm": 0.006145368795841932,
      "learning_rate": 9.542483660130718e-05,
      "loss": 0.0007,
      "step": 19300
    },
    {
      "epoch": 42.091503267973856,
      "grad_norm": 17.06403160095215,
      "learning_rate": 9.490196078431371e-05,
      "loss": 0.0137,
      "step": 19320
    },
    {
      "epoch": 42.13507625272331,
      "grad_norm": 43.93882751464844,
      "learning_rate": 9.437908496732025e-05,
      "loss": 0.0172,
      "step": 19340
    },
    {
      "epoch": 42.17864923747277,
      "grad_norm": 0.0033295266330242157,
      "learning_rate": 9.38562091503268e-05,
      "loss": 0.0025,
      "step": 19360
    },
    {
      "epoch": 42.22222222222222,
      "grad_norm": 0.004495385568588972,
      "learning_rate": 9.333333333333333e-05,
      "loss": 0.0805,
      "step": 19380
    },
    {
      "epoch": 42.265795206971674,
      "grad_norm": 0.0020236163400113583,
      "learning_rate": 9.281045751633986e-05,
      "loss": 0.0211,
      "step": 19400
    },
    {
      "epoch": 42.309368191721134,
      "grad_norm": 0.7419747710227966,
      "learning_rate": 9.228758169934639e-05,
      "loss": 0.032,
      "step": 19420
    },
    {
      "epoch": 42.35294117647059,
      "grad_norm": 0.004234721418470144,
      "learning_rate": 9.176470588235295e-05,
      "loss": 0.0032,
      "step": 19440
    },
    {
      "epoch": 42.39651416122005,
      "grad_norm": 0.00038579985266551375,
      "learning_rate": 9.124183006535947e-05,
      "loss": 0.0024,
      "step": 19460
    },
    {
      "epoch": 42.4400871459695,
      "grad_norm": 0.0005849295994266868,
      "learning_rate": 9.0718954248366e-05,
      "loss": 0.0038,
      "step": 19480
    },
    {
      "epoch": 42.48366013071895,
      "grad_norm": 0.000372359121683985,
      "learning_rate": 9.019607843137254e-05,
      "loss": 0.0001,
      "step": 19500
    },
    {
      "epoch": 42.52723311546841,
      "grad_norm": 0.0007826015935279429,
      "learning_rate": 8.967320261437907e-05,
      "loss": 0.0008,
      "step": 19520
    },
    {
      "epoch": 42.570806100217865,
      "grad_norm": 0.004776094574481249,
      "learning_rate": 8.915032679738562e-05,
      "loss": 0.0457,
      "step": 19540
    },
    {
      "epoch": 42.61437908496732,
      "grad_norm": 0.0020141571294516325,
      "learning_rate": 8.862745098039215e-05,
      "loss": 0.0366,
      "step": 19560
    },
    {
      "epoch": 42.65795206971678,
      "grad_norm": 13.363088607788086,
      "learning_rate": 8.810457516339869e-05,
      "loss": 0.0451,
      "step": 19580
    },
    {
      "epoch": 42.70152505446623,
      "grad_norm": 0.003256981261074543,
      "learning_rate": 8.758169934640521e-05,
      "loss": 0.0283,
      "step": 19600
    },
    {
      "epoch": 42.745098039215684,
      "grad_norm": 8.402279490837827e-05,
      "learning_rate": 8.705882352941177e-05,
      "loss": 0.0066,
      "step": 19620
    },
    {
      "epoch": 42.78867102396514,
      "grad_norm": 0.36109504103660583,
      "learning_rate": 8.653594771241829e-05,
      "loss": 0.0086,
      "step": 19640
    },
    {
      "epoch": 42.832244008714596,
      "grad_norm": 0.0010380776366218925,
      "learning_rate": 8.601307189542483e-05,
      "loss": 0.0012,
      "step": 19660
    },
    {
      "epoch": 42.87581699346405,
      "grad_norm": 0.0006972660194151103,
      "learning_rate": 8.549019607843136e-05,
      "loss": 0.0042,
      "step": 19680
    },
    {
      "epoch": 42.91938997821351,
      "grad_norm": 0.0014476205687969923,
      "learning_rate": 8.49673202614379e-05,
      "loss": 0.0344,
      "step": 19700
    },
    {
      "epoch": 42.96296296296296,
      "grad_norm": 0.00038687122287228703,
      "learning_rate": 8.444444444444444e-05,
      "loss": 0.0076,
      "step": 19720
    },
    {
      "epoch": 43.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8986232790988735,
      "eval_f1": 0.9148936170212766,
      "eval_loss": 0.9055674076080322,
      "eval_runtime": 13.1949,
      "eval_samples_per_second": 30.921,
      "eval_steps_per_second": 3.865,
      "step": 19737
    },
    {
      "epoch": 43.00653594771242,
      "grad_norm": 0.6788364052772522,
      "learning_rate": 8.392156862745098e-05,
      "loss": 0.0573,
      "step": 19740
    },
    {
      "epoch": 43.050108932461875,
      "grad_norm": 3.3002521991729736,
      "learning_rate": 8.339869281045751e-05,
      "loss": 0.0196,
      "step": 19760
    },
    {
      "epoch": 43.09368191721133,
      "grad_norm": 0.0020431021694093943,
      "learning_rate": 8.287581699346403e-05,
      "loss": 0.0376,
      "step": 19780
    },
    {
      "epoch": 43.13725490196079,
      "grad_norm": 11.085297584533691,
      "learning_rate": 8.23529411764706e-05,
      "loss": 0.0391,
      "step": 19800
    },
    {
      "epoch": 43.18082788671024,
      "grad_norm": 3.5464303493499756,
      "learning_rate": 8.183006535947712e-05,
      "loss": 0.0012,
      "step": 19820
    },
    {
      "epoch": 43.22440087145969,
      "grad_norm": 0.15722520649433136,
      "learning_rate": 8.130718954248365e-05,
      "loss": 0.0312,
      "step": 19840
    },
    {
      "epoch": 43.26797385620915,
      "grad_norm": 0.05445287004113197,
      "learning_rate": 8.078431372549018e-05,
      "loss": 0.0004,
      "step": 19860
    },
    {
      "epoch": 43.311546840958606,
      "grad_norm": 0.0018092092359438539,
      "learning_rate": 8.026143790849672e-05,
      "loss": 0.0113,
      "step": 19880
    },
    {
      "epoch": 43.35511982570806,
      "grad_norm": 0.0006371918134391308,
      "learning_rate": 7.973856209150327e-05,
      "loss": 0.0238,
      "step": 19900
    },
    {
      "epoch": 43.39869281045752,
      "grad_norm": 0.0314212292432785,
      "learning_rate": 7.92156862745098e-05,
      "loss": 0.0073,
      "step": 19920
    },
    {
      "epoch": 43.44226579520697,
      "grad_norm": 0.03325018286705017,
      "learning_rate": 7.869281045751634e-05,
      "loss": 0.0257,
      "step": 19940
    },
    {
      "epoch": 43.485838779956424,
      "grad_norm": 0.00019928325491491705,
      "learning_rate": 7.816993464052286e-05,
      "loss": 0.0307,
      "step": 19960
    },
    {
      "epoch": 43.529411764705884,
      "grad_norm": 0.00019745531608350575,
      "learning_rate": 7.764705882352942e-05,
      "loss": 0.0773,
      "step": 19980
    },
    {
      "epoch": 43.57298474945534,
      "grad_norm": 0.00035371709964238107,
      "learning_rate": 7.712418300653594e-05,
      "loss": 0.0022,
      "step": 20000
    },
    {
      "epoch": 43.61655773420479,
      "grad_norm": 0.010385042056441307,
      "learning_rate": 7.660130718954247e-05,
      "loss": 0.0414,
      "step": 20020
    },
    {
      "epoch": 43.66013071895425,
      "grad_norm": 0.002556345658376813,
      "learning_rate": 7.607843137254901e-05,
      "loss": 0.0034,
      "step": 20040
    },
    {
      "epoch": 43.7037037037037,
      "grad_norm": 0.41534826159477234,
      "learning_rate": 7.555555555555554e-05,
      "loss": 0.0005,
      "step": 20060
    },
    {
      "epoch": 43.74727668845316,
      "grad_norm": 0.002721560187637806,
      "learning_rate": 7.503267973856209e-05,
      "loss": 0.0001,
      "step": 20080
    },
    {
      "epoch": 43.790849673202615,
      "grad_norm": 0.000363605679012835,
      "learning_rate": 7.450980392156863e-05,
      "loss": 0.0495,
      "step": 20100
    },
    {
      "epoch": 43.83442265795207,
      "grad_norm": 0.026996659114956856,
      "learning_rate": 7.398692810457516e-05,
      "loss": 0.0235,
      "step": 20120
    },
    {
      "epoch": 43.87799564270153,
      "grad_norm": 0.0004204665310680866,
      "learning_rate": 7.34640522875817e-05,
      "loss": 0.0878,
      "step": 20140
    },
    {
      "epoch": 43.92156862745098,
      "grad_norm": 0.00922694057226181,
      "learning_rate": 7.294117647058823e-05,
      "loss": 0.0334,
      "step": 20160
    },
    {
      "epoch": 43.96514161220043,
      "grad_norm": 0.0009792036144062877,
      "learning_rate": 7.241830065359476e-05,
      "loss": 0.0843,
      "step": 20180
    },
    {
      "epoch": 44.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9008090404303315,
      "eval_f1": 0.9168141592920355,
      "eval_loss": 0.976999044418335,
      "eval_runtime": 13.2966,
      "eval_samples_per_second": 30.685,
      "eval_steps_per_second": 3.836,
      "step": 20196
    },
    {
      "epoch": 44.00871459694989,
      "grad_norm": 0.00020002743985969573,
      "learning_rate": 7.18954248366013e-05,
      "loss": 0.0005,
      "step": 20200
    },
    {
      "epoch": 44.052287581699346,
      "grad_norm": 0.003272255416959524,
      "learning_rate": 7.137254901960783e-05,
      "loss": 0.0005,
      "step": 20220
    },
    {
      "epoch": 44.0958605664488,
      "grad_norm": 0.0014488175511360168,
      "learning_rate": 7.084967320261438e-05,
      "loss": 0.0005,
      "step": 20240
    },
    {
      "epoch": 44.13943355119826,
      "grad_norm": 0.0004054500604979694,
      "learning_rate": 7.03267973856209e-05,
      "loss": 0.0609,
      "step": 20260
    },
    {
      "epoch": 44.18300653594771,
      "grad_norm": 0.0001859845797298476,
      "learning_rate": 6.980392156862745e-05,
      "loss": 0.0318,
      "step": 20280
    },
    {
      "epoch": 44.226579520697165,
      "grad_norm": 6.737508296966553,
      "learning_rate": 6.928104575163398e-05,
      "loss": 0.0235,
      "step": 20300
    },
    {
      "epoch": 44.270152505446625,
      "grad_norm": 29.374555587768555,
      "learning_rate": 6.875816993464052e-05,
      "loss": 0.0265,
      "step": 20320
    },
    {
      "epoch": 44.31372549019608,
      "grad_norm": 0.0004684270534198731,
      "learning_rate": 6.823529411764705e-05,
      "loss": 0.0065,
      "step": 20340
    },
    {
      "epoch": 44.35729847494554,
      "grad_norm": 0.0019219093956053257,
      "learning_rate": 6.771241830065359e-05,
      "loss": 0.0423,
      "step": 20360
    },
    {
      "epoch": 44.40087145969499,
      "grad_norm": 0.034059152007102966,
      "learning_rate": 6.718954248366012e-05,
      "loss": 0.0069,
      "step": 20380
    },
    {
      "epoch": 44.44444444444444,
      "grad_norm": 0.0008704978390596807,
      "learning_rate": 6.666666666666666e-05,
      "loss": 0.0028,
      "step": 20400
    },
    {
      "epoch": 44.4880174291939,
      "grad_norm": 0.0007455755840055645,
      "learning_rate": 6.61437908496732e-05,
      "loss": 0.0001,
      "step": 20420
    },
    {
      "epoch": 44.531590413943356,
      "grad_norm": 8.791505388217047e-05,
      "learning_rate": 6.562091503267973e-05,
      "loss": 0.0551,
      "step": 20440
    },
    {
      "epoch": 44.57516339869281,
      "grad_norm": 0.054268334060907364,
      "learning_rate": 6.509803921568627e-05,
      "loss": 0.0282,
      "step": 20460
    },
    {
      "epoch": 44.61873638344227,
      "grad_norm": 0.0012139822356402874,
      "learning_rate": 6.457516339869281e-05,
      "loss": 0.0445,
      "step": 20480
    },
    {
      "epoch": 44.66230936819172,
      "grad_norm": 0.016036484390497208,
      "learning_rate": 6.405228758169934e-05,
      "loss": 0.0001,
      "step": 20500
    },
    {
      "epoch": 44.705882352941174,
      "grad_norm": 0.00037655458436347544,
      "learning_rate": 6.352941176470588e-05,
      "loss": 0.0,
      "step": 20520
    },
    {
      "epoch": 44.749455337690634,
      "grad_norm": 0.000660998688545078,
      "learning_rate": 6.300653594771241e-05,
      "loss": 0.0341,
      "step": 20540
    },
    {
      "epoch": 44.79302832244009,
      "grad_norm": 0.031981825828552246,
      "learning_rate": 6.248366013071895e-05,
      "loss": 0.03,
      "step": 20560
    },
    {
      "epoch": 44.83660130718954,
      "grad_norm": 0.0005056964582763612,
      "learning_rate": 6.196078431372548e-05,
      "loss": 0.0648,
      "step": 20580
    },
    {
      "epoch": 44.880174291939,
      "grad_norm": 0.0018870101775974035,
      "learning_rate": 6.143790849673203e-05,
      "loss": 0.0001,
      "step": 20600
    },
    {
      "epoch": 44.92374727668845,
      "grad_norm": 0.0024511385709047318,
      "learning_rate": 6.0915032679738556e-05,
      "loss": 0.0001,
      "step": 20620
    },
    {
      "epoch": 44.967320261437905,
      "grad_norm": 0.0003721366811078042,
      "learning_rate": 6.03921568627451e-05,
      "loss": 0.0003,
      "step": 20640
    },
    {
      "epoch": 45.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.907209173422019,
      "eval_f1": 0.9222614840989399,
      "eval_loss": 0.9796568751335144,
      "eval_runtime": 13.2432,
      "eval_samples_per_second": 30.808,
      "eval_steps_per_second": 3.851,
      "step": 20655
    },
    {
      "epoch": 45.010893246187365,
      "grad_norm": 0.0014252947876229882,
      "learning_rate": 5.9869281045751625e-05,
      "loss": 0.0001,
      "step": 20660
    },
    {
      "epoch": 45.05446623093682,
      "grad_norm": 0.05372779816389084,
      "learning_rate": 5.9346405228758166e-05,
      "loss": 0.0037,
      "step": 20680
    },
    {
      "epoch": 45.09803921568628,
      "grad_norm": 0.0005974929081276059,
      "learning_rate": 5.88235294117647e-05,
      "loss": 0.0311,
      "step": 20700
    },
    {
      "epoch": 45.14161220043573,
      "grad_norm": 0.0006640839274041355,
      "learning_rate": 5.830065359477124e-05,
      "loss": 0.0002,
      "step": 20720
    },
    {
      "epoch": 45.18518518518518,
      "grad_norm": 0.0004977072239853442,
      "learning_rate": 5.777777777777777e-05,
      "loss": 0.0005,
      "step": 20740
    },
    {
      "epoch": 45.22875816993464,
      "grad_norm": 0.21417029201984406,
      "learning_rate": 5.7254901960784304e-05,
      "loss": 0.0265,
      "step": 20760
    },
    {
      "epoch": 45.272331154684096,
      "grad_norm": 0.0028011403046548367,
      "learning_rate": 5.6732026143790845e-05,
      "loss": 0.037,
      "step": 20780
    },
    {
      "epoch": 45.31590413943355,
      "grad_norm": 0.00015963692567311227,
      "learning_rate": 5.620915032679738e-05,
      "loss": 0.0,
      "step": 20800
    },
    {
      "epoch": 45.35947712418301,
      "grad_norm": 0.001728721079416573,
      "learning_rate": 5.568627450980392e-05,
      "loss": 0.0001,
      "step": 20820
    },
    {
      "epoch": 45.40305010893246,
      "grad_norm": 0.016077619045972824,
      "learning_rate": 5.516339869281045e-05,
      "loss": 0.0007,
      "step": 20840
    },
    {
      "epoch": 45.446623093681914,
      "grad_norm": 0.0009186835959553719,
      "learning_rate": 5.464052287581699e-05,
      "loss": 0.0904,
      "step": 20860
    },
    {
      "epoch": 45.490196078431374,
      "grad_norm": 0.0008525903103873134,
      "learning_rate": 5.4117647058823525e-05,
      "loss": 0.0299,
      "step": 20880
    },
    {
      "epoch": 45.53376906318083,
      "grad_norm": 0.011146245524287224,
      "learning_rate": 5.3594771241830066e-05,
      "loss": 0.001,
      "step": 20900
    },
    {
      "epoch": 45.57734204793028,
      "grad_norm": 19.233795166015625,
      "learning_rate": 5.3071895424836594e-05,
      "loss": 0.0063,
      "step": 20920
    },
    {
      "epoch": 45.62091503267974,
      "grad_norm": 0.0003345175937283784,
      "learning_rate": 5.254901960784313e-05,
      "loss": 0.0004,
      "step": 20940
    },
    {
      "epoch": 45.66448801742919,
      "grad_norm": 0.0006148287211544812,
      "learning_rate": 5.202614379084967e-05,
      "loss": 0.0001,
      "step": 20960
    },
    {
      "epoch": 45.70806100217865,
      "grad_norm": 0.001245443127118051,
      "learning_rate": 5.1503267973856204e-05,
      "loss": 0.031,
      "step": 20980
    },
    {
      "epoch": 45.751633986928105,
      "grad_norm": 0.0003620227798819542,
      "learning_rate": 5.0980392156862745e-05,
      "loss": 0.0617,
      "step": 21000
    },
    {
      "epoch": 45.79520697167756,
      "grad_norm": 0.00021243809896986932,
      "learning_rate": 5.045751633986927e-05,
      "loss": 0.0092,
      "step": 21020
    },
    {
      "epoch": 45.83877995642702,
      "grad_norm": 0.1921096295118332,
      "learning_rate": 4.9934640522875814e-05,
      "loss": 0.013,
      "step": 21040
    },
    {
      "epoch": 45.88235294117647,
      "grad_norm": 0.00033337835338898003,
      "learning_rate": 4.941176470588235e-05,
      "loss": 0.0054,
      "step": 21060
    },
    {
      "epoch": 45.925925925925924,
      "grad_norm": 0.006784990429878235,
      "learning_rate": 4.888888888888889e-05,
      "loss": 0.0106,
      "step": 21080
    },
    {
      "epoch": 45.969498910675384,
      "grad_norm": 0.005457994528114796,
      "learning_rate": 4.836601307189542e-05,
      "loss": 0.0531,
      "step": 21100
    },
    {
      "epoch": 46.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8940826330532212,
      "eval_f1": 0.9107142857142857,
      "eval_loss": 0.9939513802528381,
      "eval_runtime": 13.1381,
      "eval_samples_per_second": 31.055,
      "eval_steps_per_second": 3.882,
      "step": 21114
    },
    {
      "epoch": 46.01307189542484,
      "grad_norm": 0.00024816885706968606,
      "learning_rate": 4.784313725490195e-05,
      "loss": 0.0001,
      "step": 21120
    },
    {
      "epoch": 46.05664488017429,
      "grad_norm": 0.012285955250263214,
      "learning_rate": 4.732026143790849e-05,
      "loss": 0.0014,
      "step": 21140
    },
    {
      "epoch": 46.10021786492375,
      "grad_norm": 0.03780468553304672,
      "learning_rate": 4.679738562091503e-05,
      "loss": 0.0044,
      "step": 21160
    },
    {
      "epoch": 46.1437908496732,
      "grad_norm": 4.828202247619629,
      "learning_rate": 4.627450980392157e-05,
      "loss": 0.1011,
      "step": 21180
    },
    {
      "epoch": 46.187363834422655,
      "grad_norm": 0.00013747537741437554,
      "learning_rate": 4.57516339869281e-05,
      "loss": 0.0533,
      "step": 21200
    },
    {
      "epoch": 46.230936819172115,
      "grad_norm": 0.000830929959192872,
      "learning_rate": 4.522875816993464e-05,
      "loss": 0.0095,
      "step": 21220
    },
    {
      "epoch": 46.27450980392157,
      "grad_norm": 0.0006337899249047041,
      "learning_rate": 4.470588235294117e-05,
      "loss": 0.0003,
      "step": 21240
    },
    {
      "epoch": 46.31808278867102,
      "grad_norm": 0.0006158335017971694,
      "learning_rate": 4.4183006535947714e-05,
      "loss": 0.0075,
      "step": 21260
    },
    {
      "epoch": 46.36165577342048,
      "grad_norm": 0.00025909458054229617,
      "learning_rate": 4.366013071895424e-05,
      "loss": 0.0004,
      "step": 21280
    },
    {
      "epoch": 46.40522875816993,
      "grad_norm": 0.00022099165653344244,
      "learning_rate": 4.3137254901960776e-05,
      "loss": 0.0,
      "step": 21300
    },
    {
      "epoch": 46.44880174291939,
      "grad_norm": 0.0004712844383902848,
      "learning_rate": 4.261437908496732e-05,
      "loss": 0.0548,
      "step": 21320
    },
    {
      "epoch": 46.492374727668846,
      "grad_norm": 0.09285315126180649,
      "learning_rate": 4.209150326797385e-05,
      "loss": 0.026,
      "step": 21340
    },
    {
      "epoch": 46.5359477124183,
      "grad_norm": 0.0029470224399119616,
      "learning_rate": 4.156862745098039e-05,
      "loss": 0.0386,
      "step": 21360
    },
    {
      "epoch": 46.57952069716776,
      "grad_norm": 38.4396858215332,
      "learning_rate": 4.104575163398692e-05,
      "loss": 0.158,
      "step": 21380
    },
    {
      "epoch": 46.62309368191721,
      "grad_norm": 0.0008961700950749218,
      "learning_rate": 4.052287581699346e-05,
      "loss": 0.0592,
      "step": 21400
    },
    {
      "epoch": 46.666666666666664,
      "grad_norm": 0.027113748714327812,
      "learning_rate": 3.9999999999999996e-05,
      "loss": 0.0234,
      "step": 21420
    },
    {
      "epoch": 46.710239651416124,
      "grad_norm": 0.0010967846028506756,
      "learning_rate": 3.947712418300654e-05,
      "loss": 0.0008,
      "step": 21440
    },
    {
      "epoch": 46.75381263616558,
      "grad_norm": 0.003824228188022971,
      "learning_rate": 3.895424836601307e-05,
      "loss": 0.0295,
      "step": 21460
    },
    {
      "epoch": 46.79738562091503,
      "grad_norm": 0.0012670040596276522,
      "learning_rate": 3.84313725490196e-05,
      "loss": 0.0003,
      "step": 21480
    },
    {
      "epoch": 46.84095860566449,
      "grad_norm": 0.07900737226009369,
      "learning_rate": 3.790849673202614e-05,
      "loss": 0.0001,
      "step": 21500
    },
    {
      "epoch": 46.88453159041394,
      "grad_norm": 0.003133631544187665,
      "learning_rate": 3.7385620915032676e-05,
      "loss": 0.0662,
      "step": 21520
    },
    {
      "epoch": 46.928104575163395,
      "grad_norm": 0.01079026609659195,
      "learning_rate": 3.686274509803921e-05,
      "loss": 0.0099,
      "step": 21540
    },
    {
      "epoch": 46.971677559912855,
      "grad_norm": 0.0009532659314572811,
      "learning_rate": 3.6339869281045745e-05,
      "loss": 0.0116,
      "step": 21560
    },
    {
      "epoch": 47.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9031344932339133,
      "eval_f1": 0.9190140845070423,
      "eval_loss": 0.9834458827972412,
      "eval_runtime": 13.3033,
      "eval_samples_per_second": 30.669,
      "eval_steps_per_second": 3.834,
      "step": 21573
    },
    {
      "epoch": 47.01525054466231,
      "grad_norm": 0.001946263830177486,
      "learning_rate": 3.5816993464052286e-05,
      "loss": 0.0198,
      "step": 21580
    },
    {
      "epoch": 47.05882352941177,
      "grad_norm": 0.0011561005376279354,
      "learning_rate": 3.529411764705882e-05,
      "loss": 0.0001,
      "step": 21600
    },
    {
      "epoch": 47.10239651416122,
      "grad_norm": 0.0013297920813784003,
      "learning_rate": 3.4771241830065355e-05,
      "loss": 0.0041,
      "step": 21620
    },
    {
      "epoch": 47.145969498910674,
      "grad_norm": 3.7525455951690674,
      "learning_rate": 3.4248366013071896e-05,
      "loss": 0.049,
      "step": 21640
    },
    {
      "epoch": 47.189542483660134,
      "grad_norm": 0.011774157173931599,
      "learning_rate": 3.372549019607843e-05,
      "loss": 0.0605,
      "step": 21660
    },
    {
      "epoch": 47.233115468409586,
      "grad_norm": 0.002895550336688757,
      "learning_rate": 3.3202614379084965e-05,
      "loss": 0.0018,
      "step": 21680
    },
    {
      "epoch": 47.27668845315904,
      "grad_norm": 0.009820357896387577,
      "learning_rate": 3.26797385620915e-05,
      "loss": 0.0418,
      "step": 21700
    },
    {
      "epoch": 47.3202614379085,
      "grad_norm": 0.0010504379170015454,
      "learning_rate": 3.2156862745098034e-05,
      "loss": 0.0496,
      "step": 21720
    },
    {
      "epoch": 47.36383442265795,
      "grad_norm": 0.035087864845991135,
      "learning_rate": 3.163398692810457e-05,
      "loss": 0.0001,
      "step": 21740
    },
    {
      "epoch": 47.407407407407405,
      "grad_norm": 0.017134513705968857,
      "learning_rate": 3.111111111111111e-05,
      "loss": 0.0001,
      "step": 21760
    },
    {
      "epoch": 47.450980392156865,
      "grad_norm": 0.002427248051390052,
      "learning_rate": 3.0588235294117644e-05,
      "loss": 0.0661,
      "step": 21780
    },
    {
      "epoch": 47.49455337690632,
      "grad_norm": 0.23149962723255157,
      "learning_rate": 3.006535947712418e-05,
      "loss": 0.0002,
      "step": 21800
    },
    {
      "epoch": 47.53812636165577,
      "grad_norm": 0.047830261290073395,
      "learning_rate": 2.9542483660130717e-05,
      "loss": 0.0001,
      "step": 21820
    },
    {
      "epoch": 47.58169934640523,
      "grad_norm": 0.008225786499679089,
      "learning_rate": 2.9019607843137255e-05,
      "loss": 0.0132,
      "step": 21840
    },
    {
      "epoch": 47.62527233115468,
      "grad_norm": 0.0016862639458850026,
      "learning_rate": 2.849673202614379e-05,
      "loss": 0.0414,
      "step": 21860
    },
    {
      "epoch": 47.668845315904136,
      "grad_norm": 0.00041452242294326425,
      "learning_rate": 2.7973856209150327e-05,
      "loss": 0.0008,
      "step": 21880
    },
    {
      "epoch": 47.712418300653596,
      "grad_norm": 0.2951148450374603,
      "learning_rate": 2.7450980392156858e-05,
      "loss": 0.0011,
      "step": 21900
    },
    {
      "epoch": 47.75599128540305,
      "grad_norm": 0.02089710533618927,
      "learning_rate": 2.6928104575163396e-05,
      "loss": 0.0629,
      "step": 21920
    },
    {
      "epoch": 47.79956427015251,
      "grad_norm": 0.023044006898999214,
      "learning_rate": 2.640522875816993e-05,
      "loss": 0.0061,
      "step": 21940
    },
    {
      "epoch": 47.84313725490196,
      "grad_norm": 0.00889405608177185,
      "learning_rate": 2.588235294117647e-05,
      "loss": 0.0137,
      "step": 21960
    },
    {
      "epoch": 47.886710239651414,
      "grad_norm": 0.00014092176570557058,
      "learning_rate": 2.5359477124183003e-05,
      "loss": 0.0181,
      "step": 21980
    },
    {
      "epoch": 47.930283224400874,
      "grad_norm": 9.751716613769531,
      "learning_rate": 2.483660130718954e-05,
      "loss": 0.1123,
      "step": 22000
    },
    {
      "epoch": 47.97385620915033,
      "grad_norm": 0.0004407950327731669,
      "learning_rate": 2.431372549019608e-05,
      "loss": 0.0593,
      "step": 22020
    },
    {
      "epoch": 48.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8987736437331115,
      "eval_f1": 0.9151943462897526,
      "eval_loss": 0.9722766280174255,
      "eval_runtime": 12.975,
      "eval_samples_per_second": 31.445,
      "eval_steps_per_second": 3.931,
      "step": 22032
    },
    {
      "epoch": 48.01742919389978,
      "grad_norm": 0.0002662760962266475,
      "learning_rate": 2.3790849673202613e-05,
      "loss": 0.0591,
      "step": 22040
    },
    {
      "epoch": 48.06100217864924,
      "grad_norm": 0.0006591773708350956,
      "learning_rate": 2.326797385620915e-05,
      "loss": 0.0002,
      "step": 22060
    },
    {
      "epoch": 48.10457516339869,
      "grad_norm": 0.00039524989551864564,
      "learning_rate": 2.2745098039215682e-05,
      "loss": 0.0387,
      "step": 22080
    },
    {
      "epoch": 48.148148148148145,
      "grad_norm": 0.25467169284820557,
      "learning_rate": 2.222222222222222e-05,
      "loss": 0.0002,
      "step": 22100
    },
    {
      "epoch": 48.191721132897605,
      "grad_norm": 0.0003496664285194129,
      "learning_rate": 2.1699346405228754e-05,
      "loss": 0.0002,
      "step": 22120
    },
    {
      "epoch": 48.23529411764706,
      "grad_norm": 0.2906978130340576,
      "learning_rate": 2.1176470588235292e-05,
      "loss": 0.0104,
      "step": 22140
    },
    {
      "epoch": 48.27886710239651,
      "grad_norm": 1.7874476909637451,
      "learning_rate": 2.0653594771241827e-05,
      "loss": 0.0006,
      "step": 22160
    },
    {
      "epoch": 48.32244008714597,
      "grad_norm": 0.5347212553024292,
      "learning_rate": 2.0130718954248365e-05,
      "loss": 0.0495,
      "step": 22180
    },
    {
      "epoch": 48.36601307189542,
      "grad_norm": 0.011061473749577999,
      "learning_rate": 1.9607843137254903e-05,
      "loss": 0.001,
      "step": 22200
    },
    {
      "epoch": 48.40958605664488,
      "grad_norm": 0.003260752186179161,
      "learning_rate": 1.9084967320261437e-05,
      "loss": 0.0078,
      "step": 22220
    },
    {
      "epoch": 48.453159041394336,
      "grad_norm": 0.0036986025515943766,
      "learning_rate": 1.856209150326797e-05,
      "loss": 0.0002,
      "step": 22240
    },
    {
      "epoch": 48.49673202614379,
      "grad_norm": 0.0006976873846724629,
      "learning_rate": 1.803921568627451e-05,
      "loss": 0.0274,
      "step": 22260
    },
    {
      "epoch": 48.54030501089325,
      "grad_norm": 0.0002444093697704375,
      "learning_rate": 1.7516339869281044e-05,
      "loss": 0.0433,
      "step": 22280
    },
    {
      "epoch": 48.5838779956427,
      "grad_norm": 0.0001802265178412199,
      "learning_rate": 1.699346405228758e-05,
      "loss": 0.0521,
      "step": 22300
    },
    {
      "epoch": 48.627450980392155,
      "grad_norm": 0.047260694205760956,
      "learning_rate": 1.6470588235294116e-05,
      "loss": 0.003,
      "step": 22320
    },
    {
      "epoch": 48.671023965141615,
      "grad_norm": 0.09518127888441086,
      "learning_rate": 1.5947712418300654e-05,
      "loss": 0.0005,
      "step": 22340
    },
    {
      "epoch": 48.71459694989107,
      "grad_norm": 0.00604650191962719,
      "learning_rate": 1.542483660130719e-05,
      "loss": 0.0078,
      "step": 22360
    },
    {
      "epoch": 48.75816993464052,
      "grad_norm": 0.0010461807250976562,
      "learning_rate": 1.4901960784313723e-05,
      "loss": 0.0467,
      "step": 22380
    },
    {
      "epoch": 48.80174291938998,
      "grad_norm": 0.0003839902929030359,
      "learning_rate": 1.437908496732026e-05,
      "loss": 0.0002,
      "step": 22400
    },
    {
      "epoch": 48.84531590413943,
      "grad_norm": 0.001142393797636032,
      "learning_rate": 1.3856209150326795e-05,
      "loss": 0.0479,
      "step": 22420
    },
    {
      "epoch": 48.888888888888886,
      "grad_norm": 0.0010953189339488745,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0002,
      "step": 22440
    },
    {
      "epoch": 48.932461873638346,
      "grad_norm": 0.02632231079041958,
      "learning_rate": 1.281045751633987e-05,
      "loss": 0.0145,
      "step": 22460
    },
    {
      "epoch": 48.9760348583878,
      "grad_norm": 0.03130587190389633,
      "learning_rate": 1.2287581699346404e-05,
      "loss": 0.0385,
      "step": 22480
    },
    {
      "epoch": 49.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.8965881485337497,
      "eval_f1": 0.9132743362831858,
      "eval_loss": 0.9721903800964355,
      "eval_runtime": 13.3225,
      "eval_samples_per_second": 30.625,
      "eval_steps_per_second": 3.828,
      "step": 22491
    },
    {
      "epoch": 49.01960784313726,
      "grad_norm": 0.00029798614559695125,
      "learning_rate": 1.176470588235294e-05,
      "loss": 0.0,
      "step": 22500
    },
    {
      "epoch": 49.06318082788671,
      "grad_norm": 0.0016362749738618731,
      "learning_rate": 1.1241830065359476e-05,
      "loss": 0.0015,
      "step": 22520
    },
    {
      "epoch": 49.106753812636164,
      "grad_norm": 0.03429124504327774,
      "learning_rate": 1.0718954248366013e-05,
      "loss": 0.0007,
      "step": 22540
    },
    {
      "epoch": 49.150326797385624,
      "grad_norm": 0.008484754711389542,
      "learning_rate": 1.0196078431372547e-05,
      "loss": 0.071,
      "step": 22560
    },
    {
      "epoch": 49.19389978213508,
      "grad_norm": 1.6583997011184692,
      "learning_rate": 9.673202614379083e-06,
      "loss": 0.0076,
      "step": 22580
    },
    {
      "epoch": 49.23747276688453,
      "grad_norm": 0.12272623181343079,
      "learning_rate": 9.150326797385621e-06,
      "loss": 0.0001,
      "step": 22600
    },
    {
      "epoch": 49.28104575163399,
      "grad_norm": 63.48429870605469,
      "learning_rate": 8.627450980392156e-06,
      "loss": 0.0133,
      "step": 22620
    },
    {
      "epoch": 49.32461873638344,
      "grad_norm": 0.00034173630410805345,
      "learning_rate": 8.104575163398692e-06,
      "loss": 0.0182,
      "step": 22640
    },
    {
      "epoch": 49.368191721132895,
      "grad_norm": 0.00259557762183249,
      "learning_rate": 7.581699346405229e-06,
      "loss": 0.0196,
      "step": 22660
    },
    {
      "epoch": 49.411764705882355,
      "grad_norm": 0.001265074359253049,
      "learning_rate": 7.058823529411764e-06,
      "loss": 0.0135,
      "step": 22680
    },
    {
      "epoch": 49.45533769063181,
      "grad_norm": 35.96565628051758,
      "learning_rate": 6.5359477124183e-06,
      "loss": 0.0132,
      "step": 22700
    },
    {
      "epoch": 49.49891067538126,
      "grad_norm": 0.00015730086306575686,
      "learning_rate": 6.013071895424836e-06,
      "loss": 0.0405,
      "step": 22720
    },
    {
      "epoch": 49.54248366013072,
      "grad_norm": 0.0023759803734719753,
      "learning_rate": 5.490196078431373e-06,
      "loss": 0.0421,
      "step": 22740
    },
    {
      "epoch": 49.58605664488017,
      "grad_norm": 0.001760676153935492,
      "learning_rate": 4.967320261437908e-06,
      "loss": 0.0001,
      "step": 22760
    },
    {
      "epoch": 49.629629629629626,
      "grad_norm": 0.0005901558906771243,
      "learning_rate": 4.444444444444444e-06,
      "loss": 0.0098,
      "step": 22780
    },
    {
      "epoch": 49.673202614379086,
      "grad_norm": 0.008744577877223492,
      "learning_rate": 3.92156862745098e-06,
      "loss": 0.031,
      "step": 22800
    },
    {
      "epoch": 49.71677559912854,
      "grad_norm": 0.0006063564796932042,
      "learning_rate": 3.398692810457516e-06,
      "loss": 0.0273,
      "step": 22820
    },
    {
      "epoch": 49.760348583878,
      "grad_norm": 0.0010898899054154754,
      "learning_rate": 2.875816993464052e-06,
      "loss": 0.0419,
      "step": 22840
    },
    {
      "epoch": 49.80392156862745,
      "grad_norm": 0.0013087847037240863,
      "learning_rate": 2.352941176470588e-06,
      "loss": 0.0331,
      "step": 22860
    },
    {
      "epoch": 49.847494553376904,
      "grad_norm": 0.0007739267311990261,
      "learning_rate": 1.830065359477124e-06,
      "loss": 0.0,
      "step": 22880
    },
    {
      "epoch": 49.891067538126364,
      "grad_norm": 0.0006107622757554054,
      "learning_rate": 1.3071895424836602e-06,
      "loss": 0.0576,
      "step": 22900
    },
    {
      "epoch": 49.93464052287582,
      "grad_norm": 0.007670598570257425,
      "learning_rate": 7.843137254901959e-07,
      "loss": 0.0002,
      "step": 22920
    },
    {
      "epoch": 49.97821350762527,
      "grad_norm": 0.0007640878902748227,
      "learning_rate": 2.61437908496732e-07,
      "loss": 0.0889,
      "step": 22940
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8987736437331115,
      "eval_f1": 0.9151943462897526,
      "eval_loss": 0.9744044542312622,
      "eval_runtime": 13.0574,
      "eval_samples_per_second": 31.247,
      "eval_steps_per_second": 3.906,
      "step": 22950
    },
    {
      "epoch": 50.0,
      "step": 22950,
      "total_flos": 4.38375589951488e+16,
      "train_loss": 0.10641903456769455,
      "train_runtime": 13022.7417,
      "train_samples_per_second": 14.083,
      "train_steps_per_second": 1.762
    }
  ],
  "logging_steps": 20,
  "max_steps": 22950,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": -22950,
  "total_flos": 4.38375589951488e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
