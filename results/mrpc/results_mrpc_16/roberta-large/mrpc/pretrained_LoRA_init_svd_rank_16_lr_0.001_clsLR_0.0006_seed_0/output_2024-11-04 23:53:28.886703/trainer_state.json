{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 15300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 4.094788551330566,
      "learning_rate": 0.0005992156862745097,
      "loss": 0.6205,
      "step": 20
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 19.16976547241211,
      "learning_rate": 0.0005984313725490196,
      "loss": 0.5499,
      "step": 40
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 6.151974201202393,
      "learning_rate": 0.0005976470588235294,
      "loss": 0.6747,
      "step": 60
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 2.148022174835205,
      "learning_rate": 0.0005968627450980391,
      "loss": 0.497,
      "step": 80
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 8.30424976348877,
      "learning_rate": 0.000596078431372549,
      "loss": 0.6861,
      "step": 100
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 3.7290875911712646,
      "learning_rate": 0.0005952941176470588,
      "loss": 0.5003,
      "step": 120
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 3.069474458694458,
      "learning_rate": 0.0005945098039215686,
      "loss": 0.4992,
      "step": 140
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 6.94534969329834,
      "learning_rate": 0.0005937254901960784,
      "loss": 0.4378,
      "step": 160
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 3.510606527328491,
      "learning_rate": 0.0005929411764705882,
      "loss": 0.45,
      "step": 180
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 2.8938591480255127,
      "learning_rate": 0.0005921568627450981,
      "loss": 0.583,
      "step": 200
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 3.330723524093628,
      "learning_rate": 0.0005913725490196078,
      "loss": 0.4837,
      "step": 220
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 5.656651496887207,
      "learning_rate": 0.0005905882352941176,
      "loss": 0.4714,
      "step": 240
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 8.543706893920898,
      "learning_rate": 0.0005898039215686274,
      "loss": 0.3797,
      "step": 260
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 7.428273677825928,
      "learning_rate": 0.0005890196078431371,
      "loss": 0.479,
      "step": 280
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 3.9258229732513428,
      "learning_rate": 0.000588235294117647,
      "loss": 0.4314,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8235294117647058,
      "eval_combined_score": 0.8535122786978869,
      "eval_f1": 0.883495145631068,
      "eval_loss": 0.4562617242336273,
      "eval_runtime": 11.8895,
      "eval_samples_per_second": 34.316,
      "eval_steps_per_second": 4.29,
      "step": 306
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 1.6429452896118164,
      "learning_rate": 0.0005874509803921568,
      "loss": 0.374,
      "step": 320
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 6.79625129699707,
      "learning_rate": 0.0005866666666666665,
      "loss": 0.4171,
      "step": 340
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 5.495093822479248,
      "learning_rate": 0.0005858823529411764,
      "loss": 0.3254,
      "step": 360
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 3.019124984741211,
      "learning_rate": 0.0005850980392156862,
      "loss": 0.2641,
      "step": 380
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 5.669466018676758,
      "learning_rate": 0.0005843137254901961,
      "loss": 0.5666,
      "step": 400
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 3.245232343673706,
      "learning_rate": 0.0005835294117647058,
      "loss": 0.3621,
      "step": 420
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 4.277976036071777,
      "learning_rate": 0.0005827450980392156,
      "loss": 0.2943,
      "step": 440
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 5.942124843597412,
      "learning_rate": 0.0005819607843137255,
      "loss": 0.4124,
      "step": 460
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 3.9549875259399414,
      "learning_rate": 0.0005811764705882352,
      "loss": 0.3815,
      "step": 480
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 2.9174091815948486,
      "learning_rate": 0.000580392156862745,
      "loss": 0.3878,
      "step": 500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 4.45196533203125,
      "learning_rate": 0.0005796078431372549,
      "loss": 0.3922,
      "step": 520
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 2.5224854946136475,
      "learning_rate": 0.0005788235294117647,
      "loss": 0.3108,
      "step": 540
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 4.045219421386719,
      "learning_rate": 0.0005780392156862744,
      "loss": 0.4,
      "step": 560
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 6.418046951293945,
      "learning_rate": 0.0005772549019607843,
      "loss": 0.3395,
      "step": 580
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 4.220084190368652,
      "learning_rate": 0.0005764705882352941,
      "loss": 0.282,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8975401069518717,
      "eval_f1": 0.9127272727272728,
      "eval_loss": 0.2903921604156494,
      "eval_runtime": 11.9093,
      "eval_samples_per_second": 34.259,
      "eval_steps_per_second": 4.282,
      "step": 612
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 2.8354527950286865,
      "learning_rate": 0.0005756862745098039,
      "loss": 0.3978,
      "step": 620
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 6.800604343414307,
      "learning_rate": 0.0005749019607843137,
      "loss": 0.2613,
      "step": 640
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 1.1523702144622803,
      "learning_rate": 0.0005741176470588235,
      "loss": 0.3324,
      "step": 660
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 7.35753059387207,
      "learning_rate": 0.0005733333333333334,
      "loss": 0.3712,
      "step": 680
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 3.062239408493042,
      "learning_rate": 0.0005725490196078431,
      "loss": 0.3223,
      "step": 700
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 5.529262542724609,
      "learning_rate": 0.0005717647058823529,
      "loss": 0.3694,
      "step": 720
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 9.668974876403809,
      "learning_rate": 0.0005709803921568627,
      "loss": 0.2893,
      "step": 740
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 3.8595263957977295,
      "learning_rate": 0.0005701960784313724,
      "loss": 0.2579,
      "step": 760
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 1.755043387413025,
      "learning_rate": 0.0005694117647058823,
      "loss": 0.1909,
      "step": 780
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 5.892446994781494,
      "learning_rate": 0.0005686274509803921,
      "loss": 0.3953,
      "step": 800
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 1.1173455715179443,
      "learning_rate": 0.0005678431372549018,
      "loss": 0.3522,
      "step": 820
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 6.320917129516602,
      "learning_rate": 0.0005670588235294117,
      "loss": 0.3007,
      "step": 840
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 5.207169532775879,
      "learning_rate": 0.0005662745098039215,
      "loss": 0.3078,
      "step": 860
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 2.5988597869873047,
      "learning_rate": 0.0005654901960784314,
      "loss": 0.358,
      "step": 880
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 1.5679041147232056,
      "learning_rate": 0.0005647058823529411,
      "loss": 0.3131,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8972204266321913,
      "eval_f1": 0.9120879120879121,
      "eval_loss": 0.2932788133621216,
      "eval_runtime": 11.9293,
      "eval_samples_per_second": 34.202,
      "eval_steps_per_second": 4.275,
      "step": 918
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 5.393863201141357,
      "learning_rate": 0.0005639215686274509,
      "loss": 0.3486,
      "step": 920
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 3.0915310382843018,
      "learning_rate": 0.0005631372549019608,
      "loss": 0.3203,
      "step": 940
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 3.391286611557007,
      "learning_rate": 0.0005623529411764705,
      "loss": 0.2671,
      "step": 960
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 5.656245231628418,
      "learning_rate": 0.0005615686274509803,
      "loss": 0.3307,
      "step": 980
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 5.339549541473389,
      "learning_rate": 0.0005607843137254902,
      "loss": 0.3677,
      "step": 1000
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 2.793130397796631,
      "learning_rate": 0.00056,
      "loss": 0.3124,
      "step": 1020
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 7.184401988983154,
      "learning_rate": 0.0005592156862745097,
      "loss": 0.2295,
      "step": 1040
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 13.765188217163086,
      "learning_rate": 0.0005584313725490196,
      "loss": 0.3079,
      "step": 1060
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 3.129068374633789,
      "learning_rate": 0.0005576470588235294,
      "loss": 0.4003,
      "step": 1080
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 3.3026390075683594,
      "learning_rate": 0.0005568627450980392,
      "loss": 0.2022,
      "step": 1100
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 7.540597438812256,
      "learning_rate": 0.000556078431372549,
      "loss": 0.219,
      "step": 1120
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 4.461162567138672,
      "learning_rate": 0.0005552941176470588,
      "loss": 0.3598,
      "step": 1140
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 3.103111743927002,
      "learning_rate": 0.0005545098039215687,
      "loss": 0.2762,
      "step": 1160
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 3.5428996086120605,
      "learning_rate": 0.0005537254901960784,
      "loss": 0.2727,
      "step": 1180
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 1.2556060552597046,
      "learning_rate": 0.0005529411764705882,
      "loss": 0.3165,
      "step": 1200
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 0.6703328490257263,
      "learning_rate": 0.000552156862745098,
      "loss": 0.2372,
      "step": 1220
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9027021840764775,
      "eval_f1": 0.9181494661921709,
      "eval_loss": 0.32023751735687256,
      "eval_runtime": 12.1252,
      "eval_samples_per_second": 33.649,
      "eval_steps_per_second": 4.206,
      "step": 1224
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 4.012044429779053,
      "learning_rate": 0.0005513725490196077,
      "loss": 0.2424,
      "step": 1240
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 3.0535027980804443,
      "learning_rate": 0.0005505882352941176,
      "loss": 0.2342,
      "step": 1260
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 17.343338012695312,
      "learning_rate": 0.0005498039215686274,
      "loss": 0.3066,
      "step": 1280
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 1.3639718294143677,
      "learning_rate": 0.0005490196078431371,
      "loss": 0.3262,
      "step": 1300
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 0.11779449135065079,
      "learning_rate": 0.000548235294117647,
      "loss": 0.2152,
      "step": 1320
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 6.308481693267822,
      "learning_rate": 0.0005474509803921568,
      "loss": 0.2489,
      "step": 1340
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 4.75437593460083,
      "learning_rate": 0.0005466666666666667,
      "loss": 0.4005,
      "step": 1360
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 3.812121868133545,
      "learning_rate": 0.0005458823529411764,
      "loss": 0.2727,
      "step": 1380
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 2.2821645736694336,
      "learning_rate": 0.0005450980392156862,
      "loss": 0.2889,
      "step": 1400
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 4.852084636688232,
      "learning_rate": 0.0005443137254901961,
      "loss": 0.266,
      "step": 1420
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 2.4241669178009033,
      "learning_rate": 0.0005435294117647058,
      "loss": 0.2373,
      "step": 1440
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 4.893094062805176,
      "learning_rate": 0.0005427450980392156,
      "loss": 0.2082,
      "step": 1460
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 0.2343096137046814,
      "learning_rate": 0.0005419607843137255,
      "loss": 0.2787,
      "step": 1480
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 7.940176963806152,
      "learning_rate": 0.0005411764705882352,
      "loss": 0.3608,
      "step": 1500
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 1.1427289247512817,
      "learning_rate": 0.000540392156862745,
      "loss": 0.2352,
      "step": 1520
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9133428238080312,
      "eval_f1": 0.9271758436944938,
      "eval_loss": 0.3028492033481598,
      "eval_runtime": 12.0879,
      "eval_samples_per_second": 33.753,
      "eval_steps_per_second": 4.219,
      "step": 1530
    },
    {
      "epoch": 5.032679738562091,
      "grad_norm": 2.5653138160705566,
      "learning_rate": 0.0005396078431372549,
      "loss": 0.2913,
      "step": 1540
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 5.0905961990356445,
      "learning_rate": 0.0005388235294117647,
      "loss": 0.1824,
      "step": 1560
    },
    {
      "epoch": 5.163398692810458,
      "grad_norm": 5.707034587860107,
      "learning_rate": 0.0005380392156862745,
      "loss": 0.281,
      "step": 1580
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 1.3742351531982422,
      "learning_rate": 0.0005372549019607843,
      "loss": 0.22,
      "step": 1600
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 4.705128192901611,
      "learning_rate": 0.0005364705882352941,
      "loss": 0.1922,
      "step": 1620
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 3.5305428504943848,
      "learning_rate": 0.000535686274509804,
      "loss": 0.2742,
      "step": 1640
    },
    {
      "epoch": 5.42483660130719,
      "grad_norm": 4.352327346801758,
      "learning_rate": 0.0005349019607843137,
      "loss": 0.2404,
      "step": 1660
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 0.9062339663505554,
      "learning_rate": 0.0005341176470588235,
      "loss": 0.2168,
      "step": 1680
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 2.4361135959625244,
      "learning_rate": 0.0005333333333333333,
      "loss": 0.1808,
      "step": 1700
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 5.065221786499023,
      "learning_rate": 0.000532549019607843,
      "loss": 0.3942,
      "step": 1720
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 3.194488286972046,
      "learning_rate": 0.0005317647058823529,
      "loss": 0.2877,
      "step": 1740
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 2.552365303039551,
      "learning_rate": 0.0005309803921568627,
      "loss": 0.3106,
      "step": 1760
    },
    {
      "epoch": 5.816993464052287,
      "grad_norm": 5.1286797523498535,
      "learning_rate": 0.0005301960784313724,
      "loss": 0.2431,
      "step": 1780
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 2.624969482421875,
      "learning_rate": 0.0005294117647058823,
      "loss": 0.2745,
      "step": 1800
    },
    {
      "epoch": 5.947712418300654,
      "grad_norm": 3.421107053756714,
      "learning_rate": 0.0005286274509803921,
      "loss": 0.2972,
      "step": 1820
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.875,
      "eval_combined_score": 0.8933058925476604,
      "eval_f1": 0.9116117850953207,
      "eval_loss": 0.32360896468162537,
      "eval_runtime": 12.1665,
      "eval_samples_per_second": 33.535,
      "eval_steps_per_second": 4.192,
      "step": 1836
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 3.3817930221557617,
      "learning_rate": 0.000527843137254902,
      "loss": 0.3317,
      "step": 1840
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 3.209474802017212,
      "learning_rate": 0.0005270588235294117,
      "loss": 0.2417,
      "step": 1860
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 2.3181443214416504,
      "learning_rate": 0.0005262745098039215,
      "loss": 0.2331,
      "step": 1880
    },
    {
      "epoch": 6.209150326797386,
      "grad_norm": 5.485884189605713,
      "learning_rate": 0.0005254901960784314,
      "loss": 0.2627,
      "step": 1900
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 5.382503509521484,
      "learning_rate": 0.0005247058823529411,
      "loss": 0.2075,
      "step": 1920
    },
    {
      "epoch": 6.339869281045751,
      "grad_norm": 11.722038269042969,
      "learning_rate": 0.0005239215686274509,
      "loss": 0.2615,
      "step": 1940
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 4.520508766174316,
      "learning_rate": 0.0005231372549019608,
      "loss": 0.2307,
      "step": 1960
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 3.942992925643921,
      "learning_rate": 0.0005223529411764705,
      "loss": 0.1942,
      "step": 1980
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 3.102820873260498,
      "learning_rate": 0.0005215686274509803,
      "loss": 0.2322,
      "step": 2000
    },
    {
      "epoch": 6.601307189542483,
      "grad_norm": 0.918904185295105,
      "learning_rate": 0.0005207843137254902,
      "loss": 0.1446,
      "step": 2020
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.8715252876281738,
      "learning_rate": 0.00052,
      "loss": 0.3179,
      "step": 2040
    },
    {
      "epoch": 6.73202614379085,
      "grad_norm": 2.3910787105560303,
      "learning_rate": 0.0005192156862745098,
      "loss": 0.2336,
      "step": 2060
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 3.3608205318450928,
      "learning_rate": 0.0005184313725490196,
      "loss": 0.294,
      "step": 2080
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 0.915463387966156,
      "learning_rate": 0.0005176470588235294,
      "loss": 0.2261,
      "step": 2100
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 2.45554518699646,
      "learning_rate": 0.0005168627450980392,
      "loss": 0.2971,
      "step": 2120
    },
    {
      "epoch": 6.993464052287582,
      "grad_norm": 3.0262696743011475,
      "learning_rate": 0.000516078431372549,
      "loss": 0.1868,
      "step": 2140
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8700980392156863,
      "eval_combined_score": 0.8895944741532977,
      "eval_f1": 0.9090909090909091,
      "eval_loss": 0.49459558725357056,
      "eval_runtime": 12.2617,
      "eval_samples_per_second": 33.274,
      "eval_steps_per_second": 4.159,
      "step": 2142
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 2.6395487785339355,
      "learning_rate": 0.0005152941176470588,
      "loss": 0.2715,
      "step": 2160
    },
    {
      "epoch": 7.124183006535947,
      "grad_norm": 6.222313404083252,
      "learning_rate": 0.0005145098039215685,
      "loss": 0.3088,
      "step": 2180
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 4.073625564575195,
      "learning_rate": 0.0005137254901960783,
      "loss": 0.2796,
      "step": 2200
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 1.4792762994766235,
      "learning_rate": 0.0005129411764705882,
      "loss": 0.1463,
      "step": 2220
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 4.472343444824219,
      "learning_rate": 0.000512156862745098,
      "loss": 0.313,
      "step": 2240
    },
    {
      "epoch": 7.38562091503268,
      "grad_norm": 2.798659324645996,
      "learning_rate": 0.0005113725490196077,
      "loss": 0.2208,
      "step": 2260
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 5.381096839904785,
      "learning_rate": 0.0005105882352941176,
      "loss": 0.1881,
      "step": 2280
    },
    {
      "epoch": 7.516339869281046,
      "grad_norm": 3.1408798694610596,
      "learning_rate": 0.0005098039215686274,
      "loss": 0.1733,
      "step": 2300
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 5.0262956619262695,
      "learning_rate": 0.0005090196078431372,
      "loss": 0.2567,
      "step": 2320
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 4.223214149475098,
      "learning_rate": 0.000508235294117647,
      "loss": 0.2786,
      "step": 2340
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 0.13220669329166412,
      "learning_rate": 0.0005074509803921568,
      "loss": 0.2092,
      "step": 2360
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 3.7369203567504883,
      "learning_rate": 0.0005066666666666667,
      "loss": 0.133,
      "step": 2380
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 2.5343165397644043,
      "learning_rate": 0.0005058823529411764,
      "loss": 0.3432,
      "step": 2400
    },
    {
      "epoch": 7.908496732026144,
      "grad_norm": 4.448063850402832,
      "learning_rate": 0.0005050980392156862,
      "loss": 0.195,
      "step": 2420
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 5.183669090270996,
      "learning_rate": 0.0005043137254901961,
      "loss": 0.1542,
      "step": 2440
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8984718442537157,
      "eval_f1": 0.9145907473309609,
      "eval_loss": 0.4384962320327759,
      "eval_runtime": 11.7867,
      "eval_samples_per_second": 34.615,
      "eval_steps_per_second": 4.327,
      "step": 2448
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 5.273595333099365,
      "learning_rate": 0.0005035294117647058,
      "loss": 0.2217,
      "step": 2460
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 0.06172780692577362,
      "learning_rate": 0.0005027450980392156,
      "loss": 0.1454,
      "step": 2480
    },
    {
      "epoch": 8.169934640522875,
      "grad_norm": 2.226492404937744,
      "learning_rate": 0.0005019607843137255,
      "loss": 0.1981,
      "step": 2500
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 1.818300485610962,
      "learning_rate": 0.0005011764705882353,
      "loss": 0.2672,
      "step": 2520
    },
    {
      "epoch": 8.300653594771243,
      "grad_norm": 3.7324159145355225,
      "learning_rate": 0.0005003921568627451,
      "loss": 0.2294,
      "step": 2540
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 9.740617752075195,
      "learning_rate": 0.0004996078431372549,
      "loss": 0.2007,
      "step": 2560
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 1.3746023178100586,
      "learning_rate": 0.0004988235294117647,
      "loss": 0.2557,
      "step": 2580
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 4.69607400894165,
      "learning_rate": 0.0004980392156862745,
      "loss": 0.1824,
      "step": 2600
    },
    {
      "epoch": 8.562091503267974,
      "grad_norm": 1.5658860206604004,
      "learning_rate": 0.0004972549019607843,
      "loss": 0.1881,
      "step": 2620
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 1.2388360500335693,
      "learning_rate": 0.0004964705882352941,
      "loss": 0.2033,
      "step": 2640
    },
    {
      "epoch": 8.69281045751634,
      "grad_norm": 9.54979419708252,
      "learning_rate": 0.0004956862745098038,
      "loss": 0.2776,
      "step": 2660
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 5.88236141204834,
      "learning_rate": 0.0004949019607843136,
      "loss": 0.2475,
      "step": 2680
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 2.6466479301452637,
      "learning_rate": 0.0004941176470588235,
      "loss": 0.1926,
      "step": 2700
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 5.85067892074585,
      "learning_rate": 0.0004933333333333333,
      "loss": 0.2754,
      "step": 2720
    },
    {
      "epoch": 8.954248366013072,
      "grad_norm": 2.149876356124878,
      "learning_rate": 0.0004925490196078431,
      "loss": 0.2038,
      "step": 2740
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.896566805160726,
      "eval_f1": 0.9107806691449813,
      "eval_loss": 0.37029266357421875,
      "eval_runtime": 11.8534,
      "eval_samples_per_second": 34.421,
      "eval_steps_per_second": 4.303,
      "step": 2754
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 6.567801475524902,
      "learning_rate": 0.0004917647058823529,
      "loss": 0.3172,
      "step": 2760
    },
    {
      "epoch": 9.084967320261438,
      "grad_norm": 7.757810592651367,
      "learning_rate": 0.0004909803921568627,
      "loss": 0.1722,
      "step": 2780
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 4.116772174835205,
      "learning_rate": 0.0004901960784313725,
      "loss": 0.1718,
      "step": 2800
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 3.8074138164520264,
      "learning_rate": 0.0004894117647058823,
      "loss": 0.1856,
      "step": 2820
    },
    {
      "epoch": 9.281045751633988,
      "grad_norm": 3.917083740234375,
      "learning_rate": 0.0004886274509803921,
      "loss": 0.2458,
      "step": 2840
    },
    {
      "epoch": 9.34640522875817,
      "grad_norm": 5.70720100402832,
      "learning_rate": 0.0004878431372549019,
      "loss": 0.1993,
      "step": 2860
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 5.183429718017578,
      "learning_rate": 0.0004870588235294117,
      "loss": 0.1963,
      "step": 2880
    },
    {
      "epoch": 9.477124183006536,
      "grad_norm": 2.391446352005005,
      "learning_rate": 0.00048627450980392154,
      "loss": 0.1485,
      "step": 2900
    },
    {
      "epoch": 9.542483660130719,
      "grad_norm": 4.225736618041992,
      "learning_rate": 0.0004854901960784313,
      "loss": 0.3464,
      "step": 2920
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 5.981695175170898,
      "learning_rate": 0.00048470588235294113,
      "loss": 0.1887,
      "step": 2940
    },
    {
      "epoch": 9.673202614379084,
      "grad_norm": 0.4195505380630493,
      "learning_rate": 0.00048392156862745096,
      "loss": 0.1689,
      "step": 2960
    },
    {
      "epoch": 9.738562091503269,
      "grad_norm": 6.471907138824463,
      "learning_rate": 0.0004831372549019608,
      "loss": 0.3307,
      "step": 2980
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 3.063584327697754,
      "learning_rate": 0.00048235294117647055,
      "loss": 0.2572,
      "step": 3000
    },
    {
      "epoch": 9.869281045751634,
      "grad_norm": 9.338116645812988,
      "learning_rate": 0.00048156862745098037,
      "loss": 0.1875,
      "step": 3020
    },
    {
      "epoch": 9.934640522875817,
      "grad_norm": 7.038429260253906,
      "learning_rate": 0.0004807843137254902,
      "loss": 0.2542,
      "step": 3040
    },
    {
      "epoch": 10.0,
      "grad_norm": 58.04115676879883,
      "learning_rate": 0.00047999999999999996,
      "loss": 0.2093,
      "step": 3060
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8983193277310924,
      "eval_f1": 0.9142857142857143,
      "eval_loss": 0.3629760444164276,
      "eval_runtime": 11.8942,
      "eval_samples_per_second": 34.303,
      "eval_steps_per_second": 4.288,
      "step": 3060
    },
    {
      "epoch": 10.065359477124183,
      "grad_norm": 0.3896079957485199,
      "learning_rate": 0.0004792156862745098,
      "loss": 0.2045,
      "step": 3080
    },
    {
      "epoch": 10.130718954248366,
      "grad_norm": 3.0115654468536377,
      "learning_rate": 0.0004784313725490196,
      "loss": 0.1611,
      "step": 3100
    },
    {
      "epoch": 10.196078431372548,
      "grad_norm": 4.294755935668945,
      "learning_rate": 0.0004776470588235293,
      "loss": 0.1512,
      "step": 3120
    },
    {
      "epoch": 10.261437908496733,
      "grad_norm": 2.4881410598754883,
      "learning_rate": 0.00047686274509803914,
      "loss": 0.2755,
      "step": 3140
    },
    {
      "epoch": 10.326797385620916,
      "grad_norm": 6.2383856773376465,
      "learning_rate": 0.00047607843137254896,
      "loss": 0.1738,
      "step": 3160
    },
    {
      "epoch": 10.392156862745098,
      "grad_norm": 0.3094518780708313,
      "learning_rate": 0.0004752941176470588,
      "loss": 0.1557,
      "step": 3180
    },
    {
      "epoch": 10.457516339869281,
      "grad_norm": 6.757462978363037,
      "learning_rate": 0.00047450980392156855,
      "loss": 0.2254,
      "step": 3200
    },
    {
      "epoch": 10.522875816993464,
      "grad_norm": 7.907927513122559,
      "learning_rate": 0.00047372549019607837,
      "loss": 0.1749,
      "step": 3220
    },
    {
      "epoch": 10.588235294117647,
      "grad_norm": 19.834611892700195,
      "learning_rate": 0.0004729411764705882,
      "loss": 0.1871,
      "step": 3240
    },
    {
      "epoch": 10.65359477124183,
      "grad_norm": 5.360267639160156,
      "learning_rate": 0.00047215686274509796,
      "loss": 0.216,
      "step": 3260
    },
    {
      "epoch": 10.718954248366012,
      "grad_norm": 5.710057258605957,
      "learning_rate": 0.0004713725490196078,
      "loss": 0.2055,
      "step": 3280
    },
    {
      "epoch": 10.784313725490197,
      "grad_norm": 3.904207944869995,
      "learning_rate": 0.0004705882352941176,
      "loss": 0.2222,
      "step": 3300
    },
    {
      "epoch": 10.84967320261438,
      "grad_norm": 1.0633164644241333,
      "learning_rate": 0.00046980392156862743,
      "loss": 0.1558,
      "step": 3320
    },
    {
      "epoch": 10.915032679738562,
      "grad_norm": 1.8358304500579834,
      "learning_rate": 0.0004690196078431372,
      "loss": 0.2114,
      "step": 3340
    },
    {
      "epoch": 10.980392156862745,
      "grad_norm": 2.4073548316955566,
      "learning_rate": 0.000468235294117647,
      "loss": 0.2278,
      "step": 3360
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8987736437331115,
      "eval_f1": 0.9151943462897526,
      "eval_loss": 0.433199942111969,
      "eval_runtime": 11.9122,
      "eval_samples_per_second": 34.251,
      "eval_steps_per_second": 4.281,
      "step": 3366
    },
    {
      "epoch": 11.045751633986928,
      "grad_norm": 0.10616472363471985,
      "learning_rate": 0.00046745098039215684,
      "loss": 0.2084,
      "step": 3380
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 6.29855489730835,
      "learning_rate": 0.0004666666666666666,
      "loss": 0.1651,
      "step": 3400
    },
    {
      "epoch": 11.176470588235293,
      "grad_norm": 8.64156436920166,
      "learning_rate": 0.00046588235294117643,
      "loss": 0.2124,
      "step": 3420
    },
    {
      "epoch": 11.241830065359476,
      "grad_norm": 8.904486656188965,
      "learning_rate": 0.00046509803921568625,
      "loss": 0.1676,
      "step": 3440
    },
    {
      "epoch": 11.30718954248366,
      "grad_norm": 4.851956367492676,
      "learning_rate": 0.0004643137254901961,
      "loss": 0.2499,
      "step": 3460
    },
    {
      "epoch": 11.372549019607844,
      "grad_norm": 1.794715404510498,
      "learning_rate": 0.00046352941176470584,
      "loss": 0.1803,
      "step": 3480
    },
    {
      "epoch": 11.437908496732026,
      "grad_norm": 4.4059977531433105,
      "learning_rate": 0.00046274509803921566,
      "loss": 0.123,
      "step": 3500
    },
    {
      "epoch": 11.50326797385621,
      "grad_norm": 11.805132865905762,
      "learning_rate": 0.0004619607843137255,
      "loss": 0.178,
      "step": 3520
    },
    {
      "epoch": 11.568627450980392,
      "grad_norm": 8.272192001342773,
      "learning_rate": 0.00046117647058823525,
      "loss": 0.223,
      "step": 3540
    },
    {
      "epoch": 11.633986928104575,
      "grad_norm": 1.4597676992416382,
      "learning_rate": 0.0004603921568627451,
      "loss": 0.1483,
      "step": 3560
    },
    {
      "epoch": 11.699346405228757,
      "grad_norm": 3.8940494060516357,
      "learning_rate": 0.0004596078431372549,
      "loss": 0.1427,
      "step": 3580
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 3.2181243896484375,
      "learning_rate": 0.0004588235294117646,
      "loss": 0.1167,
      "step": 3600
    },
    {
      "epoch": 11.830065359477125,
      "grad_norm": 6.069653034210205,
      "learning_rate": 0.00045803921568627443,
      "loss": 0.1855,
      "step": 3620
    },
    {
      "epoch": 11.895424836601308,
      "grad_norm": 7.126559257507324,
      "learning_rate": 0.00045725490196078426,
      "loss": 0.1746,
      "step": 3640
    },
    {
      "epoch": 11.96078431372549,
      "grad_norm": 9.612767219543457,
      "learning_rate": 0.0004564705882352941,
      "loss": 0.2615,
      "step": 3660
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.8700980392156863,
      "eval_combined_score": 0.8895944741532977,
      "eval_f1": 0.9090909090909091,
      "eval_loss": 0.41122138500213623,
      "eval_runtime": 11.9292,
      "eval_samples_per_second": 34.202,
      "eval_steps_per_second": 4.275,
      "step": 3672
    },
    {
      "epoch": 12.026143790849673,
      "grad_norm": 3.0122032165527344,
      "learning_rate": 0.00045568627450980385,
      "loss": 0.1456,
      "step": 3680
    },
    {
      "epoch": 12.091503267973856,
      "grad_norm": 2.1699979305267334,
      "learning_rate": 0.00045490196078431367,
      "loss": 0.1817,
      "step": 3700
    },
    {
      "epoch": 12.156862745098039,
      "grad_norm": 1.193629264831543,
      "learning_rate": 0.0004541176470588235,
      "loss": 0.2579,
      "step": 3720
    },
    {
      "epoch": 12.222222222222221,
      "grad_norm": 9.5735445022583,
      "learning_rate": 0.00045333333333333326,
      "loss": 0.1809,
      "step": 3740
    },
    {
      "epoch": 12.287581699346406,
      "grad_norm": 4.861612319946289,
      "learning_rate": 0.0004525490196078431,
      "loss": 0.2213,
      "step": 3760
    },
    {
      "epoch": 12.352941176470589,
      "grad_norm": 1.686596155166626,
      "learning_rate": 0.0004517647058823529,
      "loss": 0.1742,
      "step": 3780
    },
    {
      "epoch": 12.418300653594772,
      "grad_norm": 3.374800682067871,
      "learning_rate": 0.0004509803921568627,
      "loss": 0.2081,
      "step": 3800
    },
    {
      "epoch": 12.483660130718954,
      "grad_norm": 0.4716832637786865,
      "learning_rate": 0.0004501960784313725,
      "loss": 0.2026,
      "step": 3820
    },
    {
      "epoch": 12.549019607843137,
      "grad_norm": 7.15357780456543,
      "learning_rate": 0.0004494117647058823,
      "loss": 0.2147,
      "step": 3840
    },
    {
      "epoch": 12.61437908496732,
      "grad_norm": 6.905532360076904,
      "learning_rate": 0.00044862745098039214,
      "loss": 0.2533,
      "step": 3860
    },
    {
      "epoch": 12.679738562091503,
      "grad_norm": 5.675382614135742,
      "learning_rate": 0.0004478431372549019,
      "loss": 0.1852,
      "step": 3880
    },
    {
      "epoch": 12.745098039215687,
      "grad_norm": 8.987394332885742,
      "learning_rate": 0.0004470588235294117,
      "loss": 0.2246,
      "step": 3900
    },
    {
      "epoch": 12.81045751633987,
      "grad_norm": 7.190474033355713,
      "learning_rate": 0.00044627450980392155,
      "loss": 0.1723,
      "step": 3920
    },
    {
      "epoch": 12.875816993464053,
      "grad_norm": 0.08707324415445328,
      "learning_rate": 0.00044549019607843137,
      "loss": 0.097,
      "step": 3940
    },
    {
      "epoch": 12.941176470588236,
      "grad_norm": 0.2681383490562439,
      "learning_rate": 0.00044470588235294114,
      "loss": 0.2044,
      "step": 3960
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.8700980392156863,
      "eval_combined_score": 0.8908086189400636,
      "eval_f1": 0.9115191986644409,
      "eval_loss": 0.6174877285957336,
      "eval_runtime": 11.9215,
      "eval_samples_per_second": 34.224,
      "eval_steps_per_second": 4.278,
      "step": 3978
    },
    {
      "epoch": 13.006535947712418,
      "grad_norm": 5.747889518737793,
      "learning_rate": 0.00044392156862745096,
      "loss": 0.1849,
      "step": 3980
    },
    {
      "epoch": 13.071895424836601,
      "grad_norm": 4.397104740142822,
      "learning_rate": 0.0004431372549019608,
      "loss": 0.2229,
      "step": 4000
    },
    {
      "epoch": 13.137254901960784,
      "grad_norm": 9.64212703704834,
      "learning_rate": 0.0004423529411764706,
      "loss": 0.1858,
      "step": 4020
    },
    {
      "epoch": 13.202614379084967,
      "grad_norm": 7.902956962585449,
      "learning_rate": 0.00044156862745098037,
      "loss": 0.2008,
      "step": 4040
    },
    {
      "epoch": 13.267973856209151,
      "grad_norm": 14.825713157653809,
      "learning_rate": 0.0004407843137254902,
      "loss": 0.1167,
      "step": 4060
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 0.5294255018234253,
      "learning_rate": 0.0004399999999999999,
      "loss": 0.2479,
      "step": 4080
    },
    {
      "epoch": 13.398692810457517,
      "grad_norm": 10.759254455566406,
      "learning_rate": 0.00043921568627450973,
      "loss": 0.2289,
      "step": 4100
    },
    {
      "epoch": 13.4640522875817,
      "grad_norm": 3.187744379043579,
      "learning_rate": 0.00043843137254901955,
      "loss": 0.2259,
      "step": 4120
    },
    {
      "epoch": 13.529411764705882,
      "grad_norm": 0.10584583133459091,
      "learning_rate": 0.0004376470588235294,
      "loss": 0.2124,
      "step": 4140
    },
    {
      "epoch": 13.594771241830065,
      "grad_norm": 4.0610857009887695,
      "learning_rate": 0.00043686274509803914,
      "loss": 0.2168,
      "step": 4160
    },
    {
      "epoch": 13.660130718954248,
      "grad_norm": 2.194441080093384,
      "learning_rate": 0.00043607843137254896,
      "loss": 0.215,
      "step": 4180
    },
    {
      "epoch": 13.72549019607843,
      "grad_norm": 7.2593302726745605,
      "learning_rate": 0.0004352941176470588,
      "loss": 0.1319,
      "step": 4200
    },
    {
      "epoch": 13.790849673202615,
      "grad_norm": 21.19906234741211,
      "learning_rate": 0.00043450980392156855,
      "loss": 0.2316,
      "step": 4220
    },
    {
      "epoch": 13.856209150326798,
      "grad_norm": 4.825569152832031,
      "learning_rate": 0.0004337254901960784,
      "loss": 0.1808,
      "step": 4240
    },
    {
      "epoch": 13.92156862745098,
      "grad_norm": 1.3077608346939087,
      "learning_rate": 0.0004329411764705882,
      "loss": 0.1509,
      "step": 4260
    },
    {
      "epoch": 13.986928104575163,
      "grad_norm": 0.4456295073032379,
      "learning_rate": 0.000432156862745098,
      "loss": 0.121,
      "step": 4280
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9047459893048129,
      "eval_f1": 0.9197860962566845,
      "eval_loss": 0.4277988374233246,
      "eval_runtime": 11.9412,
      "eval_samples_per_second": 34.167,
      "eval_steps_per_second": 4.271,
      "step": 4284
    },
    {
      "epoch": 14.052287581699346,
      "grad_norm": 3.0772275924682617,
      "learning_rate": 0.0004313725490196078,
      "loss": 0.1777,
      "step": 4300
    },
    {
      "epoch": 14.117647058823529,
      "grad_norm": 5.118890762329102,
      "learning_rate": 0.0004305882352941176,
      "loss": 0.1782,
      "step": 4320
    },
    {
      "epoch": 14.183006535947712,
      "grad_norm": 4.196028709411621,
      "learning_rate": 0.00042980392156862743,
      "loss": 0.143,
      "step": 4340
    },
    {
      "epoch": 14.248366013071895,
      "grad_norm": 6.832873821258545,
      "learning_rate": 0.0004290196078431372,
      "loss": 0.2147,
      "step": 4360
    },
    {
      "epoch": 14.313725490196079,
      "grad_norm": 3.701714515686035,
      "learning_rate": 0.000428235294117647,
      "loss": 0.1369,
      "step": 4380
    },
    {
      "epoch": 14.379084967320262,
      "grad_norm": 2.2593042850494385,
      "learning_rate": 0.00042745098039215684,
      "loss": 0.1525,
      "step": 4400
    },
    {
      "epoch": 14.444444444444445,
      "grad_norm": 2.9739737510681152,
      "learning_rate": 0.00042666666666666667,
      "loss": 0.0738,
      "step": 4420
    },
    {
      "epoch": 14.509803921568627,
      "grad_norm": 10.790017127990723,
      "learning_rate": 0.00042588235294117643,
      "loss": 0.3576,
      "step": 4440
    },
    {
      "epoch": 14.57516339869281,
      "grad_norm": 4.716683387756348,
      "learning_rate": 0.00042509803921568626,
      "loss": 0.1327,
      "step": 4460
    },
    {
      "epoch": 14.640522875816993,
      "grad_norm": 1.4590154886245728,
      "learning_rate": 0.0004243137254901961,
      "loss": 0.2675,
      "step": 4480
    },
    {
      "epoch": 14.705882352941176,
      "grad_norm": 4.250929355621338,
      "learning_rate": 0.0004235294117647059,
      "loss": 0.166,
      "step": 4500
    },
    {
      "epoch": 14.77124183006536,
      "grad_norm": 2.2062771320343018,
      "learning_rate": 0.00042274509803921567,
      "loss": 0.1315,
      "step": 4520
    },
    {
      "epoch": 14.836601307189543,
      "grad_norm": 9.825286865234375,
      "learning_rate": 0.0004219607843137255,
      "loss": 0.1782,
      "step": 4540
    },
    {
      "epoch": 14.901960784313726,
      "grad_norm": 0.9690985083580017,
      "learning_rate": 0.0004211764705882352,
      "loss": 0.1335,
      "step": 4560
    },
    {
      "epoch": 14.967320261437909,
      "grad_norm": 0.021605689078569412,
      "learning_rate": 0.000420392156862745,
      "loss": 0.1274,
      "step": 4580
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8950191964897847,
      "eval_f1": 0.9125874125874125,
      "eval_loss": 0.5395230054855347,
      "eval_runtime": 11.9347,
      "eval_samples_per_second": 34.186,
      "eval_steps_per_second": 4.273,
      "step": 4590
    },
    {
      "epoch": 15.032679738562091,
      "grad_norm": 14.966466903686523,
      "learning_rate": 0.00041960784313725485,
      "loss": 0.1628,
      "step": 4600
    },
    {
      "epoch": 15.098039215686274,
      "grad_norm": 3.043574094772339,
      "learning_rate": 0.00041882352941176467,
      "loss": 0.1662,
      "step": 4620
    },
    {
      "epoch": 15.163398692810457,
      "grad_norm": 7.358771324157715,
      "learning_rate": 0.00041803921568627444,
      "loss": 0.2032,
      "step": 4640
    },
    {
      "epoch": 15.22875816993464,
      "grad_norm": 0.2943430244922638,
      "learning_rate": 0.00041725490196078426,
      "loss": 0.1473,
      "step": 4660
    },
    {
      "epoch": 15.294117647058824,
      "grad_norm": 6.704563617706299,
      "learning_rate": 0.0004164705882352941,
      "loss": 0.2443,
      "step": 4680
    },
    {
      "epoch": 15.359477124183007,
      "grad_norm": 7.178053855895996,
      "learning_rate": 0.00041568627450980385,
      "loss": 0.136,
      "step": 4700
    },
    {
      "epoch": 15.42483660130719,
      "grad_norm": 3.0401501655578613,
      "learning_rate": 0.00041490196078431367,
      "loss": 0.0931,
      "step": 4720
    },
    {
      "epoch": 15.490196078431373,
      "grad_norm": 7.992055416107178,
      "learning_rate": 0.0004141176470588235,
      "loss": 0.0976,
      "step": 4740
    },
    {
      "epoch": 15.555555555555555,
      "grad_norm": 8.695615768432617,
      "learning_rate": 0.0004133333333333333,
      "loss": 0.1614,
      "step": 4760
    },
    {
      "epoch": 15.620915032679738,
      "grad_norm": 5.1838250160217285,
      "learning_rate": 0.0004125490196078431,
      "loss": 0.1469,
      "step": 4780
    },
    {
      "epoch": 15.686274509803921,
      "grad_norm": 0.24730412662029266,
      "learning_rate": 0.0004117647058823529,
      "loss": 0.1351,
      "step": 4800
    },
    {
      "epoch": 15.751633986928105,
      "grad_norm": 8.905023574829102,
      "learning_rate": 0.00041098039215686273,
      "loss": 0.252,
      "step": 4820
    },
    {
      "epoch": 15.816993464052288,
      "grad_norm": 1.5904427766799927,
      "learning_rate": 0.0004101960784313725,
      "loss": 0.1581,
      "step": 4840
    },
    {
      "epoch": 15.882352941176471,
      "grad_norm": 6.4876604080200195,
      "learning_rate": 0.0004094117647058823,
      "loss": 0.1783,
      "step": 4860
    },
    {
      "epoch": 15.947712418300654,
      "grad_norm": 0.06485678255558014,
      "learning_rate": 0.00040862745098039214,
      "loss": 0.1588,
      "step": 4880
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.8976366453317077,
      "eval_f1": 0.9153713298791019,
      "eval_loss": 0.4216829538345337,
      "eval_runtime": 11.9182,
      "eval_samples_per_second": 34.233,
      "eval_steps_per_second": 4.279,
      "step": 4896
    },
    {
      "epoch": 16.013071895424837,
      "grad_norm": 0.6512068510055542,
      "learning_rate": 0.00040784313725490196,
      "loss": 0.1784,
      "step": 4900
    },
    {
      "epoch": 16.07843137254902,
      "grad_norm": 0.5098556280136108,
      "learning_rate": 0.00040705882352941173,
      "loss": 0.1659,
      "step": 4920
    },
    {
      "epoch": 16.143790849673202,
      "grad_norm": 16.999635696411133,
      "learning_rate": 0.00040627450980392155,
      "loss": 0.1775,
      "step": 4940
    },
    {
      "epoch": 16.209150326797385,
      "grad_norm": 4.82088041305542,
      "learning_rate": 0.0004054901960784314,
      "loss": 0.139,
      "step": 4960
    },
    {
      "epoch": 16.274509803921568,
      "grad_norm": 0.08083713799715042,
      "learning_rate": 0.0004047058823529412,
      "loss": 0.1344,
      "step": 4980
    },
    {
      "epoch": 16.33986928104575,
      "grad_norm": 1.5249601602554321,
      "learning_rate": 0.00040392156862745096,
      "loss": 0.0864,
      "step": 5000
    },
    {
      "epoch": 16.405228758169933,
      "grad_norm": 7.463940143585205,
      "learning_rate": 0.0004031372549019608,
      "loss": 0.1665,
      "step": 5020
    },
    {
      "epoch": 16.470588235294116,
      "grad_norm": 2.22148060798645,
      "learning_rate": 0.0004023529411764705,
      "loss": 0.1423,
      "step": 5040
    },
    {
      "epoch": 16.535947712418302,
      "grad_norm": 23.744558334350586,
      "learning_rate": 0.0004015686274509803,
      "loss": 0.1573,
      "step": 5060
    },
    {
      "epoch": 16.601307189542485,
      "grad_norm": 0.9390167593955994,
      "learning_rate": 0.00040078431372549014,
      "loss": 0.2106,
      "step": 5080
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 1.7922947406768799,
      "learning_rate": 0.00039999999999999996,
      "loss": 0.1322,
      "step": 5100
    },
    {
      "epoch": 16.73202614379085,
      "grad_norm": 6.247915744781494,
      "learning_rate": 0.00039921568627450973,
      "loss": 0.1528,
      "step": 5120
    },
    {
      "epoch": 16.797385620915033,
      "grad_norm": 0.10499566793441772,
      "learning_rate": 0.00039843137254901955,
      "loss": 0.1998,
      "step": 5140
    },
    {
      "epoch": 16.862745098039216,
      "grad_norm": 9.982261657714844,
      "learning_rate": 0.0003976470588235294,
      "loss": 0.1743,
      "step": 5160
    },
    {
      "epoch": 16.9281045751634,
      "grad_norm": 5.7425055503845215,
      "learning_rate": 0.00039686274509803914,
      "loss": 0.1722,
      "step": 5180
    },
    {
      "epoch": 16.99346405228758,
      "grad_norm": 6.47723388671875,
      "learning_rate": 0.00039607843137254897,
      "loss": 0.2012,
      "step": 5200
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.8725490196078431,
      "eval_combined_score": 0.8908199643493762,
      "eval_f1": 0.9090909090909091,
      "eval_loss": 0.5137746930122375,
      "eval_runtime": 11.9213,
      "eval_samples_per_second": 34.224,
      "eval_steps_per_second": 4.278,
      "step": 5202
    },
    {
      "epoch": 17.058823529411764,
      "grad_norm": 5.667887210845947,
      "learning_rate": 0.0003952941176470588,
      "loss": 0.166,
      "step": 5220
    },
    {
      "epoch": 17.124183006535947,
      "grad_norm": 9.301752090454102,
      "learning_rate": 0.0003945098039215686,
      "loss": 0.1117,
      "step": 5240
    },
    {
      "epoch": 17.18954248366013,
      "grad_norm": 7.531226634979248,
      "learning_rate": 0.0003937254901960784,
      "loss": 0.1922,
      "step": 5260
    },
    {
      "epoch": 17.254901960784313,
      "grad_norm": 0.7468505501747131,
      "learning_rate": 0.0003929411764705882,
      "loss": 0.1307,
      "step": 5280
    },
    {
      "epoch": 17.320261437908496,
      "grad_norm": 0.1388261914253235,
      "learning_rate": 0.000392156862745098,
      "loss": 0.1173,
      "step": 5300
    },
    {
      "epoch": 17.38562091503268,
      "grad_norm": 4.58477783203125,
      "learning_rate": 0.0003913725490196078,
      "loss": 0.1787,
      "step": 5320
    },
    {
      "epoch": 17.45098039215686,
      "grad_norm": 10.907722473144531,
      "learning_rate": 0.0003905882352941176,
      "loss": 0.1961,
      "step": 5340
    },
    {
      "epoch": 17.516339869281047,
      "grad_norm": 6.919378757476807,
      "learning_rate": 0.00038980392156862743,
      "loss": 0.1174,
      "step": 5360
    },
    {
      "epoch": 17.58169934640523,
      "grad_norm": 8.384943962097168,
      "learning_rate": 0.00038901960784313726,
      "loss": 0.1557,
      "step": 5380
    },
    {
      "epoch": 17.647058823529413,
      "grad_norm": 2.457310914993286,
      "learning_rate": 0.000388235294117647,
      "loss": 0.1011,
      "step": 5400
    },
    {
      "epoch": 17.712418300653596,
      "grad_norm": 0.2068861722946167,
      "learning_rate": 0.00038745098039215685,
      "loss": 0.15,
      "step": 5420
    },
    {
      "epoch": 17.77777777777778,
      "grad_norm": 18.423786163330078,
      "learning_rate": 0.00038666666666666667,
      "loss": 0.176,
      "step": 5440
    },
    {
      "epoch": 17.84313725490196,
      "grad_norm": 8.036540031433105,
      "learning_rate": 0.0003858823529411765,
      "loss": 0.1364,
      "step": 5460
    },
    {
      "epoch": 17.908496732026144,
      "grad_norm": 15.55262279510498,
      "learning_rate": 0.00038509803921568626,
      "loss": 0.1263,
      "step": 5480
    },
    {
      "epoch": 17.973856209150327,
      "grad_norm": 6.023940086364746,
      "learning_rate": 0.000384313725490196,
      "loss": 0.2088,
      "step": 5500
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8990712074303405,
      "eval_f1": 0.9157894736842105,
      "eval_loss": 0.43500855565071106,
      "eval_runtime": 11.922,
      "eval_samples_per_second": 34.222,
      "eval_steps_per_second": 4.278,
      "step": 5508
    },
    {
      "epoch": 18.03921568627451,
      "grad_norm": 0.1371079683303833,
      "learning_rate": 0.0003835294117647058,
      "loss": 0.157,
      "step": 5520
    },
    {
      "epoch": 18.104575163398692,
      "grad_norm": 0.39095816016197205,
      "learning_rate": 0.0003827450980392156,
      "loss": 0.0995,
      "step": 5540
    },
    {
      "epoch": 18.169934640522875,
      "grad_norm": 14.031805992126465,
      "learning_rate": 0.00038196078431372544,
      "loss": 0.1675,
      "step": 5560
    },
    {
      "epoch": 18.235294117647058,
      "grad_norm": 1.1123666763305664,
      "learning_rate": 0.00038117647058823526,
      "loss": 0.1319,
      "step": 5580
    },
    {
      "epoch": 18.30065359477124,
      "grad_norm": 6.75839900970459,
      "learning_rate": 0.00038039215686274503,
      "loss": 0.1338,
      "step": 5600
    },
    {
      "epoch": 18.366013071895424,
      "grad_norm": 0.491633802652359,
      "learning_rate": 0.00037960784313725485,
      "loss": 0.1524,
      "step": 5620
    },
    {
      "epoch": 18.431372549019606,
      "grad_norm": 9.451212882995605,
      "learning_rate": 0.00037882352941176467,
      "loss": 0.1176,
      "step": 5640
    },
    {
      "epoch": 18.49673202614379,
      "grad_norm": 7.391383647918701,
      "learning_rate": 0.00037803921568627444,
      "loss": 0.163,
      "step": 5660
    },
    {
      "epoch": 18.562091503267975,
      "grad_norm": 5.188790798187256,
      "learning_rate": 0.00037725490196078426,
      "loss": 0.15,
      "step": 5680
    },
    {
      "epoch": 18.627450980392158,
      "grad_norm": 6.242737293243408,
      "learning_rate": 0.0003764705882352941,
      "loss": 0.2216,
      "step": 5700
    },
    {
      "epoch": 18.69281045751634,
      "grad_norm": 14.202898979187012,
      "learning_rate": 0.0003756862745098039,
      "loss": 0.1026,
      "step": 5720
    },
    {
      "epoch": 18.758169934640524,
      "grad_norm": 0.11569537967443466,
      "learning_rate": 0.0003749019607843137,
      "loss": 0.1552,
      "step": 5740
    },
    {
      "epoch": 18.823529411764707,
      "grad_norm": 6.31910514831543,
      "learning_rate": 0.0003741176470588235,
      "loss": 0.0535,
      "step": 5760
    },
    {
      "epoch": 18.88888888888889,
      "grad_norm": 2.6942977905273438,
      "learning_rate": 0.0003733333333333333,
      "loss": 0.1476,
      "step": 5780
    },
    {
      "epoch": 18.954248366013072,
      "grad_norm": 0.8500776886940002,
      "learning_rate": 0.0003725490196078431,
      "loss": 0.1929,
      "step": 5800
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.875,
      "eval_combined_score": 0.8931521739130435,
      "eval_f1": 0.9113043478260869,
      "eval_loss": 0.527996301651001,
      "eval_runtime": 11.8976,
      "eval_samples_per_second": 34.293,
      "eval_steps_per_second": 4.287,
      "step": 5814
    },
    {
      "epoch": 19.019607843137255,
      "grad_norm": 4.012423515319824,
      "learning_rate": 0.0003717647058823529,
      "loss": 0.0793,
      "step": 5820
    },
    {
      "epoch": 19.084967320261438,
      "grad_norm": 12.47690486907959,
      "learning_rate": 0.00037098039215686273,
      "loss": 0.1147,
      "step": 5840
    },
    {
      "epoch": 19.15032679738562,
      "grad_norm": 2.2174644470214844,
      "learning_rate": 0.00037019607843137255,
      "loss": 0.1166,
      "step": 5860
    },
    {
      "epoch": 19.215686274509803,
      "grad_norm": 12.818648338317871,
      "learning_rate": 0.0003694117647058823,
      "loss": 0.1829,
      "step": 5880
    },
    {
      "epoch": 19.281045751633986,
      "grad_norm": 0.07596474140882492,
      "learning_rate": 0.00036862745098039214,
      "loss": 0.0696,
      "step": 5900
    },
    {
      "epoch": 19.34640522875817,
      "grad_norm": 15.724624633789062,
      "learning_rate": 0.00036784313725490196,
      "loss": 0.1515,
      "step": 5920
    },
    {
      "epoch": 19.41176470588235,
      "grad_norm": 0.02755400538444519,
      "learning_rate": 0.0003670588235294118,
      "loss": 0.134,
      "step": 5940
    },
    {
      "epoch": 19.477124183006534,
      "grad_norm": 3.9958384037017822,
      "learning_rate": 0.00036627450980392155,
      "loss": 0.196,
      "step": 5960
    },
    {
      "epoch": 19.54248366013072,
      "grad_norm": 9.465599060058594,
      "learning_rate": 0.0003654901960784313,
      "loss": 0.1354,
      "step": 5980
    },
    {
      "epoch": 19.607843137254903,
      "grad_norm": 1.2814792394638062,
      "learning_rate": 0.0003647058823529411,
      "loss": 0.1543,
      "step": 6000
    },
    {
      "epoch": 19.673202614379086,
      "grad_norm": 0.019594483077526093,
      "learning_rate": 0.0003639215686274509,
      "loss": 0.1198,
      "step": 6020
    },
    {
      "epoch": 19.73856209150327,
      "grad_norm": 12.74942398071289,
      "learning_rate": 0.00036313725490196073,
      "loss": 0.1354,
      "step": 6040
    },
    {
      "epoch": 19.80392156862745,
      "grad_norm": 8.26884937286377,
      "learning_rate": 0.00036235294117647056,
      "loss": 0.2226,
      "step": 6060
    },
    {
      "epoch": 19.869281045751634,
      "grad_norm": 0.2248755395412445,
      "learning_rate": 0.0003615686274509803,
      "loss": 0.1305,
      "step": 6080
    },
    {
      "epoch": 19.934640522875817,
      "grad_norm": 17.149354934692383,
      "learning_rate": 0.00036078431372549015,
      "loss": 0.2053,
      "step": 6100
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.9508079886436462,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.0865,
      "step": 6120
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.907346037006352,
      "eval_f1": 0.9225352112676057,
      "eval_loss": 0.46163424849510193,
      "eval_runtime": 11.9179,
      "eval_samples_per_second": 34.234,
      "eval_steps_per_second": 4.279,
      "step": 6120
    },
    {
      "epoch": 20.065359477124183,
      "grad_norm": 11.533635139465332,
      "learning_rate": 0.00035921568627450974,
      "loss": 0.1104,
      "step": 6140
    },
    {
      "epoch": 20.130718954248366,
      "grad_norm": 10.810770034790039,
      "learning_rate": 0.00035843137254901956,
      "loss": 0.1143,
      "step": 6160
    },
    {
      "epoch": 20.19607843137255,
      "grad_norm": 1.765455961227417,
      "learning_rate": 0.0003576470588235294,
      "loss": 0.0674,
      "step": 6180
    },
    {
      "epoch": 20.26143790849673,
      "grad_norm": 1.5062297582626343,
      "learning_rate": 0.0003568627450980392,
      "loss": 0.1402,
      "step": 6200
    },
    {
      "epoch": 20.326797385620914,
      "grad_norm": 11.112119674682617,
      "learning_rate": 0.00035607843137254897,
      "loss": 0.0908,
      "step": 6220
    },
    {
      "epoch": 20.392156862745097,
      "grad_norm": 5.3816680908203125,
      "learning_rate": 0.0003552941176470588,
      "loss": 0.1523,
      "step": 6240
    },
    {
      "epoch": 20.45751633986928,
      "grad_norm": 7.945374488830566,
      "learning_rate": 0.0003545098039215686,
      "loss": 0.1785,
      "step": 6260
    },
    {
      "epoch": 20.522875816993466,
      "grad_norm": 11.611279487609863,
      "learning_rate": 0.0003537254901960784,
      "loss": 0.0656,
      "step": 6280
    },
    {
      "epoch": 20.58823529411765,
      "grad_norm": 9.92678165435791,
      "learning_rate": 0.0003529411764705882,
      "loss": 0.0674,
      "step": 6300
    },
    {
      "epoch": 20.65359477124183,
      "grad_norm": 4.400649070739746,
      "learning_rate": 0.000352156862745098,
      "loss": 0.0812,
      "step": 6320
    },
    {
      "epoch": 20.718954248366014,
      "grad_norm": 2.302309513092041,
      "learning_rate": 0.00035137254901960785,
      "loss": 0.2763,
      "step": 6340
    },
    {
      "epoch": 20.784313725490197,
      "grad_norm": 15.195353507995605,
      "learning_rate": 0.0003505882352941176,
      "loss": 0.2338,
      "step": 6360
    },
    {
      "epoch": 20.84967320261438,
      "grad_norm": 8.34946060180664,
      "learning_rate": 0.00034980392156862744,
      "loss": 0.0949,
      "step": 6380
    },
    {
      "epoch": 20.915032679738562,
      "grad_norm": 1.9280707836151123,
      "learning_rate": 0.00034901960784313726,
      "loss": 0.1759,
      "step": 6400
    },
    {
      "epoch": 20.980392156862745,
      "grad_norm": 5.937270641326904,
      "learning_rate": 0.0003482352941176471,
      "loss": 0.1555,
      "step": 6420
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.875,
      "eval_combined_score": 0.8929973821989529,
      "eval_f1": 0.9109947643979057,
      "eval_loss": 0.5413774847984314,
      "eval_runtime": 11.9249,
      "eval_samples_per_second": 34.214,
      "eval_steps_per_second": 4.277,
      "step": 6426
    },
    {
      "epoch": 21.045751633986928,
      "grad_norm": 5.719508171081543,
      "learning_rate": 0.00034745098039215685,
      "loss": 0.08,
      "step": 6440
    },
    {
      "epoch": 21.11111111111111,
      "grad_norm": 0.38278335332870483,
      "learning_rate": 0.0003466666666666666,
      "loss": 0.1784,
      "step": 6460
    },
    {
      "epoch": 21.176470588235293,
      "grad_norm": 8.289265632629395,
      "learning_rate": 0.0003458823529411764,
      "loss": 0.2081,
      "step": 6480
    },
    {
      "epoch": 21.241830065359476,
      "grad_norm": 0.07722136378288269,
      "learning_rate": 0.0003450980392156862,
      "loss": 0.0624,
      "step": 6500
    },
    {
      "epoch": 21.30718954248366,
      "grad_norm": 0.11830399185419083,
      "learning_rate": 0.00034431372549019603,
      "loss": 0.1945,
      "step": 6520
    },
    {
      "epoch": 21.372549019607842,
      "grad_norm": 2.9926979541778564,
      "learning_rate": 0.00034352941176470585,
      "loss": 0.1351,
      "step": 6540
    },
    {
      "epoch": 21.437908496732025,
      "grad_norm": 9.015654563903809,
      "learning_rate": 0.0003427450980392156,
      "loss": 0.1288,
      "step": 6560
    },
    {
      "epoch": 21.50326797385621,
      "grad_norm": 21.7396240234375,
      "learning_rate": 0.00034196078431372544,
      "loss": 0.1131,
      "step": 6580
    },
    {
      "epoch": 21.568627450980394,
      "grad_norm": 272.9649963378906,
      "learning_rate": 0.00034117647058823526,
      "loss": 0.1251,
      "step": 6600
    },
    {
      "epoch": 21.633986928104576,
      "grad_norm": 0.4177745580673218,
      "learning_rate": 0.00034039215686274503,
      "loss": 0.1432,
      "step": 6620
    },
    {
      "epoch": 21.69934640522876,
      "grad_norm": 6.610214710235596,
      "learning_rate": 0.00033960784313725485,
      "loss": 0.117,
      "step": 6640
    },
    {
      "epoch": 21.764705882352942,
      "grad_norm": 0.10074318945407867,
      "learning_rate": 0.0003388235294117647,
      "loss": 0.1729,
      "step": 6660
    },
    {
      "epoch": 21.830065359477125,
      "grad_norm": 4.392030239105225,
      "learning_rate": 0.0003380392156862745,
      "loss": 0.1557,
      "step": 6680
    },
    {
      "epoch": 21.895424836601308,
      "grad_norm": 8.721551895141602,
      "learning_rate": 0.00033725490196078427,
      "loss": 0.1493,
      "step": 6700
    },
    {
      "epoch": 21.96078431372549,
      "grad_norm": 17.402015686035156,
      "learning_rate": 0.0003364705882352941,
      "loss": 0.1416,
      "step": 6720
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9035577645692423,
      "eval_f1": 0.9198606271777002,
      "eval_loss": 0.5126037001609802,
      "eval_runtime": 11.9318,
      "eval_samples_per_second": 34.194,
      "eval_steps_per_second": 4.274,
      "step": 6732
    },
    {
      "epoch": 22.026143790849673,
      "grad_norm": 8.036092758178711,
      "learning_rate": 0.0003356862745098039,
      "loss": 0.1077,
      "step": 6740
    },
    {
      "epoch": 22.091503267973856,
      "grad_norm": 0.10738013684749603,
      "learning_rate": 0.00033490196078431373,
      "loss": 0.1143,
      "step": 6760
    },
    {
      "epoch": 22.15686274509804,
      "grad_norm": 0.023392735049128532,
      "learning_rate": 0.0003341176470588235,
      "loss": 0.101,
      "step": 6780
    },
    {
      "epoch": 22.22222222222222,
      "grad_norm": 0.8777532577514648,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.0351,
      "step": 6800
    },
    {
      "epoch": 22.287581699346404,
      "grad_norm": 0.2787569463253021,
      "learning_rate": 0.00033254901960784314,
      "loss": 0.209,
      "step": 6820
    },
    {
      "epoch": 22.352941176470587,
      "grad_norm": 0.006662370637059212,
      "learning_rate": 0.0003317647058823529,
      "loss": 0.1129,
      "step": 6840
    },
    {
      "epoch": 22.41830065359477,
      "grad_norm": 16.361141204833984,
      "learning_rate": 0.00033098039215686273,
      "loss": 0.108,
      "step": 6860
    },
    {
      "epoch": 22.483660130718953,
      "grad_norm": 10.083056449890137,
      "learning_rate": 0.00033019607843137256,
      "loss": 0.1447,
      "step": 6880
    },
    {
      "epoch": 22.54901960784314,
      "grad_norm": 3.399043560028076,
      "learning_rate": 0.0003294117647058824,
      "loss": 0.1464,
      "step": 6900
    },
    {
      "epoch": 22.61437908496732,
      "grad_norm": 5.703887462615967,
      "learning_rate": 0.00032862745098039215,
      "loss": 0.1606,
      "step": 6920
    },
    {
      "epoch": 22.679738562091504,
      "grad_norm": 0.062277551740407944,
      "learning_rate": 0.0003278431372549019,
      "loss": 0.1053,
      "step": 6940
    },
    {
      "epoch": 22.745098039215687,
      "grad_norm": 0.3094805181026459,
      "learning_rate": 0.0003270588235294117,
      "loss": 0.1271,
      "step": 6960
    },
    {
      "epoch": 22.81045751633987,
      "grad_norm": 10.824968338012695,
      "learning_rate": 0.0003262745098039215,
      "loss": 0.1708,
      "step": 6980
    },
    {
      "epoch": 22.875816993464053,
      "grad_norm": 1.4181222915649414,
      "learning_rate": 0.0003254901960784313,
      "loss": 0.1537,
      "step": 7000
    },
    {
      "epoch": 22.941176470588236,
      "grad_norm": 7.918502330780029,
      "learning_rate": 0.00032470588235294115,
      "loss": 0.0815,
      "step": 7020
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9048884651551561,
      "eval_f1": 0.9200710479573712,
      "eval_loss": 0.4779021441936493,
      "eval_runtime": 11.9225,
      "eval_samples_per_second": 34.221,
      "eval_steps_per_second": 4.278,
      "step": 7038
    },
    {
      "epoch": 23.00653594771242,
      "grad_norm": 0.031871676445007324,
      "learning_rate": 0.0003239215686274509,
      "loss": 0.1187,
      "step": 7040
    },
    {
      "epoch": 23.0718954248366,
      "grad_norm": 0.6657295227050781,
      "learning_rate": 0.00032313725490196074,
      "loss": 0.0959,
      "step": 7060
    },
    {
      "epoch": 23.137254901960784,
      "grad_norm": 3.833214044570923,
      "learning_rate": 0.00032235294117647056,
      "loss": 0.0721,
      "step": 7080
    },
    {
      "epoch": 23.202614379084967,
      "grad_norm": 3.8265483379364014,
      "learning_rate": 0.00032156862745098033,
      "loss": 0.0637,
      "step": 7100
    },
    {
      "epoch": 23.26797385620915,
      "grad_norm": 5.071340084075928,
      "learning_rate": 0.00032078431372549015,
      "loss": 0.1696,
      "step": 7120
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 2.3411636352539062,
      "learning_rate": 0.00031999999999999997,
      "loss": 0.1584,
      "step": 7140
    },
    {
      "epoch": 23.398692810457515,
      "grad_norm": 0.12613417208194733,
      "learning_rate": 0.0003192156862745098,
      "loss": 0.1207,
      "step": 7160
    },
    {
      "epoch": 23.464052287581698,
      "grad_norm": 0.7111382484436035,
      "learning_rate": 0.00031843137254901956,
      "loss": 0.2082,
      "step": 7180
    },
    {
      "epoch": 23.529411764705884,
      "grad_norm": 0.641817033290863,
      "learning_rate": 0.0003176470588235294,
      "loss": 0.059,
      "step": 7200
    },
    {
      "epoch": 23.594771241830067,
      "grad_norm": 10.648512840270996,
      "learning_rate": 0.0003168627450980392,
      "loss": 0.0937,
      "step": 7220
    },
    {
      "epoch": 23.66013071895425,
      "grad_norm": 0.8133097290992737,
      "learning_rate": 0.00031607843137254903,
      "loss": 0.1733,
      "step": 7240
    },
    {
      "epoch": 23.725490196078432,
      "grad_norm": 8.372954368591309,
      "learning_rate": 0.0003152941176470588,
      "loss": 0.1277,
      "step": 7260
    },
    {
      "epoch": 23.790849673202615,
      "grad_norm": 7.266061305999756,
      "learning_rate": 0.0003145098039215686,
      "loss": 0.1924,
      "step": 7280
    },
    {
      "epoch": 23.856209150326798,
      "grad_norm": 2.385904312133789,
      "learning_rate": 0.00031372549019607844,
      "loss": 0.1585,
      "step": 7300
    },
    {
      "epoch": 23.92156862745098,
      "grad_norm": 9.309332847595215,
      "learning_rate": 0.0003129411764705882,
      "loss": 0.1179,
      "step": 7320
    },
    {
      "epoch": 23.986928104575163,
      "grad_norm": 0.055493660271167755,
      "learning_rate": 0.00031215686274509803,
      "loss": 0.1011,
      "step": 7340
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9028473091364206,
      "eval_f1": 0.9184397163120569,
      "eval_loss": 0.47357672452926636,
      "eval_runtime": 11.9378,
      "eval_samples_per_second": 34.177,
      "eval_steps_per_second": 4.272,
      "step": 7344
    },
    {
      "epoch": 24.052287581699346,
      "grad_norm": 19.002012252807617,
      "learning_rate": 0.00031137254901960785,
      "loss": 0.1442,
      "step": 7360
    },
    {
      "epoch": 24.11764705882353,
      "grad_norm": 0.16537988185882568,
      "learning_rate": 0.0003105882352941177,
      "loss": 0.1185,
      "step": 7380
    },
    {
      "epoch": 24.18300653594771,
      "grad_norm": 0.8876166939735413,
      "learning_rate": 0.00030980392156862744,
      "loss": 0.1161,
      "step": 7400
    },
    {
      "epoch": 24.248366013071895,
      "grad_norm": 0.48617786169052124,
      "learning_rate": 0.0003090196078431372,
      "loss": 0.0926,
      "step": 7420
    },
    {
      "epoch": 24.313725490196077,
      "grad_norm": 5.207505702972412,
      "learning_rate": 0.000308235294117647,
      "loss": 0.1328,
      "step": 7440
    },
    {
      "epoch": 24.37908496732026,
      "grad_norm": 7.390437126159668,
      "learning_rate": 0.0003074509803921568,
      "loss": 0.0895,
      "step": 7460
    },
    {
      "epoch": 24.444444444444443,
      "grad_norm": 20.557750701904297,
      "learning_rate": 0.0003066666666666666,
      "loss": 0.1756,
      "step": 7480
    },
    {
      "epoch": 24.509803921568626,
      "grad_norm": 0.7207951545715332,
      "learning_rate": 0.00030588235294117644,
      "loss": 0.2101,
      "step": 7500
    },
    {
      "epoch": 24.575163398692812,
      "grad_norm": 0.19130948185920715,
      "learning_rate": 0.0003050980392156862,
      "loss": 0.1159,
      "step": 7520
    },
    {
      "epoch": 24.640522875816995,
      "grad_norm": 19.56056022644043,
      "learning_rate": 0.00030431372549019603,
      "loss": 0.1755,
      "step": 7540
    },
    {
      "epoch": 24.705882352941178,
      "grad_norm": 0.015268441289663315,
      "learning_rate": 0.00030352941176470586,
      "loss": 0.043,
      "step": 7560
    },
    {
      "epoch": 24.77124183006536,
      "grad_norm": 0.1007172018289566,
      "learning_rate": 0.0003027450980392156,
      "loss": 0.1858,
      "step": 7580
    },
    {
      "epoch": 24.836601307189543,
      "grad_norm": 2.5380876064300537,
      "learning_rate": 0.00030196078431372545,
      "loss": 0.1287,
      "step": 7600
    },
    {
      "epoch": 24.901960784313726,
      "grad_norm": 1.0810495615005493,
      "learning_rate": 0.00030117647058823527,
      "loss": 0.1284,
      "step": 7620
    },
    {
      "epoch": 24.96732026143791,
      "grad_norm": 0.03973091021180153,
      "learning_rate": 0.0003003921568627451,
      "loss": 0.0815,
      "step": 7640
    },
    {
      "epoch": 25.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8990712074303405,
      "eval_f1": 0.9157894736842105,
      "eval_loss": 0.5459132194519043,
      "eval_runtime": 11.9203,
      "eval_samples_per_second": 34.227,
      "eval_steps_per_second": 4.278,
      "step": 7650
    },
    {
      "epoch": 25.03267973856209,
      "grad_norm": 0.5837963819503784,
      "learning_rate": 0.00029960784313725486,
      "loss": 0.0619,
      "step": 7660
    },
    {
      "epoch": 25.098039215686274,
      "grad_norm": 0.777829647064209,
      "learning_rate": 0.0002988235294117647,
      "loss": 0.1967,
      "step": 7680
    },
    {
      "epoch": 25.163398692810457,
      "grad_norm": 0.15084831416606903,
      "learning_rate": 0.0002980392156862745,
      "loss": 0.0625,
      "step": 7700
    },
    {
      "epoch": 25.22875816993464,
      "grad_norm": 12.70517635345459,
      "learning_rate": 0.0002972549019607843,
      "loss": 0.0632,
      "step": 7720
    },
    {
      "epoch": 25.294117647058822,
      "grad_norm": 0.3564172089099884,
      "learning_rate": 0.0002964705882352941,
      "loss": 0.1191,
      "step": 7740
    },
    {
      "epoch": 25.359477124183005,
      "grad_norm": 0.12199658155441284,
      "learning_rate": 0.0002956862745098039,
      "loss": 0.124,
      "step": 7760
    },
    {
      "epoch": 25.424836601307188,
      "grad_norm": 8.390666961669922,
      "learning_rate": 0.0002949019607843137,
      "loss": 0.1563,
      "step": 7780
    },
    {
      "epoch": 25.49019607843137,
      "grad_norm": 0.048092328011989594,
      "learning_rate": 0.0002941176470588235,
      "loss": 0.1089,
      "step": 7800
    },
    {
      "epoch": 25.555555555555557,
      "grad_norm": 1.7373446226119995,
      "learning_rate": 0.00029333333333333327,
      "loss": 0.1301,
      "step": 7820
    },
    {
      "epoch": 25.62091503267974,
      "grad_norm": 1.649653673171997,
      "learning_rate": 0.0002925490196078431,
      "loss": 0.0557,
      "step": 7840
    },
    {
      "epoch": 25.686274509803923,
      "grad_norm": 0.13018372654914856,
      "learning_rate": 0.0002917647058823529,
      "loss": 0.1091,
      "step": 7860
    },
    {
      "epoch": 25.751633986928105,
      "grad_norm": 0.0024996348656713963,
      "learning_rate": 0.00029098039215686274,
      "loss": 0.054,
      "step": 7880
    },
    {
      "epoch": 25.81699346405229,
      "grad_norm": 0.02785051427781582,
      "learning_rate": 0.0002901960784313725,
      "loss": 0.2119,
      "step": 7900
    },
    {
      "epoch": 25.88235294117647,
      "grad_norm": 0.3641199767589569,
      "learning_rate": 0.00028941176470588233,
      "loss": 0.1423,
      "step": 7920
    },
    {
      "epoch": 25.947712418300654,
      "grad_norm": 0.5661678314208984,
      "learning_rate": 0.00028862745098039215,
      "loss": 0.2022,
      "step": 7940
    },
    {
      "epoch": 26.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8987736437331115,
      "eval_f1": 0.9151943462897526,
      "eval_loss": 0.5861563086509705,
      "eval_runtime": 11.9168,
      "eval_samples_per_second": 34.237,
      "eval_steps_per_second": 4.28,
      "step": 7956
    },
    {
      "epoch": 26.013071895424837,
      "grad_norm": 1.5251582860946655,
      "learning_rate": 0.00028784313725490197,
      "loss": 0.1908,
      "step": 7960
    },
    {
      "epoch": 26.07843137254902,
      "grad_norm": 0.04355171322822571,
      "learning_rate": 0.00028705882352941174,
      "loss": 0.0727,
      "step": 7980
    },
    {
      "epoch": 26.143790849673202,
      "grad_norm": 2.543306350708008,
      "learning_rate": 0.00028627450980392156,
      "loss": 0.0753,
      "step": 8000
    },
    {
      "epoch": 26.209150326797385,
      "grad_norm": 2.6487104892730713,
      "learning_rate": 0.00028549019607843133,
      "loss": 0.1272,
      "step": 8020
    },
    {
      "epoch": 26.274509803921568,
      "grad_norm": 0.6991779804229736,
      "learning_rate": 0.00028470588235294115,
      "loss": 0.0981,
      "step": 8040
    },
    {
      "epoch": 26.33986928104575,
      "grad_norm": 10.150620460510254,
      "learning_rate": 0.0002839215686274509,
      "loss": 0.1256,
      "step": 8060
    },
    {
      "epoch": 26.405228758169933,
      "grad_norm": 5.784069061279297,
      "learning_rate": 0.00028313725490196074,
      "loss": 0.0702,
      "step": 8080
    },
    {
      "epoch": 26.470588235294116,
      "grad_norm": 3.9022085666656494,
      "learning_rate": 0.00028235294117647056,
      "loss": 0.1254,
      "step": 8100
    },
    {
      "epoch": 26.535947712418302,
      "grad_norm": 4.995539665222168,
      "learning_rate": 0.0002815686274509804,
      "loss": 0.1273,
      "step": 8120
    },
    {
      "epoch": 26.601307189542485,
      "grad_norm": 9.40445327758789,
      "learning_rate": 0.00028078431372549015,
      "loss": 0.0976,
      "step": 8140
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 17.07461929321289,
      "learning_rate": 0.00028,
      "loss": 0.0944,
      "step": 8160
    },
    {
      "epoch": 26.73202614379085,
      "grad_norm": 1.6584583520889282,
      "learning_rate": 0.0002792156862745098,
      "loss": 0.1448,
      "step": 8180
    },
    {
      "epoch": 26.797385620915033,
      "grad_norm": 18.73076820373535,
      "learning_rate": 0.0002784313725490196,
      "loss": 0.1168,
      "step": 8200
    },
    {
      "epoch": 26.862745098039216,
      "grad_norm": 0.0795215591788292,
      "learning_rate": 0.0002776470588235294,
      "loss": 0.1394,
      "step": 8220
    },
    {
      "epoch": 26.9281045751634,
      "grad_norm": 0.0392233207821846,
      "learning_rate": 0.0002768627450980392,
      "loss": 0.0837,
      "step": 8240
    },
    {
      "epoch": 26.99346405228758,
      "grad_norm": 2.195676803588867,
      "learning_rate": 0.000276078431372549,
      "loss": 0.1991,
      "step": 8260
    },
    {
      "epoch": 27.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.90965068163868,
      "eval_f1": 0.924693520140105,
      "eval_loss": 0.6103105545043945,
      "eval_runtime": 11.9109,
      "eval_samples_per_second": 34.254,
      "eval_steps_per_second": 4.282,
      "step": 8262
    },
    {
      "epoch": 27.058823529411764,
      "grad_norm": 10.25865364074707,
      "learning_rate": 0.0002752941176470588,
      "loss": 0.1597,
      "step": 8280
    },
    {
      "epoch": 27.124183006535947,
      "grad_norm": 0.09212322533130646,
      "learning_rate": 0.00027450980392156857,
      "loss": 0.0842,
      "step": 8300
    },
    {
      "epoch": 27.18954248366013,
      "grad_norm": 0.1465052366256714,
      "learning_rate": 0.0002737254901960784,
      "loss": 0.0438,
      "step": 8320
    },
    {
      "epoch": 27.254901960784313,
      "grad_norm": 0.17396609485149384,
      "learning_rate": 0.0002729411764705882,
      "loss": 0.0925,
      "step": 8340
    },
    {
      "epoch": 27.320261437908496,
      "grad_norm": 6.272103309631348,
      "learning_rate": 0.00027215686274509803,
      "loss": 0.1622,
      "step": 8360
    },
    {
      "epoch": 27.38562091503268,
      "grad_norm": 0.1104956641793251,
      "learning_rate": 0.0002713725490196078,
      "loss": 0.0942,
      "step": 8380
    },
    {
      "epoch": 27.45098039215686,
      "grad_norm": 0.46027055382728577,
      "learning_rate": 0.0002705882352941176,
      "loss": 0.1402,
      "step": 8400
    },
    {
      "epoch": 27.516339869281047,
      "grad_norm": 19.902467727661133,
      "learning_rate": 0.00026980392156862745,
      "loss": 0.1369,
      "step": 8420
    },
    {
      "epoch": 27.58169934640523,
      "grad_norm": 0.038489632308483124,
      "learning_rate": 0.00026901960784313727,
      "loss": 0.1228,
      "step": 8440
    },
    {
      "epoch": 27.647058823529413,
      "grad_norm": 7.018459796905518,
      "learning_rate": 0.00026823529411764704,
      "loss": 0.0554,
      "step": 8460
    },
    {
      "epoch": 27.712418300653596,
      "grad_norm": 105.61296844482422,
      "learning_rate": 0.00026745098039215686,
      "loss": 0.1695,
      "step": 8480
    },
    {
      "epoch": 27.77777777777778,
      "grad_norm": 0.004267347976565361,
      "learning_rate": 0.0002666666666666666,
      "loss": 0.113,
      "step": 8500
    },
    {
      "epoch": 27.84313725490196,
      "grad_norm": 1.815455675125122,
      "learning_rate": 0.00026588235294117645,
      "loss": 0.0971,
      "step": 8520
    },
    {
      "epoch": 27.908496732026144,
      "grad_norm": 16.138574600219727,
      "learning_rate": 0.0002650980392156862,
      "loss": 0.17,
      "step": 8540
    },
    {
      "epoch": 27.973856209150327,
      "grad_norm": 0.01736544258892536,
      "learning_rate": 0.00026431372549019604,
      "loss": 0.1933,
      "step": 8560
    },
    {
      "epoch": 28.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9008090404303315,
      "eval_f1": 0.9168141592920355,
      "eval_loss": 0.5285115838050842,
      "eval_runtime": 11.9183,
      "eval_samples_per_second": 34.233,
      "eval_steps_per_second": 4.279,
      "step": 8568
    },
    {
      "epoch": 28.03921568627451,
      "grad_norm": 0.8440412282943726,
      "learning_rate": 0.00026352941176470586,
      "loss": 0.1125,
      "step": 8580
    },
    {
      "epoch": 28.104575163398692,
      "grad_norm": 0.7249621152877808,
      "learning_rate": 0.0002627450980392157,
      "loss": 0.0747,
      "step": 8600
    },
    {
      "epoch": 28.169934640522875,
      "grad_norm": 19.465343475341797,
      "learning_rate": 0.00026196078431372545,
      "loss": 0.1241,
      "step": 8620
    },
    {
      "epoch": 28.235294117647058,
      "grad_norm": 2.530529737472534,
      "learning_rate": 0.00026117647058823527,
      "loss": 0.0687,
      "step": 8640
    },
    {
      "epoch": 28.30065359477124,
      "grad_norm": 8.805487632751465,
      "learning_rate": 0.0002603921568627451,
      "loss": 0.1699,
      "step": 8660
    },
    {
      "epoch": 28.366013071895424,
      "grad_norm": 0.13929370045661926,
      "learning_rate": 0.0002596078431372549,
      "loss": 0.1153,
      "step": 8680
    },
    {
      "epoch": 28.431372549019606,
      "grad_norm": 0.029877474531531334,
      "learning_rate": 0.0002588235294117647,
      "loss": 0.0658,
      "step": 8700
    },
    {
      "epoch": 28.49673202614379,
      "grad_norm": 0.5653060674667358,
      "learning_rate": 0.0002580392156862745,
      "loss": 0.0581,
      "step": 8720
    },
    {
      "epoch": 28.562091503267975,
      "grad_norm": 0.005383329465985298,
      "learning_rate": 0.0002572549019607843,
      "loss": 0.1402,
      "step": 8740
    },
    {
      "epoch": 28.627450980392158,
      "grad_norm": 0.29953017830848694,
      "learning_rate": 0.0002564705882352941,
      "loss": 0.0735,
      "step": 8760
    },
    {
      "epoch": 28.69281045751634,
      "grad_norm": 0.005311052314937115,
      "learning_rate": 0.00025568627450980386,
      "loss": 0.06,
      "step": 8780
    },
    {
      "epoch": 28.758169934640524,
      "grad_norm": 0.353975772857666,
      "learning_rate": 0.0002549019607843137,
      "loss": 0.0761,
      "step": 8800
    },
    {
      "epoch": 28.823529411764707,
      "grad_norm": 0.007692285347729921,
      "learning_rate": 0.0002541176470588235,
      "loss": 0.1192,
      "step": 8820
    },
    {
      "epoch": 28.88888888888889,
      "grad_norm": 4.824830055236816,
      "learning_rate": 0.00025333333333333333,
      "loss": 0.1953,
      "step": 8840
    },
    {
      "epoch": 28.954248366013072,
      "grad_norm": 4.106053829193115,
      "learning_rate": 0.0002525490196078431,
      "loss": 0.159,
      "step": 8860
    },
    {
      "epoch": 29.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9061266072694139,
      "eval_f1": 0.9225473321858865,
      "eval_loss": 0.6427659392356873,
      "eval_runtime": 11.9233,
      "eval_samples_per_second": 34.219,
      "eval_steps_per_second": 4.277,
      "step": 8874
    },
    {
      "epoch": 29.019607843137255,
      "grad_norm": 36.567874908447266,
      "learning_rate": 0.0002517647058823529,
      "loss": 0.2412,
      "step": 8880
    },
    {
      "epoch": 29.084967320261438,
      "grad_norm": 0.6853556036949158,
      "learning_rate": 0.00025098039215686274,
      "loss": 0.0383,
      "step": 8900
    },
    {
      "epoch": 29.15032679738562,
      "grad_norm": 0.00599607964977622,
      "learning_rate": 0.00025019607843137256,
      "loss": 0.1387,
      "step": 8920
    },
    {
      "epoch": 29.215686274509803,
      "grad_norm": 1.6132481098175049,
      "learning_rate": 0.00024941176470588233,
      "loss": 0.1046,
      "step": 8940
    },
    {
      "epoch": 29.281045751633986,
      "grad_norm": 7.728435039520264,
      "learning_rate": 0.00024862745098039215,
      "loss": 0.0831,
      "step": 8960
    },
    {
      "epoch": 29.34640522875817,
      "grad_norm": 0.007838765159249306,
      "learning_rate": 0.0002478431372549019,
      "loss": 0.0963,
      "step": 8980
    },
    {
      "epoch": 29.41176470588235,
      "grad_norm": 10.06554126739502,
      "learning_rate": 0.00024705882352941174,
      "loss": 0.124,
      "step": 9000
    },
    {
      "epoch": 29.477124183006534,
      "grad_norm": 8.29558277130127,
      "learning_rate": 0.00024627450980392157,
      "loss": 0.0531,
      "step": 9020
    },
    {
      "epoch": 29.54248366013072,
      "grad_norm": 0.029810931533575058,
      "learning_rate": 0.00024549019607843133,
      "loss": 0.086,
      "step": 9040
    },
    {
      "epoch": 29.607843137254903,
      "grad_norm": 4.3034491539001465,
      "learning_rate": 0.00024470588235294116,
      "loss": 0.0921,
      "step": 9060
    },
    {
      "epoch": 29.673202614379086,
      "grad_norm": 8.192283630371094,
      "learning_rate": 0.00024392156862745095,
      "loss": 0.0203,
      "step": 9080
    },
    {
      "epoch": 29.73856209150327,
      "grad_norm": 0.026127418503165245,
      "learning_rate": 0.00024313725490196077,
      "loss": 0.0931,
      "step": 9100
    },
    {
      "epoch": 29.80392156862745,
      "grad_norm": 8.131147384643555,
      "learning_rate": 0.00024235294117647057,
      "loss": 0.1972,
      "step": 9120
    },
    {
      "epoch": 29.869281045751634,
      "grad_norm": 22.544727325439453,
      "learning_rate": 0.0002415686274509804,
      "loss": 0.1051,
      "step": 9140
    },
    {
      "epoch": 29.934640522875817,
      "grad_norm": 2.3164966106414795,
      "learning_rate": 0.00024078431372549018,
      "loss": 0.0943,
      "step": 9160
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.019072167575359344,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.0563,
      "step": 9180
    },
    {
      "epoch": 30.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9120710784313726,
      "eval_f1": 0.9270833333333334,
      "eval_loss": 0.6751447916030884,
      "eval_runtime": 11.9224,
      "eval_samples_per_second": 34.221,
      "eval_steps_per_second": 4.278,
      "step": 9180
    },
    {
      "epoch": 30.065359477124183,
      "grad_norm": 12.693909645080566,
      "learning_rate": 0.0002392156862745098,
      "loss": 0.1255,
      "step": 9200
    },
    {
      "epoch": 30.130718954248366,
      "grad_norm": 27.159215927124023,
      "learning_rate": 0.00023843137254901957,
      "loss": 0.1503,
      "step": 9220
    },
    {
      "epoch": 30.19607843137255,
      "grad_norm": 9.594362258911133,
      "learning_rate": 0.0002376470588235294,
      "loss": 0.0202,
      "step": 9240
    },
    {
      "epoch": 30.26143790849673,
      "grad_norm": 0.0680568739771843,
      "learning_rate": 0.00023686274509803919,
      "loss": 0.072,
      "step": 9260
    },
    {
      "epoch": 30.326797385620914,
      "grad_norm": 0.03687754645943642,
      "learning_rate": 0.00023607843137254898,
      "loss": 0.0921,
      "step": 9280
    },
    {
      "epoch": 30.392156862745097,
      "grad_norm": 0.026605645194649696,
      "learning_rate": 0.0002352941176470588,
      "loss": 0.1653,
      "step": 9300
    },
    {
      "epoch": 30.45751633986928,
      "grad_norm": 0.13181068003177643,
      "learning_rate": 0.0002345098039215686,
      "loss": 0.0494,
      "step": 9320
    },
    {
      "epoch": 30.522875816993466,
      "grad_norm": 0.03405923396348953,
      "learning_rate": 0.00023372549019607842,
      "loss": 0.1024,
      "step": 9340
    },
    {
      "epoch": 30.58823529411765,
      "grad_norm": 0.27019208669662476,
      "learning_rate": 0.00023294117647058821,
      "loss": 0.0547,
      "step": 9360
    },
    {
      "epoch": 30.65359477124183,
      "grad_norm": 0.008132873103022575,
      "learning_rate": 0.00023215686274509804,
      "loss": 0.1197,
      "step": 9380
    },
    {
      "epoch": 30.718954248366014,
      "grad_norm": 10.124988555908203,
      "learning_rate": 0.00023137254901960783,
      "loss": 0.1272,
      "step": 9400
    },
    {
      "epoch": 30.784313725490197,
      "grad_norm": 0.49258023500442505,
      "learning_rate": 0.00023058823529411763,
      "loss": 0.0996,
      "step": 9420
    },
    {
      "epoch": 30.84967320261438,
      "grad_norm": 5.437872886657715,
      "learning_rate": 0.00022980392156862745,
      "loss": 0.0509,
      "step": 9440
    },
    {
      "epoch": 30.915032679738562,
      "grad_norm": 0.1803438812494278,
      "learning_rate": 0.00022901960784313722,
      "loss": 0.1103,
      "step": 9460
    },
    {
      "epoch": 30.980392156862745,
      "grad_norm": 0.12491574883460999,
      "learning_rate": 0.00022823529411764704,
      "loss": 0.1807,
      "step": 9480
    },
    {
      "epoch": 31.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9076168929110106,
      "eval_f1": 0.923076923076923,
      "eval_loss": 0.5875129103660583,
      "eval_runtime": 11.9115,
      "eval_samples_per_second": 34.253,
      "eval_steps_per_second": 4.282,
      "step": 9486
    },
    {
      "epoch": 31.045751633986928,
      "grad_norm": 0.052851203829050064,
      "learning_rate": 0.00022745098039215683,
      "loss": 0.0767,
      "step": 9500
    },
    {
      "epoch": 31.11111111111111,
      "grad_norm": 0.1084156259894371,
      "learning_rate": 0.00022666666666666663,
      "loss": 0.1072,
      "step": 9520
    },
    {
      "epoch": 31.176470588235293,
      "grad_norm": 0.25035062432289124,
      "learning_rate": 0.00022588235294117645,
      "loss": 0.0751,
      "step": 9540
    },
    {
      "epoch": 31.241830065359476,
      "grad_norm": 8.488700866699219,
      "learning_rate": 0.00022509803921568625,
      "loss": 0.0324,
      "step": 9560
    },
    {
      "epoch": 31.30718954248366,
      "grad_norm": 0.08204532414674759,
      "learning_rate": 0.00022431372549019607,
      "loss": 0.1576,
      "step": 9580
    },
    {
      "epoch": 31.372549019607842,
      "grad_norm": 0.46727246046066284,
      "learning_rate": 0.00022352941176470586,
      "loss": 0.1244,
      "step": 9600
    },
    {
      "epoch": 31.437908496732025,
      "grad_norm": 1.348542332649231,
      "learning_rate": 0.00022274509803921568,
      "loss": 0.0133,
      "step": 9620
    },
    {
      "epoch": 31.50326797385621,
      "grad_norm": 0.020880402997136116,
      "learning_rate": 0.00022196078431372548,
      "loss": 0.129,
      "step": 9640
    },
    {
      "epoch": 31.568627450980394,
      "grad_norm": 0.009985391981899738,
      "learning_rate": 0.0002211764705882353,
      "loss": 0.0524,
      "step": 9660
    },
    {
      "epoch": 31.633986928104576,
      "grad_norm": 10.301347732543945,
      "learning_rate": 0.0002203921568627451,
      "loss": 0.1624,
      "step": 9680
    },
    {
      "epoch": 31.69934640522876,
      "grad_norm": 7.504049777984619,
      "learning_rate": 0.00021960784313725486,
      "loss": 0.0872,
      "step": 9700
    },
    {
      "epoch": 31.764705882352942,
      "grad_norm": 2.4051432609558105,
      "learning_rate": 0.0002188235294117647,
      "loss": 0.1507,
      "step": 9720
    },
    {
      "epoch": 31.830065359477125,
      "grad_norm": 8.382792472839355,
      "learning_rate": 0.00021803921568627448,
      "loss": 0.1706,
      "step": 9740
    },
    {
      "epoch": 31.895424836601308,
      "grad_norm": 1.3084080219268799,
      "learning_rate": 0.00021725490196078428,
      "loss": 0.1174,
      "step": 9760
    },
    {
      "epoch": 31.96078431372549,
      "grad_norm": 0.16902223229408264,
      "learning_rate": 0.0002164705882352941,
      "loss": 0.1267,
      "step": 9780
    },
    {
      "epoch": 32.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9038350634371395,
      "eval_f1": 0.9204152249134948,
      "eval_loss": 0.6238373517990112,
      "eval_runtime": 11.9135,
      "eval_samples_per_second": 34.247,
      "eval_steps_per_second": 4.281,
      "step": 9792
    },
    {
      "epoch": 32.02614379084967,
      "grad_norm": 1.5905606746673584,
      "learning_rate": 0.0002156862745098039,
      "loss": 0.095,
      "step": 9800
    },
    {
      "epoch": 32.091503267973856,
      "grad_norm": 0.013574717566370964,
      "learning_rate": 0.00021490196078431372,
      "loss": 0.074,
      "step": 9820
    },
    {
      "epoch": 32.15686274509804,
      "grad_norm": 4.809250354766846,
      "learning_rate": 0.0002141176470588235,
      "loss": 0.1271,
      "step": 9840
    },
    {
      "epoch": 32.22222222222222,
      "grad_norm": 6.869687557220459,
      "learning_rate": 0.00021333333333333333,
      "loss": 0.0844,
      "step": 9860
    },
    {
      "epoch": 32.287581699346404,
      "grad_norm": 11.849401473999023,
      "learning_rate": 0.00021254901960784313,
      "loss": 0.1025,
      "step": 9880
    },
    {
      "epoch": 32.35294117647059,
      "grad_norm": 0.024024760350584984,
      "learning_rate": 0.00021176470588235295,
      "loss": 0.1285,
      "step": 9900
    },
    {
      "epoch": 32.41830065359477,
      "grad_norm": 0.03261256590485573,
      "learning_rate": 0.00021098039215686274,
      "loss": 0.0629,
      "step": 9920
    },
    {
      "epoch": 32.48366013071895,
      "grad_norm": 0.027172209694981575,
      "learning_rate": 0.0002101960784313725,
      "loss": 0.0391,
      "step": 9940
    },
    {
      "epoch": 32.549019607843135,
      "grad_norm": 0.038128819316625595,
      "learning_rate": 0.00020941176470588233,
      "loss": 0.1801,
      "step": 9960
    },
    {
      "epoch": 32.61437908496732,
      "grad_norm": 5.266077995300293,
      "learning_rate": 0.00020862745098039213,
      "loss": 0.0803,
      "step": 9980
    },
    {
      "epoch": 32.6797385620915,
      "grad_norm": 4.7051100730896,
      "learning_rate": 0.00020784313725490192,
      "loss": 0.1209,
      "step": 10000
    },
    {
      "epoch": 32.745098039215684,
      "grad_norm": 0.25984179973602295,
      "learning_rate": 0.00020705882352941175,
      "loss": 0.0576,
      "step": 10020
    },
    {
      "epoch": 32.810457516339866,
      "grad_norm": 23.534717559814453,
      "learning_rate": 0.00020627450980392154,
      "loss": 0.0724,
      "step": 10040
    },
    {
      "epoch": 32.87581699346405,
      "grad_norm": 0.05202551186084747,
      "learning_rate": 0.00020549019607843136,
      "loss": 0.0842,
      "step": 10060
    },
    {
      "epoch": 32.94117647058823,
      "grad_norm": 16.033374786376953,
      "learning_rate": 0.00020470588235294116,
      "loss": 0.1396,
      "step": 10080
    },
    {
      "epoch": 33.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9114269382664727,
      "eval_f1": 0.9257950530035336,
      "eval_loss": 0.5899584293365479,
      "eval_runtime": 11.9181,
      "eval_samples_per_second": 34.234,
      "eval_steps_per_second": 4.279,
      "step": 10098
    },
    {
      "epoch": 33.00653594771242,
      "grad_norm": 0.017992397770285606,
      "learning_rate": 0.00020392156862745098,
      "loss": 0.0836,
      "step": 10100
    },
    {
      "epoch": 33.071895424836605,
      "grad_norm": 11.22973346710205,
      "learning_rate": 0.00020313725490196078,
      "loss": 0.0571,
      "step": 10120
    },
    {
      "epoch": 33.13725490196079,
      "grad_norm": 0.006669156718999147,
      "learning_rate": 0.0002023529411764706,
      "loss": 0.075,
      "step": 10140
    },
    {
      "epoch": 33.20261437908497,
      "grad_norm": 0.09536497294902802,
      "learning_rate": 0.0002015686274509804,
      "loss": 0.1056,
      "step": 10160
    },
    {
      "epoch": 33.26797385620915,
      "grad_norm": 6.813180923461914,
      "learning_rate": 0.00020078431372549016,
      "loss": 0.0372,
      "step": 10180
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 10.636367797851562,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.0398,
      "step": 10200
    },
    {
      "epoch": 33.39869281045752,
      "grad_norm": 0.06900381296873093,
      "learning_rate": 0.00019921568627450978,
      "loss": 0.0645,
      "step": 10220
    },
    {
      "epoch": 33.4640522875817,
      "grad_norm": 0.10824255645275116,
      "learning_rate": 0.00019843137254901957,
      "loss": 0.0709,
      "step": 10240
    },
    {
      "epoch": 33.529411764705884,
      "grad_norm": 4.236097812652588,
      "learning_rate": 0.0001976470588235294,
      "loss": 0.0884,
      "step": 10260
    },
    {
      "epoch": 33.59477124183007,
      "grad_norm": 5.58816385269165,
      "learning_rate": 0.0001968627450980392,
      "loss": 0.1725,
      "step": 10280
    },
    {
      "epoch": 33.66013071895425,
      "grad_norm": 0.003036723006516695,
      "learning_rate": 0.000196078431372549,
      "loss": 0.0567,
      "step": 10300
    },
    {
      "epoch": 33.72549019607843,
      "grad_norm": 7.409879207611084,
      "learning_rate": 0.0001952941176470588,
      "loss": 0.054,
      "step": 10320
    },
    {
      "epoch": 33.790849673202615,
      "grad_norm": 2.147592306137085,
      "learning_rate": 0.00019450980392156863,
      "loss": 0.1315,
      "step": 10340
    },
    {
      "epoch": 33.8562091503268,
      "grad_norm": 11.50338363647461,
      "learning_rate": 0.00019372549019607842,
      "loss": 0.1344,
      "step": 10360
    },
    {
      "epoch": 33.92156862745098,
      "grad_norm": 3.5915231704711914,
      "learning_rate": 0.00019294117647058825,
      "loss": 0.1404,
      "step": 10380
    },
    {
      "epoch": 33.98692810457516,
      "grad_norm": 15.17281436920166,
      "learning_rate": 0.000192156862745098,
      "loss": 0.1195,
      "step": 10400
    },
    {
      "epoch": 34.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8995098039215687,
      "eval_f1": 0.9166666666666667,
      "eval_loss": 0.6629946827888489,
      "eval_runtime": 11.9247,
      "eval_samples_per_second": 34.215,
      "eval_steps_per_second": 4.277,
      "step": 10404
    },
    {
      "epoch": 34.052287581699346,
      "grad_norm": 0.9857847094535828,
      "learning_rate": 0.0001913725490196078,
      "loss": 0.0856,
      "step": 10420
    },
    {
      "epoch": 34.11764705882353,
      "grad_norm": 23.878562927246094,
      "learning_rate": 0.00019058823529411763,
      "loss": 0.1129,
      "step": 10440
    },
    {
      "epoch": 34.18300653594771,
      "grad_norm": 16.369924545288086,
      "learning_rate": 0.00018980392156862743,
      "loss": 0.1315,
      "step": 10460
    },
    {
      "epoch": 34.248366013071895,
      "grad_norm": 0.04262454807758331,
      "learning_rate": 0.00018901960784313722,
      "loss": 0.0723,
      "step": 10480
    },
    {
      "epoch": 34.31372549019608,
      "grad_norm": 0.01891993172466755,
      "learning_rate": 0.00018823529411764704,
      "loss": 0.0889,
      "step": 10500
    },
    {
      "epoch": 34.37908496732026,
      "grad_norm": 7.149294853210449,
      "learning_rate": 0.00018745098039215684,
      "loss": 0.1275,
      "step": 10520
    },
    {
      "epoch": 34.44444444444444,
      "grad_norm": 13.642524719238281,
      "learning_rate": 0.00018666666666666666,
      "loss": 0.1637,
      "step": 10540
    },
    {
      "epoch": 34.509803921568626,
      "grad_norm": 0.13273312151432037,
      "learning_rate": 0.00018588235294117645,
      "loss": 0.0185,
      "step": 10560
    },
    {
      "epoch": 34.57516339869281,
      "grad_norm": 0.30018800497055054,
      "learning_rate": 0.00018509803921568628,
      "loss": 0.1072,
      "step": 10580
    },
    {
      "epoch": 34.64052287581699,
      "grad_norm": 8.37240982055664,
      "learning_rate": 0.00018431372549019607,
      "loss": 0.0685,
      "step": 10600
    },
    {
      "epoch": 34.705882352941174,
      "grad_norm": 0.12236550450325012,
      "learning_rate": 0.0001835294117647059,
      "loss": 0.0504,
      "step": 10620
    },
    {
      "epoch": 34.77124183006536,
      "grad_norm": 0.0821516215801239,
      "learning_rate": 0.00018274509803921566,
      "loss": 0.0769,
      "step": 10640
    },
    {
      "epoch": 34.83660130718954,
      "grad_norm": 6.118362903594971,
      "learning_rate": 0.00018196078431372546,
      "loss": 0.1231,
      "step": 10660
    },
    {
      "epoch": 34.90196078431372,
      "grad_norm": 0.023702124133706093,
      "learning_rate": 0.00018117647058823528,
      "loss": 0.1322,
      "step": 10680
    },
    {
      "epoch": 34.967320261437905,
      "grad_norm": 0.1653275489807129,
      "learning_rate": 0.00018039215686274507,
      "loss": 0.0854,
      "step": 10700
    },
    {
      "epoch": 35.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9009557526714389,
      "eval_f1": 0.9171075837742505,
      "eval_loss": 0.6053063273429871,
      "eval_runtime": 11.9111,
      "eval_samples_per_second": 34.254,
      "eval_steps_per_second": 4.282,
      "step": 10710
    },
    {
      "epoch": 35.032679738562095,
      "grad_norm": 0.19837455451488495,
      "learning_rate": 0.00017960784313725487,
      "loss": 0.0473,
      "step": 10720
    },
    {
      "epoch": 35.09803921568628,
      "grad_norm": 0.042662832885980606,
      "learning_rate": 0.0001788235294117647,
      "loss": 0.069,
      "step": 10740
    },
    {
      "epoch": 35.16339869281046,
      "grad_norm": 25.99822235107422,
      "learning_rate": 0.00017803921568627449,
      "loss": 0.1275,
      "step": 10760
    },
    {
      "epoch": 35.22875816993464,
      "grad_norm": 0.09274797886610031,
      "learning_rate": 0.0001772549019607843,
      "loss": 0.1154,
      "step": 10780
    },
    {
      "epoch": 35.294117647058826,
      "grad_norm": 6.556298732757568,
      "learning_rate": 0.0001764705882352941,
      "loss": 0.1331,
      "step": 10800
    },
    {
      "epoch": 35.35947712418301,
      "grad_norm": 5.196099758148193,
      "learning_rate": 0.00017568627450980392,
      "loss": 0.0278,
      "step": 10820
    },
    {
      "epoch": 35.42483660130719,
      "grad_norm": 0.034033019095659256,
      "learning_rate": 0.00017490196078431372,
      "loss": 0.0729,
      "step": 10840
    },
    {
      "epoch": 35.490196078431374,
      "grad_norm": 7.079174995422363,
      "learning_rate": 0.00017411764705882354,
      "loss": 0.1033,
      "step": 10860
    },
    {
      "epoch": 35.55555555555556,
      "grad_norm": 6.8245930671691895,
      "learning_rate": 0.0001733333333333333,
      "loss": 0.1067,
      "step": 10880
    },
    {
      "epoch": 35.62091503267974,
      "grad_norm": 23.1867733001709,
      "learning_rate": 0.0001725490196078431,
      "loss": 0.0222,
      "step": 10900
    },
    {
      "epoch": 35.68627450980392,
      "grad_norm": 0.39405107498168945,
      "learning_rate": 0.00017176470588235293,
      "loss": 0.0902,
      "step": 10920
    },
    {
      "epoch": 35.751633986928105,
      "grad_norm": 0.9471137523651123,
      "learning_rate": 0.00017098039215686272,
      "loss": 0.052,
      "step": 10940
    },
    {
      "epoch": 35.81699346405229,
      "grad_norm": 0.3392792046070099,
      "learning_rate": 0.00017019607843137252,
      "loss": 0.0198,
      "step": 10960
    },
    {
      "epoch": 35.88235294117647,
      "grad_norm": 1.8975378274917603,
      "learning_rate": 0.00016941176470588234,
      "loss": 0.077,
      "step": 10980
    },
    {
      "epoch": 35.947712418300654,
      "grad_norm": 0.5918986797332764,
      "learning_rate": 0.00016862745098039213,
      "loss": 0.0898,
      "step": 11000
    },
    {
      "epoch": 36.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9012460938841386,
      "eval_f1": 0.9176882661996497,
      "eval_loss": 0.7279848456382751,
      "eval_runtime": 11.9043,
      "eval_samples_per_second": 34.273,
      "eval_steps_per_second": 4.284,
      "step": 11016
    },
    {
      "epoch": 36.01307189542484,
      "grad_norm": 19.41465950012207,
      "learning_rate": 0.00016784313725490196,
      "loss": 0.0633,
      "step": 11020
    },
    {
      "epoch": 36.07843137254902,
      "grad_norm": 0.020677955821156502,
      "learning_rate": 0.00016705882352941175,
      "loss": 0.1073,
      "step": 11040
    },
    {
      "epoch": 36.1437908496732,
      "grad_norm": 0.006251906976103783,
      "learning_rate": 0.00016627450980392157,
      "loss": 0.1053,
      "step": 11060
    },
    {
      "epoch": 36.209150326797385,
      "grad_norm": 5.6633405685424805,
      "learning_rate": 0.00016549019607843137,
      "loss": 0.0577,
      "step": 11080
    },
    {
      "epoch": 36.27450980392157,
      "grad_norm": 6.943879127502441,
      "learning_rate": 0.0001647058823529412,
      "loss": 0.0454,
      "step": 11100
    },
    {
      "epoch": 36.33986928104575,
      "grad_norm": 12.999505043029785,
      "learning_rate": 0.00016392156862745096,
      "loss": 0.0909,
      "step": 11120
    },
    {
      "epoch": 36.40522875816993,
      "grad_norm": 3.544266939163208,
      "learning_rate": 0.00016313725490196075,
      "loss": 0.0705,
      "step": 11140
    },
    {
      "epoch": 36.470588235294116,
      "grad_norm": 0.0708877369761467,
      "learning_rate": 0.00016235294117647057,
      "loss": 0.0758,
      "step": 11160
    },
    {
      "epoch": 36.5359477124183,
      "grad_norm": 0.14710265398025513,
      "learning_rate": 0.00016156862745098037,
      "loss": 0.1102,
      "step": 11180
    },
    {
      "epoch": 36.60130718954248,
      "grad_norm": 0.005868867505341768,
      "learning_rate": 0.00016078431372549016,
      "loss": 0.0721,
      "step": 11200
    },
    {
      "epoch": 36.666666666666664,
      "grad_norm": 7.774419784545898,
      "learning_rate": 0.00015999999999999999,
      "loss": 0.0798,
      "step": 11220
    },
    {
      "epoch": 36.73202614379085,
      "grad_norm": 0.006330772303044796,
      "learning_rate": 0.00015921568627450978,
      "loss": 0.1418,
      "step": 11240
    },
    {
      "epoch": 36.79738562091503,
      "grad_norm": 0.032380830496549606,
      "learning_rate": 0.0001584313725490196,
      "loss": 0.0803,
      "step": 11260
    },
    {
      "epoch": 36.86274509803921,
      "grad_norm": 0.018526798114180565,
      "learning_rate": 0.0001576470588235294,
      "loss": 0.1673,
      "step": 11280
    },
    {
      "epoch": 36.928104575163395,
      "grad_norm": 11.397621154785156,
      "learning_rate": 0.00015686274509803922,
      "loss": 0.0422,
      "step": 11300
    },
    {
      "epoch": 36.99346405228758,
      "grad_norm": 1.7784074544906616,
      "learning_rate": 0.00015607843137254901,
      "loss": 0.1388,
      "step": 11320
    },
    {
      "epoch": 37.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8993646238983398,
      "eval_f1": 0.9163763066202091,
      "eval_loss": 0.651678204536438,
      "eval_runtime": 11.9156,
      "eval_samples_per_second": 34.241,
      "eval_steps_per_second": 4.28,
      "step": 11322
    },
    {
      "epoch": 37.05882352941177,
      "grad_norm": 0.020727362483739853,
      "learning_rate": 0.00015529411764705884,
      "loss": 0.0684,
      "step": 11340
    },
    {
      "epoch": 37.12418300653595,
      "grad_norm": 11.656119346618652,
      "learning_rate": 0.0001545098039215686,
      "loss": 0.0444,
      "step": 11360
    },
    {
      "epoch": 37.189542483660134,
      "grad_norm": 0.7354946732521057,
      "learning_rate": 0.0001537254901960784,
      "loss": 0.1723,
      "step": 11380
    },
    {
      "epoch": 37.254901960784316,
      "grad_norm": 7.057205677032471,
      "learning_rate": 0.00015294117647058822,
      "loss": 0.0824,
      "step": 11400
    },
    {
      "epoch": 37.3202614379085,
      "grad_norm": 17.663516998291016,
      "learning_rate": 0.00015215686274509802,
      "loss": 0.1239,
      "step": 11420
    },
    {
      "epoch": 37.38562091503268,
      "grad_norm": 12.464341163635254,
      "learning_rate": 0.0001513725490196078,
      "loss": 0.1032,
      "step": 11440
    },
    {
      "epoch": 37.450980392156865,
      "grad_norm": 3.3625247478485107,
      "learning_rate": 0.00015058823529411763,
      "loss": 0.0443,
      "step": 11460
    },
    {
      "epoch": 37.51633986928105,
      "grad_norm": 1.2525526285171509,
      "learning_rate": 0.00014980392156862743,
      "loss": 0.0635,
      "step": 11480
    },
    {
      "epoch": 37.58169934640523,
      "grad_norm": 0.012003554962575436,
      "learning_rate": 0.00014901960784313725,
      "loss": 0.0772,
      "step": 11500
    },
    {
      "epoch": 37.64705882352941,
      "grad_norm": 1.924187183380127,
      "learning_rate": 0.00014823529411764705,
      "loss": 0.1028,
      "step": 11520
    },
    {
      "epoch": 37.712418300653596,
      "grad_norm": 14.437063217163086,
      "learning_rate": 0.00014745098039215684,
      "loss": 0.0966,
      "step": 11540
    },
    {
      "epoch": 37.77777777777778,
      "grad_norm": 0.13922019302845,
      "learning_rate": 0.00014666666666666664,
      "loss": 0.0639,
      "step": 11560
    },
    {
      "epoch": 37.84313725490196,
      "grad_norm": 0.0037362854927778244,
      "learning_rate": 0.00014588235294117646,
      "loss": 0.0454,
      "step": 11580
    },
    {
      "epoch": 37.908496732026144,
      "grad_norm": 0.06565587222576141,
      "learning_rate": 0.00014509803921568625,
      "loss": 0.0495,
      "step": 11600
    },
    {
      "epoch": 37.97385620915033,
      "grad_norm": 10.508012771606445,
      "learning_rate": 0.00014431372549019607,
      "loss": 0.0849,
      "step": 11620
    },
    {
      "epoch": 38.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9054483877614092,
      "eval_f1": 0.9211908931698775,
      "eval_loss": 0.6613839268684387,
      "eval_runtime": 11.9046,
      "eval_samples_per_second": 34.272,
      "eval_steps_per_second": 4.284,
      "step": 11628
    },
    {
      "epoch": 38.03921568627451,
      "grad_norm": 0.03270430862903595,
      "learning_rate": 0.00014352941176470587,
      "loss": 0.0994,
      "step": 11640
    },
    {
      "epoch": 38.10457516339869,
      "grad_norm": 0.02908248081803322,
      "learning_rate": 0.00014274509803921566,
      "loss": 0.0636,
      "step": 11660
    },
    {
      "epoch": 38.169934640522875,
      "grad_norm": 1.041211485862732,
      "learning_rate": 0.00014196078431372546,
      "loss": 0.053,
      "step": 11680
    },
    {
      "epoch": 38.23529411764706,
      "grad_norm": 0.06390761584043503,
      "learning_rate": 0.00014117647058823528,
      "loss": 0.0675,
      "step": 11700
    },
    {
      "epoch": 38.30065359477124,
      "grad_norm": 24.06922149658203,
      "learning_rate": 0.00014039215686274508,
      "loss": 0.0906,
      "step": 11720
    },
    {
      "epoch": 38.36601307189542,
      "grad_norm": 6.797018051147461,
      "learning_rate": 0.0001396078431372549,
      "loss": 0.0931,
      "step": 11740
    },
    {
      "epoch": 38.431372549019606,
      "grad_norm": 8.745959281921387,
      "learning_rate": 0.0001388235294117647,
      "loss": 0.1019,
      "step": 11760
    },
    {
      "epoch": 38.49673202614379,
      "grad_norm": 6.387744426727295,
      "learning_rate": 0.0001380392156862745,
      "loss": 0.0874,
      "step": 11780
    },
    {
      "epoch": 38.56209150326797,
      "grad_norm": 4.578579902648926,
      "learning_rate": 0.00013725490196078428,
      "loss": 0.023,
      "step": 11800
    },
    {
      "epoch": 38.627450980392155,
      "grad_norm": 29.34686279296875,
      "learning_rate": 0.0001364705882352941,
      "loss": 0.0447,
      "step": 11820
    },
    {
      "epoch": 38.69281045751634,
      "grad_norm": 0.6543002724647522,
      "learning_rate": 0.0001356862745098039,
      "loss": 0.0474,
      "step": 11840
    },
    {
      "epoch": 38.75816993464052,
      "grad_norm": 5.4679436683654785,
      "learning_rate": 0.00013490196078431372,
      "loss": 0.0612,
      "step": 11860
    },
    {
      "epoch": 38.8235294117647,
      "grad_norm": 8.78953742980957,
      "learning_rate": 0.00013411764705882352,
      "loss": 0.008,
      "step": 11880
    },
    {
      "epoch": 38.888888888888886,
      "grad_norm": 0.17050999402999878,
      "learning_rate": 0.0001333333333333333,
      "loss": 0.0829,
      "step": 11900
    },
    {
      "epoch": 38.95424836601307,
      "grad_norm": 0.1503244787454605,
      "learning_rate": 0.0001325490196078431,
      "loss": 0.0788,
      "step": 11920
    },
    {
      "epoch": 39.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9053098831799855,
      "eval_f1": 0.9209138840070299,
      "eval_loss": 0.6797820329666138,
      "eval_runtime": 11.9126,
      "eval_samples_per_second": 34.249,
      "eval_steps_per_second": 4.281,
      "step": 11934
    },
    {
      "epoch": 39.01960784313726,
      "grad_norm": 8.584473609924316,
      "learning_rate": 0.00013176470588235293,
      "loss": 0.0791,
      "step": 11940
    },
    {
      "epoch": 39.08496732026144,
      "grad_norm": 0.09265744686126709,
      "learning_rate": 0.00013098039215686272,
      "loss": 0.1317,
      "step": 11960
    },
    {
      "epoch": 39.150326797385624,
      "grad_norm": 0.04734665900468826,
      "learning_rate": 0.00013019607843137255,
      "loss": 0.1081,
      "step": 11980
    },
    {
      "epoch": 39.21568627450981,
      "grad_norm": 19.91506576538086,
      "learning_rate": 0.00012941176470588234,
      "loss": 0.0729,
      "step": 12000
    },
    {
      "epoch": 39.28104575163399,
      "grad_norm": 0.9838488101959229,
      "learning_rate": 0.00012862745098039214,
      "loss": 0.1091,
      "step": 12020
    },
    {
      "epoch": 39.34640522875817,
      "grad_norm": 0.06256695091724396,
      "learning_rate": 0.00012784313725490193,
      "loss": 0.0579,
      "step": 12040
    },
    {
      "epoch": 39.411764705882355,
      "grad_norm": 0.950782299041748,
      "learning_rate": 0.00012705882352941175,
      "loss": 0.0186,
      "step": 12060
    },
    {
      "epoch": 39.47712418300654,
      "grad_norm": 0.03696318343281746,
      "learning_rate": 0.00012627450980392155,
      "loss": 0.0258,
      "step": 12080
    },
    {
      "epoch": 39.54248366013072,
      "grad_norm": 0.38719767332077026,
      "learning_rate": 0.00012549019607843137,
      "loss": 0.1289,
      "step": 12100
    },
    {
      "epoch": 39.6078431372549,
      "grad_norm": 0.21370887756347656,
      "learning_rate": 0.00012470588235294117,
      "loss": 0.0711,
      "step": 12120
    },
    {
      "epoch": 39.673202614379086,
      "grad_norm": 14.91977596282959,
      "learning_rate": 0.00012392156862745096,
      "loss": 0.1188,
      "step": 12140
    },
    {
      "epoch": 39.73856209150327,
      "grad_norm": 6.436690330505371,
      "learning_rate": 0.00012313725490196078,
      "loss": 0.064,
      "step": 12160
    },
    {
      "epoch": 39.80392156862745,
      "grad_norm": 2.6662750244140625,
      "learning_rate": 0.00012235294117647058,
      "loss": 0.0506,
      "step": 12180
    },
    {
      "epoch": 39.869281045751634,
      "grad_norm": 0.010417694225907326,
      "learning_rate": 0.00012156862745098039,
      "loss": 0.073,
      "step": 12200
    },
    {
      "epoch": 39.93464052287582,
      "grad_norm": 0.037001412361860275,
      "learning_rate": 0.0001207843137254902,
      "loss": 0.0482,
      "step": 12220
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.04762968420982361,
      "learning_rate": 0.00011999999999999999,
      "loss": 0.0843,
      "step": 12240
    },
    {
      "epoch": 40.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.907346037006352,
      "eval_f1": 0.9225352112676057,
      "eval_loss": 0.6729516386985779,
      "eval_runtime": 11.9103,
      "eval_samples_per_second": 34.256,
      "eval_steps_per_second": 4.282,
      "step": 12240
    },
    {
      "epoch": 40.06535947712418,
      "grad_norm": 0.032572027295827866,
      "learning_rate": 0.00011921568627450978,
      "loss": 0.0698,
      "step": 12260
    },
    {
      "epoch": 40.130718954248366,
      "grad_norm": 0.6967730522155762,
      "learning_rate": 0.00011843137254901959,
      "loss": 0.0686,
      "step": 12280
    },
    {
      "epoch": 40.19607843137255,
      "grad_norm": 0.07157175987958908,
      "learning_rate": 0.0001176470588235294,
      "loss": 0.1013,
      "step": 12300
    },
    {
      "epoch": 40.26143790849673,
      "grad_norm": 1.5621991157531738,
      "learning_rate": 0.00011686274509803921,
      "loss": 0.0834,
      "step": 12320
    },
    {
      "epoch": 40.326797385620914,
      "grad_norm": 0.013069442473351955,
      "learning_rate": 0.00011607843137254902,
      "loss": 0.0498,
      "step": 12340
    },
    {
      "epoch": 40.3921568627451,
      "grad_norm": 0.6098266839981079,
      "learning_rate": 0.00011529411764705881,
      "loss": 0.0313,
      "step": 12360
    },
    {
      "epoch": 40.45751633986928,
      "grad_norm": 0.0018084041075780988,
      "learning_rate": 0.00011450980392156861,
      "loss": 0.0714,
      "step": 12380
    },
    {
      "epoch": 40.52287581699346,
      "grad_norm": 0.015514412894845009,
      "learning_rate": 0.00011372549019607842,
      "loss": 0.086,
      "step": 12400
    },
    {
      "epoch": 40.588235294117645,
      "grad_norm": 15.738027572631836,
      "learning_rate": 0.00011294117647058823,
      "loss": 0.0459,
      "step": 12420
    },
    {
      "epoch": 40.65359477124183,
      "grad_norm": 21.07311248779297,
      "learning_rate": 0.00011215686274509803,
      "loss": 0.1053,
      "step": 12440
    },
    {
      "epoch": 40.71895424836601,
      "grad_norm": 3.5215203762054443,
      "learning_rate": 0.00011137254901960784,
      "loss": 0.0859,
      "step": 12460
    },
    {
      "epoch": 40.78431372549019,
      "grad_norm": 0.3785952925682068,
      "learning_rate": 0.00011058823529411765,
      "loss": 0.0769,
      "step": 12480
    },
    {
      "epoch": 40.849673202614376,
      "grad_norm": 8.876015663146973,
      "learning_rate": 0.00010980392156862743,
      "loss": 0.1401,
      "step": 12500
    },
    {
      "epoch": 40.91503267973856,
      "grad_norm": 0.13224728405475616,
      "learning_rate": 0.00010901960784313724,
      "loss": 0.044,
      "step": 12520
    },
    {
      "epoch": 40.98039215686274,
      "grad_norm": 1.9796152114868164,
      "learning_rate": 0.00010823529411764705,
      "loss": 0.0487,
      "step": 12540
    },
    {
      "epoch": 41.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9099126172208014,
      "eval_f1": 0.9252173913043479,
      "eval_loss": 0.7344456315040588,
      "eval_runtime": 11.9076,
      "eval_samples_per_second": 34.264,
      "eval_steps_per_second": 4.283,
      "step": 12546
    },
    {
      "epoch": 41.04575163398693,
      "grad_norm": 0.012373773381114006,
      "learning_rate": 0.00010745098039215686,
      "loss": 0.1006,
      "step": 12560
    },
    {
      "epoch": 41.111111111111114,
      "grad_norm": 0.26080548763275146,
      "learning_rate": 0.00010666666666666667,
      "loss": 0.0554,
      "step": 12580
    },
    {
      "epoch": 41.1764705882353,
      "grad_norm": 1.9840608835220337,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.0603,
      "step": 12600
    },
    {
      "epoch": 41.24183006535948,
      "grad_norm": 0.015286890789866447,
      "learning_rate": 0.00010509803921568626,
      "loss": 0.0271,
      "step": 12620
    },
    {
      "epoch": 41.30718954248366,
      "grad_norm": 1.8102021217346191,
      "learning_rate": 0.00010431372549019606,
      "loss": 0.0818,
      "step": 12640
    },
    {
      "epoch": 41.372549019607845,
      "grad_norm": 0.08651376515626907,
      "learning_rate": 0.00010352941176470587,
      "loss": 0.0244,
      "step": 12660
    },
    {
      "epoch": 41.43790849673203,
      "grad_norm": 0.6156485676765442,
      "learning_rate": 0.00010274509803921568,
      "loss": 0.0469,
      "step": 12680
    },
    {
      "epoch": 41.50326797385621,
      "grad_norm": 0.1929955929517746,
      "learning_rate": 0.00010196078431372549,
      "loss": 0.0458,
      "step": 12700
    },
    {
      "epoch": 41.568627450980394,
      "grad_norm": 3.6213412284851074,
      "learning_rate": 0.0001011764705882353,
      "loss": 0.0761,
      "step": 12720
    },
    {
      "epoch": 41.63398692810458,
      "grad_norm": 0.03205011039972305,
      "learning_rate": 0.00010039215686274508,
      "loss": 0.0265,
      "step": 12740
    },
    {
      "epoch": 41.69934640522876,
      "grad_norm": 0.0015465435571968555,
      "learning_rate": 9.960784313725489e-05,
      "loss": 0.014,
      "step": 12760
    },
    {
      "epoch": 41.76470588235294,
      "grad_norm": 0.000984210753813386,
      "learning_rate": 9.88235294117647e-05,
      "loss": 0.0772,
      "step": 12780
    },
    {
      "epoch": 41.830065359477125,
      "grad_norm": 0.015014988370239735,
      "learning_rate": 9.80392156862745e-05,
      "loss": 0.0537,
      "step": 12800
    },
    {
      "epoch": 41.89542483660131,
      "grad_norm": 0.2914767563343048,
      "learning_rate": 9.725490196078431e-05,
      "loss": 0.1139,
      "step": 12820
    },
    {
      "epoch": 41.96078431372549,
      "grad_norm": 0.019786857068538666,
      "learning_rate": 9.647058823529412e-05,
      "loss": 0.0585,
      "step": 12840
    },
    {
      "epoch": 42.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9078839869281046,
      "eval_f1": 0.9236111111111112,
      "eval_loss": 0.7714124321937561,
      "eval_runtime": 11.9149,
      "eval_samples_per_second": 34.243,
      "eval_steps_per_second": 4.28,
      "step": 12852
    },
    {
      "epoch": 42.02614379084967,
      "grad_norm": 0.09337575733661652,
      "learning_rate": 9.56862745098039e-05,
      "loss": 0.0672,
      "step": 12860
    },
    {
      "epoch": 42.091503267973856,
      "grad_norm": 0.13332441449165344,
      "learning_rate": 9.490196078431371e-05,
      "loss": 0.0453,
      "step": 12880
    },
    {
      "epoch": 42.15686274509804,
      "grad_norm": 2.3744916915893555,
      "learning_rate": 9.411764705882352e-05,
      "loss": 0.0174,
      "step": 12900
    },
    {
      "epoch": 42.22222222222222,
      "grad_norm": 2.2570741176605225,
      "learning_rate": 9.333333333333333e-05,
      "loss": 0.0724,
      "step": 12920
    },
    {
      "epoch": 42.287581699346404,
      "grad_norm": 8.810858726501465,
      "learning_rate": 9.254901960784314e-05,
      "loss": 0.034,
      "step": 12940
    },
    {
      "epoch": 42.35294117647059,
      "grad_norm": 4.587807655334473,
      "learning_rate": 9.176470588235295e-05,
      "loss": 0.0742,
      "step": 12960
    },
    {
      "epoch": 42.41830065359477,
      "grad_norm": 18.17918586730957,
      "learning_rate": 9.098039215686273e-05,
      "loss": 0.0689,
      "step": 12980
    },
    {
      "epoch": 42.48366013071895,
      "grad_norm": 0.004913196433335543,
      "learning_rate": 9.019607843137254e-05,
      "loss": 0.0182,
      "step": 13000
    },
    {
      "epoch": 42.549019607843135,
      "grad_norm": 4.861894130706787,
      "learning_rate": 8.941176470588235e-05,
      "loss": 0.0332,
      "step": 13020
    },
    {
      "epoch": 42.61437908496732,
      "grad_norm": 3.354792356491089,
      "learning_rate": 8.862745098039215e-05,
      "loss": 0.091,
      "step": 13040
    },
    {
      "epoch": 42.6797385620915,
      "grad_norm": 0.001052497187629342,
      "learning_rate": 8.784313725490196e-05,
      "loss": 0.1046,
      "step": 13060
    },
    {
      "epoch": 42.745098039215684,
      "grad_norm": 0.5527307391166687,
      "learning_rate": 8.705882352941177e-05,
      "loss": 0.0216,
      "step": 13080
    },
    {
      "epoch": 42.810457516339866,
      "grad_norm": 0.8539446592330933,
      "learning_rate": 8.627450980392155e-05,
      "loss": 0.0459,
      "step": 13100
    },
    {
      "epoch": 42.87581699346405,
      "grad_norm": 0.0035233083181083202,
      "learning_rate": 8.549019607843136e-05,
      "loss": 0.1197,
      "step": 13120
    },
    {
      "epoch": 42.94117647058823,
      "grad_norm": 0.005743759218603373,
      "learning_rate": 8.470588235294117e-05,
      "loss": 0.1044,
      "step": 13140
    },
    {
      "epoch": 43.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9099126172208014,
      "eval_f1": 0.9252173913043479,
      "eval_loss": 0.7185108065605164,
      "eval_runtime": 11.9072,
      "eval_samples_per_second": 34.265,
      "eval_steps_per_second": 4.283,
      "step": 13158
    },
    {
      "epoch": 43.00653594771242,
      "grad_norm": 4.950515270233154,
      "learning_rate": 8.392156862745098e-05,
      "loss": 0.0125,
      "step": 13160
    },
    {
      "epoch": 43.071895424836605,
      "grad_norm": 1.2372431755065918,
      "learning_rate": 8.313725490196079e-05,
      "loss": 0.0179,
      "step": 13180
    },
    {
      "epoch": 43.13725490196079,
      "grad_norm": 9.01013469696045,
      "learning_rate": 8.23529411764706e-05,
      "loss": 0.0441,
      "step": 13200
    },
    {
      "epoch": 43.20261437908497,
      "grad_norm": 0.11196369677782059,
      "learning_rate": 8.156862745098038e-05,
      "loss": 0.072,
      "step": 13220
    },
    {
      "epoch": 43.26797385620915,
      "grad_norm": 15.196036338806152,
      "learning_rate": 8.078431372549018e-05,
      "loss": 0.0588,
      "step": 13240
    },
    {
      "epoch": 43.333333333333336,
      "grad_norm": 0.0006479641306214035,
      "learning_rate": 7.999999999999999e-05,
      "loss": 0.061,
      "step": 13260
    },
    {
      "epoch": 43.39869281045752,
      "grad_norm": 0.5672726035118103,
      "learning_rate": 7.92156862745098e-05,
      "loss": 0.0331,
      "step": 13280
    },
    {
      "epoch": 43.4640522875817,
      "grad_norm": 2.9579689502716064,
      "learning_rate": 7.843137254901961e-05,
      "loss": 0.1024,
      "step": 13300
    },
    {
      "epoch": 43.529411764705884,
      "grad_norm": 0.0020718274172395468,
      "learning_rate": 7.764705882352942e-05,
      "loss": 0.0306,
      "step": 13320
    },
    {
      "epoch": 43.59477124183007,
      "grad_norm": 0.1418284922838211,
      "learning_rate": 7.68627450980392e-05,
      "loss": 0.076,
      "step": 13340
    },
    {
      "epoch": 43.66013071895425,
      "grad_norm": 0.0083114979788661,
      "learning_rate": 7.607843137254901e-05,
      "loss": 0.0684,
      "step": 13360
    },
    {
      "epoch": 43.72549019607843,
      "grad_norm": 0.0029391509015113115,
      "learning_rate": 7.529411764705882e-05,
      "loss": 0.0177,
      "step": 13380
    },
    {
      "epoch": 43.790849673202615,
      "grad_norm": 0.00809833500534296,
      "learning_rate": 7.450980392156863e-05,
      "loss": 0.0239,
      "step": 13400
    },
    {
      "epoch": 43.8562091503268,
      "grad_norm": 0.0048869880847632885,
      "learning_rate": 7.372549019607842e-05,
      "loss": 0.0775,
      "step": 13420
    },
    {
      "epoch": 43.92156862745098,
      "grad_norm": 1.7120519876480103,
      "learning_rate": 7.294117647058823e-05,
      "loss": 0.0596,
      "step": 13440
    },
    {
      "epoch": 43.98692810457516,
      "grad_norm": 0.0006776365917176008,
      "learning_rate": 7.215686274509804e-05,
      "loss": 0.0038,
      "step": 13460
    },
    {
      "epoch": 44.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9118161250514192,
      "eval_f1": 0.9265734265734265,
      "eval_loss": 0.712128758430481,
      "eval_runtime": 11.9138,
      "eval_samples_per_second": 34.246,
      "eval_steps_per_second": 4.281,
      "step": 13464
    },
    {
      "epoch": 44.052287581699346,
      "grad_norm": 28.96737289428711,
      "learning_rate": 7.137254901960783e-05,
      "loss": 0.0299,
      "step": 13480
    },
    {
      "epoch": 44.11764705882353,
      "grad_norm": 0.4360602796077728,
      "learning_rate": 7.058823529411764e-05,
      "loss": 0.0219,
      "step": 13500
    },
    {
      "epoch": 44.18300653594771,
      "grad_norm": 0.005547003820538521,
      "learning_rate": 6.980392156862745e-05,
      "loss": 0.0733,
      "step": 13520
    },
    {
      "epoch": 44.248366013071895,
      "grad_norm": 0.07940854132175446,
      "learning_rate": 6.901960784313724e-05,
      "loss": 0.1054,
      "step": 13540
    },
    {
      "epoch": 44.31372549019608,
      "grad_norm": 5.498963356018066,
      "learning_rate": 6.823529411764705e-05,
      "loss": 0.0154,
      "step": 13560
    },
    {
      "epoch": 44.37908496732026,
      "grad_norm": 0.6889201402664185,
      "learning_rate": 6.745098039215686e-05,
      "loss": 0.06,
      "step": 13580
    },
    {
      "epoch": 44.44444444444444,
      "grad_norm": 0.12721896171569824,
      "learning_rate": 6.666666666666666e-05,
      "loss": 0.0404,
      "step": 13600
    },
    {
      "epoch": 44.509803921568626,
      "grad_norm": 2.4417662620544434,
      "learning_rate": 6.588235294117646e-05,
      "loss": 0.0767,
      "step": 13620
    },
    {
      "epoch": 44.57516339869281,
      "grad_norm": 0.39804500341415405,
      "learning_rate": 6.509803921568627e-05,
      "loss": 0.0402,
      "step": 13640
    },
    {
      "epoch": 44.64052287581699,
      "grad_norm": 21.829708099365234,
      "learning_rate": 6.431372549019607e-05,
      "loss": 0.1032,
      "step": 13660
    },
    {
      "epoch": 44.705882352941174,
      "grad_norm": 0.0009552997653372586,
      "learning_rate": 6.352941176470588e-05,
      "loss": 0.0473,
      "step": 13680
    },
    {
      "epoch": 44.77124183006536,
      "grad_norm": 1.4604018926620483,
      "learning_rate": 6.274509803921569e-05,
      "loss": 0.0703,
      "step": 13700
    },
    {
      "epoch": 44.83660130718954,
      "grad_norm": 0.2619801163673401,
      "learning_rate": 6.196078431372548e-05,
      "loss": 0.0637,
      "step": 13720
    },
    {
      "epoch": 44.90196078431372,
      "grad_norm": 0.024958640336990356,
      "learning_rate": 6.117647058823529e-05,
      "loss": 0.0169,
      "step": 13740
    },
    {
      "epoch": 44.967320261437905,
      "grad_norm": 0.00232148845680058,
      "learning_rate": 6.03921568627451e-05,
      "loss": 0.0596,
      "step": 13760
    },
    {
      "epoch": 45.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9076168929110106,
      "eval_f1": 0.923076923076923,
      "eval_loss": 0.7464475631713867,
      "eval_runtime": 11.9131,
      "eval_samples_per_second": 34.248,
      "eval_steps_per_second": 4.281,
      "step": 13770
    },
    {
      "epoch": 45.032679738562095,
      "grad_norm": 0.23833656311035156,
      "learning_rate": 5.960784313725489e-05,
      "loss": 0.0717,
      "step": 13780
    },
    {
      "epoch": 45.09803921568628,
      "grad_norm": 0.0021632311400026083,
      "learning_rate": 5.88235294117647e-05,
      "loss": 0.0583,
      "step": 13800
    },
    {
      "epoch": 45.16339869281046,
      "grad_norm": 0.1729569435119629,
      "learning_rate": 5.803921568627451e-05,
      "loss": 0.0199,
      "step": 13820
    },
    {
      "epoch": 45.22875816993464,
      "grad_norm": 0.08088256418704987,
      "learning_rate": 5.7254901960784304e-05,
      "loss": 0.0207,
      "step": 13840
    },
    {
      "epoch": 45.294117647058826,
      "grad_norm": 11.681160926818848,
      "learning_rate": 5.647058823529411e-05,
      "loss": 0.0411,
      "step": 13860
    },
    {
      "epoch": 45.35947712418301,
      "grad_norm": 0.1506160944700241,
      "learning_rate": 5.568627450980392e-05,
      "loss": 0.1166,
      "step": 13880
    },
    {
      "epoch": 45.42483660130719,
      "grad_norm": 17.10993766784668,
      "learning_rate": 5.4901960784313716e-05,
      "loss": 0.0495,
      "step": 13900
    },
    {
      "epoch": 45.490196078431374,
      "grad_norm": 13.211938858032227,
      "learning_rate": 5.4117647058823525e-05,
      "loss": 0.047,
      "step": 13920
    },
    {
      "epoch": 45.55555555555556,
      "grad_norm": 0.013493786565959454,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.008,
      "step": 13940
    },
    {
      "epoch": 45.62091503267974,
      "grad_norm": 0.8041183352470398,
      "learning_rate": 5.254901960784313e-05,
      "loss": 0.1035,
      "step": 13960
    },
    {
      "epoch": 45.68627450980392,
      "grad_norm": 0.0013136252528056502,
      "learning_rate": 5.176470588235294e-05,
      "loss": 0.0976,
      "step": 13980
    },
    {
      "epoch": 45.751633986928105,
      "grad_norm": 0.001133717130869627,
      "learning_rate": 5.0980392156862745e-05,
      "loss": 0.0539,
      "step": 14000
    },
    {
      "epoch": 45.81699346405229,
      "grad_norm": 0.7165097594261169,
      "learning_rate": 5.019607843137254e-05,
      "loss": 0.0227,
      "step": 14020
    },
    {
      "epoch": 45.88235294117647,
      "grad_norm": 1.8445732593536377,
      "learning_rate": 4.941176470588235e-05,
      "loss": 0.0474,
      "step": 14040
    },
    {
      "epoch": 45.947712418300654,
      "grad_norm": 0.0008145438041538,
      "learning_rate": 4.862745098039216e-05,
      "loss": 0.0782,
      "step": 14060
    },
    {
      "epoch": 46.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9095183328164307,
      "eval_f1": 0.9244288224956063,
      "eval_loss": 0.7098846435546875,
      "eval_runtime": 11.9318,
      "eval_samples_per_second": 34.194,
      "eval_steps_per_second": 4.274,
      "step": 14076
    },
    {
      "epoch": 46.01307189542484,
      "grad_norm": 0.6921958923339844,
      "learning_rate": 4.784313725490195e-05,
      "loss": 0.0301,
      "step": 14080
    },
    {
      "epoch": 46.07843137254902,
      "grad_norm": 12.194754600524902,
      "learning_rate": 4.705882352941176e-05,
      "loss": 0.0358,
      "step": 14100
    },
    {
      "epoch": 46.1437908496732,
      "grad_norm": 22.61007308959961,
      "learning_rate": 4.627450980392157e-05,
      "loss": 0.0782,
      "step": 14120
    },
    {
      "epoch": 46.209150326797385,
      "grad_norm": 14.239679336547852,
      "learning_rate": 4.5490196078431364e-05,
      "loss": 0.1376,
      "step": 14140
    },
    {
      "epoch": 46.27450980392157,
      "grad_norm": 0.03590207174420357,
      "learning_rate": 4.470588235294117e-05,
      "loss": 0.0071,
      "step": 14160
    },
    {
      "epoch": 46.33986928104575,
      "grad_norm": 12.47805118560791,
      "learning_rate": 4.392156862745098e-05,
      "loss": 0.0834,
      "step": 14180
    },
    {
      "epoch": 46.40522875816993,
      "grad_norm": 0.6020750403404236,
      "learning_rate": 4.3137254901960776e-05,
      "loss": 0.0279,
      "step": 14200
    },
    {
      "epoch": 46.470588235294116,
      "grad_norm": 2.209165334701538,
      "learning_rate": 4.2352941176470585e-05,
      "loss": 0.0323,
      "step": 14220
    },
    {
      "epoch": 46.5359477124183,
      "grad_norm": 16.214168548583984,
      "learning_rate": 4.156862745098039e-05,
      "loss": 0.1213,
      "step": 14240
    },
    {
      "epoch": 46.60130718954248,
      "grad_norm": 3.883333206176758,
      "learning_rate": 4.078431372549019e-05,
      "loss": 0.0251,
      "step": 14260
    },
    {
      "epoch": 46.666666666666664,
      "grad_norm": 25.0358943939209,
      "learning_rate": 3.9999999999999996e-05,
      "loss": 0.0654,
      "step": 14280
    },
    {
      "epoch": 46.73202614379085,
      "grad_norm": 0.0010077336337417364,
      "learning_rate": 3.9215686274509805e-05,
      "loss": 0.0015,
      "step": 14300
    },
    {
      "epoch": 46.79738562091503,
      "grad_norm": 0.047747042030096054,
      "learning_rate": 3.84313725490196e-05,
      "loss": 0.063,
      "step": 14320
    },
    {
      "epoch": 46.86274509803921,
      "grad_norm": 2.430907964706421,
      "learning_rate": 3.764705882352941e-05,
      "loss": 0.0279,
      "step": 14340
    },
    {
      "epoch": 46.928104575163395,
      "grad_norm": 0.004969253204762936,
      "learning_rate": 3.686274509803921e-05,
      "loss": 0.0444,
      "step": 14360
    },
    {
      "epoch": 46.99346405228758,
      "grad_norm": 0.010714316740632057,
      "learning_rate": 3.607843137254902e-05,
      "loss": 0.0546,
      "step": 14380
    },
    {
      "epoch": 47.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9099126172208014,
      "eval_f1": 0.9252173913043479,
      "eval_loss": 0.7573615312576294,
      "eval_runtime": 11.9308,
      "eval_samples_per_second": 34.197,
      "eval_steps_per_second": 4.275,
      "step": 14382
    },
    {
      "epoch": 47.05882352941177,
      "grad_norm": 0.0015982581535354257,
      "learning_rate": 3.529411764705882e-05,
      "loss": 0.0405,
      "step": 14400
    },
    {
      "epoch": 47.12418300653595,
      "grad_norm": 0.011192042380571365,
      "learning_rate": 3.450980392156862e-05,
      "loss": 0.014,
      "step": 14420
    },
    {
      "epoch": 47.189542483660134,
      "grad_norm": 0.01062047854065895,
      "learning_rate": 3.372549019607843e-05,
      "loss": 0.0895,
      "step": 14440
    },
    {
      "epoch": 47.254901960784316,
      "grad_norm": 22.323719024658203,
      "learning_rate": 3.294117647058823e-05,
      "loss": 0.0497,
      "step": 14460
    },
    {
      "epoch": 47.3202614379085,
      "grad_norm": 2.1491549015045166,
      "learning_rate": 3.2156862745098034e-05,
      "loss": 0.0484,
      "step": 14480
    },
    {
      "epoch": 47.38562091503268,
      "grad_norm": 0.0321430079638958,
      "learning_rate": 3.137254901960784e-05,
      "loss": 0.0322,
      "step": 14500
    },
    {
      "epoch": 47.450980392156865,
      "grad_norm": 0.019822804257273674,
      "learning_rate": 3.0588235294117644e-05,
      "loss": 0.0252,
      "step": 14520
    },
    {
      "epoch": 47.51633986928105,
      "grad_norm": 8.59068775177002,
      "learning_rate": 2.9803921568627446e-05,
      "loss": 0.0955,
      "step": 14540
    },
    {
      "epoch": 47.58169934640523,
      "grad_norm": 0.3740919232368469,
      "learning_rate": 2.9019607843137255e-05,
      "loss": 0.0195,
      "step": 14560
    },
    {
      "epoch": 47.64705882352941,
      "grad_norm": 0.2710376977920532,
      "learning_rate": 2.8235294117647056e-05,
      "loss": 0.002,
      "step": 14580
    },
    {
      "epoch": 47.712418300653596,
      "grad_norm": 1.6021301746368408,
      "learning_rate": 2.7450980392156858e-05,
      "loss": 0.0366,
      "step": 14600
    },
    {
      "epoch": 47.77777777777778,
      "grad_norm": 0.0033545575570315123,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0131,
      "step": 14620
    },
    {
      "epoch": 47.84313725490196,
      "grad_norm": 0.05709327012300491,
      "learning_rate": 2.588235294117647e-05,
      "loss": 0.0427,
      "step": 14640
    },
    {
      "epoch": 47.908496732026144,
      "grad_norm": 0.18393301963806152,
      "learning_rate": 2.509803921568627e-05,
      "loss": 0.0489,
      "step": 14660
    },
    {
      "epoch": 47.97385620915033,
      "grad_norm": 3.9781546592712402,
      "learning_rate": 2.431372549019608e-05,
      "loss": 0.0285,
      "step": 14680
    },
    {
      "epoch": 48.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9057225063938619,
      "eval_f1": 0.9217391304347826,
      "eval_loss": 0.8064450025558472,
      "eval_runtime": 11.9213,
      "eval_samples_per_second": 34.225,
      "eval_steps_per_second": 4.278,
      "step": 14688
    },
    {
      "epoch": 48.03921568627451,
      "grad_norm": 0.01377666275948286,
      "learning_rate": 2.352941176470588e-05,
      "loss": 0.0454,
      "step": 14700
    },
    {
      "epoch": 48.10457516339869,
      "grad_norm": 0.005077941343188286,
      "learning_rate": 2.2745098039215682e-05,
      "loss": 0.0307,
      "step": 14720
    },
    {
      "epoch": 48.169934640522875,
      "grad_norm": 8.306499481201172,
      "learning_rate": 2.196078431372549e-05,
      "loss": 0.0622,
      "step": 14740
    },
    {
      "epoch": 48.23529411764706,
      "grad_norm": 0.0030061141587793827,
      "learning_rate": 2.1176470588235292e-05,
      "loss": 0.0497,
      "step": 14760
    },
    {
      "epoch": 48.30065359477124,
      "grad_norm": 0.007270505651831627,
      "learning_rate": 2.0392156862745094e-05,
      "loss": 0.0404,
      "step": 14780
    },
    {
      "epoch": 48.36601307189542,
      "grad_norm": 0.05779539793729782,
      "learning_rate": 1.9607843137254903e-05,
      "loss": 0.0821,
      "step": 14800
    },
    {
      "epoch": 48.431372549019606,
      "grad_norm": 0.9900301694869995,
      "learning_rate": 1.8823529411764704e-05,
      "loss": 0.0825,
      "step": 14820
    },
    {
      "epoch": 48.49673202614379,
      "grad_norm": 29.01378631591797,
      "learning_rate": 1.803921568627451e-05,
      "loss": 0.0673,
      "step": 14840
    },
    {
      "epoch": 48.56209150326797,
      "grad_norm": 0.21108829975128174,
      "learning_rate": 1.725490196078431e-05,
      "loss": 0.1955,
      "step": 14860
    },
    {
      "epoch": 48.627450980392155,
      "grad_norm": 0.07607850432395935,
      "learning_rate": 1.6470588235294116e-05,
      "loss": 0.0772,
      "step": 14880
    },
    {
      "epoch": 48.69281045751634,
      "grad_norm": 0.0010540616931393743,
      "learning_rate": 1.568627450980392e-05,
      "loss": 0.0344,
      "step": 14900
    },
    {
      "epoch": 48.75816993464052,
      "grad_norm": 0.029825888574123383,
      "learning_rate": 1.4901960784313723e-05,
      "loss": 0.0315,
      "step": 14920
    },
    {
      "epoch": 48.8235294117647,
      "grad_norm": 0.011976378969848156,
      "learning_rate": 1.4117647058823528e-05,
      "loss": 0.0708,
      "step": 14940
    },
    {
      "epoch": 48.888888888888886,
      "grad_norm": 0.07251883298158646,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0666,
      "step": 14960
    },
    {
      "epoch": 48.95424836601307,
      "grad_norm": 0.006018980871886015,
      "learning_rate": 1.2549019607843135e-05,
      "loss": 0.0308,
      "step": 14980
    },
    {
      "epoch": 49.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9076168929110106,
      "eval_f1": 0.923076923076923,
      "eval_loss": 0.7718162536621094,
      "eval_runtime": 11.9267,
      "eval_samples_per_second": 34.209,
      "eval_steps_per_second": 4.276,
      "step": 14994
    },
    {
      "epoch": 49.01960784313726,
      "grad_norm": 0.06330030411481857,
      "learning_rate": 1.176470588235294e-05,
      "loss": 0.1035,
      "step": 15000
    },
    {
      "epoch": 49.08496732026144,
      "grad_norm": 3.5149946212768555,
      "learning_rate": 1.0980392156862745e-05,
      "loss": 0.037,
      "step": 15020
    },
    {
      "epoch": 49.150326797385624,
      "grad_norm": 0.005850597750395536,
      "learning_rate": 1.0196078431372547e-05,
      "loss": 0.0783,
      "step": 15040
    },
    {
      "epoch": 49.21568627450981,
      "grad_norm": 13.572771072387695,
      "learning_rate": 9.411764705882352e-06,
      "loss": 0.038,
      "step": 15060
    },
    {
      "epoch": 49.28104575163399,
      "grad_norm": 0.19455035030841827,
      "learning_rate": 8.627450980392156e-06,
      "loss": 0.0341,
      "step": 15080
    },
    {
      "epoch": 49.34640522875817,
      "grad_norm": 1.4518121480941772,
      "learning_rate": 7.84313725490196e-06,
      "loss": 0.0905,
      "step": 15100
    },
    {
      "epoch": 49.411764705882355,
      "grad_norm": 0.06719496101140976,
      "learning_rate": 7.058823529411764e-06,
      "loss": 0.076,
      "step": 15120
    },
    {
      "epoch": 49.47712418300654,
      "grad_norm": 0.3339206576347351,
      "learning_rate": 6.2745098039215675e-06,
      "loss": 0.0422,
      "step": 15140
    },
    {
      "epoch": 49.54248366013072,
      "grad_norm": 0.01708628237247467,
      "learning_rate": 5.490196078431373e-06,
      "loss": 0.0435,
      "step": 15160
    },
    {
      "epoch": 49.6078431372549,
      "grad_norm": 1.2373809814453125,
      "learning_rate": 4.705882352941176e-06,
      "loss": 0.1141,
      "step": 15180
    },
    {
      "epoch": 49.673202614379086,
      "grad_norm": 0.23752310872077942,
      "learning_rate": 3.92156862745098e-06,
      "loss": 0.0167,
      "step": 15200
    },
    {
      "epoch": 49.73856209150327,
      "grad_norm": 0.0981701985001564,
      "learning_rate": 3.1372549019607838e-06,
      "loss": 0.0499,
      "step": 15220
    },
    {
      "epoch": 49.80392156862745,
      "grad_norm": 0.042276643216609955,
      "learning_rate": 2.352941176470588e-06,
      "loss": 0.0493,
      "step": 15240
    },
    {
      "epoch": 49.869281045751634,
      "grad_norm": 7.913743019104004,
      "learning_rate": 1.5686274509803919e-06,
      "loss": 0.0139,
      "step": 15260
    },
    {
      "epoch": 49.93464052287582,
      "grad_norm": 0.16453734040260315,
      "learning_rate": 7.843137254901959e-07,
      "loss": 0.0275,
      "step": 15280
    },
    {
      "epoch": 50.0,
      "grad_norm": 20.618511199951172,
      "learning_rate": 0.0,
      "loss": 0.0764,
      "step": 15300
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9097821065599014,
      "eval_f1": 0.9249563699825479,
      "eval_loss": 0.7828987240791321,
      "eval_runtime": 11.9204,
      "eval_samples_per_second": 34.227,
      "eval_steps_per_second": 4.278,
      "step": 15300
    },
    {
      "epoch": 50.0,
      "step": 15300,
      "total_flos": 4.34898751322112e+16,
      "train_loss": 0.14616565468179343,
      "train_runtime": 12145.9688,
      "train_samples_per_second": 15.1,
      "train_steps_per_second": 1.26
    }
  ],
  "logging_steps": 20,
  "max_steps": 15300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": -15300,
  "total_flos": 4.34898751322112e+16,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
