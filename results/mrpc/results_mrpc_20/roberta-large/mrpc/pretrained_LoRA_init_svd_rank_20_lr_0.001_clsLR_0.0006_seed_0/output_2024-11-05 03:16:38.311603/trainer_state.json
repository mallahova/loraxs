{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 50.0,
  "eval_steps": 500,
  "global_step": 15300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06535947712418301,
      "grad_norm": 3.7800443172454834,
      "learning_rate": 0.0005992156862745097,
      "loss": 0.6192,
      "step": 20
    },
    {
      "epoch": 0.13071895424836602,
      "grad_norm": 3.89416241645813,
      "learning_rate": 0.0005984313725490196,
      "loss": 0.5941,
      "step": 40
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 5.118508338928223,
      "learning_rate": 0.0005976470588235294,
      "loss": 0.6227,
      "step": 60
    },
    {
      "epoch": 0.26143790849673204,
      "grad_norm": 2.9381659030914307,
      "learning_rate": 0.0005968627450980391,
      "loss": 0.4982,
      "step": 80
    },
    {
      "epoch": 0.32679738562091504,
      "grad_norm": 3.06380033493042,
      "learning_rate": 0.000596078431372549,
      "loss": 0.6332,
      "step": 100
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 2.224310874938965,
      "learning_rate": 0.0005952941176470588,
      "loss": 0.5371,
      "step": 120
    },
    {
      "epoch": 0.45751633986928103,
      "grad_norm": 3.4735641479492188,
      "learning_rate": 0.0005945098039215686,
      "loss": 0.5041,
      "step": 140
    },
    {
      "epoch": 0.5228758169934641,
      "grad_norm": 3.9516193866729736,
      "learning_rate": 0.0005937254901960784,
      "loss": 0.4466,
      "step": 160
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 2.23576021194458,
      "learning_rate": 0.0005929411764705882,
      "loss": 0.4952,
      "step": 180
    },
    {
      "epoch": 0.6535947712418301,
      "grad_norm": 2.6595370769500732,
      "learning_rate": 0.0005921568627450981,
      "loss": 0.5144,
      "step": 200
    },
    {
      "epoch": 0.7189542483660131,
      "grad_norm": 3.7320730686187744,
      "learning_rate": 0.0005913725490196078,
      "loss": 0.4439,
      "step": 220
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 3.4028208255767822,
      "learning_rate": 0.0005905882352941176,
      "loss": 0.4581,
      "step": 240
    },
    {
      "epoch": 0.8496732026143791,
      "grad_norm": 14.792298316955566,
      "learning_rate": 0.0005898039215686274,
      "loss": 0.3861,
      "step": 260
    },
    {
      "epoch": 0.9150326797385621,
      "grad_norm": 2.9822652339935303,
      "learning_rate": 0.0005890196078431371,
      "loss": 0.4564,
      "step": 280
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 2.9933314323425293,
      "learning_rate": 0.000588235294117647,
      "loss": 0.4243,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8259803921568627,
      "eval_combined_score": 0.8548887230833413,
      "eval_f1": 0.88379705400982,
      "eval_loss": 0.43632885813713074,
      "eval_runtime": 11.9501,
      "eval_samples_per_second": 34.142,
      "eval_steps_per_second": 4.268,
      "step": 306
    },
    {
      "epoch": 1.0457516339869282,
      "grad_norm": 2.025226354598999,
      "learning_rate": 0.0005874509803921568,
      "loss": 0.3439,
      "step": 320
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 2.23054838180542,
      "learning_rate": 0.0005866666666666665,
      "loss": 0.4038,
      "step": 340
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 4.742482662200928,
      "learning_rate": 0.0005858823529411764,
      "loss": 0.345,
      "step": 360
    },
    {
      "epoch": 1.2418300653594772,
      "grad_norm": 2.593493700027466,
      "learning_rate": 0.0005850980392156862,
      "loss": 0.3394,
      "step": 380
    },
    {
      "epoch": 1.3071895424836601,
      "grad_norm": 13.750334739685059,
      "learning_rate": 0.0005843137254901961,
      "loss": 0.5331,
      "step": 400
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 5.067431449890137,
      "learning_rate": 0.0005835294117647058,
      "loss": 0.3264,
      "step": 420
    },
    {
      "epoch": 1.4379084967320261,
      "grad_norm": 2.4843497276306152,
      "learning_rate": 0.0005827450980392156,
      "loss": 0.2616,
      "step": 440
    },
    {
      "epoch": 1.5032679738562091,
      "grad_norm": 4.127214431762695,
      "learning_rate": 0.0005819607843137255,
      "loss": 0.3576,
      "step": 460
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 3.789790630340576,
      "learning_rate": 0.0005811764705882352,
      "loss": 0.4235,
      "step": 480
    },
    {
      "epoch": 1.6339869281045751,
      "grad_norm": 6.134223461151123,
      "learning_rate": 0.000580392156862745,
      "loss": 0.4058,
      "step": 500
    },
    {
      "epoch": 1.6993464052287581,
      "grad_norm": 3.8529117107391357,
      "learning_rate": 0.0005796078431372549,
      "loss": 0.3645,
      "step": 520
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 1.749729037284851,
      "learning_rate": 0.0005788235294117647,
      "loss": 0.3231,
      "step": 540
    },
    {
      "epoch": 1.8300653594771243,
      "grad_norm": 3.3142411708831787,
      "learning_rate": 0.0005780392156862744,
      "loss": 0.3187,
      "step": 560
    },
    {
      "epoch": 1.8954248366013071,
      "grad_norm": 4.3861918449401855,
      "learning_rate": 0.0005772549019607843,
      "loss": 0.319,
      "step": 580
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 3.857551097869873,
      "learning_rate": 0.0005764705882352941,
      "loss": 0.252,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_combined_score": 0.8793449197860963,
      "eval_f1": 0.8983957219251337,
      "eval_loss": 0.331429123878479,
      "eval_runtime": 11.9574,
      "eval_samples_per_second": 34.121,
      "eval_steps_per_second": 4.265,
      "step": 612
    },
    {
      "epoch": 2.026143790849673,
      "grad_norm": 2.6821036338806152,
      "learning_rate": 0.0005756862745098039,
      "loss": 0.4311,
      "step": 620
    },
    {
      "epoch": 2.0915032679738563,
      "grad_norm": 2.9395523071289062,
      "learning_rate": 0.0005749019607843137,
      "loss": 0.2743,
      "step": 640
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 3.1524312496185303,
      "learning_rate": 0.0005741176470588235,
      "loss": 0.3375,
      "step": 660
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 4.396014213562012,
      "learning_rate": 0.0005733333333333334,
      "loss": 0.2834,
      "step": 680
    },
    {
      "epoch": 2.287581699346405,
      "grad_norm": 3.9715633392333984,
      "learning_rate": 0.0005725490196078431,
      "loss": 0.2877,
      "step": 700
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 4.8498854637146,
      "learning_rate": 0.0005717647058823529,
      "loss": 0.4195,
      "step": 720
    },
    {
      "epoch": 2.418300653594771,
      "grad_norm": 12.725836753845215,
      "learning_rate": 0.0005709803921568627,
      "loss": 0.2522,
      "step": 740
    },
    {
      "epoch": 2.4836601307189543,
      "grad_norm": 4.191086769104004,
      "learning_rate": 0.0005701960784313724,
      "loss": 0.2833,
      "step": 760
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 5.196717739105225,
      "learning_rate": 0.0005694117647058823,
      "loss": 0.2559,
      "step": 780
    },
    {
      "epoch": 2.6143790849673203,
      "grad_norm": 5.452106952667236,
      "learning_rate": 0.0005686274509803921,
      "loss": 0.3617,
      "step": 800
    },
    {
      "epoch": 2.6797385620915035,
      "grad_norm": 1.040686845779419,
      "learning_rate": 0.0005678431372549018,
      "loss": 0.3293,
      "step": 820
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 6.310763835906982,
      "learning_rate": 0.0005670588235294117,
      "loss": 0.2693,
      "step": 840
    },
    {
      "epoch": 2.810457516339869,
      "grad_norm": 4.6378631591796875,
      "learning_rate": 0.0005662745098039215,
      "loss": 0.3318,
      "step": 860
    },
    {
      "epoch": 2.8758169934640523,
      "grad_norm": 11.010072708129883,
      "learning_rate": 0.0005654901960784314,
      "loss": 0.3478,
      "step": 880
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 2.396466016769409,
      "learning_rate": 0.0005647058823529411,
      "loss": 0.3019,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8972204266321913,
      "eval_f1": 0.9120879120879121,
      "eval_loss": 0.2993759512901306,
      "eval_runtime": 11.9483,
      "eval_samples_per_second": 34.147,
      "eval_steps_per_second": 4.268,
      "step": 918
    },
    {
      "epoch": 3.0065359477124183,
      "grad_norm": 4.645467281341553,
      "learning_rate": 0.0005639215686274509,
      "loss": 0.3394,
      "step": 920
    },
    {
      "epoch": 3.0718954248366015,
      "grad_norm": 2.6087090969085693,
      "learning_rate": 0.0005631372549019608,
      "loss": 0.3281,
      "step": 940
    },
    {
      "epoch": 3.1372549019607843,
      "grad_norm": 2.5626585483551025,
      "learning_rate": 0.0005623529411764705,
      "loss": 0.2716,
      "step": 960
    },
    {
      "epoch": 3.2026143790849675,
      "grad_norm": 3.9296278953552246,
      "learning_rate": 0.0005615686274509803,
      "loss": 0.2685,
      "step": 980
    },
    {
      "epoch": 3.2679738562091503,
      "grad_norm": 8.216133117675781,
      "learning_rate": 0.0005607843137254902,
      "loss": 0.4563,
      "step": 1000
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 4.873265266418457,
      "learning_rate": 0.00056,
      "loss": 0.4107,
      "step": 1020
    },
    {
      "epoch": 3.3986928104575163,
      "grad_norm": 0.9590650200843811,
      "learning_rate": 0.0005592156862745097,
      "loss": 0.2202,
      "step": 1040
    },
    {
      "epoch": 3.4640522875816995,
      "grad_norm": 2.2053518295288086,
      "learning_rate": 0.0005584313725490196,
      "loss": 0.2667,
      "step": 1060
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 3.694532632827759,
      "learning_rate": 0.0005576470588235294,
      "loss": 0.3373,
      "step": 1080
    },
    {
      "epoch": 3.5947712418300655,
      "grad_norm": 3.4971370697021484,
      "learning_rate": 0.0005568627450980392,
      "loss": 0.2424,
      "step": 1100
    },
    {
      "epoch": 3.6601307189542482,
      "grad_norm": 3.3165502548217773,
      "learning_rate": 0.000556078431372549,
      "loss": 0.236,
      "step": 1120
    },
    {
      "epoch": 3.7254901960784315,
      "grad_norm": 2.718398094177246,
      "learning_rate": 0.0005552941176470588,
      "loss": 0.3101,
      "step": 1140
    },
    {
      "epoch": 3.7908496732026142,
      "grad_norm": 3.100783586502075,
      "learning_rate": 0.0005545098039215687,
      "loss": 0.2914,
      "step": 1160
    },
    {
      "epoch": 3.8562091503267975,
      "grad_norm": 4.70971155166626,
      "learning_rate": 0.0005537254901960784,
      "loss": 0.2948,
      "step": 1180
    },
    {
      "epoch": 3.9215686274509802,
      "grad_norm": 1.172106146812439,
      "learning_rate": 0.0005529411764705882,
      "loss": 0.2684,
      "step": 1200
    },
    {
      "epoch": 3.9869281045751634,
      "grad_norm": 4.200486660003662,
      "learning_rate": 0.000552156862745098,
      "loss": 0.2437,
      "step": 1220
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8947114056890362,
      "eval_f1": 0.9119718309859154,
      "eval_loss": 0.3311227560043335,
      "eval_runtime": 11.9616,
      "eval_samples_per_second": 34.109,
      "eval_steps_per_second": 4.264,
      "step": 1224
    },
    {
      "epoch": 4.052287581699346,
      "grad_norm": 3.782418727874756,
      "learning_rate": 0.0005513725490196077,
      "loss": 0.3003,
      "step": 1240
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 4.634069919586182,
      "learning_rate": 0.0005505882352941176,
      "loss": 0.204,
      "step": 1260
    },
    {
      "epoch": 4.183006535947713,
      "grad_norm": 35.00051498413086,
      "learning_rate": 0.0005498039215686274,
      "loss": 0.2864,
      "step": 1280
    },
    {
      "epoch": 4.248366013071895,
      "grad_norm": 0.4172249734401703,
      "learning_rate": 0.0005490196078431371,
      "loss": 0.2585,
      "step": 1300
    },
    {
      "epoch": 4.313725490196078,
      "grad_norm": 0.24222944676876068,
      "learning_rate": 0.000548235294117647,
      "loss": 0.2745,
      "step": 1320
    },
    {
      "epoch": 4.379084967320262,
      "grad_norm": 2.5718228816986084,
      "learning_rate": 0.0005474509803921568,
      "loss": 0.1855,
      "step": 1340
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 9.107670783996582,
      "learning_rate": 0.0005466666666666667,
      "loss": 0.3738,
      "step": 1360
    },
    {
      "epoch": 4.509803921568627,
      "grad_norm": 2.0659406185150146,
      "learning_rate": 0.0005458823529411764,
      "loss": 0.1507,
      "step": 1380
    },
    {
      "epoch": 4.57516339869281,
      "grad_norm": 4.2988715171813965,
      "learning_rate": 0.0005450980392156862,
      "loss": 0.302,
      "step": 1400
    },
    {
      "epoch": 4.640522875816993,
      "grad_norm": 4.810104846954346,
      "learning_rate": 0.0005443137254901961,
      "loss": 0.3035,
      "step": 1420
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 2.6397759914398193,
      "learning_rate": 0.0005435294117647058,
      "loss": 0.2355,
      "step": 1440
    },
    {
      "epoch": 4.771241830065359,
      "grad_norm": 1.2083194255828857,
      "learning_rate": 0.0005427450980392156,
      "loss": 0.2322,
      "step": 1460
    },
    {
      "epoch": 4.836601307189542,
      "grad_norm": 1.0405787229537964,
      "learning_rate": 0.0005419607843137255,
      "loss": 0.2662,
      "step": 1480
    },
    {
      "epoch": 4.901960784313726,
      "grad_norm": 5.267285346984863,
      "learning_rate": 0.0005411764705882352,
      "loss": 0.3669,
      "step": 1500
    },
    {
      "epoch": 4.967320261437909,
      "grad_norm": 3.6876659393310547,
      "learning_rate": 0.000540392156862745,
      "loss": 0.2629,
      "step": 1520
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9074819401444789,
      "eval_f1": 0.9228070175438596,
      "eval_loss": 0.3000694811344147,
      "eval_runtime": 11.9649,
      "eval_samples_per_second": 34.1,
      "eval_steps_per_second": 4.262,
      "step": 1530
    },
    {
      "epoch": 5.032679738562091,
      "grad_norm": 1.5898648500442505,
      "learning_rate": 0.0005396078431372549,
      "loss": 0.3208,
      "step": 1540
    },
    {
      "epoch": 5.098039215686274,
      "grad_norm": 1.447279930114746,
      "learning_rate": 0.0005388235294117647,
      "loss": 0.1781,
      "step": 1560
    },
    {
      "epoch": 5.163398692810458,
      "grad_norm": 5.361898899078369,
      "learning_rate": 0.0005380392156862745,
      "loss": 0.3103,
      "step": 1580
    },
    {
      "epoch": 5.228758169934641,
      "grad_norm": 0.9315328001976013,
      "learning_rate": 0.0005372549019607843,
      "loss": 0.265,
      "step": 1600
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 7.564032554626465,
      "learning_rate": 0.0005364705882352941,
      "loss": 0.1717,
      "step": 1620
    },
    {
      "epoch": 5.359477124183006,
      "grad_norm": 16.866893768310547,
      "learning_rate": 0.000535686274509804,
      "loss": 0.3269,
      "step": 1640
    },
    {
      "epoch": 5.42483660130719,
      "grad_norm": 2.9135701656341553,
      "learning_rate": 0.0005349019607843137,
      "loss": 0.1584,
      "step": 1660
    },
    {
      "epoch": 5.490196078431373,
      "grad_norm": 0.3262028098106384,
      "learning_rate": 0.0005341176470588235,
      "loss": 0.1896,
      "step": 1680
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 8.402338027954102,
      "learning_rate": 0.0005333333333333333,
      "loss": 0.1836,
      "step": 1700
    },
    {
      "epoch": 5.620915032679738,
      "grad_norm": 2.7335710525512695,
      "learning_rate": 0.000532549019607843,
      "loss": 0.3551,
      "step": 1720
    },
    {
      "epoch": 5.686274509803922,
      "grad_norm": 6.535219669342041,
      "learning_rate": 0.0005317647058823529,
      "loss": 0.2689,
      "step": 1740
    },
    {
      "epoch": 5.751633986928105,
      "grad_norm": 2.5054678916931152,
      "learning_rate": 0.0005309803921568627,
      "loss": 0.313,
      "step": 1760
    },
    {
      "epoch": 5.816993464052287,
      "grad_norm": 5.165404796600342,
      "learning_rate": 0.0005301960784313724,
      "loss": 0.2553,
      "step": 1780
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 2.1054389476776123,
      "learning_rate": 0.0005294117647058823,
      "loss": 0.2612,
      "step": 1800
    },
    {
      "epoch": 5.947712418300654,
      "grad_norm": 1.9079116582870483,
      "learning_rate": 0.0005286274509803921,
      "loss": 0.2606,
      "step": 1820
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9138529755159507,
      "eval_f1": 0.9281961471103327,
      "eval_loss": 0.27797386050224304,
      "eval_runtime": 11.9593,
      "eval_samples_per_second": 34.116,
      "eval_steps_per_second": 4.264,
      "step": 1836
    },
    {
      "epoch": 6.0130718954248366,
      "grad_norm": 4.4803338050842285,
      "learning_rate": 0.000527843137254902,
      "loss": 0.3402,
      "step": 1840
    },
    {
      "epoch": 6.078431372549019,
      "grad_norm": 1.640169382095337,
      "learning_rate": 0.0005270588235294117,
      "loss": 0.2295,
      "step": 1860
    },
    {
      "epoch": 6.143790849673203,
      "grad_norm": 5.708596706390381,
      "learning_rate": 0.0005262745098039215,
      "loss": 0.2147,
      "step": 1880
    },
    {
      "epoch": 6.209150326797386,
      "grad_norm": 6.364956855773926,
      "learning_rate": 0.0005254901960784314,
      "loss": 0.2213,
      "step": 1900
    },
    {
      "epoch": 6.2745098039215685,
      "grad_norm": 4.43653678894043,
      "learning_rate": 0.0005247058823529411,
      "loss": 0.2266,
      "step": 1920
    },
    {
      "epoch": 6.339869281045751,
      "grad_norm": 1.3800114393234253,
      "learning_rate": 0.0005239215686274509,
      "loss": 0.1783,
      "step": 1940
    },
    {
      "epoch": 6.405228758169935,
      "grad_norm": 2.4690215587615967,
      "learning_rate": 0.0005231372549019608,
      "loss": 0.2977,
      "step": 1960
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 3.1684410572052,
      "learning_rate": 0.0005223529411764705,
      "loss": 0.2056,
      "step": 1980
    },
    {
      "epoch": 6.5359477124183005,
      "grad_norm": 3.9608781337738037,
      "learning_rate": 0.0005215686274509803,
      "loss": 0.2286,
      "step": 2000
    },
    {
      "epoch": 6.601307189542483,
      "grad_norm": 2.2007317543029785,
      "learning_rate": 0.0005207843137254902,
      "loss": 0.215,
      "step": 2020
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 1.618101954460144,
      "learning_rate": 0.00052,
      "loss": 0.2841,
      "step": 2040
    },
    {
      "epoch": 6.73202614379085,
      "grad_norm": 1.1713366508483887,
      "learning_rate": 0.0005192156862745098,
      "loss": 0.26,
      "step": 2060
    },
    {
      "epoch": 6.7973856209150325,
      "grad_norm": 3.232452869415283,
      "learning_rate": 0.0005184313725490196,
      "loss": 0.2335,
      "step": 2080
    },
    {
      "epoch": 6.862745098039216,
      "grad_norm": 1.1073113679885864,
      "learning_rate": 0.0005176470588235294,
      "loss": 0.2397,
      "step": 2100
    },
    {
      "epoch": 6.928104575163399,
      "grad_norm": 1.6601616144180298,
      "learning_rate": 0.0005168627450980392,
      "loss": 0.2285,
      "step": 2120
    },
    {
      "epoch": 6.993464052287582,
      "grad_norm": 2.22908353805542,
      "learning_rate": 0.000516078431372549,
      "loss": 0.2181,
      "step": 2140
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9142263057736093,
      "eval_f1": 0.9289428076256498,
      "eval_loss": 0.3008016049861908,
      "eval_runtime": 11.965,
      "eval_samples_per_second": 34.1,
      "eval_steps_per_second": 4.262,
      "step": 2142
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.855569064617157,
      "learning_rate": 0.0005152941176470588,
      "loss": 0.2353,
      "step": 2160
    },
    {
      "epoch": 7.124183006535947,
      "grad_norm": 7.413936138153076,
      "learning_rate": 0.0005145098039215685,
      "loss": 0.37,
      "step": 2180
    },
    {
      "epoch": 7.189542483660131,
      "grad_norm": 6.928088665008545,
      "learning_rate": 0.0005137254901960783,
      "loss": 0.2313,
      "step": 2200
    },
    {
      "epoch": 7.254901960784314,
      "grad_norm": 2.279984951019287,
      "learning_rate": 0.0005129411764705882,
      "loss": 0.1633,
      "step": 2220
    },
    {
      "epoch": 7.3202614379084965,
      "grad_norm": 3.9491126537323,
      "learning_rate": 0.000512156862745098,
      "loss": 0.2588,
      "step": 2240
    },
    {
      "epoch": 7.38562091503268,
      "grad_norm": 1.9122536182403564,
      "learning_rate": 0.0005113725490196077,
      "loss": 0.2053,
      "step": 2260
    },
    {
      "epoch": 7.450980392156863,
      "grad_norm": 6.549323081970215,
      "learning_rate": 0.0005105882352941176,
      "loss": 0.1942,
      "step": 2280
    },
    {
      "epoch": 7.516339869281046,
      "grad_norm": 4.496145725250244,
      "learning_rate": 0.0005098039215686274,
      "loss": 0.1637,
      "step": 2300
    },
    {
      "epoch": 7.5816993464052285,
      "grad_norm": 9.647686004638672,
      "learning_rate": 0.0005090196078431372,
      "loss": 0.1748,
      "step": 2320
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 3.3421521186828613,
      "learning_rate": 0.000508235294117647,
      "loss": 0.2896,
      "step": 2340
    },
    {
      "epoch": 7.712418300653595,
      "grad_norm": 0.7983757853507996,
      "learning_rate": 0.0005074509803921568,
      "loss": 0.2073,
      "step": 2360
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 6.602777481079102,
      "learning_rate": 0.0005066666666666667,
      "loss": 0.1583,
      "step": 2380
    },
    {
      "epoch": 7.8431372549019605,
      "grad_norm": 1.4318517446517944,
      "learning_rate": 0.0005058823529411764,
      "loss": 0.279,
      "step": 2400
    },
    {
      "epoch": 7.908496732026144,
      "grad_norm": 4.89084005355835,
      "learning_rate": 0.0005050980392156862,
      "loss": 0.2265,
      "step": 2420
    },
    {
      "epoch": 7.973856209150327,
      "grad_norm": 4.68000602722168,
      "learning_rate": 0.0005043137254901961,
      "loss": 0.1798,
      "step": 2440
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9141027280477408,
      "eval_f1": 0.928695652173913,
      "eval_loss": 0.35808250308036804,
      "eval_runtime": 11.9558,
      "eval_samples_per_second": 34.126,
      "eval_steps_per_second": 4.266,
      "step": 2448
    },
    {
      "epoch": 8.03921568627451,
      "grad_norm": 2.4421544075012207,
      "learning_rate": 0.0005035294117647058,
      "loss": 0.1665,
      "step": 2460
    },
    {
      "epoch": 8.104575163398692,
      "grad_norm": 1.3303033113479614,
      "learning_rate": 0.0005027450980392156,
      "loss": 0.1736,
      "step": 2480
    },
    {
      "epoch": 8.169934640522875,
      "grad_norm": 0.9030994176864624,
      "learning_rate": 0.0005019607843137255,
      "loss": 0.2107,
      "step": 2500
    },
    {
      "epoch": 8.235294117647058,
      "grad_norm": 6.755064964294434,
      "learning_rate": 0.0005011764705882353,
      "loss": 0.2056,
      "step": 2520
    },
    {
      "epoch": 8.300653594771243,
      "grad_norm": 1.496461033821106,
      "learning_rate": 0.0005003921568627451,
      "loss": 0.2057,
      "step": 2540
    },
    {
      "epoch": 8.366013071895425,
      "grad_norm": 0.5946741104125977,
      "learning_rate": 0.0004996078431372549,
      "loss": 0.2179,
      "step": 2560
    },
    {
      "epoch": 8.431372549019608,
      "grad_norm": 0.31766799092292786,
      "learning_rate": 0.0004988235294117647,
      "loss": 0.1711,
      "step": 2580
    },
    {
      "epoch": 8.49673202614379,
      "grad_norm": 2.69278621673584,
      "learning_rate": 0.0004980392156862745,
      "loss": 0.2476,
      "step": 2600
    },
    {
      "epoch": 8.562091503267974,
      "grad_norm": 4.922366142272949,
      "learning_rate": 0.0004972549019607843,
      "loss": 0.1497,
      "step": 2620
    },
    {
      "epoch": 8.627450980392156,
      "grad_norm": 0.2578981816768646,
      "learning_rate": 0.0004964705882352941,
      "loss": 0.1403,
      "step": 2640
    },
    {
      "epoch": 8.69281045751634,
      "grad_norm": 7.190384387969971,
      "learning_rate": 0.0004956862745098038,
      "loss": 0.2769,
      "step": 2660
    },
    {
      "epoch": 8.758169934640524,
      "grad_norm": 5.238662242889404,
      "learning_rate": 0.0004949019607843136,
      "loss": 0.2835,
      "step": 2680
    },
    {
      "epoch": 8.823529411764707,
      "grad_norm": 6.523594856262207,
      "learning_rate": 0.0004941176470588235,
      "loss": 0.2123,
      "step": 2700
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 3.9674699306488037,
      "learning_rate": 0.0004933333333333333,
      "loss": 0.2162,
      "step": 2720
    },
    {
      "epoch": 8.954248366013072,
      "grad_norm": 3.311605215072632,
      "learning_rate": 0.0004925490196078431,
      "loss": 0.2211,
      "step": 2740
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.906651908075058,
      "eval_f1": 0.921146953405018,
      "eval_loss": 0.3562364876270294,
      "eval_runtime": 11.9516,
      "eval_samples_per_second": 34.138,
      "eval_steps_per_second": 4.267,
      "step": 2754
    },
    {
      "epoch": 9.019607843137255,
      "grad_norm": 3.022454261779785,
      "learning_rate": 0.0004917647058823529,
      "loss": 0.3061,
      "step": 2760
    },
    {
      "epoch": 9.084967320261438,
      "grad_norm": 15.491849899291992,
      "learning_rate": 0.0004909803921568627,
      "loss": 0.1573,
      "step": 2780
    },
    {
      "epoch": 9.15032679738562,
      "grad_norm": 6.4086012840271,
      "learning_rate": 0.0004901960784313725,
      "loss": 0.1512,
      "step": 2800
    },
    {
      "epoch": 9.215686274509803,
      "grad_norm": 4.04702091217041,
      "learning_rate": 0.0004894117647058823,
      "loss": 0.1301,
      "step": 2820
    },
    {
      "epoch": 9.281045751633988,
      "grad_norm": 4.807467460632324,
      "learning_rate": 0.0004886274509803921,
      "loss": 0.1315,
      "step": 2840
    },
    {
      "epoch": 9.34640522875817,
      "grad_norm": 6.300073623657227,
      "learning_rate": 0.0004878431372549019,
      "loss": 0.2022,
      "step": 2860
    },
    {
      "epoch": 9.411764705882353,
      "grad_norm": 7.9394307136535645,
      "learning_rate": 0.0004870588235294117,
      "loss": 0.1779,
      "step": 2880
    },
    {
      "epoch": 9.477124183006536,
      "grad_norm": 1.7852895259857178,
      "learning_rate": 0.00048627450980392154,
      "loss": 0.156,
      "step": 2900
    },
    {
      "epoch": 9.542483660130719,
      "grad_norm": 1.7419672012329102,
      "learning_rate": 0.0004854901960784313,
      "loss": 0.2253,
      "step": 2920
    },
    {
      "epoch": 9.607843137254902,
      "grad_norm": 6.737024307250977,
      "learning_rate": 0.00048470588235294113,
      "loss": 0.1469,
      "step": 2940
    },
    {
      "epoch": 9.673202614379084,
      "grad_norm": 1.3834307193756104,
      "learning_rate": 0.00048392156862745096,
      "loss": 0.2022,
      "step": 2960
    },
    {
      "epoch": 9.738562091503269,
      "grad_norm": 6.46701717376709,
      "learning_rate": 0.0004831372549019608,
      "loss": 0.3382,
      "step": 2980
    },
    {
      "epoch": 9.803921568627452,
      "grad_norm": 3.949556350708008,
      "learning_rate": 0.00048235294117647055,
      "loss": 0.2216,
      "step": 3000
    },
    {
      "epoch": 9.869281045751634,
      "grad_norm": 9.619282722473145,
      "learning_rate": 0.00048156862745098037,
      "loss": 0.2283,
      "step": 3020
    },
    {
      "epoch": 9.934640522875817,
      "grad_norm": 0.1094827950000763,
      "learning_rate": 0.0004807843137254902,
      "loss": 0.2146,
      "step": 3040
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.700221300125122,
      "learning_rate": 0.00047999999999999996,
      "loss": 0.2247,
      "step": 3060
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9125498202910929,
      "eval_f1": 0.925589836660617,
      "eval_loss": 0.3477495312690735,
      "eval_runtime": 11.958,
      "eval_samples_per_second": 34.119,
      "eval_steps_per_second": 4.265,
      "step": 3060
    },
    {
      "epoch": 10.065359477124183,
      "grad_norm": 1.7822571992874146,
      "learning_rate": 0.0004792156862745098,
      "loss": 0.1484,
      "step": 3080
    },
    {
      "epoch": 10.130718954248366,
      "grad_norm": 11.092995643615723,
      "learning_rate": 0.0004784313725490196,
      "loss": 0.186,
      "step": 3100
    },
    {
      "epoch": 10.196078431372548,
      "grad_norm": 7.484725475311279,
      "learning_rate": 0.0004776470588235293,
      "loss": 0.2001,
      "step": 3120
    },
    {
      "epoch": 10.261437908496733,
      "grad_norm": 0.3438127934932709,
      "learning_rate": 0.00047686274509803914,
      "loss": 0.201,
      "step": 3140
    },
    {
      "epoch": 10.326797385620916,
      "grad_norm": 5.263582706451416,
      "learning_rate": 0.00047607843137254896,
      "loss": 0.1609,
      "step": 3160
    },
    {
      "epoch": 10.392156862745098,
      "grad_norm": 0.36115047335624695,
      "learning_rate": 0.0004752941176470588,
      "loss": 0.114,
      "step": 3180
    },
    {
      "epoch": 10.457516339869281,
      "grad_norm": 8.980892181396484,
      "learning_rate": 0.00047450980392156855,
      "loss": 0.2511,
      "step": 3200
    },
    {
      "epoch": 10.522875816993464,
      "grad_norm": 5.282325267791748,
      "learning_rate": 0.00047372549019607837,
      "loss": 0.2013,
      "step": 3220
    },
    {
      "epoch": 10.588235294117647,
      "grad_norm": 11.015218734741211,
      "learning_rate": 0.0004729411764705882,
      "loss": 0.2174,
      "step": 3240
    },
    {
      "epoch": 10.65359477124183,
      "grad_norm": 6.642446517944336,
      "learning_rate": 0.00047215686274509796,
      "loss": 0.207,
      "step": 3260
    },
    {
      "epoch": 10.718954248366012,
      "grad_norm": 3.6671667098999023,
      "learning_rate": 0.0004713725490196078,
      "loss": 0.2747,
      "step": 3280
    },
    {
      "epoch": 10.784313725490197,
      "grad_norm": 5.705511569976807,
      "learning_rate": 0.0004705882352941176,
      "loss": 0.1834,
      "step": 3300
    },
    {
      "epoch": 10.84967320261438,
      "grad_norm": 0.14827509224414825,
      "learning_rate": 0.00046980392156862743,
      "loss": 0.0956,
      "step": 3320
    },
    {
      "epoch": 10.915032679738562,
      "grad_norm": 0.9989062547683716,
      "learning_rate": 0.0004690196078431372,
      "loss": 0.2268,
      "step": 3340
    },
    {
      "epoch": 10.980392156862745,
      "grad_norm": 4.184368133544922,
      "learning_rate": 0.000468235294117647,
      "loss": 0.282,
      "step": 3360
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.8946078431372549,
      "eval_combined_score": 0.9093850503164229,
      "eval_f1": 0.9241622574955909,
      "eval_loss": 0.30440929532051086,
      "eval_runtime": 11.9498,
      "eval_samples_per_second": 34.143,
      "eval_steps_per_second": 4.268,
      "step": 3366
    },
    {
      "epoch": 11.045751633986928,
      "grad_norm": 0.15280760824680328,
      "learning_rate": 0.00046745098039215684,
      "loss": 0.1836,
      "step": 3380
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 4.14169454574585,
      "learning_rate": 0.0004666666666666666,
      "loss": 0.1659,
      "step": 3400
    },
    {
      "epoch": 11.176470588235293,
      "grad_norm": 14.336217880249023,
      "learning_rate": 0.00046588235294117643,
      "loss": 0.1171,
      "step": 3420
    },
    {
      "epoch": 11.241830065359476,
      "grad_norm": 10.518474578857422,
      "learning_rate": 0.00046509803921568625,
      "loss": 0.1935,
      "step": 3440
    },
    {
      "epoch": 11.30718954248366,
      "grad_norm": 1.071908950805664,
      "learning_rate": 0.0004643137254901961,
      "loss": 0.148,
      "step": 3460
    },
    {
      "epoch": 11.372549019607844,
      "grad_norm": 6.557212829589844,
      "learning_rate": 0.00046352941176470584,
      "loss": 0.171,
      "step": 3480
    },
    {
      "epoch": 11.437908496732026,
      "grad_norm": 1.0911800861358643,
      "learning_rate": 0.00046274509803921566,
      "loss": 0.1207,
      "step": 3500
    },
    {
      "epoch": 11.50326797385621,
      "grad_norm": 4.661269187927246,
      "learning_rate": 0.0004619607843137255,
      "loss": 0.1804,
      "step": 3520
    },
    {
      "epoch": 11.568627450980392,
      "grad_norm": 4.453891277313232,
      "learning_rate": 0.00046117647058823525,
      "loss": 0.2059,
      "step": 3540
    },
    {
      "epoch": 11.633986928104575,
      "grad_norm": 2.1102066040039062,
      "learning_rate": 0.0004603921568627451,
      "loss": 0.1565,
      "step": 3560
    },
    {
      "epoch": 11.699346405228757,
      "grad_norm": 0.1123812273144722,
      "learning_rate": 0.0004596078431372549,
      "loss": 0.2144,
      "step": 3580
    },
    {
      "epoch": 11.764705882352942,
      "grad_norm": 3.9240477085113525,
      "learning_rate": 0.0004588235294117646,
      "loss": 0.1036,
      "step": 3600
    },
    {
      "epoch": 11.830065359477125,
      "grad_norm": 0.27771079540252686,
      "learning_rate": 0.00045803921568627443,
      "loss": 0.2237,
      "step": 3620
    },
    {
      "epoch": 11.895424836601308,
      "grad_norm": 5.90934944152832,
      "learning_rate": 0.00045725490196078426,
      "loss": 0.1205,
      "step": 3640
    },
    {
      "epoch": 11.96078431372549,
      "grad_norm": 3.9147021770477295,
      "learning_rate": 0.0004564705882352941,
      "loss": 0.2307,
      "step": 3660
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.8700980392156863,
      "eval_combined_score": 0.8902097641086892,
      "eval_f1": 0.9103214890016922,
      "eval_loss": 0.4950874149799347,
      "eval_runtime": 11.9593,
      "eval_samples_per_second": 34.116,
      "eval_steps_per_second": 4.264,
      "step": 3672
    },
    {
      "epoch": 12.026143790849673,
      "grad_norm": 4.837399959564209,
      "learning_rate": 0.00045568627450980385,
      "loss": 0.1556,
      "step": 3680
    },
    {
      "epoch": 12.091503267973856,
      "grad_norm": 4.455804824829102,
      "learning_rate": 0.00045490196078431367,
      "loss": 0.1576,
      "step": 3700
    },
    {
      "epoch": 12.156862745098039,
      "grad_norm": 1.5147387981414795,
      "learning_rate": 0.0004541176470588235,
      "loss": 0.1569,
      "step": 3720
    },
    {
      "epoch": 12.222222222222221,
      "grad_norm": 4.6850972175598145,
      "learning_rate": 0.00045333333333333326,
      "loss": 0.1477,
      "step": 3740
    },
    {
      "epoch": 12.287581699346406,
      "grad_norm": 5.148276329040527,
      "learning_rate": 0.0004525490196078431,
      "loss": 0.1855,
      "step": 3760
    },
    {
      "epoch": 12.352941176470589,
      "grad_norm": 0.7494524121284485,
      "learning_rate": 0.0004517647058823529,
      "loss": 0.1299,
      "step": 3780
    },
    {
      "epoch": 12.418300653594772,
      "grad_norm": 1.7841078042984009,
      "learning_rate": 0.0004509803921568627,
      "loss": 0.1527,
      "step": 3800
    },
    {
      "epoch": 12.483660130718954,
      "grad_norm": 0.3846886157989502,
      "learning_rate": 0.0004501960784313725,
      "loss": 0.1804,
      "step": 3820
    },
    {
      "epoch": 12.549019607843137,
      "grad_norm": 8.342315673828125,
      "learning_rate": 0.0004494117647058823,
      "loss": 0.1824,
      "step": 3840
    },
    {
      "epoch": 12.61437908496732,
      "grad_norm": 2.3434946537017822,
      "learning_rate": 0.00044862745098039214,
      "loss": 0.0849,
      "step": 3860
    },
    {
      "epoch": 12.679738562091503,
      "grad_norm": 6.6159186363220215,
      "learning_rate": 0.0004478431372549019,
      "loss": 0.1886,
      "step": 3880
    },
    {
      "epoch": 12.745098039215687,
      "grad_norm": 6.494353294372559,
      "learning_rate": 0.0004470588235294117,
      "loss": 0.2654,
      "step": 3900
    },
    {
      "epoch": 12.81045751633987,
      "grad_norm": 3.485604763031006,
      "learning_rate": 0.00044627450980392155,
      "loss": 0.1072,
      "step": 3920
    },
    {
      "epoch": 12.875816993464053,
      "grad_norm": 0.03399898111820221,
      "learning_rate": 0.00044549019607843137,
      "loss": 0.1366,
      "step": 3940
    },
    {
      "epoch": 12.941176470588236,
      "grad_norm": 1.4398078918457031,
      "learning_rate": 0.00044470588235294114,
      "loss": 0.183,
      "step": 3960
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9058581404832297,
      "eval_f1": 0.9220103986135182,
      "eval_loss": 0.42281797528266907,
      "eval_runtime": 11.9491,
      "eval_samples_per_second": 34.145,
      "eval_steps_per_second": 4.268,
      "step": 3978
    },
    {
      "epoch": 13.006535947712418,
      "grad_norm": 1.9903664588928223,
      "learning_rate": 0.00044392156862745096,
      "loss": 0.1198,
      "step": 3980
    },
    {
      "epoch": 13.071895424836601,
      "grad_norm": 1.4325822591781616,
      "learning_rate": 0.0004431372549019608,
      "loss": 0.1351,
      "step": 4000
    },
    {
      "epoch": 13.137254901960784,
      "grad_norm": 7.276063442230225,
      "learning_rate": 0.0004423529411764706,
      "loss": 0.2296,
      "step": 4020
    },
    {
      "epoch": 13.202614379084967,
      "grad_norm": 7.340198516845703,
      "learning_rate": 0.00044156862745098037,
      "loss": 0.1898,
      "step": 4040
    },
    {
      "epoch": 13.267973856209151,
      "grad_norm": 1.1673604249954224,
      "learning_rate": 0.0004407843137254902,
      "loss": 0.0855,
      "step": 4060
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 4.5891547203063965,
      "learning_rate": 0.0004399999999999999,
      "loss": 0.1633,
      "step": 4080
    },
    {
      "epoch": 13.398692810457517,
      "grad_norm": 1.6155791282653809,
      "learning_rate": 0.00043921568627450973,
      "loss": 0.2132,
      "step": 4100
    },
    {
      "epoch": 13.4640522875817,
      "grad_norm": 6.876200199127197,
      "learning_rate": 0.00043843137254901955,
      "loss": 0.2033,
      "step": 4120
    },
    {
      "epoch": 13.529411764705882,
      "grad_norm": 0.07491148263216019,
      "learning_rate": 0.0004376470588235294,
      "loss": 0.1888,
      "step": 4140
    },
    {
      "epoch": 13.594771241830065,
      "grad_norm": 1.1716071367263794,
      "learning_rate": 0.00043686274509803914,
      "loss": 0.1557,
      "step": 4160
    },
    {
      "epoch": 13.660130718954248,
      "grad_norm": 1.3040838241577148,
      "learning_rate": 0.00043607843137254896,
      "loss": 0.2177,
      "step": 4180
    },
    {
      "epoch": 13.72549019607843,
      "grad_norm": 0.822040319442749,
      "learning_rate": 0.0004352941176470588,
      "loss": 0.1657,
      "step": 4200
    },
    {
      "epoch": 13.790849673202615,
      "grad_norm": 8.000886917114258,
      "learning_rate": 0.00043450980392156855,
      "loss": 0.1792,
      "step": 4220
    },
    {
      "epoch": 13.856209150326798,
      "grad_norm": 3.2432217597961426,
      "learning_rate": 0.0004337254901960784,
      "loss": 0.1542,
      "step": 4240
    },
    {
      "epoch": 13.92156862745098,
      "grad_norm": 4.460245609283447,
      "learning_rate": 0.0004329411764705882,
      "loss": 0.2342,
      "step": 4260
    },
    {
      "epoch": 13.986928104575163,
      "grad_norm": 0.20906591415405273,
      "learning_rate": 0.000432156862745098,
      "loss": 0.0696,
      "step": 4280
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.9044117647058824,
      "eval_combined_score": 0.9178143479614068,
      "eval_f1": 0.9312169312169313,
      "eval_loss": 0.4137885868549347,
      "eval_runtime": 11.9491,
      "eval_samples_per_second": 34.145,
      "eval_steps_per_second": 4.268,
      "step": 4284
    },
    {
      "epoch": 14.052287581699346,
      "grad_norm": 4.850734710693359,
      "learning_rate": 0.0004313725490196078,
      "loss": 0.1242,
      "step": 4300
    },
    {
      "epoch": 14.117647058823529,
      "grad_norm": 13.984084129333496,
      "learning_rate": 0.0004305882352941176,
      "loss": 0.1654,
      "step": 4320
    },
    {
      "epoch": 14.183006535947712,
      "grad_norm": 0.074443519115448,
      "learning_rate": 0.00042980392156862743,
      "loss": 0.1604,
      "step": 4340
    },
    {
      "epoch": 14.248366013071895,
      "grad_norm": 5.473904609680176,
      "learning_rate": 0.0004290196078431372,
      "loss": 0.214,
      "step": 4360
    },
    {
      "epoch": 14.313725490196079,
      "grad_norm": 4.592876434326172,
      "learning_rate": 0.000428235294117647,
      "loss": 0.1104,
      "step": 4380
    },
    {
      "epoch": 14.379084967320262,
      "grad_norm": 0.25073376297950745,
      "learning_rate": 0.00042745098039215684,
      "loss": 0.177,
      "step": 4400
    },
    {
      "epoch": 14.444444444444445,
      "grad_norm": 1.575695276260376,
      "learning_rate": 0.00042666666666666667,
      "loss": 0.156,
      "step": 4420
    },
    {
      "epoch": 14.509803921568627,
      "grad_norm": 8.624187469482422,
      "learning_rate": 0.00042588235294117643,
      "loss": 0.2114,
      "step": 4440
    },
    {
      "epoch": 14.57516339869281,
      "grad_norm": 4.4689788818359375,
      "learning_rate": 0.00042509803921568626,
      "loss": 0.1541,
      "step": 4460
    },
    {
      "epoch": 14.640522875816993,
      "grad_norm": 0.6240836381912231,
      "learning_rate": 0.0004243137254901961,
      "loss": 0.2473,
      "step": 4480
    },
    {
      "epoch": 14.705882352941176,
      "grad_norm": 7.235789775848389,
      "learning_rate": 0.0004235294117647059,
      "loss": 0.1665,
      "step": 4500
    },
    {
      "epoch": 14.77124183006536,
      "grad_norm": 0.3825497329235077,
      "learning_rate": 0.00042274509803921567,
      "loss": 0.1075,
      "step": 4520
    },
    {
      "epoch": 14.836601307189543,
      "grad_norm": 5.1506218910217285,
      "learning_rate": 0.0004219607843137255,
      "loss": 0.2006,
      "step": 4540
    },
    {
      "epoch": 14.901960784313726,
      "grad_norm": 3.321704149246216,
      "learning_rate": 0.0004211764705882352,
      "loss": 0.1147,
      "step": 4560
    },
    {
      "epoch": 14.967320261437909,
      "grad_norm": 2.2285404205322266,
      "learning_rate": 0.000420392156862745,
      "loss": 0.1633,
      "step": 4580
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9028473091364206,
      "eval_f1": 0.9184397163120569,
      "eval_loss": 0.4253237843513489,
      "eval_runtime": 11.9521,
      "eval_samples_per_second": 34.136,
      "eval_steps_per_second": 4.267,
      "step": 4590
    },
    {
      "epoch": 15.032679738562091,
      "grad_norm": 0.12407972663640976,
      "learning_rate": 0.00041960784313725485,
      "loss": 0.1311,
      "step": 4600
    },
    {
      "epoch": 15.098039215686274,
      "grad_norm": 0.9592891335487366,
      "learning_rate": 0.00041882352941176467,
      "loss": 0.195,
      "step": 4620
    },
    {
      "epoch": 15.163398692810457,
      "grad_norm": 0.218643456697464,
      "learning_rate": 0.00041803921568627444,
      "loss": 0.1772,
      "step": 4640
    },
    {
      "epoch": 15.22875816993464,
      "grad_norm": 0.2766958773136139,
      "learning_rate": 0.00041725490196078426,
      "loss": 0.1007,
      "step": 4660
    },
    {
      "epoch": 15.294117647058824,
      "grad_norm": 5.236995220184326,
      "learning_rate": 0.0004164705882352941,
      "loss": 0.1097,
      "step": 4680
    },
    {
      "epoch": 15.359477124183007,
      "grad_norm": 1.4215495586395264,
      "learning_rate": 0.00041568627450980385,
      "loss": 0.1761,
      "step": 4700
    },
    {
      "epoch": 15.42483660130719,
      "grad_norm": 1.805820345878601,
      "learning_rate": 0.00041490196078431367,
      "loss": 0.088,
      "step": 4720
    },
    {
      "epoch": 15.490196078431373,
      "grad_norm": 6.328919410705566,
      "learning_rate": 0.0004141176470588235,
      "loss": 0.0945,
      "step": 4740
    },
    {
      "epoch": 15.555555555555555,
      "grad_norm": 3.131990671157837,
      "learning_rate": 0.0004133333333333333,
      "loss": 0.2321,
      "step": 4760
    },
    {
      "epoch": 15.620915032679738,
      "grad_norm": 4.390999794006348,
      "learning_rate": 0.0004125490196078431,
      "loss": 0.0784,
      "step": 4780
    },
    {
      "epoch": 15.686274509803921,
      "grad_norm": 5.304937362670898,
      "learning_rate": 0.0004117647058823529,
      "loss": 0.1624,
      "step": 4800
    },
    {
      "epoch": 15.751633986928105,
      "grad_norm": 0.020077360793948174,
      "learning_rate": 0.00041098039215686273,
      "loss": 0.159,
      "step": 4820
    },
    {
      "epoch": 15.816993464052288,
      "grad_norm": 10.05256175994873,
      "learning_rate": 0.0004101960784313725,
      "loss": 0.1302,
      "step": 4840
    },
    {
      "epoch": 15.882352941176471,
      "grad_norm": 2.5162487030029297,
      "learning_rate": 0.0004094117647058823,
      "loss": 0.1796,
      "step": 4860
    },
    {
      "epoch": 15.947712418300654,
      "grad_norm": 0.14693355560302734,
      "learning_rate": 0.00040862745098039214,
      "loss": 0.2482,
      "step": 4880
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.8995098039215687,
      "eval_combined_score": 0.9137267824528758,
      "eval_f1": 0.9279437609841829,
      "eval_loss": 0.33945372700691223,
      "eval_runtime": 11.9532,
      "eval_samples_per_second": 34.133,
      "eval_steps_per_second": 4.267,
      "step": 4896
    },
    {
      "epoch": 16.013071895424837,
      "grad_norm": 5.6031951904296875,
      "learning_rate": 0.00040784313725490196,
      "loss": 0.1616,
      "step": 4900
    },
    {
      "epoch": 16.07843137254902,
      "grad_norm": 1.4807695150375366,
      "learning_rate": 0.00040705882352941173,
      "loss": 0.1263,
      "step": 4920
    },
    {
      "epoch": 16.143790849673202,
      "grad_norm": 7.64145565032959,
      "learning_rate": 0.00040627450980392155,
      "loss": 0.1353,
      "step": 4940
    },
    {
      "epoch": 16.209150326797385,
      "grad_norm": 9.916455268859863,
      "learning_rate": 0.0004054901960784314,
      "loss": 0.1221,
      "step": 4960
    },
    {
      "epoch": 16.274509803921568,
      "grad_norm": 0.6161637306213379,
      "learning_rate": 0.0004047058823529412,
      "loss": 0.1109,
      "step": 4980
    },
    {
      "epoch": 16.33986928104575,
      "grad_norm": 2.932879686355591,
      "learning_rate": 0.00040392156862745096,
      "loss": 0.1337,
      "step": 5000
    },
    {
      "epoch": 16.405228758169933,
      "grad_norm": 3.8208088874816895,
      "learning_rate": 0.0004031372549019608,
      "loss": 0.2655,
      "step": 5020
    },
    {
      "epoch": 16.470588235294116,
      "grad_norm": 18.503374099731445,
      "learning_rate": 0.0004023529411764705,
      "loss": 0.1759,
      "step": 5040
    },
    {
      "epoch": 16.535947712418302,
      "grad_norm": 16.59507179260254,
      "learning_rate": 0.0004015686274509803,
      "loss": 0.1486,
      "step": 5060
    },
    {
      "epoch": 16.601307189542485,
      "grad_norm": 7.588067531585693,
      "learning_rate": 0.00040078431372549014,
      "loss": 0.2148,
      "step": 5080
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 0.5454922318458557,
      "learning_rate": 0.00039999999999999996,
      "loss": 0.085,
      "step": 5100
    },
    {
      "epoch": 16.73202614379085,
      "grad_norm": 3.8556129932403564,
      "learning_rate": 0.00039921568627450973,
      "loss": 0.1506,
      "step": 5120
    },
    {
      "epoch": 16.797385620915033,
      "grad_norm": 2.1090681552886963,
      "learning_rate": 0.00039843137254901955,
      "loss": 0.1474,
      "step": 5140
    },
    {
      "epoch": 16.862745098039216,
      "grad_norm": 5.881377220153809,
      "learning_rate": 0.0003976470588235294,
      "loss": 0.1415,
      "step": 5160
    },
    {
      "epoch": 16.9281045751634,
      "grad_norm": 7.87180757522583,
      "learning_rate": 0.00039686274509803914,
      "loss": 0.1351,
      "step": 5180
    },
    {
      "epoch": 16.99346405228758,
      "grad_norm": 5.354614734649658,
      "learning_rate": 0.00039607843137254897,
      "loss": 0.14,
      "step": 5200
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.9019607843137255,
      "eval_combined_score": 0.9160153571918277,
      "eval_f1": 0.93006993006993,
      "eval_loss": 0.44401922821998596,
      "eval_runtime": 11.9716,
      "eval_samples_per_second": 34.081,
      "eval_steps_per_second": 4.26,
      "step": 5202
    },
    {
      "epoch": 17.058823529411764,
      "grad_norm": 14.85346508026123,
      "learning_rate": 0.0003952941176470588,
      "loss": 0.1655,
      "step": 5220
    },
    {
      "epoch": 17.124183006535947,
      "grad_norm": 5.092591285705566,
      "learning_rate": 0.0003945098039215686,
      "loss": 0.131,
      "step": 5240
    },
    {
      "epoch": 17.18954248366013,
      "grad_norm": 12.174332618713379,
      "learning_rate": 0.0003937254901960784,
      "loss": 0.1779,
      "step": 5260
    },
    {
      "epoch": 17.254901960784313,
      "grad_norm": 0.05835346132516861,
      "learning_rate": 0.0003929411764705882,
      "loss": 0.0481,
      "step": 5280
    },
    {
      "epoch": 17.320261437908496,
      "grad_norm": 0.09890154749155045,
      "learning_rate": 0.000392156862745098,
      "loss": 0.1554,
      "step": 5300
    },
    {
      "epoch": 17.38562091503268,
      "grad_norm": 8.049307823181152,
      "learning_rate": 0.0003913725490196078,
      "loss": 0.1541,
      "step": 5320
    },
    {
      "epoch": 17.45098039215686,
      "grad_norm": 2.463918924331665,
      "learning_rate": 0.0003905882352941176,
      "loss": 0.0964,
      "step": 5340
    },
    {
      "epoch": 17.516339869281047,
      "grad_norm": 7.615236759185791,
      "learning_rate": 0.00038980392156862743,
      "loss": 0.1209,
      "step": 5360
    },
    {
      "epoch": 17.58169934640523,
      "grad_norm": 7.682754039764404,
      "learning_rate": 0.00038901960784313726,
      "loss": 0.1713,
      "step": 5380
    },
    {
      "epoch": 17.647058823529413,
      "grad_norm": 5.317078590393066,
      "learning_rate": 0.000388235294117647,
      "loss": 0.0991,
      "step": 5400
    },
    {
      "epoch": 17.712418300653596,
      "grad_norm": 0.014454442076385021,
      "learning_rate": 0.00038745098039215685,
      "loss": 0.1004,
      "step": 5420
    },
    {
      "epoch": 17.77777777777778,
      "grad_norm": 7.126928329467773,
      "learning_rate": 0.00038666666666666667,
      "loss": 0.0894,
      "step": 5440
    },
    {
      "epoch": 17.84313725490196,
      "grad_norm": 0.06457933038473129,
      "learning_rate": 0.0003858823529411765,
      "loss": 0.1271,
      "step": 5460
    },
    {
      "epoch": 17.908496732026144,
      "grad_norm": 8.109347343444824,
      "learning_rate": 0.00038509803921568626,
      "loss": 0.1322,
      "step": 5480
    },
    {
      "epoch": 17.973856209150327,
      "grad_norm": 0.0630723163485527,
      "learning_rate": 0.000384313725490196,
      "loss": 0.1327,
      "step": 5500
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9076168929110106,
      "eval_f1": 0.923076923076923,
      "eval_loss": 0.45573046803474426,
      "eval_runtime": 11.9645,
      "eval_samples_per_second": 34.101,
      "eval_steps_per_second": 4.263,
      "step": 5508
    },
    {
      "epoch": 18.03921568627451,
      "grad_norm": 0.06821898370981216,
      "learning_rate": 0.0003835294117647058,
      "loss": 0.1142,
      "step": 5520
    },
    {
      "epoch": 18.104575163398692,
      "grad_norm": 0.10398806631565094,
      "learning_rate": 0.0003827450980392156,
      "loss": 0.1159,
      "step": 5540
    },
    {
      "epoch": 18.169934640522875,
      "grad_norm": 5.916348934173584,
      "learning_rate": 0.00038196078431372544,
      "loss": 0.1566,
      "step": 5560
    },
    {
      "epoch": 18.235294117647058,
      "grad_norm": 0.2511496841907501,
      "learning_rate": 0.00038117647058823526,
      "loss": 0.1379,
      "step": 5580
    },
    {
      "epoch": 18.30065359477124,
      "grad_norm": 11.161033630371094,
      "learning_rate": 0.00038039215686274503,
      "loss": 0.1186,
      "step": 5600
    },
    {
      "epoch": 18.366013071895424,
      "grad_norm": 6.109652996063232,
      "learning_rate": 0.00037960784313725485,
      "loss": 0.1396,
      "step": 5620
    },
    {
      "epoch": 18.431372549019606,
      "grad_norm": 14.264362335205078,
      "learning_rate": 0.00037882352941176467,
      "loss": 0.1162,
      "step": 5640
    },
    {
      "epoch": 18.49673202614379,
      "grad_norm": 6.993854522705078,
      "learning_rate": 0.00037803921568627444,
      "loss": 0.1864,
      "step": 5660
    },
    {
      "epoch": 18.562091503267975,
      "grad_norm": 0.477141797542572,
      "learning_rate": 0.00037725490196078426,
      "loss": 0.111,
      "step": 5680
    },
    {
      "epoch": 18.627450980392158,
      "grad_norm": 4.158173561096191,
      "learning_rate": 0.0003764705882352941,
      "loss": 0.2248,
      "step": 5700
    },
    {
      "epoch": 18.69281045751634,
      "grad_norm": 4.795426845550537,
      "learning_rate": 0.0003756862745098039,
      "loss": 0.113,
      "step": 5720
    },
    {
      "epoch": 18.758169934640524,
      "grad_norm": 0.03684293106198311,
      "learning_rate": 0.0003749019607843137,
      "loss": 0.0687,
      "step": 5740
    },
    {
      "epoch": 18.823529411764707,
      "grad_norm": 5.437267303466797,
      "learning_rate": 0.0003741176470588235,
      "loss": 0.133,
      "step": 5760
    },
    {
      "epoch": 18.88888888888889,
      "grad_norm": 2.162487268447876,
      "learning_rate": 0.0003733333333333333,
      "loss": 0.1661,
      "step": 5780
    },
    {
      "epoch": 18.954248366013072,
      "grad_norm": 0.117294080555439,
      "learning_rate": 0.0003725490196078431,
      "loss": 0.0849,
      "step": 5800
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9051704014939308,
      "eval_f1": 0.9206349206349206,
      "eval_loss": 0.5016602277755737,
      "eval_runtime": 11.9534,
      "eval_samples_per_second": 34.132,
      "eval_steps_per_second": 4.267,
      "step": 5814
    },
    {
      "epoch": 19.019607843137255,
      "grad_norm": 1.773790717124939,
      "learning_rate": 0.0003717647058823529,
      "loss": 0.0468,
      "step": 5820
    },
    {
      "epoch": 19.084967320261438,
      "grad_norm": 11.320133209228516,
      "learning_rate": 0.00037098039215686273,
      "loss": 0.0987,
      "step": 5840
    },
    {
      "epoch": 19.15032679738562,
      "grad_norm": 5.163414478302002,
      "learning_rate": 0.00037019607843137255,
      "loss": 0.1444,
      "step": 5860
    },
    {
      "epoch": 19.215686274509803,
      "grad_norm": 0.1242661327123642,
      "learning_rate": 0.0003694117647058823,
      "loss": 0.0608,
      "step": 5880
    },
    {
      "epoch": 19.281045751633986,
      "grad_norm": 0.06177467480301857,
      "learning_rate": 0.00036862745098039214,
      "loss": 0.1477,
      "step": 5900
    },
    {
      "epoch": 19.34640522875817,
      "grad_norm": 11.424345016479492,
      "learning_rate": 0.00036784313725490196,
      "loss": 0.1079,
      "step": 5920
    },
    {
      "epoch": 19.41176470588235,
      "grad_norm": 0.3528129756450653,
      "learning_rate": 0.0003670588235294118,
      "loss": 0.1747,
      "step": 5940
    },
    {
      "epoch": 19.477124183006534,
      "grad_norm": 0.14027000963687897,
      "learning_rate": 0.00036627450980392155,
      "loss": 0.1188,
      "step": 5960
    },
    {
      "epoch": 19.54248366013072,
      "grad_norm": 8.069780349731445,
      "learning_rate": 0.0003654901960784313,
      "loss": 0.1201,
      "step": 5980
    },
    {
      "epoch": 19.607843137254903,
      "grad_norm": 4.695131778717041,
      "learning_rate": 0.0003647058823529411,
      "loss": 0.1198,
      "step": 6000
    },
    {
      "epoch": 19.673202614379086,
      "grad_norm": 0.41035163402557373,
      "learning_rate": 0.0003639215686274509,
      "loss": 0.1147,
      "step": 6020
    },
    {
      "epoch": 19.73856209150327,
      "grad_norm": 0.04528703913092613,
      "learning_rate": 0.00036313725490196073,
      "loss": 0.1416,
      "step": 6040
    },
    {
      "epoch": 19.80392156862745,
      "grad_norm": 0.5360374450683594,
      "learning_rate": 0.00036235294117647056,
      "loss": 0.2076,
      "step": 6060
    },
    {
      "epoch": 19.869281045751634,
      "grad_norm": 0.17365539073944092,
      "learning_rate": 0.0003615686274509803,
      "loss": 0.108,
      "step": 6080
    },
    {
      "epoch": 19.934640522875817,
      "grad_norm": 7.919004440307617,
      "learning_rate": 0.00036078431372549015,
      "loss": 0.1146,
      "step": 6100
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.14525765180587769,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.172,
      "step": 6120
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9115575807787903,
      "eval_f1": 0.926056338028169,
      "eval_loss": 0.45042967796325684,
      "eval_runtime": 11.9507,
      "eval_samples_per_second": 34.14,
      "eval_steps_per_second": 4.268,
      "step": 6120
    },
    {
      "epoch": 20.065359477124183,
      "grad_norm": 5.499730587005615,
      "learning_rate": 0.00035921568627450974,
      "loss": 0.0843,
      "step": 6140
    },
    {
      "epoch": 20.130718954248366,
      "grad_norm": 0.0853385254740715,
      "learning_rate": 0.00035843137254901956,
      "loss": 0.0723,
      "step": 6160
    },
    {
      "epoch": 20.19607843137255,
      "grad_norm": 8.807609558105469,
      "learning_rate": 0.0003576470588235294,
      "loss": 0.0918,
      "step": 6180
    },
    {
      "epoch": 20.26143790849673,
      "grad_norm": 0.0733054131269455,
      "learning_rate": 0.0003568627450980392,
      "loss": 0.1027,
      "step": 6200
    },
    {
      "epoch": 20.326797385620914,
      "grad_norm": 8.253071784973145,
      "learning_rate": 0.00035607843137254897,
      "loss": 0.0921,
      "step": 6220
    },
    {
      "epoch": 20.392156862745097,
      "grad_norm": 37.408538818359375,
      "learning_rate": 0.0003552941176470588,
      "loss": 0.1415,
      "step": 6240
    },
    {
      "epoch": 20.45751633986928,
      "grad_norm": 0.016247672960162163,
      "learning_rate": 0.0003545098039215686,
      "loss": 0.0894,
      "step": 6260
    },
    {
      "epoch": 20.522875816993466,
      "grad_norm": 12.566849708557129,
      "learning_rate": 0.0003537254901960784,
      "loss": 0.0831,
      "step": 6280
    },
    {
      "epoch": 20.58823529411765,
      "grad_norm": 7.607224941253662,
      "learning_rate": 0.0003529411764705882,
      "loss": 0.0635,
      "step": 6300
    },
    {
      "epoch": 20.65359477124183,
      "grad_norm": 0.01653227210044861,
      "learning_rate": 0.000352156862745098,
      "loss": 0.064,
      "step": 6320
    },
    {
      "epoch": 20.718954248366014,
      "grad_norm": 5.551966190338135,
      "learning_rate": 0.00035137254901960785,
      "loss": 0.1159,
      "step": 6340
    },
    {
      "epoch": 20.784313725490197,
      "grad_norm": 0.9653968811035156,
      "learning_rate": 0.0003505882352941176,
      "loss": 0.0849,
      "step": 6360
    },
    {
      "epoch": 20.84967320261438,
      "grad_norm": 0.36158278584480286,
      "learning_rate": 0.00034980392156862744,
      "loss": 0.1695,
      "step": 6380
    },
    {
      "epoch": 20.915032679738562,
      "grad_norm": 0.08153170347213745,
      "learning_rate": 0.00034901960784313726,
      "loss": 0.2076,
      "step": 6400
    },
    {
      "epoch": 20.980392156862745,
      "grad_norm": 5.144143581390381,
      "learning_rate": 0.0003482352941176471,
      "loss": 0.1254,
      "step": 6420
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9013897443794272,
      "eval_f1": 0.917975567190227,
      "eval_loss": 0.5246854424476624,
      "eval_runtime": 11.9612,
      "eval_samples_per_second": 34.11,
      "eval_steps_per_second": 4.264,
      "step": 6426
    },
    {
      "epoch": 21.045751633986928,
      "grad_norm": 0.3207872807979584,
      "learning_rate": 0.00034745098039215685,
      "loss": 0.1385,
      "step": 6440
    },
    {
      "epoch": 21.11111111111111,
      "grad_norm": 0.14827010035514832,
      "learning_rate": 0.0003466666666666666,
      "loss": 0.1428,
      "step": 6460
    },
    {
      "epoch": 21.176470588235293,
      "grad_norm": 7.394554138183594,
      "learning_rate": 0.0003458823529411764,
      "loss": 0.1047,
      "step": 6480
    },
    {
      "epoch": 21.241830065359476,
      "grad_norm": 0.4185710847377777,
      "learning_rate": 0.0003450980392156862,
      "loss": 0.0872,
      "step": 6500
    },
    {
      "epoch": 21.30718954248366,
      "grad_norm": 0.5061014890670776,
      "learning_rate": 0.00034431372549019603,
      "loss": 0.1226,
      "step": 6520
    },
    {
      "epoch": 21.372549019607842,
      "grad_norm": 1.6493788957595825,
      "learning_rate": 0.00034352941176470585,
      "loss": 0.0792,
      "step": 6540
    },
    {
      "epoch": 21.437908496732025,
      "grad_norm": 0.07876412570476532,
      "learning_rate": 0.0003427450980392156,
      "loss": 0.1166,
      "step": 6560
    },
    {
      "epoch": 21.50326797385621,
      "grad_norm": 3.4057931900024414,
      "learning_rate": 0.00034196078431372544,
      "loss": 0.0852,
      "step": 6580
    },
    {
      "epoch": 21.568627450980394,
      "grad_norm": 11.29244327545166,
      "learning_rate": 0.00034117647058823526,
      "loss": 0.0852,
      "step": 6600
    },
    {
      "epoch": 21.633986928104576,
      "grad_norm": 0.09026951342821121,
      "learning_rate": 0.00034039215686274503,
      "loss": 0.1316,
      "step": 6620
    },
    {
      "epoch": 21.69934640522876,
      "grad_norm": 9.601801872253418,
      "learning_rate": 0.00033960784313725485,
      "loss": 0.123,
      "step": 6640
    },
    {
      "epoch": 21.764705882352942,
      "grad_norm": 0.12229126691818237,
      "learning_rate": 0.0003388235294117647,
      "loss": 0.1404,
      "step": 6660
    },
    {
      "epoch": 21.830065359477125,
      "grad_norm": 7.187041759490967,
      "learning_rate": 0.0003380392156862745,
      "loss": 0.0723,
      "step": 6680
    },
    {
      "epoch": 21.895424836601308,
      "grad_norm": 0.07107984274625778,
      "learning_rate": 0.00033725490196078427,
      "loss": 0.1529,
      "step": 6700
    },
    {
      "epoch": 21.96078431372549,
      "grad_norm": 3.4469006061553955,
      "learning_rate": 0.0003364705882352941,
      "loss": 0.1045,
      "step": 6720
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9036968954248366,
      "eval_f1": 0.9201388888888888,
      "eval_loss": 0.5595327019691467,
      "eval_runtime": 11.9532,
      "eval_samples_per_second": 34.133,
      "eval_steps_per_second": 4.267,
      "step": 6732
    },
    {
      "epoch": 22.026143790849673,
      "grad_norm": 16.91180419921875,
      "learning_rate": 0.0003356862745098039,
      "loss": 0.0905,
      "step": 6740
    },
    {
      "epoch": 22.091503267973856,
      "grad_norm": 4.72934103012085,
      "learning_rate": 0.00033490196078431373,
      "loss": 0.0696,
      "step": 6760
    },
    {
      "epoch": 22.15686274509804,
      "grad_norm": 1.552341341972351,
      "learning_rate": 0.0003341176470588235,
      "loss": 0.0809,
      "step": 6780
    },
    {
      "epoch": 22.22222222222222,
      "grad_norm": 0.49434053897857666,
      "learning_rate": 0.0003333333333333333,
      "loss": 0.0541,
      "step": 6800
    },
    {
      "epoch": 22.287581699346404,
      "grad_norm": 0.1429198831319809,
      "learning_rate": 0.00033254901960784314,
      "loss": 0.0588,
      "step": 6820
    },
    {
      "epoch": 22.352941176470587,
      "grad_norm": 0.09753906726837158,
      "learning_rate": 0.0003317647058823529,
      "loss": 0.1736,
      "step": 6840
    },
    {
      "epoch": 22.41830065359477,
      "grad_norm": 7.246877193450928,
      "learning_rate": 0.00033098039215686273,
      "loss": 0.1458,
      "step": 6860
    },
    {
      "epoch": 22.483660130718953,
      "grad_norm": 1.1065592765808105,
      "learning_rate": 0.00033019607843137256,
      "loss": 0.1008,
      "step": 6880
    },
    {
      "epoch": 22.54901960784314,
      "grad_norm": 8.00223445892334,
      "learning_rate": 0.0003294117647058824,
      "loss": 0.1239,
      "step": 6900
    },
    {
      "epoch": 22.61437908496732,
      "grad_norm": 10.344074249267578,
      "learning_rate": 0.00032862745098039215,
      "loss": 0.0673,
      "step": 6920
    },
    {
      "epoch": 22.679738562091504,
      "grad_norm": 1.1807918548583984,
      "learning_rate": 0.0003278431372549019,
      "loss": 0.1859,
      "step": 6940
    },
    {
      "epoch": 22.745098039215687,
      "grad_norm": 3.571071147918701,
      "learning_rate": 0.0003270588235294117,
      "loss": 0.0993,
      "step": 6960
    },
    {
      "epoch": 22.81045751633987,
      "grad_norm": 4.5022406578063965,
      "learning_rate": 0.0003262745098039215,
      "loss": 0.1322,
      "step": 6980
    },
    {
      "epoch": 22.875816993464053,
      "grad_norm": 0.6930977702140808,
      "learning_rate": 0.0003254901960784313,
      "loss": 0.0553,
      "step": 7000
    },
    {
      "epoch": 22.941176470588236,
      "grad_norm": 18.4013729095459,
      "learning_rate": 0.00032470588235294115,
      "loss": 0.0814,
      "step": 7020
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.8872549019607843,
      "eval_combined_score": 0.9035577645692423,
      "eval_f1": 0.9198606271777002,
      "eval_loss": 0.5762403011322021,
      "eval_runtime": 11.9544,
      "eval_samples_per_second": 34.13,
      "eval_steps_per_second": 4.266,
      "step": 7038
    },
    {
      "epoch": 23.00653594771242,
      "grad_norm": 0.012776296585798264,
      "learning_rate": 0.0003239215686274509,
      "loss": 0.0927,
      "step": 7040
    },
    {
      "epoch": 23.0718954248366,
      "grad_norm": 0.053850751370191574,
      "learning_rate": 0.00032313725490196074,
      "loss": 0.0255,
      "step": 7060
    },
    {
      "epoch": 23.137254901960784,
      "grad_norm": 15.525837898254395,
      "learning_rate": 0.00032235294117647056,
      "loss": 0.0327,
      "step": 7080
    },
    {
      "epoch": 23.202614379084967,
      "grad_norm": 3.535093307495117,
      "learning_rate": 0.00032156862745098033,
      "loss": 0.0506,
      "step": 7100
    },
    {
      "epoch": 23.26797385620915,
      "grad_norm": 17.32471466064453,
      "learning_rate": 0.00032078431372549015,
      "loss": 0.1189,
      "step": 7120
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 2.452493190765381,
      "learning_rate": 0.00031999999999999997,
      "loss": 0.1197,
      "step": 7140
    },
    {
      "epoch": 23.398692810457515,
      "grad_norm": 0.09721812605857849,
      "learning_rate": 0.0003192156862745098,
      "loss": 0.0893,
      "step": 7160
    },
    {
      "epoch": 23.464052287581698,
      "grad_norm": 11.136232376098633,
      "learning_rate": 0.00031843137254901956,
      "loss": 0.1844,
      "step": 7180
    },
    {
      "epoch": 23.529411764705884,
      "grad_norm": 1.7250614166259766,
      "learning_rate": 0.0003176470588235294,
      "loss": 0.0279,
      "step": 7200
    },
    {
      "epoch": 23.594771241830067,
      "grad_norm": 7.489307880401611,
      "learning_rate": 0.0003168627450980392,
      "loss": 0.1263,
      "step": 7220
    },
    {
      "epoch": 23.66013071895425,
      "grad_norm": 4.298872947692871,
      "learning_rate": 0.00031607843137254903,
      "loss": 0.1251,
      "step": 7240
    },
    {
      "epoch": 23.725490196078432,
      "grad_norm": 1.604806900024414,
      "learning_rate": 0.0003152941176470588,
      "loss": 0.1223,
      "step": 7260
    },
    {
      "epoch": 23.790849673202615,
      "grad_norm": 8.520652770996094,
      "learning_rate": 0.0003145098039215686,
      "loss": 0.2229,
      "step": 7280
    },
    {
      "epoch": 23.856209150326798,
      "grad_norm": 0.7017878890037537,
      "learning_rate": 0.00031372549019607844,
      "loss": 0.1469,
      "step": 7300
    },
    {
      "epoch": 23.92156862745098,
      "grad_norm": 3.2451393604278564,
      "learning_rate": 0.0003129411764705882,
      "loss": 0.151,
      "step": 7320
    },
    {
      "epoch": 23.986928104575163,
      "grad_norm": 0.017027713358402252,
      "learning_rate": 0.00031215686274509803,
      "loss": 0.0626,
      "step": 7340
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.8970588235294118,
      "eval_combined_score": 0.9106232745805904,
      "eval_f1": 0.924187725631769,
      "eval_loss": 0.49321985244750977,
      "eval_runtime": 11.9509,
      "eval_samples_per_second": 34.14,
      "eval_steps_per_second": 4.267,
      "step": 7344
    },
    {
      "epoch": 24.052287581699346,
      "grad_norm": 15.836014747619629,
      "learning_rate": 0.00031137254901960785,
      "loss": 0.1176,
      "step": 7360
    },
    {
      "epoch": 24.11764705882353,
      "grad_norm": 0.5734719038009644,
      "learning_rate": 0.0003105882352941177,
      "loss": 0.1273,
      "step": 7380
    },
    {
      "epoch": 24.18300653594771,
      "grad_norm": 1.067301869392395,
      "learning_rate": 0.00030980392156862744,
      "loss": 0.0602,
      "step": 7400
    },
    {
      "epoch": 24.248366013071895,
      "grad_norm": 8.062907218933105,
      "learning_rate": 0.0003090196078431372,
      "loss": 0.0487,
      "step": 7420
    },
    {
      "epoch": 24.313725490196077,
      "grad_norm": 0.8933614492416382,
      "learning_rate": 0.000308235294117647,
      "loss": 0.0681,
      "step": 7440
    },
    {
      "epoch": 24.37908496732026,
      "grad_norm": 10.321391105651855,
      "learning_rate": 0.0003074509803921568,
      "loss": 0.1072,
      "step": 7460
    },
    {
      "epoch": 24.444444444444443,
      "grad_norm": 9.288618087768555,
      "learning_rate": 0.0003066666666666666,
      "loss": 0.071,
      "step": 7480
    },
    {
      "epoch": 24.509803921568626,
      "grad_norm": 8.385490417480469,
      "learning_rate": 0.00030588235294117644,
      "loss": 0.0974,
      "step": 7500
    },
    {
      "epoch": 24.575163398692812,
      "grad_norm": 9.483976364135742,
      "learning_rate": 0.0003050980392156862,
      "loss": 0.1074,
      "step": 7520
    },
    {
      "epoch": 24.640522875816995,
      "grad_norm": 0.09042439609766006,
      "learning_rate": 0.00030431372549019603,
      "loss": 0.1526,
      "step": 7540
    },
    {
      "epoch": 24.705882352941178,
      "grad_norm": 4.177304267883301,
      "learning_rate": 0.00030352941176470586,
      "loss": 0.0338,
      "step": 7560
    },
    {
      "epoch": 24.77124183006536,
      "grad_norm": 0.07276514917612076,
      "learning_rate": 0.0003027450980392156,
      "loss": 0.1157,
      "step": 7580
    },
    {
      "epoch": 24.836601307189543,
      "grad_norm": 1.7003920078277588,
      "learning_rate": 0.00030196078431372545,
      "loss": 0.0622,
      "step": 7600
    },
    {
      "epoch": 24.901960784313726,
      "grad_norm": 0.0716177374124527,
      "learning_rate": 0.00030117647058823527,
      "loss": 0.1029,
      "step": 7620
    },
    {
      "epoch": 24.96732026143791,
      "grad_norm": 0.04725756496191025,
      "learning_rate": 0.0003003921568627451,
      "loss": 0.0622,
      "step": 7640
    },
    {
      "epoch": 25.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9050299323269131,
      "eval_f1": 0.9203539823008849,
      "eval_loss": 0.6411890387535095,
      "eval_runtime": 11.9616,
      "eval_samples_per_second": 34.109,
      "eval_steps_per_second": 4.264,
      "step": 7650
    },
    {
      "epoch": 25.03267973856209,
      "grad_norm": 10.729212760925293,
      "learning_rate": 0.00029960784313725486,
      "loss": 0.0609,
      "step": 7660
    },
    {
      "epoch": 25.098039215686274,
      "grad_norm": 0.045960135757923126,
      "learning_rate": 0.0002988235294117647,
      "loss": 0.1708,
      "step": 7680
    },
    {
      "epoch": 25.163398692810457,
      "grad_norm": 6.589200973510742,
      "learning_rate": 0.0002980392156862745,
      "loss": 0.0797,
      "step": 7700
    },
    {
      "epoch": 25.22875816993464,
      "grad_norm": 1.5080831050872803,
      "learning_rate": 0.0002972549019607843,
      "loss": 0.0871,
      "step": 7720
    },
    {
      "epoch": 25.294117647058822,
      "grad_norm": 0.09014543145895004,
      "learning_rate": 0.0002964705882352941,
      "loss": 0.0393,
      "step": 7740
    },
    {
      "epoch": 25.359477124183005,
      "grad_norm": 0.19773057103157043,
      "learning_rate": 0.0002956862745098039,
      "loss": 0.1679,
      "step": 7760
    },
    {
      "epoch": 25.424836601307188,
      "grad_norm": 14.501076698303223,
      "learning_rate": 0.0002949019607843137,
      "loss": 0.1589,
      "step": 7780
    },
    {
      "epoch": 25.49019607843137,
      "grad_norm": 0.1989598423242569,
      "learning_rate": 0.0002941176470588235,
      "loss": 0.118,
      "step": 7800
    },
    {
      "epoch": 25.555555555555557,
      "grad_norm": 4.426935195922852,
      "learning_rate": 0.00029333333333333327,
      "loss": 0.1127,
      "step": 7820
    },
    {
      "epoch": 25.62091503267974,
      "grad_norm": 0.05231088399887085,
      "learning_rate": 0.0002925490196078431,
      "loss": 0.0577,
      "step": 7840
    },
    {
      "epoch": 25.686274509803923,
      "grad_norm": 0.5034932494163513,
      "learning_rate": 0.0002917647058823529,
      "loss": 0.0603,
      "step": 7860
    },
    {
      "epoch": 25.751633986928105,
      "grad_norm": 0.017480535432696342,
      "learning_rate": 0.00029098039215686274,
      "loss": 0.0526,
      "step": 7880
    },
    {
      "epoch": 25.81699346405229,
      "grad_norm": 0.006578951142728329,
      "learning_rate": 0.0002901960784313725,
      "loss": 0.1208,
      "step": 7900
    },
    {
      "epoch": 25.88235294117647,
      "grad_norm": 0.4971144497394562,
      "learning_rate": 0.00028941176470588233,
      "loss": 0.0705,
      "step": 7920
    },
    {
      "epoch": 25.947712418300654,
      "grad_norm": 0.01807534135878086,
      "learning_rate": 0.00028862745098039215,
      "loss": 0.1041,
      "step": 7940
    },
    {
      "epoch": 26.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9070713391739675,
      "eval_f1": 0.9219858156028369,
      "eval_loss": 0.5435708165168762,
      "eval_runtime": 11.9532,
      "eval_samples_per_second": 34.133,
      "eval_steps_per_second": 4.267,
      "step": 7956
    },
    {
      "epoch": 26.013071895424837,
      "grad_norm": 0.06287990510463715,
      "learning_rate": 0.00028784313725490197,
      "loss": 0.1319,
      "step": 7960
    },
    {
      "epoch": 26.07843137254902,
      "grad_norm": 0.024078452959656715,
      "learning_rate": 0.00028705882352941174,
      "loss": 0.024,
      "step": 7980
    },
    {
      "epoch": 26.143790849673202,
      "grad_norm": 0.07958294451236725,
      "learning_rate": 0.00028627450980392156,
      "loss": 0.1114,
      "step": 8000
    },
    {
      "epoch": 26.209150326797385,
      "grad_norm": 0.2585567831993103,
      "learning_rate": 0.00028549019607843133,
      "loss": 0.0581,
      "step": 8020
    },
    {
      "epoch": 26.274509803921568,
      "grad_norm": 6.6978440284729,
      "learning_rate": 0.00028470588235294115,
      "loss": 0.054,
      "step": 8040
    },
    {
      "epoch": 26.33986928104575,
      "grad_norm": 7.017145156860352,
      "learning_rate": 0.0002839215686274509,
      "loss": 0.1183,
      "step": 8060
    },
    {
      "epoch": 26.405228758169933,
      "grad_norm": 0.21821202337741852,
      "learning_rate": 0.00028313725490196074,
      "loss": 0.032,
      "step": 8080
    },
    {
      "epoch": 26.470588235294116,
      "grad_norm": 0.5337369441986084,
      "learning_rate": 0.00028235294117647056,
      "loss": 0.0832,
      "step": 8100
    },
    {
      "epoch": 26.535947712418302,
      "grad_norm": 2.792083740234375,
      "learning_rate": 0.0002815686274509804,
      "loss": 0.1154,
      "step": 8120
    },
    {
      "epoch": 26.601307189542485,
      "grad_norm": 11.735109329223633,
      "learning_rate": 0.00028078431372549015,
      "loss": 0.0781,
      "step": 8140
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 25.485557556152344,
      "learning_rate": 0.00028,
      "loss": 0.0996,
      "step": 8160
    },
    {
      "epoch": 26.73202614379085,
      "grad_norm": 0.5266021490097046,
      "learning_rate": 0.0002792156862745098,
      "loss": 0.0896,
      "step": 8180
    },
    {
      "epoch": 26.797385620915033,
      "grad_norm": 13.181658744812012,
      "learning_rate": 0.0002784313725490196,
      "loss": 0.1127,
      "step": 8200
    },
    {
      "epoch": 26.862745098039216,
      "grad_norm": 2.2177164554595947,
      "learning_rate": 0.0002776470588235294,
      "loss": 0.0638,
      "step": 8220
    },
    {
      "epoch": 26.9281045751634,
      "grad_norm": 0.03391483426094055,
      "learning_rate": 0.0002768627450980392,
      "loss": 0.0204,
      "step": 8240
    },
    {
      "epoch": 26.99346405228758,
      "grad_norm": 16.409563064575195,
      "learning_rate": 0.000276078431372549,
      "loss": 0.1017,
      "step": 8260
    },
    {
      "epoch": 27.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8996539792387543,
      "eval_f1": 0.9169550173010381,
      "eval_loss": 0.7347922921180725,
      "eval_runtime": 11.952,
      "eval_samples_per_second": 34.137,
      "eval_steps_per_second": 4.267,
      "step": 8262
    },
    {
      "epoch": 27.058823529411764,
      "grad_norm": 0.3406218886375427,
      "learning_rate": 0.0002752941176470588,
      "loss": 0.0723,
      "step": 8280
    },
    {
      "epoch": 27.124183006535947,
      "grad_norm": 7.386413097381592,
      "learning_rate": 0.00027450980392156857,
      "loss": 0.0284,
      "step": 8300
    },
    {
      "epoch": 27.18954248366013,
      "grad_norm": 0.008278724737465382,
      "learning_rate": 0.0002737254901960784,
      "loss": 0.0894,
      "step": 8320
    },
    {
      "epoch": 27.254901960784313,
      "grad_norm": 3.5614187717437744,
      "learning_rate": 0.0002729411764705882,
      "loss": 0.1126,
      "step": 8340
    },
    {
      "epoch": 27.320261437908496,
      "grad_norm": 0.10082467645406723,
      "learning_rate": 0.00027215686274509803,
      "loss": 0.1021,
      "step": 8360
    },
    {
      "epoch": 27.38562091503268,
      "grad_norm": 14.493637084960938,
      "learning_rate": 0.0002713725490196078,
      "loss": 0.043,
      "step": 8380
    },
    {
      "epoch": 27.45098039215686,
      "grad_norm": 17.607332229614258,
      "learning_rate": 0.0002705882352941176,
      "loss": 0.0848,
      "step": 8400
    },
    {
      "epoch": 27.516339869281047,
      "grad_norm": 12.673638343811035,
      "learning_rate": 0.00026980392156862745,
      "loss": 0.1295,
      "step": 8420
    },
    {
      "epoch": 27.58169934640523,
      "grad_norm": 0.03777057304978371,
      "learning_rate": 0.00026901960784313727,
      "loss": 0.0774,
      "step": 8440
    },
    {
      "epoch": 27.647058823529413,
      "grad_norm": 2.556501865386963,
      "learning_rate": 0.00026823529411764704,
      "loss": 0.0521,
      "step": 8460
    },
    {
      "epoch": 27.712418300653596,
      "grad_norm": 4.22048282623291,
      "learning_rate": 0.00026745098039215686,
      "loss": 0.0927,
      "step": 8480
    },
    {
      "epoch": 27.77777777777778,
      "grad_norm": 0.32469919323921204,
      "learning_rate": 0.0002666666666666666,
      "loss": 0.1129,
      "step": 8500
    },
    {
      "epoch": 27.84313725490196,
      "grad_norm": 9.013318061828613,
      "learning_rate": 0.00026588235294117645,
      "loss": 0.0878,
      "step": 8520
    },
    {
      "epoch": 27.908496732026144,
      "grad_norm": 12.733858108520508,
      "learning_rate": 0.0002650980392156862,
      "loss": 0.1104,
      "step": 8540
    },
    {
      "epoch": 27.973856209150327,
      "grad_norm": 0.07724031060934067,
      "learning_rate": 0.00026431372549019604,
      "loss": 0.1696,
      "step": 8560
    },
    {
      "epoch": 28.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8983193277310924,
      "eval_f1": 0.9142857142857143,
      "eval_loss": 0.5338821411132812,
      "eval_runtime": 11.9514,
      "eval_samples_per_second": 34.138,
      "eval_steps_per_second": 4.267,
      "step": 8568
    },
    {
      "epoch": 28.03921568627451,
      "grad_norm": 1.2812801599502563,
      "learning_rate": 0.00026352941176470586,
      "loss": 0.0783,
      "step": 8580
    },
    {
      "epoch": 28.104575163398692,
      "grad_norm": 0.13323332369327545,
      "learning_rate": 0.0002627450980392157,
      "loss": 0.1191,
      "step": 8600
    },
    {
      "epoch": 28.169934640522875,
      "grad_norm": 4.686931610107422,
      "learning_rate": 0.00026196078431372545,
      "loss": 0.0445,
      "step": 8620
    },
    {
      "epoch": 28.235294117647058,
      "grad_norm": 0.4949227273464203,
      "learning_rate": 0.00026117647058823527,
      "loss": 0.0315,
      "step": 8640
    },
    {
      "epoch": 28.30065359477124,
      "grad_norm": 12.937880516052246,
      "learning_rate": 0.0002603921568627451,
      "loss": 0.1378,
      "step": 8660
    },
    {
      "epoch": 28.366013071895424,
      "grad_norm": 0.009427887387573719,
      "learning_rate": 0.0002596078431372549,
      "loss": 0.0466,
      "step": 8680
    },
    {
      "epoch": 28.431372549019606,
      "grad_norm": 4.5028157234191895,
      "learning_rate": 0.0002588235294117647,
      "loss": 0.1136,
      "step": 8700
    },
    {
      "epoch": 28.49673202614379,
      "grad_norm": 11.679624557495117,
      "learning_rate": 0.0002580392156862745,
      "loss": 0.0251,
      "step": 8720
    },
    {
      "epoch": 28.562091503267975,
      "grad_norm": 0.022696662694215775,
      "learning_rate": 0.0002572549019607843,
      "loss": 0.0442,
      "step": 8740
    },
    {
      "epoch": 28.627450980392158,
      "grad_norm": 0.07846517115831375,
      "learning_rate": 0.0002564705882352941,
      "loss": 0.0748,
      "step": 8760
    },
    {
      "epoch": 28.69281045751634,
      "grad_norm": 0.006788012571632862,
      "learning_rate": 0.00025568627450980386,
      "loss": 0.0943,
      "step": 8780
    },
    {
      "epoch": 28.758169934640524,
      "grad_norm": 1.2966099977493286,
      "learning_rate": 0.0002549019607843137,
      "loss": 0.0441,
      "step": 8800
    },
    {
      "epoch": 28.823529411764707,
      "grad_norm": 0.018267156556248665,
      "learning_rate": 0.0002541176470588235,
      "loss": 0.0438,
      "step": 8820
    },
    {
      "epoch": 28.88888888888889,
      "grad_norm": 15.135056495666504,
      "learning_rate": 0.00025333333333333333,
      "loss": 0.1555,
      "step": 8840
    },
    {
      "epoch": 28.954248366013072,
      "grad_norm": 3.742523431777954,
      "learning_rate": 0.0002525490196078431,
      "loss": 0.1654,
      "step": 8860
    },
    {
      "epoch": 29.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8953227124183006,
      "eval_f1": 0.9131944444444444,
      "eval_loss": 0.6780969500541687,
      "eval_runtime": 11.9673,
      "eval_samples_per_second": 34.093,
      "eval_steps_per_second": 4.262,
      "step": 8874
    },
    {
      "epoch": 29.019607843137255,
      "grad_norm": 17.77669906616211,
      "learning_rate": 0.0002517647058823529,
      "loss": 0.1004,
      "step": 8880
    },
    {
      "epoch": 29.084967320261438,
      "grad_norm": 0.36836227774620056,
      "learning_rate": 0.00025098039215686274,
      "loss": 0.0322,
      "step": 8900
    },
    {
      "epoch": 29.15032679738562,
      "grad_norm": 0.010133803822100163,
      "learning_rate": 0.00025019607843137256,
      "loss": 0.0934,
      "step": 8920
    },
    {
      "epoch": 29.215686274509803,
      "grad_norm": 0.054959818720817566,
      "learning_rate": 0.00024941176470588233,
      "loss": 0.0243,
      "step": 8940
    },
    {
      "epoch": 29.281045751633986,
      "grad_norm": 0.03508850187063217,
      "learning_rate": 0.00024862745098039215,
      "loss": 0.0609,
      "step": 8960
    },
    {
      "epoch": 29.34640522875817,
      "grad_norm": 0.029781369492411613,
      "learning_rate": 0.0002478431372549019,
      "loss": 0.0967,
      "step": 8980
    },
    {
      "epoch": 29.41176470588235,
      "grad_norm": 2.1993918418884277,
      "learning_rate": 0.00024705882352941174,
      "loss": 0.1114,
      "step": 9000
    },
    {
      "epoch": 29.477124183006534,
      "grad_norm": 0.9398176074028015,
      "learning_rate": 0.00024627450980392157,
      "loss": 0.1372,
      "step": 9020
    },
    {
      "epoch": 29.54248366013072,
      "grad_norm": 0.003290093969553709,
      "learning_rate": 0.00024549019607843133,
      "loss": 0.0738,
      "step": 9040
    },
    {
      "epoch": 29.607843137254903,
      "grad_norm": 7.983092308044434,
      "learning_rate": 0.00024470588235294116,
      "loss": 0.0417,
      "step": 9060
    },
    {
      "epoch": 29.673202614379086,
      "grad_norm": 0.014052003622055054,
      "learning_rate": 0.00024392156862745095,
      "loss": 0.1209,
      "step": 9080
    },
    {
      "epoch": 29.73856209150327,
      "grad_norm": 0.018822165206074715,
      "learning_rate": 0.00024313725490196077,
      "loss": 0.125,
      "step": 9100
    },
    {
      "epoch": 29.80392156862745,
      "grad_norm": 9.920445442199707,
      "learning_rate": 0.00024235294117647057,
      "loss": 0.1267,
      "step": 9120
    },
    {
      "epoch": 29.869281045751634,
      "grad_norm": 17.98666000366211,
      "learning_rate": 0.0002415686274509804,
      "loss": 0.1198,
      "step": 9140
    },
    {
      "epoch": 29.934640522875817,
      "grad_norm": 0.028126263990998268,
      "learning_rate": 0.00024078431372549018,
      "loss": 0.0649,
      "step": 9160
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.0029955911450088024,
      "learning_rate": 0.00023999999999999998,
      "loss": 0.0384,
      "step": 9180
    },
    {
      "epoch": 30.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9013897443794272,
      "eval_f1": 0.917975567190227,
      "eval_loss": 0.7186201214790344,
      "eval_runtime": 11.9794,
      "eval_samples_per_second": 34.059,
      "eval_steps_per_second": 4.257,
      "step": 9180
    },
    {
      "epoch": 30.065359477124183,
      "grad_norm": 10.44947624206543,
      "learning_rate": 0.0002392156862745098,
      "loss": 0.0413,
      "step": 9200
    },
    {
      "epoch": 30.130718954248366,
      "grad_norm": 5.835049152374268,
      "learning_rate": 0.00023843137254901957,
      "loss": 0.0424,
      "step": 9220
    },
    {
      "epoch": 30.19607843137255,
      "grad_norm": 0.3200570344924927,
      "learning_rate": 0.0002376470588235294,
      "loss": 0.0383,
      "step": 9240
    },
    {
      "epoch": 30.26143790849673,
      "grad_norm": 0.2859416604042053,
      "learning_rate": 0.00023686274509803919,
      "loss": 0.0655,
      "step": 9260
    },
    {
      "epoch": 30.326797385620914,
      "grad_norm": 0.11281481385231018,
      "learning_rate": 0.00023607843137254898,
      "loss": 0.0658,
      "step": 9280
    },
    {
      "epoch": 30.392156862745097,
      "grad_norm": 0.10508567839860916,
      "learning_rate": 0.0002352941176470588,
      "loss": 0.1083,
      "step": 9300
    },
    {
      "epoch": 30.45751633986928,
      "grad_norm": 0.9076414704322815,
      "learning_rate": 0.0002345098039215686,
      "loss": 0.0604,
      "step": 9320
    },
    {
      "epoch": 30.522875816993466,
      "grad_norm": 0.015928905457258224,
      "learning_rate": 0.00023372549019607842,
      "loss": 0.0369,
      "step": 9340
    },
    {
      "epoch": 30.58823529411765,
      "grad_norm": 8.626611709594727,
      "learning_rate": 0.00023294117647058821,
      "loss": 0.049,
      "step": 9360
    },
    {
      "epoch": 30.65359477124183,
      "grad_norm": 0.3390911817550659,
      "learning_rate": 0.00023215686274509804,
      "loss": 0.049,
      "step": 9380
    },
    {
      "epoch": 30.718954248366014,
      "grad_norm": 1.8838859796524048,
      "learning_rate": 0.00023137254901960783,
      "loss": 0.1749,
      "step": 9400
    },
    {
      "epoch": 30.784313725490197,
      "grad_norm": 0.29082632064819336,
      "learning_rate": 0.00023058823529411763,
      "loss": 0.0641,
      "step": 9420
    },
    {
      "epoch": 30.84967320261438,
      "grad_norm": 0.028152436017990112,
      "learning_rate": 0.00022980392156862745,
      "loss": 0.1074,
      "step": 9440
    },
    {
      "epoch": 30.915032679738562,
      "grad_norm": 0.04836714640259743,
      "learning_rate": 0.00022901960784313722,
      "loss": 0.0773,
      "step": 9460
    },
    {
      "epoch": 30.980392156862745,
      "grad_norm": 12.941253662109375,
      "learning_rate": 0.00022823529411764704,
      "loss": 0.048,
      "step": 9480
    },
    {
      "epoch": 31.0,
      "eval_accuracy": 0.875,
      "eval_combined_score": 0.8933058925476604,
      "eval_f1": 0.9116117850953207,
      "eval_loss": 0.7120599150657654,
      "eval_runtime": 11.9727,
      "eval_samples_per_second": 34.077,
      "eval_steps_per_second": 4.26,
      "step": 9486
    },
    {
      "epoch": 31.045751633986928,
      "grad_norm": 0.03565327078104019,
      "learning_rate": 0.00022745098039215683,
      "loss": 0.0967,
      "step": 9500
    },
    {
      "epoch": 31.11111111111111,
      "grad_norm": 0.0044064330868422985,
      "learning_rate": 0.00022666666666666663,
      "loss": 0.0769,
      "step": 9520
    },
    {
      "epoch": 31.176470588235293,
      "grad_norm": 0.026852697134017944,
      "learning_rate": 0.00022588235294117645,
      "loss": 0.1002,
      "step": 9540
    },
    {
      "epoch": 31.241830065359476,
      "grad_norm": 0.1341017186641693,
      "learning_rate": 0.00022509803921568625,
      "loss": 0.0752,
      "step": 9560
    },
    {
      "epoch": 31.30718954248366,
      "grad_norm": 13.383613586425781,
      "learning_rate": 0.00022431372549019607,
      "loss": 0.1434,
      "step": 9580
    },
    {
      "epoch": 31.372549019607842,
      "grad_norm": 8.46074390411377,
      "learning_rate": 0.00022352941176470586,
      "loss": 0.0448,
      "step": 9600
    },
    {
      "epoch": 31.437908496732025,
      "grad_norm": 14.338112831115723,
      "learning_rate": 0.00022274509803921568,
      "loss": 0.0243,
      "step": 9620
    },
    {
      "epoch": 31.50326797385621,
      "grad_norm": 14.431519508361816,
      "learning_rate": 0.00022196078431372548,
      "loss": 0.1026,
      "step": 9640
    },
    {
      "epoch": 31.568627450980394,
      "grad_norm": 0.11864468455314636,
      "learning_rate": 0.0002211764705882353,
      "loss": 0.0406,
      "step": 9660
    },
    {
      "epoch": 31.633986928104576,
      "grad_norm": 9.156575202941895,
      "learning_rate": 0.0002203921568627451,
      "loss": 0.0397,
      "step": 9680
    },
    {
      "epoch": 31.69934640522876,
      "grad_norm": 3.2760353088378906,
      "learning_rate": 0.00021960784313725486,
      "loss": 0.0598,
      "step": 9700
    },
    {
      "epoch": 31.764705882352942,
      "grad_norm": 0.07375016063451767,
      "learning_rate": 0.0002188235294117647,
      "loss": 0.0671,
      "step": 9720
    },
    {
      "epoch": 31.830065359477125,
      "grad_norm": 0.31621408462524414,
      "learning_rate": 0.00021803921568627448,
      "loss": 0.0694,
      "step": 9740
    },
    {
      "epoch": 31.895424836601308,
      "grad_norm": 0.26817506551742554,
      "learning_rate": 0.00021725490196078428,
      "loss": 0.0464,
      "step": 9760
    },
    {
      "epoch": 31.96078431372549,
      "grad_norm": 0.04023582488298416,
      "learning_rate": 0.0002164705882352941,
      "loss": 0.1021,
      "step": 9780
    },
    {
      "epoch": 32.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8953227124183006,
      "eval_f1": 0.9131944444444444,
      "eval_loss": 0.8170291781425476,
      "eval_runtime": 11.9493,
      "eval_samples_per_second": 34.144,
      "eval_steps_per_second": 4.268,
      "step": 9792
    },
    {
      "epoch": 32.02614379084967,
      "grad_norm": 0.06816098093986511,
      "learning_rate": 0.0002156862745098039,
      "loss": 0.0607,
      "step": 9800
    },
    {
      "epoch": 32.091503267973856,
      "grad_norm": 0.07965269684791565,
      "learning_rate": 0.00021490196078431372,
      "loss": 0.0211,
      "step": 9820
    },
    {
      "epoch": 32.15686274509804,
      "grad_norm": 0.11200394481420517,
      "learning_rate": 0.0002141176470588235,
      "loss": 0.1474,
      "step": 9840
    },
    {
      "epoch": 32.22222222222222,
      "grad_norm": 0.08386384695768356,
      "learning_rate": 0.00021333333333333333,
      "loss": 0.0609,
      "step": 9860
    },
    {
      "epoch": 32.287581699346404,
      "grad_norm": 0.46318352222442627,
      "learning_rate": 0.00021254901960784313,
      "loss": 0.0071,
      "step": 9880
    },
    {
      "epoch": 32.35294117647059,
      "grad_norm": 0.6758168935775757,
      "learning_rate": 0.00021176470588235295,
      "loss": 0.0839,
      "step": 9900
    },
    {
      "epoch": 32.41830065359477,
      "grad_norm": 8.67170524597168,
      "learning_rate": 0.00021098039215686274,
      "loss": 0.0835,
      "step": 9920
    },
    {
      "epoch": 32.48366013071895,
      "grad_norm": 0.0028420693706721067,
      "learning_rate": 0.0002101960784313725,
      "loss": 0.0519,
      "step": 9940
    },
    {
      "epoch": 32.549019607843135,
      "grad_norm": 0.001666289521381259,
      "learning_rate": 0.00020941176470588233,
      "loss": 0.0551,
      "step": 9960
    },
    {
      "epoch": 32.61437908496732,
      "grad_norm": 0.13179433345794678,
      "learning_rate": 0.00020862745098039213,
      "loss": 0.0804,
      "step": 9980
    },
    {
      "epoch": 32.6797385620915,
      "grad_norm": 0.08728189021348953,
      "learning_rate": 0.00020784313725490192,
      "loss": 0.074,
      "step": 10000
    },
    {
      "epoch": 32.745098039215684,
      "grad_norm": 7.628300666809082,
      "learning_rate": 0.00020705882352941175,
      "loss": 0.1046,
      "step": 10020
    },
    {
      "epoch": 32.810457516339866,
      "grad_norm": 22.997314453125,
      "learning_rate": 0.00020627450980392154,
      "loss": 0.1731,
      "step": 10040
    },
    {
      "epoch": 32.87581699346405,
      "grad_norm": 0.2123638242483139,
      "learning_rate": 0.00020549019607843136,
      "loss": 0.0692,
      "step": 10060
    },
    {
      "epoch": 32.94117647058823,
      "grad_norm": 29.414339065551758,
      "learning_rate": 0.00020470588235294116,
      "loss": 0.0817,
      "step": 10080
    },
    {
      "epoch": 33.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9009557526714389,
      "eval_f1": 0.9171075837742505,
      "eval_loss": 0.6743506789207458,
      "eval_runtime": 11.9639,
      "eval_samples_per_second": 34.102,
      "eval_steps_per_second": 4.263,
      "step": 10098
    },
    {
      "epoch": 33.00653594771242,
      "grad_norm": 0.7462655901908875,
      "learning_rate": 0.00020392156862745098,
      "loss": 0.0513,
      "step": 10100
    },
    {
      "epoch": 33.071895424836605,
      "grad_norm": 5.385300636291504,
      "learning_rate": 0.00020313725490196078,
      "loss": 0.138,
      "step": 10120
    },
    {
      "epoch": 33.13725490196079,
      "grad_norm": 2.0441994667053223,
      "learning_rate": 0.0002023529411764706,
      "loss": 0.0404,
      "step": 10140
    },
    {
      "epoch": 33.20261437908497,
      "grad_norm": 0.9674340486526489,
      "learning_rate": 0.0002015686274509804,
      "loss": 0.0523,
      "step": 10160
    },
    {
      "epoch": 33.26797385620915,
      "grad_norm": 9.442944526672363,
      "learning_rate": 0.00020078431372549016,
      "loss": 0.0921,
      "step": 10180
    },
    {
      "epoch": 33.333333333333336,
      "grad_norm": 3.1334667205810547,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.0273,
      "step": 10200
    },
    {
      "epoch": 33.39869281045752,
      "grad_norm": 0.0021165625657886267,
      "learning_rate": 0.00019921568627450978,
      "loss": 0.0704,
      "step": 10220
    },
    {
      "epoch": 33.4640522875817,
      "grad_norm": 0.03050527535378933,
      "learning_rate": 0.00019843137254901957,
      "loss": 0.0969,
      "step": 10240
    },
    {
      "epoch": 33.529411764705884,
      "grad_norm": 3.508297920227051,
      "learning_rate": 0.0001976470588235294,
      "loss": 0.0971,
      "step": 10260
    },
    {
      "epoch": 33.59477124183007,
      "grad_norm": 10.880485534667969,
      "learning_rate": 0.0001968627450980392,
      "loss": 0.1286,
      "step": 10280
    },
    {
      "epoch": 33.66013071895425,
      "grad_norm": 3.250887870788574,
      "learning_rate": 0.000196078431372549,
      "loss": 0.0895,
      "step": 10300
    },
    {
      "epoch": 33.72549019607843,
      "grad_norm": 0.04845894128084183,
      "learning_rate": 0.0001952941176470588,
      "loss": 0.0159,
      "step": 10320
    },
    {
      "epoch": 33.790849673202615,
      "grad_norm": 0.011053519323468208,
      "learning_rate": 0.00019450980392156863,
      "loss": 0.0612,
      "step": 10340
    },
    {
      "epoch": 33.8562091503268,
      "grad_norm": 1.7176134586334229,
      "learning_rate": 0.00019372549019607842,
      "loss": 0.0935,
      "step": 10360
    },
    {
      "epoch": 33.92156862745098,
      "grad_norm": 5.183273792266846,
      "learning_rate": 0.00019294117647058825,
      "loss": 0.141,
      "step": 10380
    },
    {
      "epoch": 33.98692810457516,
      "grad_norm": 8.633758544921875,
      "learning_rate": 0.000192156862745098,
      "loss": 0.0621,
      "step": 10400
    },
    {
      "epoch": 34.0,
      "eval_accuracy": 0.8725490196078431,
      "eval_combined_score": 0.8912918108419838,
      "eval_f1": 0.9100346020761245,
      "eval_loss": 0.6932860016822815,
      "eval_runtime": 11.9622,
      "eval_samples_per_second": 34.108,
      "eval_steps_per_second": 4.263,
      "step": 10404
    },
    {
      "epoch": 34.052287581699346,
      "grad_norm": 0.28372764587402344,
      "learning_rate": 0.0001913725490196078,
      "loss": 0.0565,
      "step": 10420
    },
    {
      "epoch": 34.11764705882353,
      "grad_norm": 1.0709675550460815,
      "learning_rate": 0.00019058823529411763,
      "loss": 0.1023,
      "step": 10440
    },
    {
      "epoch": 34.18300653594771,
      "grad_norm": 0.12720905244350433,
      "learning_rate": 0.00018980392156862743,
      "loss": 0.0384,
      "step": 10460
    },
    {
      "epoch": 34.248366013071895,
      "grad_norm": 0.004913812968879938,
      "learning_rate": 0.00018901960784313722,
      "loss": 0.0529,
      "step": 10480
    },
    {
      "epoch": 34.31372549019608,
      "grad_norm": 0.0038619942497462034,
      "learning_rate": 0.00018823529411764704,
      "loss": 0.06,
      "step": 10500
    },
    {
      "epoch": 34.37908496732026,
      "grad_norm": 22.880996704101562,
      "learning_rate": 0.00018745098039215684,
      "loss": 0.085,
      "step": 10520
    },
    {
      "epoch": 34.44444444444444,
      "grad_norm": 0.737066388130188,
      "learning_rate": 0.00018666666666666666,
      "loss": 0.0509,
      "step": 10540
    },
    {
      "epoch": 34.509803921568626,
      "grad_norm": 0.004470130894333124,
      "learning_rate": 0.00018588235294117645,
      "loss": 0.0046,
      "step": 10560
    },
    {
      "epoch": 34.57516339869281,
      "grad_norm": 0.6009312868118286,
      "learning_rate": 0.00018509803921568628,
      "loss": 0.0743,
      "step": 10580
    },
    {
      "epoch": 34.64052287581699,
      "grad_norm": 5.527158260345459,
      "learning_rate": 0.00018431372549019607,
      "loss": 0.0434,
      "step": 10600
    },
    {
      "epoch": 34.705882352941174,
      "grad_norm": 0.032165318727493286,
      "learning_rate": 0.0001835294117647059,
      "loss": 0.0726,
      "step": 10620
    },
    {
      "epoch": 34.77124183006536,
      "grad_norm": 3.5749642848968506,
      "learning_rate": 0.00018274509803921566,
      "loss": 0.045,
      "step": 10640
    },
    {
      "epoch": 34.83660130718954,
      "grad_norm": 0.4729267358779907,
      "learning_rate": 0.00018196078431372546,
      "loss": 0.0812,
      "step": 10660
    },
    {
      "epoch": 34.90196078431372,
      "grad_norm": 19.995637893676758,
      "learning_rate": 0.00018117647058823528,
      "loss": 0.0433,
      "step": 10680
    },
    {
      "epoch": 34.967320261437905,
      "grad_norm": 0.0010339469881728292,
      "learning_rate": 0.00018039215686274507,
      "loss": 0.0389,
      "step": 10700
    },
    {
      "epoch": 35.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9057225063938619,
      "eval_f1": 0.9217391304347826,
      "eval_loss": 0.7593510150909424,
      "eval_runtime": 11.9668,
      "eval_samples_per_second": 34.094,
      "eval_steps_per_second": 4.262,
      "step": 10710
    },
    {
      "epoch": 35.032679738562095,
      "grad_norm": 0.013946645893156528,
      "learning_rate": 0.00017960784313725487,
      "loss": 0.0347,
      "step": 10720
    },
    {
      "epoch": 35.09803921568628,
      "grad_norm": 0.10535861551761627,
      "learning_rate": 0.0001788235294117647,
      "loss": 0.0274,
      "step": 10740
    },
    {
      "epoch": 35.16339869281046,
      "grad_norm": 0.37278735637664795,
      "learning_rate": 0.00017803921568627449,
      "loss": 0.0479,
      "step": 10760
    },
    {
      "epoch": 35.22875816993464,
      "grad_norm": 0.15949733555316925,
      "learning_rate": 0.0001772549019607843,
      "loss": 0.1597,
      "step": 10780
    },
    {
      "epoch": 35.294117647058826,
      "grad_norm": 6.746579647064209,
      "learning_rate": 0.0001764705882352941,
      "loss": 0.0435,
      "step": 10800
    },
    {
      "epoch": 35.35947712418301,
      "grad_norm": 0.003279888303950429,
      "learning_rate": 0.00017568627450980392,
      "loss": 0.0825,
      "step": 10820
    },
    {
      "epoch": 35.42483660130719,
      "grad_norm": 0.01250919234007597,
      "learning_rate": 0.00017490196078431372,
      "loss": 0.0898,
      "step": 10840
    },
    {
      "epoch": 35.490196078431374,
      "grad_norm": 0.025250619277358055,
      "learning_rate": 0.00017411764705882354,
      "loss": 0.0538,
      "step": 10860
    },
    {
      "epoch": 35.55555555555556,
      "grad_norm": 2.3840439319610596,
      "learning_rate": 0.0001733333333333333,
      "loss": 0.0201,
      "step": 10880
    },
    {
      "epoch": 35.62091503267974,
      "grad_norm": 0.0565568208694458,
      "learning_rate": 0.0001725490196078431,
      "loss": 0.0491,
      "step": 10900
    },
    {
      "epoch": 35.68627450980392,
      "grad_norm": 2.6634902954101562,
      "learning_rate": 0.00017176470588235293,
      "loss": 0.0115,
      "step": 10920
    },
    {
      "epoch": 35.751633986928105,
      "grad_norm": 0.013034711591899395,
      "learning_rate": 0.00017098039215686272,
      "loss": 0.0561,
      "step": 10940
    },
    {
      "epoch": 35.81699346405229,
      "grad_norm": 0.0010620246175676584,
      "learning_rate": 0.00017019607843137252,
      "loss": 0.0396,
      "step": 10960
    },
    {
      "epoch": 35.88235294117647,
      "grad_norm": 11.691851615905762,
      "learning_rate": 0.00016941176470588234,
      "loss": 0.0997,
      "step": 10980
    },
    {
      "epoch": 35.947712418300654,
      "grad_norm": 1.8364883661270142,
      "learning_rate": 0.00016862745098039213,
      "loss": 0.0355,
      "step": 11000
    },
    {
      "epoch": 36.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9051704014939308,
      "eval_f1": 0.9206349206349206,
      "eval_loss": 0.8271551728248596,
      "eval_runtime": 11.9544,
      "eval_samples_per_second": 34.13,
      "eval_steps_per_second": 4.266,
      "step": 11016
    },
    {
      "epoch": 36.01307189542484,
      "grad_norm": 12.357970237731934,
      "learning_rate": 0.00016784313725490196,
      "loss": 0.1087,
      "step": 11020
    },
    {
      "epoch": 36.07843137254902,
      "grad_norm": 12.258790016174316,
      "learning_rate": 0.00016705882352941175,
      "loss": 0.12,
      "step": 11040
    },
    {
      "epoch": 36.1437908496732,
      "grad_norm": 0.004277643747627735,
      "learning_rate": 0.00016627450980392157,
      "loss": 0.0096,
      "step": 11060
    },
    {
      "epoch": 36.209150326797385,
      "grad_norm": 0.03678453713655472,
      "learning_rate": 0.00016549019607843137,
      "loss": 0.1059,
      "step": 11080
    },
    {
      "epoch": 36.27450980392157,
      "grad_norm": 3.5528995990753174,
      "learning_rate": 0.0001647058823529412,
      "loss": 0.0439,
      "step": 11100
    },
    {
      "epoch": 36.33986928104575,
      "grad_norm": 26.79630470275879,
      "learning_rate": 0.00016392156862745096,
      "loss": 0.157,
      "step": 11120
    },
    {
      "epoch": 36.40522875816993,
      "grad_norm": 12.300174713134766,
      "learning_rate": 0.00016313725490196075,
      "loss": 0.0784,
      "step": 11140
    },
    {
      "epoch": 36.470588235294116,
      "grad_norm": 0.04871568828821182,
      "learning_rate": 0.00016235294117647057,
      "loss": 0.1156,
      "step": 11160
    },
    {
      "epoch": 36.5359477124183,
      "grad_norm": 0.07578842341899872,
      "learning_rate": 0.00016156862745098037,
      "loss": 0.0676,
      "step": 11180
    },
    {
      "epoch": 36.60130718954248,
      "grad_norm": 0.011304018087685108,
      "learning_rate": 0.00016078431372549016,
      "loss": 0.0392,
      "step": 11200
    },
    {
      "epoch": 36.666666666666664,
      "grad_norm": 0.3884975016117096,
      "learning_rate": 0.00015999999999999999,
      "loss": 0.0925,
      "step": 11220
    },
    {
      "epoch": 36.73202614379085,
      "grad_norm": 0.2817727029323578,
      "learning_rate": 0.00015921568627450978,
      "loss": 0.0854,
      "step": 11240
    },
    {
      "epoch": 36.79738562091503,
      "grad_norm": 0.027938706800341606,
      "learning_rate": 0.0001584313725490196,
      "loss": 0.0157,
      "step": 11260
    },
    {
      "epoch": 36.86274509803921,
      "grad_norm": 1.2718970775604248,
      "learning_rate": 0.0001576470588235294,
      "loss": 0.0616,
      "step": 11280
    },
    {
      "epoch": 36.928104575163395,
      "grad_norm": 12.730072021484375,
      "learning_rate": 0.00015686274509803922,
      "loss": 0.0826,
      "step": 11300
    },
    {
      "epoch": 36.99346405228758,
      "grad_norm": 5.087636470794678,
      "learning_rate": 0.00015607843137254901,
      "loss": 0.0689,
      "step": 11320
    },
    {
      "epoch": 37.0,
      "eval_accuracy": 0.8725490196078431,
      "eval_combined_score": 0.8909783425565347,
      "eval_f1": 0.9094076655052264,
      "eval_loss": 0.742295503616333,
      "eval_runtime": 11.9521,
      "eval_samples_per_second": 34.136,
      "eval_steps_per_second": 4.267,
      "step": 11322
    },
    {
      "epoch": 37.05882352941177,
      "grad_norm": 0.014086202718317509,
      "learning_rate": 0.00015529411764705884,
      "loss": 0.0169,
      "step": 11340
    },
    {
      "epoch": 37.12418300653595,
      "grad_norm": 0.002843962050974369,
      "learning_rate": 0.0001545098039215686,
      "loss": 0.0115,
      "step": 11360
    },
    {
      "epoch": 37.189542483660134,
      "grad_norm": 0.003363637486472726,
      "learning_rate": 0.0001537254901960784,
      "loss": 0.0104,
      "step": 11380
    },
    {
      "epoch": 37.254901960784316,
      "grad_norm": 33.64669418334961,
      "learning_rate": 0.00015294117647058822,
      "loss": 0.0723,
      "step": 11400
    },
    {
      "epoch": 37.3202614379085,
      "grad_norm": 0.014711327850818634,
      "learning_rate": 0.00015215686274509802,
      "loss": 0.0617,
      "step": 11420
    },
    {
      "epoch": 37.38562091503268,
      "grad_norm": 17.891517639160156,
      "learning_rate": 0.0001513725490196078,
      "loss": 0.1076,
      "step": 11440
    },
    {
      "epoch": 37.450980392156865,
      "grad_norm": 0.01619555801153183,
      "learning_rate": 0.00015058823529411763,
      "loss": 0.0419,
      "step": 11460
    },
    {
      "epoch": 37.51633986928105,
      "grad_norm": 0.007837088778614998,
      "learning_rate": 0.00014980392156862743,
      "loss": 0.0641,
      "step": 11480
    },
    {
      "epoch": 37.58169934640523,
      "grad_norm": 0.03337310254573822,
      "learning_rate": 0.00014901960784313725,
      "loss": 0.0047,
      "step": 11500
    },
    {
      "epoch": 37.64705882352941,
      "grad_norm": 0.1106182411313057,
      "learning_rate": 0.00014823529411764705,
      "loss": 0.069,
      "step": 11520
    },
    {
      "epoch": 37.712418300653596,
      "grad_norm": 0.05945856496691704,
      "learning_rate": 0.00014745098039215684,
      "loss": 0.0499,
      "step": 11540
    },
    {
      "epoch": 37.77777777777778,
      "grad_norm": 0.004021621774882078,
      "learning_rate": 0.00014666666666666664,
      "loss": 0.018,
      "step": 11560
    },
    {
      "epoch": 37.84313725490196,
      "grad_norm": 0.001344032003544271,
      "learning_rate": 0.00014588235294117646,
      "loss": 0.0295,
      "step": 11580
    },
    {
      "epoch": 37.908496732026144,
      "grad_norm": 0.025977732613682747,
      "learning_rate": 0.00014509803921568625,
      "loss": 0.0333,
      "step": 11600
    },
    {
      "epoch": 37.97385620915033,
      "grad_norm": 12.961490631103516,
      "learning_rate": 0.00014431372549019607,
      "loss": 0.0348,
      "step": 11620
    },
    {
      "epoch": 38.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.897342284739983,
      "eval_f1": 0.9147826086956522,
      "eval_loss": 0.8737739324569702,
      "eval_runtime": 11.9527,
      "eval_samples_per_second": 34.135,
      "eval_steps_per_second": 4.267,
      "step": 11628
    },
    {
      "epoch": 38.03921568627451,
      "grad_norm": 0.009790090844035149,
      "learning_rate": 0.00014352941176470587,
      "loss": 0.0969,
      "step": 11640
    },
    {
      "epoch": 38.10457516339869,
      "grad_norm": 0.006135791074484587,
      "learning_rate": 0.00014274509803921566,
      "loss": 0.0455,
      "step": 11660
    },
    {
      "epoch": 38.169934640522875,
      "grad_norm": 0.01271616667509079,
      "learning_rate": 0.00014196078431372546,
      "loss": 0.0314,
      "step": 11680
    },
    {
      "epoch": 38.23529411764706,
      "grad_norm": 0.00819647591561079,
      "learning_rate": 0.00014117647058823528,
      "loss": 0.1092,
      "step": 11700
    },
    {
      "epoch": 38.30065359477124,
      "grad_norm": 1.0244601964950562,
      "learning_rate": 0.00014039215686274508,
      "loss": 0.0337,
      "step": 11720
    },
    {
      "epoch": 38.36601307189542,
      "grad_norm": 0.022920556366443634,
      "learning_rate": 0.0001396078431372549,
      "loss": 0.0421,
      "step": 11740
    },
    {
      "epoch": 38.431372549019606,
      "grad_norm": 0.0221243966370821,
      "learning_rate": 0.0001388235294117647,
      "loss": 0.0535,
      "step": 11760
    },
    {
      "epoch": 38.49673202614379,
      "grad_norm": 8.234420776367188,
      "learning_rate": 0.0001380392156862745,
      "loss": 0.0431,
      "step": 11780
    },
    {
      "epoch": 38.56209150326797,
      "grad_norm": 0.0010578096844255924,
      "learning_rate": 0.00013725490196078428,
      "loss": 0.0544,
      "step": 11800
    },
    {
      "epoch": 38.627450980392155,
      "grad_norm": 0.01305039506405592,
      "learning_rate": 0.0001364705882352941,
      "loss": 0.046,
      "step": 11820
    },
    {
      "epoch": 38.69281045751634,
      "grad_norm": 12.639961242675781,
      "learning_rate": 0.0001356862745098039,
      "loss": 0.092,
      "step": 11840
    },
    {
      "epoch": 38.75816993464052,
      "grad_norm": 0.01703931763768196,
      "learning_rate": 0.00013490196078431372,
      "loss": 0.0984,
      "step": 11860
    },
    {
      "epoch": 38.8235294117647,
      "grad_norm": 0.02560766413807869,
      "learning_rate": 0.00013411764705882352,
      "loss": 0.0041,
      "step": 11880
    },
    {
      "epoch": 38.888888888888886,
      "grad_norm": 21.455780029296875,
      "learning_rate": 0.0001333333333333333,
      "loss": 0.104,
      "step": 11900
    },
    {
      "epoch": 38.95424836601307,
      "grad_norm": 16.439916610717773,
      "learning_rate": 0.0001325490196078431,
      "loss": 0.0593,
      "step": 11920
    },
    {
      "epoch": 39.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8954728950403692,
      "eval_f1": 0.9134948096885814,
      "eval_loss": 0.8192163109779358,
      "eval_runtime": 11.9678,
      "eval_samples_per_second": 34.092,
      "eval_steps_per_second": 4.261,
      "step": 11934
    },
    {
      "epoch": 39.01960784313726,
      "grad_norm": 1.2939985990524292,
      "learning_rate": 0.00013176470588235293,
      "loss": 0.0231,
      "step": 11940
    },
    {
      "epoch": 39.08496732026144,
      "grad_norm": 0.007247337605804205,
      "learning_rate": 0.00013098039215686272,
      "loss": 0.0398,
      "step": 11960
    },
    {
      "epoch": 39.150326797385624,
      "grad_norm": 0.24816234409809113,
      "learning_rate": 0.00013019607843137255,
      "loss": 0.0136,
      "step": 11980
    },
    {
      "epoch": 39.21568627450981,
      "grad_norm": 0.005901755765080452,
      "learning_rate": 0.00012941176470588234,
      "loss": 0.0481,
      "step": 12000
    },
    {
      "epoch": 39.28104575163399,
      "grad_norm": 0.14439719915390015,
      "learning_rate": 0.00012862745098039214,
      "loss": 0.0571,
      "step": 12020
    },
    {
      "epoch": 39.34640522875817,
      "grad_norm": 0.007117862813174725,
      "learning_rate": 0.00012784313725490193,
      "loss": 0.1352,
      "step": 12040
    },
    {
      "epoch": 39.411764705882355,
      "grad_norm": 0.9280982613563538,
      "learning_rate": 0.00012705882352941175,
      "loss": 0.0308,
      "step": 12060
    },
    {
      "epoch": 39.47712418300654,
      "grad_norm": 0.001995271537452936,
      "learning_rate": 0.00012627450980392155,
      "loss": 0.0142,
      "step": 12080
    },
    {
      "epoch": 39.54248366013072,
      "grad_norm": 0.002764597302302718,
      "learning_rate": 0.00012549019607843137,
      "loss": 0.0782,
      "step": 12100
    },
    {
      "epoch": 39.6078431372549,
      "grad_norm": 0.37719088792800903,
      "learning_rate": 0.00012470588235294117,
      "loss": 0.0484,
      "step": 12120
    },
    {
      "epoch": 39.673202614379086,
      "grad_norm": 5.005431175231934,
      "learning_rate": 0.00012392156862745096,
      "loss": 0.0555,
      "step": 12140
    },
    {
      "epoch": 39.73856209150327,
      "grad_norm": 0.37180736660957336,
      "learning_rate": 0.00012313725490196078,
      "loss": 0.0335,
      "step": 12160
    },
    {
      "epoch": 39.80392156862745,
      "grad_norm": 0.001648223609663546,
      "learning_rate": 0.00012235294117647058,
      "loss": 0.0334,
      "step": 12180
    },
    {
      "epoch": 39.869281045751634,
      "grad_norm": 0.61408931016922,
      "learning_rate": 0.00012156862745098039,
      "loss": 0.0732,
      "step": 12200
    },
    {
      "epoch": 39.93464052287582,
      "grad_norm": 0.8473007678985596,
      "learning_rate": 0.0001207843137254902,
      "loss": 0.0519,
      "step": 12220
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.003953597508370876,
      "learning_rate": 0.00011999999999999999,
      "loss": 0.0402,
      "step": 12240
    },
    {
      "epoch": 40.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8987736437331115,
      "eval_f1": 0.9151943462897526,
      "eval_loss": 0.8504908084869385,
      "eval_runtime": 11.9571,
      "eval_samples_per_second": 34.122,
      "eval_steps_per_second": 4.265,
      "step": 12240
    },
    {
      "epoch": 40.06535947712418,
      "grad_norm": 0.018779119476675987,
      "learning_rate": 0.00011921568627450978,
      "loss": 0.0169,
      "step": 12260
    },
    {
      "epoch": 40.130718954248366,
      "grad_norm": 0.013212972320616245,
      "learning_rate": 0.00011843137254901959,
      "loss": 0.0522,
      "step": 12280
    },
    {
      "epoch": 40.19607843137255,
      "grad_norm": 20.727985382080078,
      "learning_rate": 0.0001176470588235294,
      "loss": 0.0715,
      "step": 12300
    },
    {
      "epoch": 40.26143790849673,
      "grad_norm": 42.757179260253906,
      "learning_rate": 0.00011686274509803921,
      "loss": 0.0729,
      "step": 12320
    },
    {
      "epoch": 40.326797385620914,
      "grad_norm": 0.01119854487478733,
      "learning_rate": 0.00011607843137254902,
      "loss": 0.0528,
      "step": 12340
    },
    {
      "epoch": 40.3921568627451,
      "grad_norm": 0.0014326596865430474,
      "learning_rate": 0.00011529411764705881,
      "loss": 0.0881,
      "step": 12360
    },
    {
      "epoch": 40.45751633986928,
      "grad_norm": 0.00011559866106836125,
      "learning_rate": 0.00011450980392156861,
      "loss": 0.0588,
      "step": 12380
    },
    {
      "epoch": 40.52287581699346,
      "grad_norm": 0.0009466828196309507,
      "learning_rate": 0.00011372549019607842,
      "loss": 0.1433,
      "step": 12400
    },
    {
      "epoch": 40.588235294117645,
      "grad_norm": 0.0008254120475612581,
      "learning_rate": 0.00011294117647058823,
      "loss": 0.0551,
      "step": 12420
    },
    {
      "epoch": 40.65359477124183,
      "grad_norm": 0.00011254847049713135,
      "learning_rate": 0.00011215686274509803,
      "loss": 0.0518,
      "step": 12440
    },
    {
      "epoch": 40.71895424836601,
      "grad_norm": 0.008341015316545963,
      "learning_rate": 0.00011137254901960784,
      "loss": 0.027,
      "step": 12460
    },
    {
      "epoch": 40.78431372549019,
      "grad_norm": 0.004425765946507454,
      "learning_rate": 0.00011058823529411765,
      "loss": 0.1206,
      "step": 12480
    },
    {
      "epoch": 40.849673202614376,
      "grad_norm": 0.0074539887718856335,
      "learning_rate": 0.00010980392156862743,
      "loss": 0.1123,
      "step": 12500
    },
    {
      "epoch": 40.91503267973856,
      "grad_norm": 24.540773391723633,
      "learning_rate": 0.00010901960784313724,
      "loss": 0.0278,
      "step": 12520
    },
    {
      "epoch": 40.98039215686274,
      "grad_norm": 0.09948567301034927,
      "learning_rate": 0.00010823529411764705,
      "loss": 0.0184,
      "step": 12540
    },
    {
      "epoch": 41.0,
      "eval_accuracy": 0.8921568627450981,
      "eval_combined_score": 0.9078839869281046,
      "eval_f1": 0.9236111111111112,
      "eval_loss": 0.8671751022338867,
      "eval_runtime": 11.9583,
      "eval_samples_per_second": 34.119,
      "eval_steps_per_second": 4.265,
      "step": 12546
    },
    {
      "epoch": 41.04575163398693,
      "grad_norm": 0.019378013908863068,
      "learning_rate": 0.00010745098039215686,
      "loss": 0.1064,
      "step": 12560
    },
    {
      "epoch": 41.111111111111114,
      "grad_norm": 0.002428667852655053,
      "learning_rate": 0.00010666666666666667,
      "loss": 0.0483,
      "step": 12580
    },
    {
      "epoch": 41.1764705882353,
      "grad_norm": 9.72632122039795,
      "learning_rate": 0.00010588235294117647,
      "loss": 0.0623,
      "step": 12600
    },
    {
      "epoch": 41.24183006535948,
      "grad_norm": 9.074976921081543,
      "learning_rate": 0.00010509803921568626,
      "loss": 0.1066,
      "step": 12620
    },
    {
      "epoch": 41.30718954248366,
      "grad_norm": 2.420901298522949,
      "learning_rate": 0.00010431372549019606,
      "loss": 0.0201,
      "step": 12640
    },
    {
      "epoch": 41.372549019607845,
      "grad_norm": 0.02012590691447258,
      "learning_rate": 0.00010352941176470587,
      "loss": 0.1507,
      "step": 12660
    },
    {
      "epoch": 41.43790849673203,
      "grad_norm": 0.5169700384140015,
      "learning_rate": 0.00010274509803921568,
      "loss": 0.0563,
      "step": 12680
    },
    {
      "epoch": 41.50326797385621,
      "grad_norm": 0.005548669490963221,
      "learning_rate": 0.00010196078431372549,
      "loss": 0.0664,
      "step": 12700
    },
    {
      "epoch": 41.568627450980394,
      "grad_norm": 8.393292427062988,
      "learning_rate": 0.0001011764705882353,
      "loss": 0.0563,
      "step": 12720
    },
    {
      "epoch": 41.63398692810458,
      "grad_norm": 0.12657877802848816,
      "learning_rate": 0.00010039215686274508,
      "loss": 0.0534,
      "step": 12740
    },
    {
      "epoch": 41.69934640522876,
      "grad_norm": 0.010376553982496262,
      "learning_rate": 9.960784313725489e-05,
      "loss": 0.0162,
      "step": 12760
    },
    {
      "epoch": 41.76470588235294,
      "grad_norm": 0.004798365291208029,
      "learning_rate": 9.88235294117647e-05,
      "loss": 0.0407,
      "step": 12780
    },
    {
      "epoch": 41.830065359477125,
      "grad_norm": 0.0032928131986409426,
      "learning_rate": 9.80392156862745e-05,
      "loss": 0.0101,
      "step": 12800
    },
    {
      "epoch": 41.89542483660131,
      "grad_norm": 20.199827194213867,
      "learning_rate": 9.725490196078431e-05,
      "loss": 0.0989,
      "step": 12820
    },
    {
      "epoch": 41.96078431372549,
      "grad_norm": 0.001698854612186551,
      "learning_rate": 9.647058823529412e-05,
      "loss": 0.1238,
      "step": 12840
    },
    {
      "epoch": 42.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9051704014939308,
      "eval_f1": 0.9206349206349206,
      "eval_loss": 0.7697716355323792,
      "eval_runtime": 11.9622,
      "eval_samples_per_second": 34.107,
      "eval_steps_per_second": 4.263,
      "step": 12852
    },
    {
      "epoch": 42.02614379084967,
      "grad_norm": 13.223979949951172,
      "learning_rate": 9.56862745098039e-05,
      "loss": 0.0727,
      "step": 12860
    },
    {
      "epoch": 42.091503267973856,
      "grad_norm": 0.14974245429039001,
      "learning_rate": 9.490196078431371e-05,
      "loss": 0.0411,
      "step": 12880
    },
    {
      "epoch": 42.15686274509804,
      "grad_norm": 0.012569806538522243,
      "learning_rate": 9.411764705882352e-05,
      "loss": 0.0662,
      "step": 12900
    },
    {
      "epoch": 42.22222222222222,
      "grad_norm": 0.008457187563180923,
      "learning_rate": 9.333333333333333e-05,
      "loss": 0.0589,
      "step": 12920
    },
    {
      "epoch": 42.287581699346404,
      "grad_norm": 0.05031042918562889,
      "learning_rate": 9.254901960784314e-05,
      "loss": 0.0253,
      "step": 12940
    },
    {
      "epoch": 42.35294117647059,
      "grad_norm": 1.1227010488510132,
      "learning_rate": 9.176470588235295e-05,
      "loss": 0.0759,
      "step": 12960
    },
    {
      "epoch": 42.41830065359477,
      "grad_norm": 10.623421669006348,
      "learning_rate": 9.098039215686273e-05,
      "loss": 0.0819,
      "step": 12980
    },
    {
      "epoch": 42.48366013071895,
      "grad_norm": 0.006372513249516487,
      "learning_rate": 9.019607843137254e-05,
      "loss": 0.0132,
      "step": 13000
    },
    {
      "epoch": 42.549019607843135,
      "grad_norm": 28.541112899780273,
      "learning_rate": 8.941176470588235e-05,
      "loss": 0.0231,
      "step": 13020
    },
    {
      "epoch": 42.61437908496732,
      "grad_norm": 7.940781116485596,
      "learning_rate": 8.862745098039215e-05,
      "loss": 0.0583,
      "step": 13040
    },
    {
      "epoch": 42.6797385620915,
      "grad_norm": 0.010630197823047638,
      "learning_rate": 8.784313725490196e-05,
      "loss": 0.08,
      "step": 13060
    },
    {
      "epoch": 42.745098039215684,
      "grad_norm": 13.31913948059082,
      "learning_rate": 8.705882352941177e-05,
      "loss": 0.0434,
      "step": 13080
    },
    {
      "epoch": 42.810457516339866,
      "grad_norm": 0.19489862024784088,
      "learning_rate": 8.627450980392155e-05,
      "loss": 0.1026,
      "step": 13100
    },
    {
      "epoch": 42.87581699346405,
      "grad_norm": 0.0022482567001134157,
      "learning_rate": 8.549019607843136e-05,
      "loss": 0.0231,
      "step": 13120
    },
    {
      "epoch": 42.94117647058823,
      "grad_norm": 0.0012697980273514986,
      "learning_rate": 8.470588235294117e-05,
      "loss": 0.0537,
      "step": 13140
    },
    {
      "epoch": 43.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9009557526714389,
      "eval_f1": 0.9171075837742505,
      "eval_loss": 0.7996037602424622,
      "eval_runtime": 11.952,
      "eval_samples_per_second": 34.137,
      "eval_steps_per_second": 4.267,
      "step": 13158
    },
    {
      "epoch": 43.00653594771242,
      "grad_norm": 0.9499553442001343,
      "learning_rate": 8.392156862745098e-05,
      "loss": 0.027,
      "step": 13160
    },
    {
      "epoch": 43.071895424836605,
      "grad_norm": 28.7779541015625,
      "learning_rate": 8.313725490196079e-05,
      "loss": 0.0615,
      "step": 13180
    },
    {
      "epoch": 43.13725490196079,
      "grad_norm": 1.2652802467346191,
      "learning_rate": 8.23529411764706e-05,
      "loss": 0.0345,
      "step": 13200
    },
    {
      "epoch": 43.20261437908497,
      "grad_norm": 11.883901596069336,
      "learning_rate": 8.156862745098038e-05,
      "loss": 0.0721,
      "step": 13220
    },
    {
      "epoch": 43.26797385620915,
      "grad_norm": 0.017437994480133057,
      "learning_rate": 8.078431372549018e-05,
      "loss": 0.0203,
      "step": 13240
    },
    {
      "epoch": 43.333333333333336,
      "grad_norm": 0.001157812075689435,
      "learning_rate": 7.999999999999999e-05,
      "loss": 0.0501,
      "step": 13260
    },
    {
      "epoch": 43.39869281045752,
      "grad_norm": 0.09854873269796371,
      "learning_rate": 7.92156862745098e-05,
      "loss": 0.045,
      "step": 13280
    },
    {
      "epoch": 43.4640522875817,
      "grad_norm": 0.39756155014038086,
      "learning_rate": 7.843137254901961e-05,
      "loss": 0.058,
      "step": 13300
    },
    {
      "epoch": 43.529411764705884,
      "grad_norm": 0.13072538375854492,
      "learning_rate": 7.764705882352942e-05,
      "loss": 0.1496,
      "step": 13320
    },
    {
      "epoch": 43.59477124183007,
      "grad_norm": 2.4422411918640137,
      "learning_rate": 7.68627450980392e-05,
      "loss": 0.0356,
      "step": 13340
    },
    {
      "epoch": 43.66013071895425,
      "grad_norm": 0.014378521591424942,
      "learning_rate": 7.607843137254901e-05,
      "loss": 0.0434,
      "step": 13360
    },
    {
      "epoch": 43.72549019607843,
      "grad_norm": 0.0011479355162009597,
      "learning_rate": 7.529411764705882e-05,
      "loss": 0.0057,
      "step": 13380
    },
    {
      "epoch": 43.790849673202615,
      "grad_norm": 0.005248935893177986,
      "learning_rate": 7.450980392156863e-05,
      "loss": 0.05,
      "step": 13400
    },
    {
      "epoch": 43.8562091503268,
      "grad_norm": 0.00722928624600172,
      "learning_rate": 7.372549019607842e-05,
      "loss": 0.034,
      "step": 13420
    },
    {
      "epoch": 43.92156862745098,
      "grad_norm": 14.02191162109375,
      "learning_rate": 7.294117647058823e-05,
      "loss": 0.0936,
      "step": 13440
    },
    {
      "epoch": 43.98692810457516,
      "grad_norm": 0.0020134435035288334,
      "learning_rate": 7.215686274509804e-05,
      "loss": 0.0361,
      "step": 13460
    },
    {
      "epoch": 44.0,
      "eval_accuracy": 0.8897058823529411,
      "eval_combined_score": 0.9050299323269131,
      "eval_f1": 0.9203539823008849,
      "eval_loss": 0.7677664756774902,
      "eval_runtime": 11.9515,
      "eval_samples_per_second": 34.138,
      "eval_steps_per_second": 4.267,
      "step": 13464
    },
    {
      "epoch": 44.052287581699346,
      "grad_norm": 11.06198501586914,
      "learning_rate": 7.137254901960783e-05,
      "loss": 0.0744,
      "step": 13480
    },
    {
      "epoch": 44.11764705882353,
      "grad_norm": 0.0028843299951404333,
      "learning_rate": 7.058823529411764e-05,
      "loss": 0.0145,
      "step": 13500
    },
    {
      "epoch": 44.18300653594771,
      "grad_norm": 0.02684146910905838,
      "learning_rate": 6.980392156862745e-05,
      "loss": 0.0495,
      "step": 13520
    },
    {
      "epoch": 44.248366013071895,
      "grad_norm": 15.614134788513184,
      "learning_rate": 6.901960784313724e-05,
      "loss": 0.0725,
      "step": 13540
    },
    {
      "epoch": 44.31372549019608,
      "grad_norm": 0.033160265535116196,
      "learning_rate": 6.823529411764705e-05,
      "loss": 0.043,
      "step": 13560
    },
    {
      "epoch": 44.37908496732026,
      "grad_norm": 0.013779956847429276,
      "learning_rate": 6.745098039215686e-05,
      "loss": 0.064,
      "step": 13580
    },
    {
      "epoch": 44.44444444444444,
      "grad_norm": 0.07655248790979385,
      "learning_rate": 6.666666666666666e-05,
      "loss": 0.0225,
      "step": 13600
    },
    {
      "epoch": 44.509803921568626,
      "grad_norm": 0.3936629593372345,
      "learning_rate": 6.588235294117646e-05,
      "loss": 0.039,
      "step": 13620
    },
    {
      "epoch": 44.57516339869281,
      "grad_norm": 0.015359530225396156,
      "learning_rate": 6.509803921568627e-05,
      "loss": 0.0483,
      "step": 13640
    },
    {
      "epoch": 44.64052287581699,
      "grad_norm": 0.0880126878619194,
      "learning_rate": 6.431372549019607e-05,
      "loss": 0.0082,
      "step": 13660
    },
    {
      "epoch": 44.705882352941174,
      "grad_norm": 0.0008487066370435059,
      "learning_rate": 6.352941176470588e-05,
      "loss": 0.0297,
      "step": 13680
    },
    {
      "epoch": 44.77124183006536,
      "grad_norm": 0.001453931676223874,
      "learning_rate": 6.274509803921569e-05,
      "loss": 0.0312,
      "step": 13700
    },
    {
      "epoch": 44.83660130718954,
      "grad_norm": 0.0007796298596076667,
      "learning_rate": 6.196078431372548e-05,
      "loss": 0.0584,
      "step": 13720
    },
    {
      "epoch": 44.90196078431372,
      "grad_norm": 0.10422520339488983,
      "learning_rate": 6.117647058823529e-05,
      "loss": 0.0439,
      "step": 13740
    },
    {
      "epoch": 44.967320261437905,
      "grad_norm": 0.00038431238499470055,
      "learning_rate": 6.03921568627451e-05,
      "loss": 0.0182,
      "step": 13760
    },
    {
      "epoch": 45.0,
      "eval_accuracy": 0.8848039215686274,
      "eval_combined_score": 0.9005124777183601,
      "eval_f1": 0.9162210338680927,
      "eval_loss": 0.8066762089729309,
      "eval_runtime": 11.9748,
      "eval_samples_per_second": 34.072,
      "eval_steps_per_second": 4.259,
      "step": 13770
    },
    {
      "epoch": 45.032679738562095,
      "grad_norm": 0.8508086800575256,
      "learning_rate": 5.960784313725489e-05,
      "loss": 0.0021,
      "step": 13780
    },
    {
      "epoch": 45.09803921568628,
      "grad_norm": 16.163930892944336,
      "learning_rate": 5.88235294117647e-05,
      "loss": 0.0664,
      "step": 13800
    },
    {
      "epoch": 45.16339869281046,
      "grad_norm": 0.2731395959854126,
      "learning_rate": 5.803921568627451e-05,
      "loss": 0.0263,
      "step": 13820
    },
    {
      "epoch": 45.22875816993464,
      "grad_norm": 0.001286427373997867,
      "learning_rate": 5.7254901960784304e-05,
      "loss": 0.0315,
      "step": 13840
    },
    {
      "epoch": 45.294117647058826,
      "grad_norm": 0.06896906346082687,
      "learning_rate": 5.647058823529411e-05,
      "loss": 0.0314,
      "step": 13860
    },
    {
      "epoch": 45.35947712418301,
      "grad_norm": 0.018643371760845184,
      "learning_rate": 5.568627450980392e-05,
      "loss": 0.0536,
      "step": 13880
    },
    {
      "epoch": 45.42483660130719,
      "grad_norm": 0.0025906164664775133,
      "learning_rate": 5.4901960784313716e-05,
      "loss": 0.0019,
      "step": 13900
    },
    {
      "epoch": 45.490196078431374,
      "grad_norm": 0.0010077898623421788,
      "learning_rate": 5.4117647058823525e-05,
      "loss": 0.0042,
      "step": 13920
    },
    {
      "epoch": 45.55555555555556,
      "grad_norm": 0.00539019238203764,
      "learning_rate": 5.333333333333333e-05,
      "loss": 0.066,
      "step": 13940
    },
    {
      "epoch": 45.62091503267974,
      "grad_norm": 0.006323817186057568,
      "learning_rate": 5.254901960784313e-05,
      "loss": 0.0584,
      "step": 13960
    },
    {
      "epoch": 45.68627450980392,
      "grad_norm": 0.00173494266346097,
      "learning_rate": 5.176470588235294e-05,
      "loss": 0.0978,
      "step": 13980
    },
    {
      "epoch": 45.751633986928105,
      "grad_norm": 0.19262737035751343,
      "learning_rate": 5.0980392156862745e-05,
      "loss": 0.0721,
      "step": 14000
    },
    {
      "epoch": 45.81699346405229,
      "grad_norm": 14.195771217346191,
      "learning_rate": 5.019607843137254e-05,
      "loss": 0.0531,
      "step": 14020
    },
    {
      "epoch": 45.88235294117647,
      "grad_norm": 0.003421203000470996,
      "learning_rate": 4.941176470588235e-05,
      "loss": 0.069,
      "step": 14040
    },
    {
      "epoch": 45.947712418300654,
      "grad_norm": 0.00712626101449132,
      "learning_rate": 4.862745098039216e-05,
      "loss": 0.0765,
      "step": 14060
    },
    {
      "epoch": 46.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.8965881485337497,
      "eval_f1": 0.9132743362831858,
      "eval_loss": 0.8166525363922119,
      "eval_runtime": 11.9729,
      "eval_samples_per_second": 34.077,
      "eval_steps_per_second": 4.26,
      "step": 14076
    },
    {
      "epoch": 46.01307189542484,
      "grad_norm": 6.900408744812012,
      "learning_rate": 4.784313725490195e-05,
      "loss": 0.0519,
      "step": 14080
    },
    {
      "epoch": 46.07843137254902,
      "grad_norm": 0.026165109127759933,
      "learning_rate": 4.705882352941176e-05,
      "loss": 0.0559,
      "step": 14100
    },
    {
      "epoch": 46.1437908496732,
      "grad_norm": 0.29829996824264526,
      "learning_rate": 4.627450980392157e-05,
      "loss": 0.0056,
      "step": 14120
    },
    {
      "epoch": 46.209150326797385,
      "grad_norm": 0.03600732982158661,
      "learning_rate": 4.5490196078431364e-05,
      "loss": 0.0843,
      "step": 14140
    },
    {
      "epoch": 46.27450980392157,
      "grad_norm": 0.07216735184192657,
      "learning_rate": 4.470588235294117e-05,
      "loss": 0.0442,
      "step": 14160
    },
    {
      "epoch": 46.33986928104575,
      "grad_norm": 0.02473633922636509,
      "learning_rate": 4.392156862745098e-05,
      "loss": 0.0574,
      "step": 14180
    },
    {
      "epoch": 46.40522875816993,
      "grad_norm": 0.2810506224632263,
      "learning_rate": 4.3137254901960776e-05,
      "loss": 0.0112,
      "step": 14200
    },
    {
      "epoch": 46.470588235294116,
      "grad_norm": 0.0325956754386425,
      "learning_rate": 4.2352941176470585e-05,
      "loss": 0.0239,
      "step": 14220
    },
    {
      "epoch": 46.5359477124183,
      "grad_norm": 0.5234469771385193,
      "learning_rate": 4.156862745098039e-05,
      "loss": 0.0392,
      "step": 14240
    },
    {
      "epoch": 46.60130718954248,
      "grad_norm": 0.002006568480283022,
      "learning_rate": 4.078431372549019e-05,
      "loss": 0.035,
      "step": 14260
    },
    {
      "epoch": 46.666666666666664,
      "grad_norm": 1.2386394739151,
      "learning_rate": 3.9999999999999996e-05,
      "loss": 0.0776,
      "step": 14280
    },
    {
      "epoch": 46.73202614379085,
      "grad_norm": 0.0009810096817091107,
      "learning_rate": 3.9215686274509805e-05,
      "loss": 0.0052,
      "step": 14300
    },
    {
      "epoch": 46.79738562091503,
      "grad_norm": 0.006588195916265249,
      "learning_rate": 3.84313725490196e-05,
      "loss": 0.0042,
      "step": 14320
    },
    {
      "epoch": 46.86274509803921,
      "grad_norm": 0.009583204053342342,
      "learning_rate": 3.764705882352941e-05,
      "loss": 0.0473,
      "step": 14340
    },
    {
      "epoch": 46.928104575163395,
      "grad_norm": 1.9980920553207397,
      "learning_rate": 3.686274509803921e-05,
      "loss": 0.0183,
      "step": 14360
    },
    {
      "epoch": 46.99346405228758,
      "grad_norm": 0.6025753617286682,
      "learning_rate": 3.607843137254902e-05,
      "loss": 0.0341,
      "step": 14380
    },
    {
      "epoch": 47.0,
      "eval_accuracy": 0.8725490196078431,
      "eval_combined_score": 0.8904998619165976,
      "eval_f1": 0.9084507042253521,
      "eval_loss": 0.8467381000518799,
      "eval_runtime": 11.9572,
      "eval_samples_per_second": 34.122,
      "eval_steps_per_second": 4.265,
      "step": 14382
    },
    {
      "epoch": 47.05882352941177,
      "grad_norm": 0.05553147941827774,
      "learning_rate": 3.529411764705882e-05,
      "loss": 0.0238,
      "step": 14400
    },
    {
      "epoch": 47.12418300653595,
      "grad_norm": 0.001462025917135179,
      "learning_rate": 3.450980392156862e-05,
      "loss": 0.0173,
      "step": 14420
    },
    {
      "epoch": 47.189542483660134,
      "grad_norm": 0.020017145201563835,
      "learning_rate": 3.372549019607843e-05,
      "loss": 0.0206,
      "step": 14440
    },
    {
      "epoch": 47.254901960784316,
      "grad_norm": 11.629006385803223,
      "learning_rate": 3.294117647058823e-05,
      "loss": 0.0305,
      "step": 14460
    },
    {
      "epoch": 47.3202614379085,
      "grad_norm": 0.009164671413600445,
      "learning_rate": 3.2156862745098034e-05,
      "loss": 0.0688,
      "step": 14480
    },
    {
      "epoch": 47.38562091503268,
      "grad_norm": 0.0073707615956664085,
      "learning_rate": 3.137254901960784e-05,
      "loss": 0.0214,
      "step": 14500
    },
    {
      "epoch": 47.450980392156865,
      "grad_norm": 0.030496099963784218,
      "learning_rate": 3.0588235294117644e-05,
      "loss": 0.0142,
      "step": 14520
    },
    {
      "epoch": 47.51633986928105,
      "grad_norm": 0.03257589787244797,
      "learning_rate": 2.9803921568627446e-05,
      "loss": 0.0124,
      "step": 14540
    },
    {
      "epoch": 47.58169934640523,
      "grad_norm": 0.21603398025035858,
      "learning_rate": 2.9019607843137255e-05,
      "loss": 0.0171,
      "step": 14560
    },
    {
      "epoch": 47.64705882352941,
      "grad_norm": 0.317466676235199,
      "learning_rate": 2.8235294117647056e-05,
      "loss": 0.0237,
      "step": 14580
    },
    {
      "epoch": 47.712418300653596,
      "grad_norm": 0.017358846962451935,
      "learning_rate": 2.7450980392156858e-05,
      "loss": 0.0014,
      "step": 14600
    },
    {
      "epoch": 47.77777777777778,
      "grad_norm": 0.26074808835983276,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.0297,
      "step": 14620
    },
    {
      "epoch": 47.84313725490196,
      "grad_norm": 0.0018984710332006216,
      "learning_rate": 2.588235294117647e-05,
      "loss": 0.0493,
      "step": 14640
    },
    {
      "epoch": 47.908496732026144,
      "grad_norm": 0.0714212954044342,
      "learning_rate": 2.509803921568627e-05,
      "loss": 0.0584,
      "step": 14660
    },
    {
      "epoch": 47.97385620915033,
      "grad_norm": 0.005983748938888311,
      "learning_rate": 2.431372549019608e-05,
      "loss": 0.0126,
      "step": 14680
    },
    {
      "epoch": 48.0,
      "eval_accuracy": 0.8799019607843137,
      "eval_combined_score": 0.896741103848947,
      "eval_f1": 0.9135802469135803,
      "eval_loss": 0.8770530819892883,
      "eval_runtime": 11.9608,
      "eval_samples_per_second": 34.111,
      "eval_steps_per_second": 4.264,
      "step": 14688
    },
    {
      "epoch": 48.03921568627451,
      "grad_norm": 0.00210335711017251,
      "learning_rate": 2.352941176470588e-05,
      "loss": 0.0599,
      "step": 14700
    },
    {
      "epoch": 48.10457516339869,
      "grad_norm": 0.371260404586792,
      "learning_rate": 2.2745098039215682e-05,
      "loss": 0.0591,
      "step": 14720
    },
    {
      "epoch": 48.169934640522875,
      "grad_norm": 0.04861721396446228,
      "learning_rate": 2.196078431372549e-05,
      "loss": 0.0037,
      "step": 14740
    },
    {
      "epoch": 48.23529411764706,
      "grad_norm": 0.038894373923540115,
      "learning_rate": 2.1176470588235292e-05,
      "loss": 0.0306,
      "step": 14760
    },
    {
      "epoch": 48.30065359477124,
      "grad_norm": 0.0027313046157360077,
      "learning_rate": 2.0392156862745094e-05,
      "loss": 0.0232,
      "step": 14780
    },
    {
      "epoch": 48.36601307189542,
      "grad_norm": 0.002817396307364106,
      "learning_rate": 1.9607843137254903e-05,
      "loss": 0.1121,
      "step": 14800
    },
    {
      "epoch": 48.431372549019606,
      "grad_norm": 18.415979385375977,
      "learning_rate": 1.8823529411764704e-05,
      "loss": 0.0348,
      "step": 14820
    },
    {
      "epoch": 48.49673202614379,
      "grad_norm": 0.03309300169348717,
      "learning_rate": 1.803921568627451e-05,
      "loss": 0.0149,
      "step": 14840
    },
    {
      "epoch": 48.56209150326797,
      "grad_norm": 0.006555068772286177,
      "learning_rate": 1.725490196078431e-05,
      "loss": 0.0494,
      "step": 14860
    },
    {
      "epoch": 48.627450980392155,
      "grad_norm": 0.6777506470680237,
      "learning_rate": 1.6470588235294116e-05,
      "loss": 0.0538,
      "step": 14880
    },
    {
      "epoch": 48.69281045751634,
      "grad_norm": 0.0010429923422634602,
      "learning_rate": 1.568627450980392e-05,
      "loss": 0.0228,
      "step": 14900
    },
    {
      "epoch": 48.75816993464052,
      "grad_norm": 0.2281913012266159,
      "learning_rate": 1.4901960784313723e-05,
      "loss": 0.0354,
      "step": 14920
    },
    {
      "epoch": 48.8235294117647,
      "grad_norm": 2.0161635875701904,
      "learning_rate": 1.4117647058823528e-05,
      "loss": 0.0367,
      "step": 14940
    },
    {
      "epoch": 48.888888888888886,
      "grad_norm": 0.03645370900630951,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.0226,
      "step": 14960
    },
    {
      "epoch": 48.95424836601307,
      "grad_norm": 0.6237454414367676,
      "learning_rate": 1.2549019607843135e-05,
      "loss": 0.0475,
      "step": 14980
    },
    {
      "epoch": 49.0,
      "eval_accuracy": 0.8774509803921569,
      "eval_combined_score": 0.8943992490613266,
      "eval_f1": 0.9113475177304964,
      "eval_loss": 0.8550097942352295,
      "eval_runtime": 11.9741,
      "eval_samples_per_second": 34.074,
      "eval_steps_per_second": 4.259,
      "step": 14994
    },
    {
      "epoch": 49.01960784313726,
      "grad_norm": 0.001322672818787396,
      "learning_rate": 1.176470588235294e-05,
      "loss": 0.0187,
      "step": 15000
    },
    {
      "epoch": 49.08496732026144,
      "grad_norm": 0.008652898482978344,
      "learning_rate": 1.0980392156862745e-05,
      "loss": 0.0369,
      "step": 15020
    },
    {
      "epoch": 49.150326797385624,
      "grad_norm": 0.9252829551696777,
      "learning_rate": 1.0196078431372547e-05,
      "loss": 0.0486,
      "step": 15040
    },
    {
      "epoch": 49.21568627450981,
      "grad_norm": 0.0003771857591345906,
      "learning_rate": 9.411764705882352e-06,
      "loss": 0.0611,
      "step": 15060
    },
    {
      "epoch": 49.28104575163399,
      "grad_norm": 0.013086730614304543,
      "learning_rate": 8.627450980392156e-06,
      "loss": 0.0381,
      "step": 15080
    },
    {
      "epoch": 49.34640522875817,
      "grad_norm": 0.04143597185611725,
      "learning_rate": 7.84313725490196e-06,
      "loss": 0.0132,
      "step": 15100
    },
    {
      "epoch": 49.411764705882355,
      "grad_norm": 0.00021906523033976555,
      "learning_rate": 7.058823529411764e-06,
      "loss": 0.0856,
      "step": 15120
    },
    {
      "epoch": 49.47712418300654,
      "grad_norm": 0.051862798631191254,
      "learning_rate": 6.2745098039215675e-06,
      "loss": 0.0031,
      "step": 15140
    },
    {
      "epoch": 49.54248366013072,
      "grad_norm": 0.0019265080336481333,
      "learning_rate": 5.490196078431373e-06,
      "loss": 0.0311,
      "step": 15160
    },
    {
      "epoch": 49.6078431372549,
      "grad_norm": 0.0032548580784350634,
      "learning_rate": 4.705882352941176e-06,
      "loss": 0.0658,
      "step": 15180
    },
    {
      "epoch": 49.673202614379086,
      "grad_norm": 0.0024980453308671713,
      "learning_rate": 3.92156862745098e-06,
      "loss": 0.0229,
      "step": 15200
    },
    {
      "epoch": 49.73856209150327,
      "grad_norm": 0.03868748992681503,
      "learning_rate": 3.1372549019607838e-06,
      "loss": 0.0698,
      "step": 15220
    },
    {
      "epoch": 49.80392156862745,
      "grad_norm": 1.2491284608840942,
      "learning_rate": 2.352941176470588e-06,
      "loss": 0.0527,
      "step": 15240
    },
    {
      "epoch": 49.869281045751634,
      "grad_norm": 0.0057687945663928986,
      "learning_rate": 1.5686274509803919e-06,
      "loss": 0.0335,
      "step": 15260
    },
    {
      "epoch": 49.93464052287582,
      "grad_norm": 0.007835968397557735,
      "learning_rate": 7.843137254901959e-07,
      "loss": 0.0084,
      "step": 15280
    },
    {
      "epoch": 50.0,
      "grad_norm": 9.380617141723633,
      "learning_rate": 0.0,
      "loss": 0.041,
      "step": 15300
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.8823529411764706,
      "eval_combined_score": 0.8986232790988735,
      "eval_f1": 0.9148936170212766,
      "eval_loss": 0.8551087975502014,
      "eval_runtime": 11.9658,
      "eval_samples_per_second": 34.097,
      "eval_steps_per_second": 4.262,
      "step": 15300
    },
    {
      "epoch": 50.0,
      "step": 15300,
      "total_flos": 4.36441308592128e+16,
      "train_loss": 0.12932207763706352,
      "train_runtime": 12138.895,
      "train_samples_per_second": 15.108,
      "train_steps_per_second": 1.26
    }
  ],
  "logging_steps": 20,
  "max_steps": 15300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": -15300,
  "total_flos": 4.36441308592128e+16,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
