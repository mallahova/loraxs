{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 70.0,
  "eval_steps": 500,
  "global_step": 23380,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.059880239520958084,
      "grad_norm": 16.618825912475586,
      "learning_rate": 0.0005994867408041061,
      "loss": 0.6835,
      "step": 20
    },
    {
      "epoch": 0.11976047904191617,
      "grad_norm": 10.29835319519043,
      "learning_rate": 0.0005989734816082121,
      "loss": 0.6096,
      "step": 40
    },
    {
      "epoch": 0.17964071856287425,
      "grad_norm": 10.39295768737793,
      "learning_rate": 0.0005984602224123181,
      "loss": 0.6594,
      "step": 60
    },
    {
      "epoch": 0.23952095808383234,
      "grad_norm": 5.938471794128418,
      "learning_rate": 0.0005979469632164243,
      "loss": 0.5796,
      "step": 80
    },
    {
      "epoch": 0.2994011976047904,
      "grad_norm": 39.505645751953125,
      "learning_rate": 0.0005974337040205303,
      "loss": 0.6562,
      "step": 100
    },
    {
      "epoch": 0.3592814371257485,
      "grad_norm": 5.309491157531738,
      "learning_rate": 0.0005969204448246365,
      "loss": 0.6132,
      "step": 120
    },
    {
      "epoch": 0.41916167664670656,
      "grad_norm": 2.4857170581817627,
      "learning_rate": 0.0005964071856287424,
      "loss": 0.6447,
      "step": 140
    },
    {
      "epoch": 0.47904191616766467,
      "grad_norm": 4.261806964874268,
      "learning_rate": 0.0005958939264328485,
      "loss": 0.5783,
      "step": 160
    },
    {
      "epoch": 0.5389221556886228,
      "grad_norm": 2.691986560821533,
      "learning_rate": 0.0005953806672369547,
      "loss": 0.6034,
      "step": 180
    },
    {
      "epoch": 0.5988023952095808,
      "grad_norm": 1.6799355745315552,
      "learning_rate": 0.0005948674080410607,
      "loss": 0.6202,
      "step": 200
    },
    {
      "epoch": 0.6586826347305389,
      "grad_norm": 6.835055828094482,
      "learning_rate": 0.0005943541488451668,
      "loss": 0.6576,
      "step": 220
    },
    {
      "epoch": 0.718562874251497,
      "grad_norm": 5.823128700256348,
      "learning_rate": 0.0005938408896492729,
      "loss": 0.556,
      "step": 240
    },
    {
      "epoch": 0.7784431137724551,
      "grad_norm": 1.7132949829101562,
      "learning_rate": 0.0005933276304533789,
      "loss": 0.529,
      "step": 260
    },
    {
      "epoch": 0.8383233532934131,
      "grad_norm": 1.787726879119873,
      "learning_rate": 0.000592814371257485,
      "loss": 0.4818,
      "step": 280
    },
    {
      "epoch": 0.8982035928143712,
      "grad_norm": 3.2786436080932617,
      "learning_rate": 0.0005923011120615911,
      "loss": 0.5034,
      "step": 300
    },
    {
      "epoch": 0.9580838323353293,
      "grad_norm": 1.7057358026504517,
      "learning_rate": 0.0005917878528656971,
      "loss": 0.6142,
      "step": 320
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7426470588235294,
      "eval_accuracy_10": 0.7450980392156863,
      "eval_accuracy_11": 0.7426470588235294,
      "eval_accuracy_12": 0.7426470588235294,
      "eval_accuracy_13": 0.7426470588235294,
      "eval_accuracy_14": 0.7426470588235294,
      "eval_accuracy_15": 0.7426470588235294,
      "eval_accuracy_16": 0.7426470588235294,
      "eval_accuracy_17": 0.7426470588235294,
      "eval_accuracy_18": 0.7426470588235294,
      "eval_accuracy_19": 0.7426470588235294,
      "eval_accuracy_20": 0.7426470588235294,
      "eval_accuracy_21": 0.7426470588235294,
      "eval_accuracy_22": 0.7426470588235294,
      "eval_accuracy_23": 0.7426470588235294,
      "eval_accuracy_24": 0.7426470588235294,
      "eval_accuracy_25": 0.7426470588235294,
      "eval_combined_score": 0.7886463640574339,
      "eval_f1": 0.8346456692913385,
      "eval_loss": 0.5016956925392151,
      "eval_runtime": 204.2062,
      "eval_samples_per_second": 1.998,
      "eval_steps_per_second": 0.25,
      "step": 334
    },
    {
      "epoch": 1.0179640718562875,
      "grad_norm": 18.09206771850586,
      "learning_rate": 0.0005912745936698032,
      "loss": 0.5203,
      "step": 340
    },
    {
      "epoch": 1.0778443113772456,
      "grad_norm": 1.2760690450668335,
      "learning_rate": 0.0005907613344739093,
      "loss": 0.4571,
      "step": 360
    },
    {
      "epoch": 1.1377245508982037,
      "grad_norm": 6.494649410247803,
      "learning_rate": 0.0005902480752780154,
      "loss": 0.5965,
      "step": 380
    },
    {
      "epoch": 1.1976047904191618,
      "grad_norm": 6.826463222503662,
      "learning_rate": 0.0005897348160821214,
      "loss": 0.5953,
      "step": 400
    },
    {
      "epoch": 1.2574850299401197,
      "grad_norm": 2.1898343563079834,
      "learning_rate": 0.0005892215568862275,
      "loss": 0.4567,
      "step": 420
    },
    {
      "epoch": 1.3173652694610778,
      "grad_norm": 3.651390552520752,
      "learning_rate": 0.0005887082976903336,
      "loss": 0.4935,
      "step": 440
    },
    {
      "epoch": 1.377245508982036,
      "grad_norm": 1.5505529642105103,
      "learning_rate": 0.0005881950384944396,
      "loss": 0.5176,
      "step": 460
    },
    {
      "epoch": 1.437125748502994,
      "grad_norm": 2.6391444206237793,
      "learning_rate": 0.0005876817792985458,
      "loss": 0.4433,
      "step": 480
    },
    {
      "epoch": 1.4970059880239521,
      "grad_norm": 4.533216953277588,
      "learning_rate": 0.0005871685201026518,
      "loss": 0.4815,
      "step": 500
    },
    {
      "epoch": 1.55688622754491,
      "grad_norm": 7.71444034576416,
      "learning_rate": 0.0005866552609067578,
      "loss": 0.4758,
      "step": 520
    },
    {
      "epoch": 1.6167664670658684,
      "grad_norm": 9.339191436767578,
      "learning_rate": 0.000586142001710864,
      "loss": 0.5591,
      "step": 540
    },
    {
      "epoch": 1.6766467065868262,
      "grad_norm": 2.2312750816345215,
      "learning_rate": 0.00058562874251497,
      "loss": 0.4685,
      "step": 560
    },
    {
      "epoch": 1.7365269461077846,
      "grad_norm": 5.054171085357666,
      "learning_rate": 0.000585115483319076,
      "loss": 0.4148,
      "step": 580
    },
    {
      "epoch": 1.7964071856287425,
      "grad_norm": 4.06920051574707,
      "learning_rate": 0.0005846022241231822,
      "loss": 0.4118,
      "step": 600
    },
    {
      "epoch": 1.8562874251497006,
      "grad_norm": 2.812931537628174,
      "learning_rate": 0.0005840889649272882,
      "loss": 0.4672,
      "step": 620
    },
    {
      "epoch": 1.9161676646706587,
      "grad_norm": 1.4347254037857056,
      "learning_rate": 0.0005835757057313944,
      "loss": 0.3306,
      "step": 640
    },
    {
      "epoch": 1.9760479041916168,
      "grad_norm": 11.488344192504883,
      "learning_rate": 0.0005830624465355004,
      "loss": 0.4385,
      "step": 660
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8455882352941176,
      "eval_accuracy_10": 0.8455882352941176,
      "eval_accuracy_11": 0.8480392156862745,
      "eval_accuracy_12": 0.8504901960784313,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8504901960784313,
      "eval_accuracy_15": 0.8480392156862745,
      "eval_accuracy_16": 0.8529411764705882,
      "eval_accuracy_17": 0.8480392156862745,
      "eval_accuracy_18": 0.8504901960784313,
      "eval_accuracy_19": 0.8504901960784313,
      "eval_accuracy_20": 0.8529411764705882,
      "eval_accuracy_21": 0.8529411764705882,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8455882352941176,
      "eval_accuracy_25": 0.8455882352941176,
      "eval_combined_score": 0.8687632428614671,
      "eval_f1": 0.8919382504288165,
      "eval_loss": 0.41016989946365356,
      "eval_runtime": 204.1931,
      "eval_samples_per_second": 1.998,
      "eval_steps_per_second": 0.25,
      "step": 668
    },
    {
      "epoch": 2.035928143712575,
      "grad_norm": 5.758140563964844,
      "learning_rate": 0.0005825491873396064,
      "loss": 0.3528,
      "step": 680
    },
    {
      "epoch": 2.095808383233533,
      "grad_norm": 9.699262619018555,
      "learning_rate": 0.0005820359281437126,
      "loss": 0.4357,
      "step": 700
    },
    {
      "epoch": 2.155688622754491,
      "grad_norm": 1.8066529035568237,
      "learning_rate": 0.0005815226689478186,
      "loss": 0.4265,
      "step": 720
    },
    {
      "epoch": 2.215568862275449,
      "grad_norm": 32.27989959716797,
      "learning_rate": 0.0005810094097519247,
      "loss": 0.3309,
      "step": 740
    },
    {
      "epoch": 2.2754491017964074,
      "grad_norm": 6.361663818359375,
      "learning_rate": 0.0005804961505560308,
      "loss": 0.4939,
      "step": 760
    },
    {
      "epoch": 2.3353293413173652,
      "grad_norm": 3.2733092308044434,
      "learning_rate": 0.0005799828913601368,
      "loss": 0.4418,
      "step": 780
    },
    {
      "epoch": 2.3952095808383236,
      "grad_norm": 4.200281143188477,
      "learning_rate": 0.0005794696321642429,
      "loss": 0.3245,
      "step": 800
    },
    {
      "epoch": 2.4550898203592815,
      "grad_norm": 4.998908042907715,
      "learning_rate": 0.000578956372968349,
      "loss": 0.4615,
      "step": 820
    },
    {
      "epoch": 2.5149700598802394,
      "grad_norm": 4.852157115936279,
      "learning_rate": 0.0005784431137724551,
      "loss": 0.3891,
      "step": 840
    },
    {
      "epoch": 2.5748502994011977,
      "grad_norm": 4.767732620239258,
      "learning_rate": 0.0005779298545765611,
      "loss": 0.4157,
      "step": 860
    },
    {
      "epoch": 2.6347305389221556,
      "grad_norm": 2.2413477897644043,
      "learning_rate": 0.0005774165953806672,
      "loss": 0.4174,
      "step": 880
    },
    {
      "epoch": 2.694610778443114,
      "grad_norm": 2.7891788482666016,
      "learning_rate": 0.0005769033361847733,
      "loss": 0.38,
      "step": 900
    },
    {
      "epoch": 2.754491017964072,
      "grad_norm": 2.891390085220337,
      "learning_rate": 0.0005763900769888793,
      "loss": 0.4266,
      "step": 920
    },
    {
      "epoch": 2.81437125748503,
      "grad_norm": 9.116893768310547,
      "learning_rate": 0.0005758768177929854,
      "loss": 0.3887,
      "step": 940
    },
    {
      "epoch": 2.874251497005988,
      "grad_norm": 2.347411870956421,
      "learning_rate": 0.0005753635585970915,
      "loss": 0.3531,
      "step": 960
    },
    {
      "epoch": 2.934131736526946,
      "grad_norm": 4.388574123382568,
      "learning_rate": 0.0005748502994011975,
      "loss": 0.3451,
      "step": 980
    },
    {
      "epoch": 2.9940119760479043,
      "grad_norm": 4.3641533851623535,
      "learning_rate": 0.0005743370402053037,
      "loss": 0.4452,
      "step": 1000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8455882352941176,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8480392156862745,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8529411764705882,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8504901960784313,
      "eval_accuracy_20": 0.8504901960784313,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8504901960784313,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.866037360890302,
      "eval_f1": 0.8864864864864864,
      "eval_loss": 0.31861525774002075,
      "eval_runtime": 204.2895,
      "eval_samples_per_second": 1.997,
      "eval_steps_per_second": 0.25,
      "step": 1002
    },
    {
      "epoch": 3.053892215568862,
      "grad_norm": 7.489530563354492,
      "learning_rate": 0.0005738237810094097,
      "loss": 0.5249,
      "step": 1020
    },
    {
      "epoch": 3.1137724550898205,
      "grad_norm": 10.044442176818848,
      "learning_rate": 0.0005733105218135157,
      "loss": 0.3732,
      "step": 1040
    },
    {
      "epoch": 3.1736526946107784,
      "grad_norm": 14.407474517822266,
      "learning_rate": 0.0005727972626176219,
      "loss": 0.3582,
      "step": 1060
    },
    {
      "epoch": 3.2335329341317367,
      "grad_norm": 1.9446616172790527,
      "learning_rate": 0.0005722840034217279,
      "loss": 0.3276,
      "step": 1080
    },
    {
      "epoch": 3.2934131736526946,
      "grad_norm": 7.112531661987305,
      "learning_rate": 0.000571770744225834,
      "loss": 0.4605,
      "step": 1100
    },
    {
      "epoch": 3.3532934131736525,
      "grad_norm": 4.955165386199951,
      "learning_rate": 0.0005712574850299401,
      "loss": 0.4331,
      "step": 1120
    },
    {
      "epoch": 3.413173652694611,
      "grad_norm": 6.345362663269043,
      "learning_rate": 0.0005707442258340461,
      "loss": 0.2931,
      "step": 1140
    },
    {
      "epoch": 3.4730538922155687,
      "grad_norm": 1.939867615699768,
      "learning_rate": 0.0005702309666381522,
      "loss": 0.3125,
      "step": 1160
    },
    {
      "epoch": 3.532934131736527,
      "grad_norm": 6.728488445281982,
      "learning_rate": 0.0005697177074422583,
      "loss": 0.4129,
      "step": 1180
    },
    {
      "epoch": 3.592814371257485,
      "grad_norm": 2.0550143718719482,
      "learning_rate": 0.0005692044482463644,
      "loss": 0.3369,
      "step": 1200
    },
    {
      "epoch": 3.6526946107784433,
      "grad_norm": 4.0195417404174805,
      "learning_rate": 0.0005686911890504704,
      "loss": 0.3626,
      "step": 1220
    },
    {
      "epoch": 3.712574850299401,
      "grad_norm": 14.323053359985352,
      "learning_rate": 0.0005681779298545765,
      "loss": 0.3676,
      "step": 1240
    },
    {
      "epoch": 3.772455089820359,
      "grad_norm": 7.840348243713379,
      "learning_rate": 0.0005676646706586826,
      "loss": 0.3199,
      "step": 1260
    },
    {
      "epoch": 3.8323353293413174,
      "grad_norm": 7.671788215637207,
      "learning_rate": 0.0005671514114627887,
      "loss": 0.435,
      "step": 1280
    },
    {
      "epoch": 3.8922155688622757,
      "grad_norm": 7.671257019042969,
      "learning_rate": 0.0005666381522668947,
      "loss": 0.3485,
      "step": 1300
    },
    {
      "epoch": 3.9520958083832336,
      "grad_norm": 10.345162391662598,
      "learning_rate": 0.0005661248930710008,
      "loss": 0.3582,
      "step": 1320
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8700980392156863,
      "eval_accuracy_10": 0.875,
      "eval_accuracy_11": 0.875,
      "eval_accuracy_12": 0.8774509803921569,
      "eval_accuracy_13": 0.8823529411764706,
      "eval_accuracy_14": 0.8700980392156863,
      "eval_accuracy_15": 0.8725490196078431,
      "eval_accuracy_16": 0.8700980392156863,
      "eval_accuracy_17": 0.8700980392156863,
      "eval_accuracy_18": 0.8700980392156863,
      "eval_accuracy_19": 0.8700980392156863,
      "eval_accuracy_20": 0.8774509803921569,
      "eval_accuracy_21": 0.8774509803921569,
      "eval_accuracy_22": 0.8799019607843137,
      "eval_accuracy_23": 0.8799019607843137,
      "eval_accuracy_24": 0.875,
      "eval_accuracy_25": 0.8725490196078431,
      "eval_combined_score": 0.8895944741532977,
      "eval_f1": 0.9090909090909091,
      "eval_loss": 0.3521663546562195,
      "eval_runtime": 205.9044,
      "eval_samples_per_second": 1.982,
      "eval_steps_per_second": 0.248,
      "step": 1336
    },
    {
      "epoch": 4.0119760479041915,
      "grad_norm": 5.619628429412842,
      "learning_rate": 0.0005656116338751069,
      "loss": 0.36,
      "step": 1340
    },
    {
      "epoch": 4.07185628742515,
      "grad_norm": 7.62594747543335,
      "learning_rate": 0.000565098374679213,
      "loss": 0.3377,
      "step": 1360
    },
    {
      "epoch": 4.131736526946108,
      "grad_norm": 5.764281272888184,
      "learning_rate": 0.000564585115483319,
      "loss": 0.374,
      "step": 1380
    },
    {
      "epoch": 4.191616766467066,
      "grad_norm": 2.1015453338623047,
      "learning_rate": 0.000564071856287425,
      "loss": 0.2746,
      "step": 1400
    },
    {
      "epoch": 4.251497005988024,
      "grad_norm": 7.485937118530273,
      "learning_rate": 0.0005635585970915312,
      "loss": 0.424,
      "step": 1420
    },
    {
      "epoch": 4.311377245508982,
      "grad_norm": 6.388436317443848,
      "learning_rate": 0.0005630453378956372,
      "loss": 0.337,
      "step": 1440
    },
    {
      "epoch": 4.37125748502994,
      "grad_norm": 3.841261386871338,
      "learning_rate": 0.0005625320786997434,
      "loss": 0.3645,
      "step": 1460
    },
    {
      "epoch": 4.431137724550898,
      "grad_norm": 4.881021976470947,
      "learning_rate": 0.0005620188195038494,
      "loss": 0.4611,
      "step": 1480
    },
    {
      "epoch": 4.491017964071856,
      "grad_norm": 4.391282558441162,
      "learning_rate": 0.0005615055603079554,
      "loss": 0.4077,
      "step": 1500
    },
    {
      "epoch": 4.550898203592815,
      "grad_norm": 3.5570261478424072,
      "learning_rate": 0.0005609923011120616,
      "loss": 0.3016,
      "step": 1520
    },
    {
      "epoch": 4.610778443113772,
      "grad_norm": 4.000016212463379,
      "learning_rate": 0.0005604790419161676,
      "loss": 0.3885,
      "step": 1540
    },
    {
      "epoch": 4.6706586826347305,
      "grad_norm": 9.066264152526855,
      "learning_rate": 0.0005599657827202736,
      "loss": 0.3403,
      "step": 1560
    },
    {
      "epoch": 4.730538922155689,
      "grad_norm": 3.004307270050049,
      "learning_rate": 0.0005594525235243798,
      "loss": 0.384,
      "step": 1580
    },
    {
      "epoch": 4.790419161676647,
      "grad_norm": 5.606960773468018,
      "learning_rate": 0.0005589392643284858,
      "loss": 0.2845,
      "step": 1600
    },
    {
      "epoch": 4.850299401197605,
      "grad_norm": 2.941500663757324,
      "learning_rate": 0.0005584260051325919,
      "loss": 0.3664,
      "step": 1620
    },
    {
      "epoch": 4.910179640718563,
      "grad_norm": 5.108543872833252,
      "learning_rate": 0.000557912745936698,
      "loss": 0.3798,
      "step": 1640
    },
    {
      "epoch": 4.970059880239521,
      "grad_norm": 12.937678337097168,
      "learning_rate": 0.000557399486740804,
      "loss": 0.3972,
      "step": 1660
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8651960784313726,
      "eval_accuracy_10": 0.8578431372549019,
      "eval_accuracy_11": 0.8578431372549019,
      "eval_accuracy_12": 0.8553921568627451,
      "eval_accuracy_13": 0.8578431372549019,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8602941176470589,
      "eval_accuracy_19": 0.8627450980392157,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8602941176470589,
      "eval_accuracy_23": 0.8602941176470589,
      "eval_accuracy_24": 0.8602941176470589,
      "eval_accuracy_25": 0.8627450980392157,
      "eval_combined_score": 0.8852658533292836,
      "eval_f1": 0.9053356282271946,
      "eval_loss": 0.326693058013916,
      "eval_runtime": 208.8285,
      "eval_samples_per_second": 1.954,
      "eval_steps_per_second": 0.244,
      "step": 1670
    },
    {
      "epoch": 5.029940119760479,
      "grad_norm": 4.47260856628418,
      "learning_rate": 0.0005568862275449101,
      "loss": 0.3902,
      "step": 1680
    },
    {
      "epoch": 5.089820359281437,
      "grad_norm": 3.867724657058716,
      "learning_rate": 0.0005563729683490162,
      "loss": 0.3053,
      "step": 1700
    },
    {
      "epoch": 5.149700598802395,
      "grad_norm": 10.164628028869629,
      "learning_rate": 0.0005558597091531223,
      "loss": 0.3375,
      "step": 1720
    },
    {
      "epoch": 5.209580838323353,
      "grad_norm": 5.460809230804443,
      "learning_rate": 0.0005553464499572283,
      "loss": 0.3784,
      "step": 1740
    },
    {
      "epoch": 5.269461077844311,
      "grad_norm": 6.648670673370361,
      "learning_rate": 0.0005548331907613344,
      "loss": 0.3224,
      "step": 1760
    },
    {
      "epoch": 5.3293413173652695,
      "grad_norm": 5.143093109130859,
      "learning_rate": 0.0005543199315654405,
      "loss": 0.3289,
      "step": 1780
    },
    {
      "epoch": 5.389221556886228,
      "grad_norm": 2.349175214767456,
      "learning_rate": 0.0005538066723695465,
      "loss": 0.2891,
      "step": 1800
    },
    {
      "epoch": 5.449101796407185,
      "grad_norm": 8.000243186950684,
      "learning_rate": 0.0005532934131736527,
      "loss": 0.2972,
      "step": 1820
    },
    {
      "epoch": 5.508982035928144,
      "grad_norm": 5.045477390289307,
      "learning_rate": 0.0005527801539777587,
      "loss": 0.2908,
      "step": 1840
    },
    {
      "epoch": 5.568862275449102,
      "grad_norm": 11.813980102539062,
      "learning_rate": 0.0005522668947818647,
      "loss": 0.3146,
      "step": 1860
    },
    {
      "epoch": 5.62874251497006,
      "grad_norm": 8.85957145690918,
      "learning_rate": 0.0005517536355859709,
      "loss": 0.3535,
      "step": 1880
    },
    {
      "epoch": 5.688622754491018,
      "grad_norm": 9.397229194641113,
      "learning_rate": 0.0005512403763900769,
      "loss": 0.392,
      "step": 1900
    },
    {
      "epoch": 5.748502994011976,
      "grad_norm": 5.4369001388549805,
      "learning_rate": 0.000550727117194183,
      "loss": 0.335,
      "step": 1920
    },
    {
      "epoch": 5.808383233532934,
      "grad_norm": 6.41180944442749,
      "learning_rate": 0.0005502138579982891,
      "loss": 0.344,
      "step": 1940
    },
    {
      "epoch": 5.868263473053892,
      "grad_norm": 3.6162400245666504,
      "learning_rate": 0.0005497005988023951,
      "loss": 0.3054,
      "step": 1960
    },
    {
      "epoch": 5.92814371257485,
      "grad_norm": 3.231815814971924,
      "learning_rate": 0.0005491873396065013,
      "loss": 0.3672,
      "step": 1980
    },
    {
      "epoch": 5.9880239520958085,
      "grad_norm": 11.913002967834473,
      "learning_rate": 0.0005486740804106073,
      "loss": 0.3681,
      "step": 2000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_accuracy_10": 0.8651960784313726,
      "eval_accuracy_11": 0.8651960784313726,
      "eval_accuracy_12": 0.8676470588235294,
      "eval_accuracy_13": 0.8602941176470589,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8602941176470589,
      "eval_accuracy_18": 0.8602941176470589,
      "eval_accuracy_19": 0.8627450980392157,
      "eval_accuracy_20": 0.8627450980392157,
      "eval_accuracy_21": 0.8651960784313726,
      "eval_accuracy_22": 0.8602941176470589,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8767632952461559,
      "eval_f1": 0.89568345323741,
      "eval_loss": 0.3147943615913391,
      "eval_runtime": 212.5197,
      "eval_samples_per_second": 1.92,
      "eval_steps_per_second": 0.24,
      "step": 2004
    },
    {
      "epoch": 6.047904191616767,
      "grad_norm": 3.339017391204834,
      "learning_rate": 0.0005481608212147133,
      "loss": 0.415,
      "step": 2020
    },
    {
      "epoch": 6.107784431137724,
      "grad_norm": 4.915680408477783,
      "learning_rate": 0.0005476475620188195,
      "loss": 0.3368,
      "step": 2040
    },
    {
      "epoch": 6.167664670658683,
      "grad_norm": 6.042603492736816,
      "learning_rate": 0.0005471343028229255,
      "loss": 0.3416,
      "step": 2060
    },
    {
      "epoch": 6.227544910179641,
      "grad_norm": 3.6257870197296143,
      "learning_rate": 0.0005466210436270316,
      "loss": 0.3343,
      "step": 2080
    },
    {
      "epoch": 6.287425149700598,
      "grad_norm": 2.630631923675537,
      "learning_rate": 0.0005461077844311377,
      "loss": 0.2426,
      "step": 2100
    },
    {
      "epoch": 6.347305389221557,
      "grad_norm": 5.497998237609863,
      "learning_rate": 0.0005455945252352437,
      "loss": 0.3732,
      "step": 2120
    },
    {
      "epoch": 6.407185628742515,
      "grad_norm": 1.7368559837341309,
      "learning_rate": 0.0005450812660393498,
      "loss": 0.3417,
      "step": 2140
    },
    {
      "epoch": 6.467065868263473,
      "grad_norm": 4.2468037605285645,
      "learning_rate": 0.0005445680068434559,
      "loss": 0.2431,
      "step": 2160
    },
    {
      "epoch": 6.526946107784431,
      "grad_norm": 5.769498825073242,
      "learning_rate": 0.0005440547476475619,
      "loss": 0.366,
      "step": 2180
    },
    {
      "epoch": 6.586826347305389,
      "grad_norm": 3.5063259601593018,
      "learning_rate": 0.000543541488451668,
      "loss": 0.386,
      "step": 2200
    },
    {
      "epoch": 6.6467065868263475,
      "grad_norm": 51.016845703125,
      "learning_rate": 0.0005430282292557741,
      "loss": 0.2862,
      "step": 2220
    },
    {
      "epoch": 6.706586826347305,
      "grad_norm": 3.8470029830932617,
      "learning_rate": 0.0005425149700598802,
      "loss": 0.3051,
      "step": 2240
    },
    {
      "epoch": 6.766467065868263,
      "grad_norm": 8.068126678466797,
      "learning_rate": 0.0005420017108639863,
      "loss": 0.2499,
      "step": 2260
    },
    {
      "epoch": 6.826347305389222,
      "grad_norm": 3.8854007720947266,
      "learning_rate": 0.0005414884516680923,
      "loss": 0.4015,
      "step": 2280
    },
    {
      "epoch": 6.88622754491018,
      "grad_norm": 2.434370279312134,
      "learning_rate": 0.0005409751924721984,
      "loss": 0.3161,
      "step": 2300
    },
    {
      "epoch": 6.946107784431137,
      "grad_norm": 4.481163501739502,
      "learning_rate": 0.0005404619332763045,
      "loss": 0.2455,
      "step": 2320
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8651960784313726,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8578431372549019,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8602941176470589,
      "eval_accuracy_14": 0.8602941176470589,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8627450980392157,
      "eval_accuracy_18": 0.8627450980392157,
      "eval_accuracy_19": 0.8627450980392157,
      "eval_accuracy_20": 0.8627450980392157,
      "eval_accuracy_21": 0.8627450980392157,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8627450980392157,
      "eval_combined_score": 0.8857496576143234,
      "eval_f1": 0.9063032367972743,
      "eval_loss": 0.4084160625934601,
      "eval_runtime": 211.8427,
      "eval_samples_per_second": 1.926,
      "eval_steps_per_second": 0.241,
      "step": 2338
    },
    {
      "epoch": 7.005988023952096,
      "grad_norm": 1.6261343955993652,
      "learning_rate": 0.0005399486740804106,
      "loss": 0.319,
      "step": 2340
    },
    {
      "epoch": 7.065868263473054,
      "grad_norm": 4.141797065734863,
      "learning_rate": 0.0005394354148845166,
      "loss": 0.3195,
      "step": 2360
    },
    {
      "epoch": 7.125748502994012,
      "grad_norm": 6.1067376136779785,
      "learning_rate": 0.0005389221556886226,
      "loss": 0.3826,
      "step": 2380
    },
    {
      "epoch": 7.18562874251497,
      "grad_norm": 3.8302505016326904,
      "learning_rate": 0.0005384088964927288,
      "loss": 0.3683,
      "step": 2400
    },
    {
      "epoch": 7.245508982035928,
      "grad_norm": 7.499330997467041,
      "learning_rate": 0.0005378956372968349,
      "loss": 0.2192,
      "step": 2420
    },
    {
      "epoch": 7.3053892215568865,
      "grad_norm": 6.347085952758789,
      "learning_rate": 0.000537382378100941,
      "loss": 0.3206,
      "step": 2440
    },
    {
      "epoch": 7.365269461077844,
      "grad_norm": 2.1861557960510254,
      "learning_rate": 0.000536869118905047,
      "loss": 0.3206,
      "step": 2460
    },
    {
      "epoch": 7.425149700598802,
      "grad_norm": 0.5036484003067017,
      "learning_rate": 0.0005363558597091531,
      "loss": 0.3558,
      "step": 2480
    },
    {
      "epoch": 7.485029940119761,
      "grad_norm": 3.9596235752105713,
      "learning_rate": 0.0005358426005132592,
      "loss": 0.2757,
      "step": 2500
    },
    {
      "epoch": 7.544910179640718,
      "grad_norm": 3.8585472106933594,
      "learning_rate": 0.0005353293413173653,
      "loss": 0.3008,
      "step": 2520
    },
    {
      "epoch": 7.604790419161676,
      "grad_norm": 2.553173065185547,
      "learning_rate": 0.0005348160821214712,
      "loss": 0.3162,
      "step": 2540
    },
    {
      "epoch": 7.664670658682635,
      "grad_norm": 6.913729190826416,
      "learning_rate": 0.0005343028229255774,
      "loss": 0.3735,
      "step": 2560
    },
    {
      "epoch": 7.724550898203593,
      "grad_norm": 3.968977451324463,
      "learning_rate": 0.0005337895637296835,
      "loss": 0.2765,
      "step": 2580
    },
    {
      "epoch": 7.7844311377245505,
      "grad_norm": 4.992636680603027,
      "learning_rate": 0.0005332763045337895,
      "loss": 0.2862,
      "step": 2600
    },
    {
      "epoch": 7.844311377245509,
      "grad_norm": 6.784542560577393,
      "learning_rate": 0.0005327630453378957,
      "loss": 0.3825,
      "step": 2620
    },
    {
      "epoch": 7.904191616766467,
      "grad_norm": 2.7047171592712402,
      "learning_rate": 0.0005322497861420017,
      "loss": 0.295,
      "step": 2640
    },
    {
      "epoch": 7.9640718562874255,
      "grad_norm": 3.512986183166504,
      "learning_rate": 0.0005317365269461077,
      "loss": 0.3553,
      "step": 2660
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8529411764705882,
      "eval_accuracy_10": 0.8504901960784313,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8553921568627451,
      "eval_accuracy_13": 0.8578431372549019,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8602941176470589,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8553921568627451,
      "eval_accuracy_21": 0.8529411764705882,
      "eval_accuracy_22": 0.8529411764705882,
      "eval_accuracy_23": 0.8504901960784313,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8763033641550265,
      "eval_f1": 0.8996655518394648,
      "eval_loss": 0.4535497725009918,
      "eval_runtime": 212.2186,
      "eval_samples_per_second": 1.923,
      "eval_steps_per_second": 0.24,
      "step": 2672
    },
    {
      "epoch": 8.023952095808383,
      "grad_norm": 2.7094738483428955,
      "learning_rate": 0.0005312232677502139,
      "loss": 0.223,
      "step": 2680
    },
    {
      "epoch": 8.08383233532934,
      "grad_norm": 7.64896821975708,
      "learning_rate": 0.0005307100085543199,
      "loss": 0.3085,
      "step": 2700
    },
    {
      "epoch": 8.1437125748503,
      "grad_norm": 5.329763889312744,
      "learning_rate": 0.0005301967493584259,
      "loss": 0.2754,
      "step": 2720
    },
    {
      "epoch": 8.203592814371257,
      "grad_norm": 0.7111997008323669,
      "learning_rate": 0.0005296834901625321,
      "loss": 0.3139,
      "step": 2740
    },
    {
      "epoch": 8.263473053892216,
      "grad_norm": 9.967636108398438,
      "learning_rate": 0.0005291702309666381,
      "loss": 0.3704,
      "step": 2760
    },
    {
      "epoch": 8.323353293413174,
      "grad_norm": 1.4900487661361694,
      "learning_rate": 0.0005286569717707442,
      "loss": 0.396,
      "step": 2780
    },
    {
      "epoch": 8.383233532934131,
      "grad_norm": 1.957094669342041,
      "learning_rate": 0.0005281437125748503,
      "loss": 0.2461,
      "step": 2800
    },
    {
      "epoch": 8.44311377245509,
      "grad_norm": 2.979292869567871,
      "learning_rate": 0.0005276304533789563,
      "loss": 0.3182,
      "step": 2820
    },
    {
      "epoch": 8.502994011976048,
      "grad_norm": 6.6321001052856445,
      "learning_rate": 0.0005271171941830624,
      "loss": 0.3774,
      "step": 2840
    },
    {
      "epoch": 8.562874251497005,
      "grad_norm": 6.556360244750977,
      "learning_rate": 0.0005266039349871685,
      "loss": 0.269,
      "step": 2860
    },
    {
      "epoch": 8.622754491017965,
      "grad_norm": 1.4305447340011597,
      "learning_rate": 0.0005260906757912746,
      "loss": 0.3597,
      "step": 2880
    },
    {
      "epoch": 8.682634730538922,
      "grad_norm": 1.672015905380249,
      "learning_rate": 0.0005255774165953806,
      "loss": 0.378,
      "step": 2900
    },
    {
      "epoch": 8.74251497005988,
      "grad_norm": 5.030071258544922,
      "learning_rate": 0.0005250641573994867,
      "loss": 0.2871,
      "step": 2920
    },
    {
      "epoch": 8.802395209580839,
      "grad_norm": 6.2470574378967285,
      "learning_rate": 0.0005245508982035928,
      "loss": 0.3041,
      "step": 2940
    },
    {
      "epoch": 8.862275449101796,
      "grad_norm": 4.697446346282959,
      "learning_rate": 0.0005240376390076988,
      "loss": 0.3275,
      "step": 2960
    },
    {
      "epoch": 8.922155688622755,
      "grad_norm": 4.984197616577148,
      "learning_rate": 0.0005235243798118049,
      "loss": 0.4016,
      "step": 2980
    },
    {
      "epoch": 8.982035928143713,
      "grad_norm": 6.535458564758301,
      "learning_rate": 0.000523011120615911,
      "loss": 0.2922,
      "step": 3000
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.8455882352941176,
      "eval_accuracy_10": 0.8431372549019608,
      "eval_accuracy_11": 0.8431372549019608,
      "eval_accuracy_12": 0.8504901960784313,
      "eval_accuracy_13": 0.8455882352941176,
      "eval_accuracy_14": 0.8406862745098039,
      "eval_accuracy_15": 0.8455882352941176,
      "eval_accuracy_16": 0.8480392156862745,
      "eval_accuracy_17": 0.8480392156862745,
      "eval_accuracy_18": 0.8455882352941176,
      "eval_accuracy_19": 0.8480392156862745,
      "eval_accuracy_20": 0.8455882352941176,
      "eval_accuracy_21": 0.8431372549019608,
      "eval_accuracy_22": 0.8480392156862745,
      "eval_accuracy_23": 0.8455882352941176,
      "eval_accuracy_24": 0.8480392156862745,
      "eval_accuracy_25": 0.8431372549019608,
      "eval_combined_score": 0.8662411553490337,
      "eval_f1": 0.8868940754039497,
      "eval_loss": 0.32536017894744873,
      "eval_runtime": 206.6502,
      "eval_samples_per_second": 1.974,
      "eval_steps_per_second": 0.247,
      "step": 3006
    },
    {
      "epoch": 9.04191616766467,
      "grad_norm": 2.3984837532043457,
      "learning_rate": 0.000522497861420017,
      "loss": 0.3423,
      "step": 3020
    },
    {
      "epoch": 9.10179640718563,
      "grad_norm": 2.3654625415802,
      "learning_rate": 0.0005219846022241232,
      "loss": 0.2383,
      "step": 3040
    },
    {
      "epoch": 9.161676646706587,
      "grad_norm": 12.015230178833008,
      "learning_rate": 0.0005214713430282292,
      "loss": 0.2798,
      "step": 3060
    },
    {
      "epoch": 9.221556886227544,
      "grad_norm": 0.9001509547233582,
      "learning_rate": 0.0005209580838323352,
      "loss": 0.1707,
      "step": 3080
    },
    {
      "epoch": 9.281437125748504,
      "grad_norm": 0.8675571084022522,
      "learning_rate": 0.0005204448246364414,
      "loss": 0.2373,
      "step": 3100
    },
    {
      "epoch": 9.341317365269461,
      "grad_norm": 7.998110771179199,
      "learning_rate": 0.0005199315654405474,
      "loss": 0.3252,
      "step": 3120
    },
    {
      "epoch": 9.401197604790418,
      "grad_norm": 0.4949710965156555,
      "learning_rate": 0.0005194183062446536,
      "loss": 0.3137,
      "step": 3140
    },
    {
      "epoch": 9.461077844311378,
      "grad_norm": 2.265923023223877,
      "learning_rate": 0.0005189050470487596,
      "loss": 0.2805,
      "step": 3160
    },
    {
      "epoch": 9.520958083832335,
      "grad_norm": 3.469191789627075,
      "learning_rate": 0.0005183917878528656,
      "loss": 0.2478,
      "step": 3180
    },
    {
      "epoch": 9.580838323353294,
      "grad_norm": 2.677485942840576,
      "learning_rate": 0.0005178785286569718,
      "loss": 0.3572,
      "step": 3200
    },
    {
      "epoch": 9.640718562874252,
      "grad_norm": 8.934036254882812,
      "learning_rate": 0.0005173652694610778,
      "loss": 0.3023,
      "step": 3220
    },
    {
      "epoch": 9.70059880239521,
      "grad_norm": 9.100430488586426,
      "learning_rate": 0.0005168520102651839,
      "loss": 0.2881,
      "step": 3240
    },
    {
      "epoch": 9.760479041916168,
      "grad_norm": 3.598686456680298,
      "learning_rate": 0.00051633875106929,
      "loss": 0.3664,
      "step": 3260
    },
    {
      "epoch": 9.820359281437126,
      "grad_norm": 12.83108901977539,
      "learning_rate": 0.000515825491873396,
      "loss": 0.3191,
      "step": 3280
    },
    {
      "epoch": 9.880239520958083,
      "grad_norm": 2.526704788208008,
      "learning_rate": 0.0005153122326775021,
      "loss": 0.3961,
      "step": 3300
    },
    {
      "epoch": 9.940119760479043,
      "grad_norm": 0.9333739280700684,
      "learning_rate": 0.0005147989734816082,
      "loss": 0.325,
      "step": 3320
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.6420985460281372,
      "learning_rate": 0.0005142857142857142,
      "loss": 0.2909,
      "step": 3340
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.8529411764705882,
      "eval_accuracy_10": 0.8578431372549019,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8627450980392157,
      "eval_accuracy_14": 0.8627450980392157,
      "eval_accuracy_15": 0.8480392156862745,
      "eval_accuracy_16": 0.8504901960784313,
      "eval_accuracy_17": 0.8480392156862745,
      "eval_accuracy_18": 0.8480392156862745,
      "eval_accuracy_19": 0.8504901960784313,
      "eval_accuracy_20": 0.8529411764705882,
      "eval_accuracy_21": 0.8529411764705882,
      "eval_accuracy_22": 0.8504901960784313,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8734670546663895,
      "eval_f1": 0.8939929328621908,
      "eval_loss": 0.3566276729106903,
      "eval_runtime": 210.0451,
      "eval_samples_per_second": 1.942,
      "eval_steps_per_second": 0.243,
      "step": 3340
    },
    {
      "epoch": 10.059880239520957,
      "grad_norm": 4.248920440673828,
      "learning_rate": 0.0005137724550898203,
      "loss": 0.2701,
      "step": 3360
    },
    {
      "epoch": 10.119760479041917,
      "grad_norm": 4.624114513397217,
      "learning_rate": 0.0005132591958939264,
      "loss": 0.3707,
      "step": 3380
    },
    {
      "epoch": 10.179640718562874,
      "grad_norm": 8.071730613708496,
      "learning_rate": 0.0005127459366980325,
      "loss": 0.2703,
      "step": 3400
    },
    {
      "epoch": 10.239520958083832,
      "grad_norm": 30.34539222717285,
      "learning_rate": 0.0005122326775021385,
      "loss": 0.2556,
      "step": 3420
    },
    {
      "epoch": 10.29940119760479,
      "grad_norm": 4.076787948608398,
      "learning_rate": 0.0005117194183062446,
      "loss": 0.271,
      "step": 3440
    },
    {
      "epoch": 10.359281437125748,
      "grad_norm": 4.121046543121338,
      "learning_rate": 0.0005112061591103507,
      "loss": 0.2598,
      "step": 3460
    },
    {
      "epoch": 10.419161676646706,
      "grad_norm": 0.3281767666339874,
      "learning_rate": 0.0005106928999144567,
      "loss": 0.2408,
      "step": 3480
    },
    {
      "epoch": 10.479041916167665,
      "grad_norm": 4.73399543762207,
      "learning_rate": 0.0005101796407185629,
      "loss": 0.2997,
      "step": 3500
    },
    {
      "epoch": 10.538922155688622,
      "grad_norm": 3.544107675552368,
      "learning_rate": 0.0005096663815226689,
      "loss": 0.3688,
      "step": 3520
    },
    {
      "epoch": 10.598802395209582,
      "grad_norm": 3.053870916366577,
      "learning_rate": 0.0005091531223267749,
      "loss": 0.3137,
      "step": 3540
    },
    {
      "epoch": 10.658682634730539,
      "grad_norm": 11.210087776184082,
      "learning_rate": 0.0005086398631308811,
      "loss": 0.2781,
      "step": 3560
    },
    {
      "epoch": 10.718562874251496,
      "grad_norm": 3.150069236755371,
      "learning_rate": 0.0005081266039349871,
      "loss": 0.2271,
      "step": 3580
    },
    {
      "epoch": 10.778443113772456,
      "grad_norm": 5.243595600128174,
      "learning_rate": 0.0005076133447390932,
      "loss": 0.3284,
      "step": 3600
    },
    {
      "epoch": 10.838323353293413,
      "grad_norm": 6.600507736206055,
      "learning_rate": 0.0005071000855431993,
      "loss": 0.2884,
      "step": 3620
    },
    {
      "epoch": 10.89820359281437,
      "grad_norm": 4.206586837768555,
      "learning_rate": 0.0005065868263473053,
      "loss": 0.3074,
      "step": 3640
    },
    {
      "epoch": 10.95808383233533,
      "grad_norm": 17.368549346923828,
      "learning_rate": 0.0005060735671514115,
      "loss": 0.3042,
      "step": 3660
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.8455882352941176,
      "eval_accuracy_10": 0.8431372549019608,
      "eval_accuracy_11": 0.8431372549019608,
      "eval_accuracy_12": 0.8431372549019608,
      "eval_accuracy_13": 0.8382352941176471,
      "eval_accuracy_14": 0.8406862745098039,
      "eval_accuracy_15": 0.8406862745098039,
      "eval_accuracy_16": 0.8406862745098039,
      "eval_accuracy_17": 0.8455882352941176,
      "eval_accuracy_18": 0.8431372549019608,
      "eval_accuracy_19": 0.8431372549019608,
      "eval_accuracy_20": 0.8455882352941176,
      "eval_accuracy_21": 0.8406862745098039,
      "eval_accuracy_22": 0.8455882352941176,
      "eval_accuracy_23": 0.8455882352941176,
      "eval_accuracy_24": 0.8406862745098039,
      "eval_accuracy_25": 0.8431372549019608,
      "eval_combined_score": 0.869494625261272,
      "eval_f1": 0.8934010152284263,
      "eval_loss": 0.4373951852321625,
      "eval_runtime": 206.7946,
      "eval_samples_per_second": 1.973,
      "eval_steps_per_second": 0.247,
      "step": 3674
    },
    {
      "epoch": 11.017964071856287,
      "grad_norm": 6.328403949737549,
      "learning_rate": 0.0005055603079555175,
      "loss": 0.2779,
      "step": 3680
    },
    {
      "epoch": 11.077844311377245,
      "grad_norm": 6.1922712326049805,
      "learning_rate": 0.0005050470487596235,
      "loss": 0.3148,
      "step": 3700
    },
    {
      "epoch": 11.137724550898204,
      "grad_norm": 0.6378050446510315,
      "learning_rate": 0.0005045337895637297,
      "loss": 0.2877,
      "step": 3720
    },
    {
      "epoch": 11.197604790419161,
      "grad_norm": 3.7051093578338623,
      "learning_rate": 0.0005040205303678357,
      "loss": 0.2961,
      "step": 3740
    },
    {
      "epoch": 11.25748502994012,
      "grad_norm": 3.396141290664673,
      "learning_rate": 0.0005035072711719418,
      "loss": 0.2901,
      "step": 3760
    },
    {
      "epoch": 11.317365269461078,
      "grad_norm": 5.171055793762207,
      "learning_rate": 0.0005029940119760479,
      "loss": 0.3092,
      "step": 3780
    },
    {
      "epoch": 11.377245508982035,
      "grad_norm": 7.162662506103516,
      "learning_rate": 0.0005024807527801539,
      "loss": 0.304,
      "step": 3800
    },
    {
      "epoch": 11.437125748502995,
      "grad_norm": 2.586989402770996,
      "learning_rate": 0.00050196749358426,
      "loss": 0.2538,
      "step": 3820
    },
    {
      "epoch": 11.497005988023952,
      "grad_norm": 4.488342761993408,
      "learning_rate": 0.0005014542343883661,
      "loss": 0.2902,
      "step": 3840
    },
    {
      "epoch": 11.55688622754491,
      "grad_norm": 5.252584934234619,
      "learning_rate": 0.0005009409751924722,
      "loss": 0.3497,
      "step": 3860
    },
    {
      "epoch": 11.616766467065869,
      "grad_norm": 6.263484001159668,
      "learning_rate": 0.0005004277159965782,
      "loss": 0.3106,
      "step": 3880
    },
    {
      "epoch": 11.676646706586826,
      "grad_norm": 4.285712242126465,
      "learning_rate": 0.0004999144568006843,
      "loss": 0.3026,
      "step": 3900
    },
    {
      "epoch": 11.736526946107784,
      "grad_norm": 9.73587703704834,
      "learning_rate": 0.0004994011976047904,
      "loss": 0.2251,
      "step": 3920
    },
    {
      "epoch": 11.796407185628743,
      "grad_norm": 0.9115926027297974,
      "learning_rate": 0.0004988879384088964,
      "loss": 0.236,
      "step": 3940
    },
    {
      "epoch": 11.8562874251497,
      "grad_norm": 3.8838422298431396,
      "learning_rate": 0.0004983746792130025,
      "loss": 0.2432,
      "step": 3960
    },
    {
      "epoch": 11.91616766467066,
      "grad_norm": 3.9579570293426514,
      "learning_rate": 0.0004978614200171086,
      "loss": 0.2945,
      "step": 3980
    },
    {
      "epoch": 11.976047904191617,
      "grad_norm": 2.9458608627319336,
      "learning_rate": 0.0004973481608212146,
      "loss": 0.2753,
      "step": 4000
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.8455882352941176,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8504901960784313,
      "eval_accuracy_16": 0.8504901960784313,
      "eval_accuracy_17": 0.8504901960784313,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8529411764705882,
      "eval_accuracy_21": 0.8480392156862745,
      "eval_accuracy_22": 0.8431372549019608,
      "eval_accuracy_23": 0.8504901960784313,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8455882352941176,
      "eval_combined_score": 0.8691314259945886,
      "eval_f1": 0.8926746166950595,
      "eval_loss": 0.4434082806110382,
      "eval_runtime": 209.0394,
      "eval_samples_per_second": 1.952,
      "eval_steps_per_second": 0.244,
      "step": 4008
    },
    {
      "epoch": 12.035928143712574,
      "grad_norm": 4.483409881591797,
      "learning_rate": 0.0004968349016253208,
      "loss": 0.2636,
      "step": 4020
    },
    {
      "epoch": 12.095808383233534,
      "grad_norm": 9.086481094360352,
      "learning_rate": 0.0004963216424294268,
      "loss": 0.2957,
      "step": 4040
    },
    {
      "epoch": 12.155688622754491,
      "grad_norm": 0.7851865887641907,
      "learning_rate": 0.0004958083832335328,
      "loss": 0.3316,
      "step": 4060
    },
    {
      "epoch": 12.215568862275449,
      "grad_norm": 4.570064544677734,
      "learning_rate": 0.000495295124037639,
      "loss": 0.2529,
      "step": 4080
    },
    {
      "epoch": 12.275449101796408,
      "grad_norm": 4.448611736297607,
      "learning_rate": 0.000494781864841745,
      "loss": 0.3822,
      "step": 4100
    },
    {
      "epoch": 12.335329341317365,
      "grad_norm": 5.369385719299316,
      "learning_rate": 0.0004942686056458511,
      "loss": 0.2846,
      "step": 4120
    },
    {
      "epoch": 12.395209580838323,
      "grad_norm": 6.859628677368164,
      "learning_rate": 0.0004937553464499572,
      "loss": 0.2895,
      "step": 4140
    },
    {
      "epoch": 12.455089820359282,
      "grad_norm": 5.59089994430542,
      "learning_rate": 0.0004932420872540632,
      "loss": 0.3359,
      "step": 4160
    },
    {
      "epoch": 12.51497005988024,
      "grad_norm": 2.4217004776000977,
      "learning_rate": 0.0004927288280581693,
      "loss": 0.2864,
      "step": 4180
    },
    {
      "epoch": 12.574850299401197,
      "grad_norm": 4.586709022521973,
      "learning_rate": 0.0004922155688622754,
      "loss": 0.2471,
      "step": 4200
    },
    {
      "epoch": 12.634730538922156,
      "grad_norm": 0.8242369890213013,
      "learning_rate": 0.0004917023096663815,
      "loss": 0.2878,
      "step": 4220
    },
    {
      "epoch": 12.694610778443113,
      "grad_norm": 3.8960788249969482,
      "learning_rate": 0.0004911890504704875,
      "loss": 0.2714,
      "step": 4240
    },
    {
      "epoch": 12.754491017964071,
      "grad_norm": 6.703079700469971,
      "learning_rate": 0.0004906757912745936,
      "loss": 0.2809,
      "step": 4260
    },
    {
      "epoch": 12.81437125748503,
      "grad_norm": 7.072812080383301,
      "learning_rate": 0.0004901625320786997,
      "loss": 0.2365,
      "step": 4280
    },
    {
      "epoch": 12.874251497005988,
      "grad_norm": 0.3620661795139313,
      "learning_rate": 0.0004896492728828057,
      "loss": 0.2174,
      "step": 4300
    },
    {
      "epoch": 12.934131736526947,
      "grad_norm": 14.49907398223877,
      "learning_rate": 0.0004891360136869118,
      "loss": 0.3623,
      "step": 4320
    },
    {
      "epoch": 12.994011976047904,
      "grad_norm": 2.4784247875213623,
      "learning_rate": 0.0004886227544910179,
      "loss": 0.2404,
      "step": 4340
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.8651960784313726,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8627450980392157,
      "eval_accuracy_13": 0.8651960784313726,
      "eval_accuracy_14": 0.8627450980392157,
      "eval_accuracy_15": 0.8627450980392157,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8676470588235294,
      "eval_accuracy_18": 0.8676470588235294,
      "eval_accuracy_19": 0.8700980392156863,
      "eval_accuracy_20": 0.8700980392156863,
      "eval_accuracy_21": 0.8651960784313726,
      "eval_accuracy_22": 0.8651960784313726,
      "eval_accuracy_23": 0.8651960784313726,
      "eval_accuracy_24": 0.8651960784313726,
      "eval_accuracy_25": 0.8651960784313726,
      "eval_combined_score": 0.8865343876243965,
      "eval_f1": 0.9078726968174204,
      "eval_loss": 0.45344963669776917,
      "eval_runtime": 214.2946,
      "eval_samples_per_second": 1.904,
      "eval_steps_per_second": 0.238,
      "step": 4342
    },
    {
      "epoch": 13.053892215568862,
      "grad_norm": 7.832187652587891,
      "learning_rate": 0.000488109495295124,
      "loss": 0.2002,
      "step": 4360
    },
    {
      "epoch": 13.113772455089821,
      "grad_norm": 1.43065345287323,
      "learning_rate": 0.0004875962360992301,
      "loss": 0.2739,
      "step": 4380
    },
    {
      "epoch": 13.173652694610778,
      "grad_norm": 4.2725911140441895,
      "learning_rate": 0.0004870829769033362,
      "loss": 0.3278,
      "step": 4400
    },
    {
      "epoch": 13.233532934131736,
      "grad_norm": 3.7002809047698975,
      "learning_rate": 0.0004865697177074422,
      "loss": 0.2792,
      "step": 4420
    },
    {
      "epoch": 13.293413173652695,
      "grad_norm": 3.5393288135528564,
      "learning_rate": 0.0004860564585115483,
      "loss": 0.2729,
      "step": 4440
    },
    {
      "epoch": 13.353293413173652,
      "grad_norm": 3.4351813793182373,
      "learning_rate": 0.0004855431993156544,
      "loss": 0.2459,
      "step": 4460
    },
    {
      "epoch": 13.41317365269461,
      "grad_norm": 9.591960906982422,
      "learning_rate": 0.00048502994011976046,
      "loss": 0.3367,
      "step": 4480
    },
    {
      "epoch": 13.47305389221557,
      "grad_norm": 4.0739898681640625,
      "learning_rate": 0.0004845166809238665,
      "loss": 0.3857,
      "step": 4500
    },
    {
      "epoch": 13.532934131736527,
      "grad_norm": 1.4556591510772705,
      "learning_rate": 0.0004840034217279726,
      "loss": 0.202,
      "step": 4520
    },
    {
      "epoch": 13.592814371257486,
      "grad_norm": 5.318310260772705,
      "learning_rate": 0.00048349016253207866,
      "loss": 0.3054,
      "step": 4540
    },
    {
      "epoch": 13.652694610778443,
      "grad_norm": 6.246960639953613,
      "learning_rate": 0.00048297690333618475,
      "loss": 0.3322,
      "step": 4560
    },
    {
      "epoch": 13.7125748502994,
      "grad_norm": 3.865100145339966,
      "learning_rate": 0.0004824636441402908,
      "loss": 0.2419,
      "step": 4580
    },
    {
      "epoch": 13.77245508982036,
      "grad_norm": 0.4802861511707306,
      "learning_rate": 0.00048195038494439687,
      "loss": 0.3032,
      "step": 4600
    },
    {
      "epoch": 13.832335329341317,
      "grad_norm": 3.3573460578918457,
      "learning_rate": 0.00048143712574850295,
      "loss": 0.3794,
      "step": 4620
    },
    {
      "epoch": 13.892215568862275,
      "grad_norm": 1.9500569105148315,
      "learning_rate": 0.00048092386655260904,
      "loss": 0.2313,
      "step": 4640
    },
    {
      "epoch": 13.952095808383234,
      "grad_norm": 7.687557220458984,
      "learning_rate": 0.0004804106073567151,
      "loss": 0.3065,
      "step": 4660
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.8651960784313726,
      "eval_accuracy_10": 0.8504901960784313,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8627450980392157,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8651960784313726,
      "eval_accuracy_20": 0.8627450980392157,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8529411764705882,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8602941176470589,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8847719522591646,
      "eval_f1": 0.9043478260869565,
      "eval_loss": 0.397605299949646,
      "eval_runtime": 212.9135,
      "eval_samples_per_second": 1.916,
      "eval_steps_per_second": 0.24,
      "step": 4676
    },
    {
      "epoch": 14.011976047904191,
      "grad_norm": 2.7383358478546143,
      "learning_rate": 0.00047989734816082115,
      "loss": 0.1857,
      "step": 4680
    },
    {
      "epoch": 14.071856287425149,
      "grad_norm": 6.026001453399658,
      "learning_rate": 0.00047938408896492724,
      "loss": 0.2767,
      "step": 4700
    },
    {
      "epoch": 14.131736526946108,
      "grad_norm": 2.0068111419677734,
      "learning_rate": 0.0004788708297690333,
      "loss": 0.2835,
      "step": 4720
    },
    {
      "epoch": 14.191616766467066,
      "grad_norm": 5.57038688659668,
      "learning_rate": 0.0004783575705731394,
      "loss": 0.2282,
      "step": 4740
    },
    {
      "epoch": 14.251497005988025,
      "grad_norm": 1.1998820304870605,
      "learning_rate": 0.00047784431137724544,
      "loss": 0.1977,
      "step": 4760
    },
    {
      "epoch": 14.311377245508982,
      "grad_norm": 3.021491765975952,
      "learning_rate": 0.0004773310521813515,
      "loss": 0.2396,
      "step": 4780
    },
    {
      "epoch": 14.37125748502994,
      "grad_norm": 2.3788676261901855,
      "learning_rate": 0.0004768177929854576,
      "loss": 0.3469,
      "step": 4800
    },
    {
      "epoch": 14.431137724550899,
      "grad_norm": 2.1162161827087402,
      "learning_rate": 0.0004763045337895637,
      "loss": 0.2204,
      "step": 4820
    },
    {
      "epoch": 14.491017964071856,
      "grad_norm": 5.254051208496094,
      "learning_rate": 0.0004757912745936698,
      "loss": 0.3218,
      "step": 4840
    },
    {
      "epoch": 14.550898203592814,
      "grad_norm": 3.0026209354400635,
      "learning_rate": 0.0004752780153977758,
      "loss": 0.2502,
      "step": 4860
    },
    {
      "epoch": 14.610778443113773,
      "grad_norm": 4.401191711425781,
      "learning_rate": 0.0004747647562018819,
      "loss": 0.3392,
      "step": 4880
    },
    {
      "epoch": 14.67065868263473,
      "grad_norm": 5.285458087921143,
      "learning_rate": 0.000474251497005988,
      "loss": 0.2788,
      "step": 4900
    },
    {
      "epoch": 14.730538922155688,
      "grad_norm": 4.261010646820068,
      "learning_rate": 0.00047373823781009407,
      "loss": 0.3155,
      "step": 4920
    },
    {
      "epoch": 14.790419161676647,
      "grad_norm": 0.8265636563301086,
      "learning_rate": 0.0004732249786142001,
      "loss": 0.2837,
      "step": 4940
    },
    {
      "epoch": 14.850299401197605,
      "grad_norm": 5.885661602020264,
      "learning_rate": 0.0004727117194183062,
      "loss": 0.2177,
      "step": 4960
    },
    {
      "epoch": 14.910179640718562,
      "grad_norm": 8.718489646911621,
      "learning_rate": 0.00047219846022241227,
      "loss": 0.2498,
      "step": 4980
    },
    {
      "epoch": 14.970059880239521,
      "grad_norm": 13.910058975219727,
      "learning_rate": 0.00047168520102651836,
      "loss": 0.3092,
      "step": 5000
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_accuracy_10": 0.8627450980392157,
      "eval_accuracy_11": 0.8627450980392157,
      "eval_accuracy_12": 0.8651960784313726,
      "eval_accuracy_13": 0.8602941176470589,
      "eval_accuracy_14": 0.8602941176470589,
      "eval_accuracy_15": 0.8651960784313726,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8602941176470589,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8627450980392157,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8602941176470589,
      "eval_accuracy_23": 0.8602941176470589,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8578431372549019,
      "eval_combined_score": 0.8817599620493359,
      "eval_f1": 0.9032258064516129,
      "eval_loss": 0.43134576082229614,
      "eval_runtime": 212.3314,
      "eval_samples_per_second": 1.922,
      "eval_steps_per_second": 0.24,
      "step": 5010
    },
    {
      "epoch": 15.029940119760479,
      "grad_norm": 1.704479455947876,
      "learning_rate": 0.00047117194183062444,
      "loss": 0.2667,
      "step": 5020
    },
    {
      "epoch": 15.089820359281438,
      "grad_norm": 12.93994140625,
      "learning_rate": 0.00047065868263473047,
      "loss": 0.2658,
      "step": 5040
    },
    {
      "epoch": 15.149700598802395,
      "grad_norm": 4.430103778839111,
      "learning_rate": 0.00047014542343883656,
      "loss": 0.3096,
      "step": 5060
    },
    {
      "epoch": 15.209580838323353,
      "grad_norm": 4.523717403411865,
      "learning_rate": 0.00046963216424294264,
      "loss": 0.2073,
      "step": 5080
    },
    {
      "epoch": 15.269461077844312,
      "grad_norm": 4.897899627685547,
      "learning_rate": 0.00046911890504704873,
      "loss": 0.279,
      "step": 5100
    },
    {
      "epoch": 15.32934131736527,
      "grad_norm": 4.358017921447754,
      "learning_rate": 0.00046860564585115476,
      "loss": 0.2782,
      "step": 5120
    },
    {
      "epoch": 15.389221556886227,
      "grad_norm": 1.6505379676818848,
      "learning_rate": 0.00046809238665526085,
      "loss": 0.3169,
      "step": 5140
    },
    {
      "epoch": 15.449101796407186,
      "grad_norm": 7.602416038513184,
      "learning_rate": 0.00046757912745936693,
      "loss": 0.3216,
      "step": 5160
    },
    {
      "epoch": 15.508982035928144,
      "grad_norm": 4.121583938598633,
      "learning_rate": 0.000467065868263473,
      "loss": 0.2126,
      "step": 5180
    },
    {
      "epoch": 15.568862275449101,
      "grad_norm": 6.035893440246582,
      "learning_rate": 0.0004665526090675791,
      "loss": 0.2134,
      "step": 5200
    },
    {
      "epoch": 15.62874251497006,
      "grad_norm": 3.558452606201172,
      "learning_rate": 0.00046603934987168513,
      "loss": 0.2061,
      "step": 5220
    },
    {
      "epoch": 15.688622754491018,
      "grad_norm": 7.301466941833496,
      "learning_rate": 0.0004655260906757912,
      "loss": 0.337,
      "step": 5240
    },
    {
      "epoch": 15.748502994011975,
      "grad_norm": 5.5150227546691895,
      "learning_rate": 0.0004650128314798973,
      "loss": 0.3137,
      "step": 5260
    },
    {
      "epoch": 15.808383233532934,
      "grad_norm": 6.66827392578125,
      "learning_rate": 0.0004644995722840034,
      "loss": 0.2022,
      "step": 5280
    },
    {
      "epoch": 15.868263473053892,
      "grad_norm": 4.595180511474609,
      "learning_rate": 0.0004639863130881094,
      "loss": 0.2984,
      "step": 5300
    },
    {
      "epoch": 15.928143712574851,
      "grad_norm": 3.965491533279419,
      "learning_rate": 0.0004634730538922155,
      "loss": 0.3427,
      "step": 5320
    },
    {
      "epoch": 15.988023952095809,
      "grad_norm": 4.166816234588623,
      "learning_rate": 0.0004629597946963216,
      "loss": 0.2683,
      "step": 5340
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_accuracy_10": 0.8504901960784313,
      "eval_accuracy_11": 0.8455882352941176,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8627450980392157,
      "eval_accuracy_18": 0.8627450980392157,
      "eval_accuracy_19": 0.8627450980392157,
      "eval_accuracy_20": 0.8578431372549019,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8790933899332929,
      "eval_f1": 0.9003436426116839,
      "eval_loss": 0.40082624554634094,
      "eval_runtime": 225.1867,
      "eval_samples_per_second": 1.812,
      "eval_steps_per_second": 0.226,
      "step": 5344
    },
    {
      "epoch": 16.047904191616766,
      "grad_norm": 4.716643810272217,
      "learning_rate": 0.0004624465355004277,
      "loss": 0.2231,
      "step": 5360
    },
    {
      "epoch": 16.107784431137723,
      "grad_norm": 18.881052017211914,
      "learning_rate": 0.0004619332763045337,
      "loss": 0.3312,
      "step": 5380
    },
    {
      "epoch": 16.16766467065868,
      "grad_norm": 4.892086982727051,
      "learning_rate": 0.0004614200171086398,
      "loss": 0.3216,
      "step": 5400
    },
    {
      "epoch": 16.227544910179642,
      "grad_norm": 4.640265464782715,
      "learning_rate": 0.0004609067579127459,
      "loss": 0.2167,
      "step": 5420
    },
    {
      "epoch": 16.2874251497006,
      "grad_norm": 7.654716968536377,
      "learning_rate": 0.00046039349871685196,
      "loss": 0.3159,
      "step": 5440
    },
    {
      "epoch": 16.347305389221557,
      "grad_norm": 0.8010303974151611,
      "learning_rate": 0.00045988023952095805,
      "loss": 0.227,
      "step": 5460
    },
    {
      "epoch": 16.407185628742514,
      "grad_norm": 5.913218021392822,
      "learning_rate": 0.0004593669803250641,
      "loss": 0.3101,
      "step": 5480
    },
    {
      "epoch": 16.46706586826347,
      "grad_norm": 17.01060676574707,
      "learning_rate": 0.00045885372112917016,
      "loss": 0.2798,
      "step": 5500
    },
    {
      "epoch": 16.526946107784433,
      "grad_norm": 3.5357303619384766,
      "learning_rate": 0.00045834046193327625,
      "loss": 0.1544,
      "step": 5520
    },
    {
      "epoch": 16.58682634730539,
      "grad_norm": 4.812244415283203,
      "learning_rate": 0.00045782720273738234,
      "loss": 0.383,
      "step": 5540
    },
    {
      "epoch": 16.646706586826348,
      "grad_norm": 6.745712757110596,
      "learning_rate": 0.00045731394354148837,
      "loss": 0.2813,
      "step": 5560
    },
    {
      "epoch": 16.706586826347305,
      "grad_norm": 24.57972526550293,
      "learning_rate": 0.00045680068434559445,
      "loss": 0.3229,
      "step": 5580
    },
    {
      "epoch": 16.766467065868262,
      "grad_norm": 1.0740814208984375,
      "learning_rate": 0.00045628742514970054,
      "loss": 0.3359,
      "step": 5600
    },
    {
      "epoch": 16.82634730538922,
      "grad_norm": 1.41206955909729,
      "learning_rate": 0.0004557741659538066,
      "loss": 0.2519,
      "step": 5620
    },
    {
      "epoch": 16.88622754491018,
      "grad_norm": 0.17928700149059296,
      "learning_rate": 0.00045526090675791276,
      "loss": 0.2956,
      "step": 5640
    },
    {
      "epoch": 16.94610778443114,
      "grad_norm": 1.9444135427474976,
      "learning_rate": 0.00045474764756201874,
      "loss": 0.1511,
      "step": 5660
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8578431372549019,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8578431372549019,
      "eval_accuracy_14": 0.8627450980392157,
      "eval_accuracy_15": 0.8651960784313726,
      "eval_accuracy_16": 0.8676470588235294,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8578431372549019,
      "eval_accuracy_20": 0.8651960784313726,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8602941176470589,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8602941176470589,
      "eval_combined_score": 0.8812619816365654,
      "eval_f1": 0.902229845626072,
      "eval_loss": 0.5148725509643555,
      "eval_runtime": 226.1598,
      "eval_samples_per_second": 1.804,
      "eval_steps_per_second": 0.226,
      "step": 5678
    },
    {
      "epoch": 17.005988023952096,
      "grad_norm": 5.2501349449157715,
      "learning_rate": 0.0004542343883661248,
      "loss": 0.2554,
      "step": 5680
    },
    {
      "epoch": 17.065868263473053,
      "grad_norm": 1.4982609748840332,
      "learning_rate": 0.0004537211291702309,
      "loss": 0.4024,
      "step": 5700
    },
    {
      "epoch": 17.12574850299401,
      "grad_norm": 1.2215747833251953,
      "learning_rate": 0.00045320786997433705,
      "loss": 0.2991,
      "step": 5720
    },
    {
      "epoch": 17.18562874251497,
      "grad_norm": 2.259282350540161,
      "learning_rate": 0.000452694610778443,
      "loss": 0.1826,
      "step": 5740
    },
    {
      "epoch": 17.24550898203593,
      "grad_norm": 6.385440349578857,
      "learning_rate": 0.0004521813515825491,
      "loss": 0.3231,
      "step": 5760
    },
    {
      "epoch": 17.305389221556887,
      "grad_norm": 2.376189708709717,
      "learning_rate": 0.0004516680923866552,
      "loss": 0.2598,
      "step": 5780
    },
    {
      "epoch": 17.365269461077844,
      "grad_norm": 0.5617302060127258,
      "learning_rate": 0.00045115483319076134,
      "loss": 0.218,
      "step": 5800
    },
    {
      "epoch": 17.4251497005988,
      "grad_norm": 0.3727525770664215,
      "learning_rate": 0.0004506415739948674,
      "loss": 0.2646,
      "step": 5820
    },
    {
      "epoch": 17.48502994011976,
      "grad_norm": 5.246517658233643,
      "learning_rate": 0.0004501283147989734,
      "loss": 0.2745,
      "step": 5840
    },
    {
      "epoch": 17.54491017964072,
      "grad_norm": 4.137659549713135,
      "learning_rate": 0.0004496150556030795,
      "loss": 0.2197,
      "step": 5860
    },
    {
      "epoch": 17.604790419161677,
      "grad_norm": 1.6710222959518433,
      "learning_rate": 0.0004491017964071856,
      "loss": 0.3152,
      "step": 5880
    },
    {
      "epoch": 17.664670658682635,
      "grad_norm": 5.283569812774658,
      "learning_rate": 0.0004485885372112917,
      "loss": 0.2458,
      "step": 5900
    },
    {
      "epoch": 17.724550898203592,
      "grad_norm": 3.5217092037200928,
      "learning_rate": 0.0004480752780153977,
      "loss": 0.2501,
      "step": 5920
    },
    {
      "epoch": 17.78443113772455,
      "grad_norm": 2.1806302070617676,
      "learning_rate": 0.00044756201881950377,
      "loss": 0.2712,
      "step": 5940
    },
    {
      "epoch": 17.84431137724551,
      "grad_norm": 5.01891565322876,
      "learning_rate": 0.0004470487596236099,
      "loss": 0.3004,
      "step": 5960
    },
    {
      "epoch": 17.904191616766468,
      "grad_norm": 2.828833818435669,
      "learning_rate": 0.000446535500427716,
      "loss": 0.1692,
      "step": 5980
    },
    {
      "epoch": 17.964071856287426,
      "grad_norm": 4.858027935028076,
      "learning_rate": 0.0004460222412318221,
      "loss": 0.2883,
      "step": 6000
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8578431372549019,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8627450980392157,
      "eval_accuracy_14": 0.8651960784313726,
      "eval_accuracy_15": 0.8627450980392157,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8578431372549019,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8602941176470589,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8578431372549019,
      "eval_combined_score": 0.8763917306052855,
      "eval_f1": 0.897391304347826,
      "eval_loss": 0.40657761693000793,
      "eval_runtime": 215.2738,
      "eval_samples_per_second": 1.895,
      "eval_steps_per_second": 0.237,
      "step": 6012
    },
    {
      "epoch": 18.023952095808383,
      "grad_norm": 11.800222396850586,
      "learning_rate": 0.0004455089820359281,
      "loss": 0.2619,
      "step": 6020
    },
    {
      "epoch": 18.08383233532934,
      "grad_norm": 2.047377109527588,
      "learning_rate": 0.0004449957228400342,
      "loss": 0.2041,
      "step": 6040
    },
    {
      "epoch": 18.143712574850298,
      "grad_norm": 4.510089874267578,
      "learning_rate": 0.0004444824636441403,
      "loss": 0.2577,
      "step": 6060
    },
    {
      "epoch": 18.20359281437126,
      "grad_norm": 5.89771032333374,
      "learning_rate": 0.00044396920444824637,
      "loss": 0.3125,
      "step": 6080
    },
    {
      "epoch": 18.263473053892216,
      "grad_norm": 3.008802890777588,
      "learning_rate": 0.0004434559452523524,
      "loss": 0.1911,
      "step": 6100
    },
    {
      "epoch": 18.323353293413174,
      "grad_norm": 4.925946235656738,
      "learning_rate": 0.0004429426860564585,
      "loss": 0.2856,
      "step": 6120
    },
    {
      "epoch": 18.38323353293413,
      "grad_norm": 1.997543454170227,
      "learning_rate": 0.00044242942686056457,
      "loss": 0.2278,
      "step": 6140
    },
    {
      "epoch": 18.44311377245509,
      "grad_norm": 4.17555570602417,
      "learning_rate": 0.00044191616766467066,
      "loss": 0.2568,
      "step": 6160
    },
    {
      "epoch": 18.50299401197605,
      "grad_norm": 2.4502663612365723,
      "learning_rate": 0.0004414029084687767,
      "loss": 0.27,
      "step": 6180
    },
    {
      "epoch": 18.562874251497007,
      "grad_norm": 1.5677253007888794,
      "learning_rate": 0.00044088964927288277,
      "loss": 0.2609,
      "step": 6200
    },
    {
      "epoch": 18.622754491017965,
      "grad_norm": 9.535093307495117,
      "learning_rate": 0.00044037639007698886,
      "loss": 0.3188,
      "step": 6220
    },
    {
      "epoch": 18.682634730538922,
      "grad_norm": 4.511999607086182,
      "learning_rate": 0.00043986313088109494,
      "loss": 0.2817,
      "step": 6240
    },
    {
      "epoch": 18.74251497005988,
      "grad_norm": 33.439937591552734,
      "learning_rate": 0.00043934987168520103,
      "loss": 0.235,
      "step": 6260
    },
    {
      "epoch": 18.802395209580837,
      "grad_norm": 3.131812810897827,
      "learning_rate": 0.00043883661248930706,
      "loss": 0.159,
      "step": 6280
    },
    {
      "epoch": 18.862275449101798,
      "grad_norm": 1.7299774885177612,
      "learning_rate": 0.00043832335329341314,
      "loss": 0.1603,
      "step": 6300
    },
    {
      "epoch": 18.922155688622755,
      "grad_norm": 1.9234988689422607,
      "learning_rate": 0.00043781009409751923,
      "loss": 0.2458,
      "step": 6320
    },
    {
      "epoch": 18.982035928143713,
      "grad_norm": 2.5797595977783203,
      "learning_rate": 0.0004372968349016253,
      "loss": 0.2665,
      "step": 6340
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.8676470588235294,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8553921568627451,
      "eval_accuracy_13": 0.8578431372549019,
      "eval_accuracy_14": 0.8602941176470589,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8627450980392157,
      "eval_accuracy_18": 0.8651960784313726,
      "eval_accuracy_19": 0.8651960784313726,
      "eval_accuracy_20": 0.8627450980392157,
      "eval_accuracy_21": 0.8651960784313726,
      "eval_accuracy_22": 0.8651960784313726,
      "eval_accuracy_23": 0.8627450980392157,
      "eval_accuracy_24": 0.8627450980392157,
      "eval_accuracy_25": 0.8651960784313726,
      "eval_combined_score": 0.8872718052738338,
      "eval_f1": 0.906896551724138,
      "eval_loss": 0.45521506667137146,
      "eval_runtime": 237.1059,
      "eval_samples_per_second": 1.721,
      "eval_steps_per_second": 0.215,
      "step": 6346
    },
    {
      "epoch": 19.04191616766467,
      "grad_norm": 3.7306551933288574,
      "learning_rate": 0.00043678357570573135,
      "loss": 0.1838,
      "step": 6360
    },
    {
      "epoch": 19.101796407185628,
      "grad_norm": 7.722446441650391,
      "learning_rate": 0.00043627031650983743,
      "loss": 0.1817,
      "step": 6380
    },
    {
      "epoch": 19.161676646706585,
      "grad_norm": 9.55370807647705,
      "learning_rate": 0.0004357570573139435,
      "loss": 0.3759,
      "step": 6400
    },
    {
      "epoch": 19.221556886227546,
      "grad_norm": 6.598506927490234,
      "learning_rate": 0.0004352437981180496,
      "loss": 0.3,
      "step": 6420
    },
    {
      "epoch": 19.281437125748504,
      "grad_norm": 4.581058025360107,
      "learning_rate": 0.0004347305389221557,
      "loss": 0.14,
      "step": 6440
    },
    {
      "epoch": 19.34131736526946,
      "grad_norm": 5.651775360107422,
      "learning_rate": 0.0004342172797262617,
      "loss": 0.203,
      "step": 6460
    },
    {
      "epoch": 19.40119760479042,
      "grad_norm": 8.018948554992676,
      "learning_rate": 0.0004337040205303678,
      "loss": 0.3436,
      "step": 6480
    },
    {
      "epoch": 19.461077844311376,
      "grad_norm": 2.9529147148132324,
      "learning_rate": 0.0004331907613344739,
      "loss": 0.3626,
      "step": 6500
    },
    {
      "epoch": 19.520958083832337,
      "grad_norm": 7.239572525024414,
      "learning_rate": 0.00043267750213858,
      "loss": 0.1912,
      "step": 6520
    },
    {
      "epoch": 19.580838323353294,
      "grad_norm": 6.025620937347412,
      "learning_rate": 0.000432164242942686,
      "loss": 0.2834,
      "step": 6540
    },
    {
      "epoch": 19.64071856287425,
      "grad_norm": 3.374380350112915,
      "learning_rate": 0.0004316509837467921,
      "loss": 0.1595,
      "step": 6560
    },
    {
      "epoch": 19.70059880239521,
      "grad_norm": 8.892724990844727,
      "learning_rate": 0.0004311377245508982,
      "loss": 0.2965,
      "step": 6580
    },
    {
      "epoch": 19.760479041916167,
      "grad_norm": 6.323834419250488,
      "learning_rate": 0.00043062446535500426,
      "loss": 0.1493,
      "step": 6600
    },
    {
      "epoch": 19.820359281437124,
      "grad_norm": 9.175785064697266,
      "learning_rate": 0.00043011120615911035,
      "loss": 0.3914,
      "step": 6620
    },
    {
      "epoch": 19.880239520958085,
      "grad_norm": 0.8098928332328796,
      "learning_rate": 0.0004295979469632164,
      "loss": 0.2093,
      "step": 6640
    },
    {
      "epoch": 19.940119760479043,
      "grad_norm": 1.8111298084259033,
      "learning_rate": 0.00042908468776732246,
      "loss": 0.2605,
      "step": 6660
    },
    {
      "epoch": 20.0,
      "grad_norm": 4.232679843902588,
      "learning_rate": 0.00042857142857142855,
      "loss": 0.2353,
      "step": 6680
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_accuracy_10": 0.8627450980392157,
      "eval_accuracy_11": 0.8578431372549019,
      "eval_accuracy_12": 0.8627450980392157,
      "eval_accuracy_13": 0.8627450980392157,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8578431372549019,
      "eval_accuracy_20": 0.8578431372549019,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8529411764705882,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.8796018407362944,
      "eval_f1": 0.901360544217687,
      "eval_loss": 0.433159738779068,
      "eval_runtime": 205.8145,
      "eval_samples_per_second": 1.982,
      "eval_steps_per_second": 0.248,
      "step": 6680
    },
    {
      "epoch": 20.059880239520957,
      "grad_norm": 5.203393936157227,
      "learning_rate": 0.00042805816937553463,
      "loss": 0.2302,
      "step": 6700
    },
    {
      "epoch": 20.119760479041915,
      "grad_norm": 1.9031604528427124,
      "learning_rate": 0.00042754491017964067,
      "loss": 0.2462,
      "step": 6720
    },
    {
      "epoch": 20.179640718562876,
      "grad_norm": 1.2461915016174316,
      "learning_rate": 0.00042703165098374675,
      "loss": 0.1945,
      "step": 6740
    },
    {
      "epoch": 20.239520958083833,
      "grad_norm": 7.6703386306762695,
      "learning_rate": 0.00042651839178785284,
      "loss": 0.3256,
      "step": 6760
    },
    {
      "epoch": 20.29940119760479,
      "grad_norm": 0.4439413845539093,
      "learning_rate": 0.0004260051325919589,
      "loss": 0.2448,
      "step": 6780
    },
    {
      "epoch": 20.35928143712575,
      "grad_norm": 4.412731647491455,
      "learning_rate": 0.000425491873396065,
      "loss": 0.2203,
      "step": 6800
    },
    {
      "epoch": 20.419161676646706,
      "grad_norm": 16.24985122680664,
      "learning_rate": 0.00042497861420017104,
      "loss": 0.1519,
      "step": 6820
    },
    {
      "epoch": 20.479041916167663,
      "grad_norm": 12.000653266906738,
      "learning_rate": 0.0004244653550042771,
      "loss": 0.2838,
      "step": 6840
    },
    {
      "epoch": 20.538922155688624,
      "grad_norm": 1.7618122100830078,
      "learning_rate": 0.0004239520958083832,
      "loss": 0.2206,
      "step": 6860
    },
    {
      "epoch": 20.59880239520958,
      "grad_norm": 5.532967567443848,
      "learning_rate": 0.0004234388366124893,
      "loss": 0.2952,
      "step": 6880
    },
    {
      "epoch": 20.65868263473054,
      "grad_norm": 3.9665262699127197,
      "learning_rate": 0.0004229255774165953,
      "loss": 0.1906,
      "step": 6900
    },
    {
      "epoch": 20.718562874251496,
      "grad_norm": 2.3747944831848145,
      "learning_rate": 0.0004224123182207014,
      "loss": 0.3028,
      "step": 6920
    },
    {
      "epoch": 20.778443113772454,
      "grad_norm": 0.7960200905799866,
      "learning_rate": 0.0004218990590248075,
      "loss": 0.2368,
      "step": 6940
    },
    {
      "epoch": 20.83832335329341,
      "grad_norm": 9.155211448669434,
      "learning_rate": 0.0004213857998289136,
      "loss": 0.2153,
      "step": 6960
    },
    {
      "epoch": 20.898203592814372,
      "grad_norm": 4.580178260803223,
      "learning_rate": 0.0004208725406330196,
      "loss": 0.2619,
      "step": 6980
    },
    {
      "epoch": 20.95808383233533,
      "grad_norm": 2.1945183277130127,
      "learning_rate": 0.0004203592814371257,
      "loss": 0.2157,
      "step": 7000
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8627450980392157,
      "eval_accuracy_13": 0.8627450980392157,
      "eval_accuracy_14": 0.8602941176470589,
      "eval_accuracy_15": 0.8676470588235294,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8627450980392157,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8578431372549019,
      "eval_accuracy_20": 0.8553921568627451,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8602941176470589,
      "eval_accuracy_25": 0.8602941176470589,
      "eval_combined_score": 0.8796018407362944,
      "eval_f1": 0.901360544217687,
      "eval_loss": 0.40903374552726746,
      "eval_runtime": 203.7414,
      "eval_samples_per_second": 2.003,
      "eval_steps_per_second": 0.25,
      "step": 7014
    },
    {
      "epoch": 21.017964071856287,
      "grad_norm": 4.669585227966309,
      "learning_rate": 0.0004198460222412318,
      "loss": 0.3306,
      "step": 7020
    },
    {
      "epoch": 21.077844311377245,
      "grad_norm": 3.842742919921875,
      "learning_rate": 0.00041933276304533787,
      "loss": 0.1909,
      "step": 7040
    },
    {
      "epoch": 21.137724550898202,
      "grad_norm": 6.610357284545898,
      "learning_rate": 0.00041881950384944395,
      "loss": 0.2634,
      "step": 7060
    },
    {
      "epoch": 21.197604790419163,
      "grad_norm": 4.259194374084473,
      "learning_rate": 0.00041830624465355,
      "loss": 0.1905,
      "step": 7080
    },
    {
      "epoch": 21.25748502994012,
      "grad_norm": 2.5172624588012695,
      "learning_rate": 0.00041779298545765607,
      "loss": 0.2038,
      "step": 7100
    },
    {
      "epoch": 21.317365269461078,
      "grad_norm": 4.834283351898193,
      "learning_rate": 0.00041727972626176216,
      "loss": 0.3246,
      "step": 7120
    },
    {
      "epoch": 21.377245508982035,
      "grad_norm": 7.643441677093506,
      "learning_rate": 0.00041676646706586824,
      "loss": 0.2066,
      "step": 7140
    },
    {
      "epoch": 21.437125748502993,
      "grad_norm": 3.2573492527008057,
      "learning_rate": 0.00041625320786997427,
      "loss": 0.2575,
      "step": 7160
    },
    {
      "epoch": 21.49700598802395,
      "grad_norm": 2.342587947845459,
      "learning_rate": 0.00041573994867408036,
      "loss": 0.2492,
      "step": 7180
    },
    {
      "epoch": 21.55688622754491,
      "grad_norm": 10.073022842407227,
      "learning_rate": 0.00041522668947818644,
      "loss": 0.2225,
      "step": 7200
    },
    {
      "epoch": 21.61676646706587,
      "grad_norm": 3.569196939468384,
      "learning_rate": 0.00041471343028229253,
      "loss": 0.2668,
      "step": 7220
    },
    {
      "epoch": 21.676646706586826,
      "grad_norm": 5.580859184265137,
      "learning_rate": 0.0004142001710863986,
      "loss": 0.2136,
      "step": 7240
    },
    {
      "epoch": 21.736526946107784,
      "grad_norm": 10.979632377624512,
      "learning_rate": 0.00041368691189050464,
      "loss": 0.3085,
      "step": 7260
    },
    {
      "epoch": 21.79640718562874,
      "grad_norm": 3.198659658432007,
      "learning_rate": 0.00041317365269461073,
      "loss": 0.2625,
      "step": 7280
    },
    {
      "epoch": 21.856287425149702,
      "grad_norm": 3.4929001331329346,
      "learning_rate": 0.0004126603934987168,
      "loss": 0.2404,
      "step": 7300
    },
    {
      "epoch": 21.91616766467066,
      "grad_norm": 8.187590599060059,
      "learning_rate": 0.0004121471343028229,
      "loss": 0.2261,
      "step": 7320
    },
    {
      "epoch": 21.976047904191617,
      "grad_norm": 5.441122531890869,
      "learning_rate": 0.00041163387510692893,
      "loss": 0.2533,
      "step": 7340
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.8529411764705882,
      "eval_accuracy_10": 0.8578431372549019,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8504901960784313,
      "eval_accuracy_21": 0.8480392156862745,
      "eval_accuracy_22": 0.8480392156862745,
      "eval_accuracy_23": 0.8480392156862745,
      "eval_accuracy_24": 0.8504901960784313,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8749241964827168,
      "eval_f1": 0.8969072164948454,
      "eval_loss": 0.45304471254348755,
      "eval_runtime": 203.819,
      "eval_samples_per_second": 2.002,
      "eval_steps_per_second": 0.25,
      "step": 7348
    },
    {
      "epoch": 22.035928143712574,
      "grad_norm": 5.5344390869140625,
      "learning_rate": 0.000411120615911035,
      "loss": 0.151,
      "step": 7360
    },
    {
      "epoch": 22.095808383233532,
      "grad_norm": 3.741905450820923,
      "learning_rate": 0.0004106073567151411,
      "loss": 0.2606,
      "step": 7380
    },
    {
      "epoch": 22.15568862275449,
      "grad_norm": 6.666343688964844,
      "learning_rate": 0.0004100940975192472,
      "loss": 0.2402,
      "step": 7400
    },
    {
      "epoch": 22.21556886227545,
      "grad_norm": 3.2950093746185303,
      "learning_rate": 0.0004095808383233533,
      "loss": 0.2094,
      "step": 7420
    },
    {
      "epoch": 22.275449101796408,
      "grad_norm": 6.624527454376221,
      "learning_rate": 0.0004090675791274593,
      "loss": 0.1448,
      "step": 7440
    },
    {
      "epoch": 22.335329341317365,
      "grad_norm": 3.6131434440612793,
      "learning_rate": 0.0004085543199315654,
      "loss": 0.2541,
      "step": 7460
    },
    {
      "epoch": 22.395209580838323,
      "grad_norm": 2.6455507278442383,
      "learning_rate": 0.0004080410607356715,
      "loss": 0.1876,
      "step": 7480
    },
    {
      "epoch": 22.45508982035928,
      "grad_norm": 0.508755087852478,
      "learning_rate": 0.00040752780153977756,
      "loss": 0.3253,
      "step": 7500
    },
    {
      "epoch": 22.51497005988024,
      "grad_norm": 8.42805004119873,
      "learning_rate": 0.0004070145423438836,
      "loss": 0.3149,
      "step": 7520
    },
    {
      "epoch": 22.5748502994012,
      "grad_norm": 0.9558829069137573,
      "learning_rate": 0.0004065012831479897,
      "loss": 0.2672,
      "step": 7540
    },
    {
      "epoch": 22.634730538922156,
      "grad_norm": 2.2804653644561768,
      "learning_rate": 0.00040598802395209576,
      "loss": 0.2168,
      "step": 7560
    },
    {
      "epoch": 22.694610778443113,
      "grad_norm": 4.942838191986084,
      "learning_rate": 0.00040547476475620185,
      "loss": 0.2449,
      "step": 7580
    },
    {
      "epoch": 22.75449101796407,
      "grad_norm": 0.7222310900688171,
      "learning_rate": 0.00040496150556030793,
      "loss": 0.1856,
      "step": 7600
    },
    {
      "epoch": 22.81437125748503,
      "grad_norm": 7.8669352531433105,
      "learning_rate": 0.00040444824636441396,
      "loss": 0.2448,
      "step": 7620
    },
    {
      "epoch": 22.87425149700599,
      "grad_norm": 4.581406593322754,
      "learning_rate": 0.00040393498716852005,
      "loss": 0.2568,
      "step": 7640
    },
    {
      "epoch": 22.934131736526947,
      "grad_norm": 3.601301908493042,
      "learning_rate": 0.00040342172797262613,
      "loss": 0.2229,
      "step": 7660
    },
    {
      "epoch": 22.994011976047904,
      "grad_norm": 10.266254425048828,
      "learning_rate": 0.0004029084687767322,
      "loss": 0.245,
      "step": 7680
    },
    {
      "epoch": 23.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8578431372549019,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8602941176470589,
      "eval_accuracy_18": 0.8602941176470589,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8578431372549019,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8578431372549019,
      "eval_combined_score": 0.8782222679281503,
      "eval_f1": 0.8986013986013986,
      "eval_loss": 0.4722978472709656,
      "eval_runtime": 204.0102,
      "eval_samples_per_second": 2.0,
      "eval_steps_per_second": 0.25,
      "step": 7682
    },
    {
      "epoch": 23.05389221556886,
      "grad_norm": 6.455636978149414,
      "learning_rate": 0.00040239520958083825,
      "loss": 0.1897,
      "step": 7700
    },
    {
      "epoch": 23.11377245508982,
      "grad_norm": 4.9314727783203125,
      "learning_rate": 0.00040188195038494434,
      "loss": 0.2131,
      "step": 7720
    },
    {
      "epoch": 23.17365269461078,
      "grad_norm": 0.6424026489257812,
      "learning_rate": 0.0004013686911890504,
      "loss": 0.1139,
      "step": 7740
    },
    {
      "epoch": 23.233532934131738,
      "grad_norm": 10.881915092468262,
      "learning_rate": 0.0004008554319931565,
      "loss": 0.3073,
      "step": 7760
    },
    {
      "epoch": 23.293413173652695,
      "grad_norm": 2.108348846435547,
      "learning_rate": 0.00040034217279726254,
      "loss": 0.2098,
      "step": 7780
    },
    {
      "epoch": 23.353293413173652,
      "grad_norm": 5.9636311531066895,
      "learning_rate": 0.0003998289136013686,
      "loss": 0.2306,
      "step": 7800
    },
    {
      "epoch": 23.41317365269461,
      "grad_norm": 9.042328834533691,
      "learning_rate": 0.0003993156544054747,
      "loss": 0.2649,
      "step": 7820
    },
    {
      "epoch": 23.473053892215567,
      "grad_norm": 2.6637837886810303,
      "learning_rate": 0.0003988023952095808,
      "loss": 0.2629,
      "step": 7840
    },
    {
      "epoch": 23.53293413173653,
      "grad_norm": 4.812868595123291,
      "learning_rate": 0.0003982891360136869,
      "loss": 0.2124,
      "step": 7860
    },
    {
      "epoch": 23.592814371257486,
      "grad_norm": 0.6484938263893127,
      "learning_rate": 0.0003977758768177929,
      "loss": 0.1908,
      "step": 7880
    },
    {
      "epoch": 23.652694610778443,
      "grad_norm": 4.810173988342285,
      "learning_rate": 0.000397262617621899,
      "loss": 0.2747,
      "step": 7900
    },
    {
      "epoch": 23.7125748502994,
      "grad_norm": 5.966800212860107,
      "learning_rate": 0.0003967493584260051,
      "loss": 0.2105,
      "step": 7920
    },
    {
      "epoch": 23.772455089820358,
      "grad_norm": 1.1179618835449219,
      "learning_rate": 0.00039623609923011117,
      "loss": 0.2276,
      "step": 7940
    },
    {
      "epoch": 23.83233532934132,
      "grad_norm": 4.413389205932617,
      "learning_rate": 0.0003957228400342172,
      "loss": 0.2948,
      "step": 7960
    },
    {
      "epoch": 23.892215568862277,
      "grad_norm": 3.02079701423645,
      "learning_rate": 0.0003952095808383233,
      "loss": 0.259,
      "step": 7980
    },
    {
      "epoch": 23.952095808383234,
      "grad_norm": 0.36484962701797485,
      "learning_rate": 0.00039469632164242937,
      "loss": 0.2505,
      "step": 8000
    },
    {
      "epoch": 24.0,
      "eval_accuracy": 0.8529411764705882,
      "eval_accuracy_10": 0.8455882352941176,
      "eval_accuracy_11": 0.8431372549019608,
      "eval_accuracy_12": 0.8480392156862745,
      "eval_accuracy_13": 0.8455882352941176,
      "eval_accuracy_14": 0.8480392156862745,
      "eval_accuracy_15": 0.8480392156862745,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8504901960784313,
      "eval_accuracy_18": 0.8504901960784313,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8529411764705882,
      "eval_accuracy_21": 0.8504901960784313,
      "eval_accuracy_22": 0.8529411764705882,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8578431372549019,
      "eval_combined_score": 0.8747464503042597,
      "eval_f1": 0.896551724137931,
      "eval_loss": 0.5171259045600891,
      "eval_runtime": 203.7909,
      "eval_samples_per_second": 2.002,
      "eval_steps_per_second": 0.25,
      "step": 8016
    },
    {
      "epoch": 24.01197604790419,
      "grad_norm": 40.63340759277344,
      "learning_rate": 0.00039418306244653545,
      "loss": 0.2816,
      "step": 8020
    },
    {
      "epoch": 24.07185628742515,
      "grad_norm": 0.3675876557826996,
      "learning_rate": 0.0003936698032506416,
      "loss": 0.2626,
      "step": 8040
    },
    {
      "epoch": 24.131736526946106,
      "grad_norm": 5.451335906982422,
      "learning_rate": 0.00039315654405474757,
      "loss": 0.2189,
      "step": 8060
    },
    {
      "epoch": 24.191616766467067,
      "grad_norm": 4.52438497543335,
      "learning_rate": 0.00039264328485885366,
      "loss": 0.1637,
      "step": 8080
    },
    {
      "epoch": 24.251497005988025,
      "grad_norm": 5.894973278045654,
      "learning_rate": 0.00039213002566295974,
      "loss": 0.2374,
      "step": 8100
    },
    {
      "epoch": 24.311377245508982,
      "grad_norm": 3.388559341430664,
      "learning_rate": 0.0003916167664670659,
      "loss": 0.2069,
      "step": 8120
    },
    {
      "epoch": 24.37125748502994,
      "grad_norm": 2.971435070037842,
      "learning_rate": 0.00039110350727117186,
      "loss": 0.2739,
      "step": 8140
    },
    {
      "epoch": 24.431137724550897,
      "grad_norm": 7.842030048370361,
      "learning_rate": 0.00039059024807527794,
      "loss": 0.2219,
      "step": 8160
    },
    {
      "epoch": 24.491017964071855,
      "grad_norm": 5.1422929763793945,
      "learning_rate": 0.0003900769888793841,
      "loss": 0.2354,
      "step": 8180
    },
    {
      "epoch": 24.550898203592816,
      "grad_norm": 7.247654438018799,
      "learning_rate": 0.00038956372968349017,
      "loss": 0.209,
      "step": 8200
    },
    {
      "epoch": 24.610778443113773,
      "grad_norm": 7.264695167541504,
      "learning_rate": 0.00038905047048759625,
      "loss": 0.2771,
      "step": 8220
    },
    {
      "epoch": 24.67065868263473,
      "grad_norm": 6.709504127502441,
      "learning_rate": 0.00038853721129170223,
      "loss": 0.3169,
      "step": 8240
    },
    {
      "epoch": 24.730538922155688,
      "grad_norm": 5.329006671905518,
      "learning_rate": 0.00038802395209580837,
      "loss": 0.2274,
      "step": 8260
    },
    {
      "epoch": 24.790419161676645,
      "grad_norm": 8.774713516235352,
      "learning_rate": 0.00038751069289991446,
      "loss": 0.3228,
      "step": 8280
    },
    {
      "epoch": 24.850299401197606,
      "grad_norm": 6.371893405914307,
      "learning_rate": 0.00038699743370402054,
      "loss": 0.1831,
      "step": 8300
    },
    {
      "epoch": 24.910179640718564,
      "grad_norm": 7.743559837341309,
      "learning_rate": 0.0003864841745081265,
      "loss": 0.1929,
      "step": 8320
    },
    {
      "epoch": 24.97005988023952,
      "grad_norm": 3.569146156311035,
      "learning_rate": 0.00038597091531223266,
      "loss": 0.2344,
      "step": 8340
    },
    {
      "epoch": 25.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8480392156862745,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8504901960784313,
      "eval_accuracy_14": 0.8504901960784313,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8529411764705882,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8553921568627451,
      "eval_accuracy_21": 0.8529411764705882,
      "eval_accuracy_22": 0.8529411764705882,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8770957353781993,
      "eval_f1": 0.8987993138936535,
      "eval_loss": 0.5206566452980042,
      "eval_runtime": 203.513,
      "eval_samples_per_second": 2.005,
      "eval_steps_per_second": 0.251,
      "step": 8350
    },
    {
      "epoch": 25.02994011976048,
      "grad_norm": 0.1901863068342209,
      "learning_rate": 0.00038545765611633874,
      "loss": 0.208,
      "step": 8360
    },
    {
      "epoch": 25.089820359281436,
      "grad_norm": 5.6383843421936035,
      "learning_rate": 0.00038494439692044483,
      "loss": 0.3356,
      "step": 8380
    },
    {
      "epoch": 25.149700598802394,
      "grad_norm": 4.384023189544678,
      "learning_rate": 0.0003844311377245509,
      "loss": 0.2235,
      "step": 8400
    },
    {
      "epoch": 25.209580838323355,
      "grad_norm": 2.2561519145965576,
      "learning_rate": 0.00038391787852865694,
      "loss": 0.1894,
      "step": 8420
    },
    {
      "epoch": 25.269461077844312,
      "grad_norm": 8.583490371704102,
      "learning_rate": 0.00038340461933276303,
      "loss": 0.2231,
      "step": 8440
    },
    {
      "epoch": 25.32934131736527,
      "grad_norm": 8.399455070495605,
      "learning_rate": 0.0003828913601368691,
      "loss": 0.2382,
      "step": 8460
    },
    {
      "epoch": 25.389221556886227,
      "grad_norm": 1.0900791883468628,
      "learning_rate": 0.0003823781009409752,
      "loss": 0.1583,
      "step": 8480
    },
    {
      "epoch": 25.449101796407184,
      "grad_norm": 6.37172794342041,
      "learning_rate": 0.00038186484174508123,
      "loss": 0.1812,
      "step": 8500
    },
    {
      "epoch": 25.508982035928145,
      "grad_norm": 5.176609039306641,
      "learning_rate": 0.0003813515825491873,
      "loss": 0.2358,
      "step": 8520
    },
    {
      "epoch": 25.568862275449103,
      "grad_norm": 9.296566009521484,
      "learning_rate": 0.0003808383233532934,
      "loss": 0.2339,
      "step": 8540
    },
    {
      "epoch": 25.62874251497006,
      "grad_norm": 4.95284366607666,
      "learning_rate": 0.0003803250641573995,
      "loss": 0.2695,
      "step": 8560
    },
    {
      "epoch": 25.688622754491018,
      "grad_norm": 7.462698459625244,
      "learning_rate": 0.0003798118049615055,
      "loss": 0.0958,
      "step": 8580
    },
    {
      "epoch": 25.748502994011975,
      "grad_norm": 1.6097335815429688,
      "learning_rate": 0.0003792985457656116,
      "loss": 0.1801,
      "step": 8600
    },
    {
      "epoch": 25.808383233532933,
      "grad_norm": 1.1364750862121582,
      "learning_rate": 0.0003787852865697177,
      "loss": 0.2536,
      "step": 8620
    },
    {
      "epoch": 25.868263473053894,
      "grad_norm": 2.4479260444641113,
      "learning_rate": 0.0003782720273738238,
      "loss": 0.288,
      "step": 8640
    },
    {
      "epoch": 25.92814371257485,
      "grad_norm": 5.997844219207764,
      "learning_rate": 0.00037775876817792986,
      "loss": 0.2597,
      "step": 8660
    },
    {
      "epoch": 25.98802395209581,
      "grad_norm": 3.7902650833129883,
      "learning_rate": 0.0003772455089820359,
      "loss": 0.2894,
      "step": 8680
    },
    {
      "epoch": 26.0,
      "eval_accuracy": 0.8480392156862745,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8602941176470589,
      "eval_accuracy_14": 0.8602941176470589,
      "eval_accuracy_15": 0.8627450980392157,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8602941176470589,
      "eval_accuracy_18": 0.8602941176470589,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8602941176470589,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8725245912318416,
      "eval_f1": 0.8970099667774086,
      "eval_loss": 0.5185214877128601,
      "eval_runtime": 203.5985,
      "eval_samples_per_second": 2.004,
      "eval_steps_per_second": 0.25,
      "step": 8684
    },
    {
      "epoch": 26.047904191616766,
      "grad_norm": 5.359076023101807,
      "learning_rate": 0.000376732249786142,
      "loss": 0.2627,
      "step": 8700
    },
    {
      "epoch": 26.107784431137723,
      "grad_norm": 16.499235153198242,
      "learning_rate": 0.00037621899059024806,
      "loss": 0.2909,
      "step": 8720
    },
    {
      "epoch": 26.16766467065868,
      "grad_norm": 9.920149803161621,
      "learning_rate": 0.00037570573139435415,
      "loss": 0.1974,
      "step": 8740
    },
    {
      "epoch": 26.227544910179642,
      "grad_norm": 10.280229568481445,
      "learning_rate": 0.0003751924721984602,
      "loss": 0.218,
      "step": 8760
    },
    {
      "epoch": 26.2874251497006,
      "grad_norm": 1.3502007722854614,
      "learning_rate": 0.00037467921300256626,
      "loss": 0.2209,
      "step": 8780
    },
    {
      "epoch": 26.347305389221557,
      "grad_norm": 7.5650954246521,
      "learning_rate": 0.00037416595380667235,
      "loss": 0.2645,
      "step": 8800
    },
    {
      "epoch": 26.407185628742514,
      "grad_norm": 17.461023330688477,
      "learning_rate": 0.00037365269461077843,
      "loss": 0.2598,
      "step": 8820
    },
    {
      "epoch": 26.46706586826347,
      "grad_norm": 10.490964889526367,
      "learning_rate": 0.0003731394354148845,
      "loss": 0.2331,
      "step": 8840
    },
    {
      "epoch": 26.526946107784433,
      "grad_norm": 2.368351697921753,
      "learning_rate": 0.00037262617621899055,
      "loss": 0.2974,
      "step": 8860
    },
    {
      "epoch": 26.58682634730539,
      "grad_norm": 2.813997745513916,
      "learning_rate": 0.00037211291702309664,
      "loss": 0.1241,
      "step": 8880
    },
    {
      "epoch": 26.646706586826348,
      "grad_norm": 0.7580224871635437,
      "learning_rate": 0.0003715996578272027,
      "loss": 0.2369,
      "step": 8900
    },
    {
      "epoch": 26.706586826347305,
      "grad_norm": 2.7061140537261963,
      "learning_rate": 0.0003710863986313088,
      "loss": 0.2996,
      "step": 8920
    },
    {
      "epoch": 26.766467065868262,
      "grad_norm": 9.527039527893066,
      "learning_rate": 0.00037057313943541484,
      "loss": 0.1428,
      "step": 8940
    },
    {
      "epoch": 26.82634730538922,
      "grad_norm": 1.179010033607483,
      "learning_rate": 0.0003700598802395209,
      "loss": 0.2005,
      "step": 8960
    },
    {
      "epoch": 26.88622754491018,
      "grad_norm": 1.3746885061264038,
      "learning_rate": 0.000369546621043627,
      "loss": 0.2529,
      "step": 8980
    },
    {
      "epoch": 26.94610778443114,
      "grad_norm": 6.781186103820801,
      "learning_rate": 0.0003690333618477331,
      "loss": 0.1651,
      "step": 9000
    },
    {
      "epoch": 27.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8627450980392157,
      "eval_accuracy_17": 0.8602941176470589,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8578431372549019,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8578431372549019,
      "eval_combined_score": 0.8802346244977852,
      "eval_f1": 0.9001751313485115,
      "eval_loss": 0.5428389310836792,
      "eval_runtime": 203.3388,
      "eval_samples_per_second": 2.007,
      "eval_steps_per_second": 0.251,
      "step": 9018
    },
    {
      "epoch": 27.005988023952096,
      "grad_norm": 9.522945404052734,
      "learning_rate": 0.0003685201026518392,
      "loss": 0.2027,
      "step": 9020
    },
    {
      "epoch": 27.065868263473053,
      "grad_norm": 2.858999729156494,
      "learning_rate": 0.0003680068434559452,
      "loss": 0.2654,
      "step": 9040
    },
    {
      "epoch": 27.12574850299401,
      "grad_norm": 7.404101848602295,
      "learning_rate": 0.0003674935842600513,
      "loss": 0.2227,
      "step": 9060
    },
    {
      "epoch": 27.18562874251497,
      "grad_norm": 1.2177067995071411,
      "learning_rate": 0.0003669803250641574,
      "loss": 0.2189,
      "step": 9080
    },
    {
      "epoch": 27.24550898203593,
      "grad_norm": 11.679303169250488,
      "learning_rate": 0.00036646706586826347,
      "loss": 0.2296,
      "step": 9100
    },
    {
      "epoch": 27.305389221556887,
      "grad_norm": 3.711866617202759,
      "learning_rate": 0.0003659538066723695,
      "loss": 0.2017,
      "step": 9120
    },
    {
      "epoch": 27.365269461077844,
      "grad_norm": 9.402048110961914,
      "learning_rate": 0.0003654405474764756,
      "loss": 0.2589,
      "step": 9140
    },
    {
      "epoch": 27.4251497005988,
      "grad_norm": 5.800785064697266,
      "learning_rate": 0.00036492728828058167,
      "loss": 0.2295,
      "step": 9160
    },
    {
      "epoch": 27.48502994011976,
      "grad_norm": 2.442629337310791,
      "learning_rate": 0.00036441402908468775,
      "loss": 0.2862,
      "step": 9180
    },
    {
      "epoch": 27.54491017964072,
      "grad_norm": 6.519311904907227,
      "learning_rate": 0.00036390076988879384,
      "loss": 0.171,
      "step": 9200
    },
    {
      "epoch": 27.604790419161677,
      "grad_norm": 2.3172714710235596,
      "learning_rate": 0.00036338751069289987,
      "loss": 0.195,
      "step": 9220
    },
    {
      "epoch": 27.664670658682635,
      "grad_norm": 2.2657980918884277,
      "learning_rate": 0.00036287425149700596,
      "loss": 0.2313,
      "step": 9240
    },
    {
      "epoch": 27.724550898203592,
      "grad_norm": 5.665033340454102,
      "learning_rate": 0.00036236099230111204,
      "loss": 0.2158,
      "step": 9260
    },
    {
      "epoch": 27.78443113772455,
      "grad_norm": 5.845540523529053,
      "learning_rate": 0.0003618477331052181,
      "loss": 0.2947,
      "step": 9280
    },
    {
      "epoch": 27.84431137724551,
      "grad_norm": 1.082487940788269,
      "learning_rate": 0.00036133447390932416,
      "loss": 0.159,
      "step": 9300
    },
    {
      "epoch": 27.904191616766468,
      "grad_norm": 3.991488218307495,
      "learning_rate": 0.00036082121471343024,
      "loss": 0.1719,
      "step": 9320
    },
    {
      "epoch": 27.964071856287426,
      "grad_norm": 10.277505874633789,
      "learning_rate": 0.00036030795551753633,
      "loss": 0.2582,
      "step": 9340
    },
    {
      "epoch": 28.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8504901960784313,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8627450980392157,
      "eval_accuracy_17": 0.8651960784313726,
      "eval_accuracy_18": 0.8627450980392157,
      "eval_accuracy_19": 0.8627450980392157,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8627450980392157,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8812619816365654,
      "eval_f1": 0.902229845626072,
      "eval_loss": 0.5320290327072144,
      "eval_runtime": 203.5062,
      "eval_samples_per_second": 2.005,
      "eval_steps_per_second": 0.251,
      "step": 9352
    },
    {
      "epoch": 28.023952095808383,
      "grad_norm": 21.47610092163086,
      "learning_rate": 0.0003597946963216424,
      "loss": 0.2497,
      "step": 9360
    },
    {
      "epoch": 28.08383233532934,
      "grad_norm": 1.9332811832427979,
      "learning_rate": 0.00035928143712574844,
      "loss": 0.1763,
      "step": 9380
    },
    {
      "epoch": 28.143712574850298,
      "grad_norm": 4.169668197631836,
      "learning_rate": 0.00035876817792985453,
      "loss": 0.2077,
      "step": 9400
    },
    {
      "epoch": 28.20359281437126,
      "grad_norm": 2.0931801795959473,
      "learning_rate": 0.0003582549187339606,
      "loss": 0.2282,
      "step": 9420
    },
    {
      "epoch": 28.263473053892216,
      "grad_norm": 12.181859016418457,
      "learning_rate": 0.0003577416595380667,
      "loss": 0.198,
      "step": 9440
    },
    {
      "epoch": 28.323353293413174,
      "grad_norm": 4.247338771820068,
      "learning_rate": 0.0003572284003421728,
      "loss": 0.3005,
      "step": 9460
    },
    {
      "epoch": 28.38323353293413,
      "grad_norm": 1.4059669971466064,
      "learning_rate": 0.0003567151411462788,
      "loss": 0.2157,
      "step": 9480
    },
    {
      "epoch": 28.44311377245509,
      "grad_norm": 7.135693550109863,
      "learning_rate": 0.0003562018819503849,
      "loss": 0.1392,
      "step": 9500
    },
    {
      "epoch": 28.50299401197605,
      "grad_norm": 6.671319961547852,
      "learning_rate": 0.000355688622754491,
      "loss": 0.1783,
      "step": 9520
    },
    {
      "epoch": 28.562874251497007,
      "grad_norm": 10.308104515075684,
      "learning_rate": 0.0003551753635585971,
      "loss": 0.2486,
      "step": 9540
    },
    {
      "epoch": 28.622754491017965,
      "grad_norm": 0.5764693021774292,
      "learning_rate": 0.0003546621043627031,
      "loss": 0.1821,
      "step": 9560
    },
    {
      "epoch": 28.682634730538922,
      "grad_norm": 0.08440223336219788,
      "learning_rate": 0.0003541488451668092,
      "loss": 0.2329,
      "step": 9580
    },
    {
      "epoch": 28.74251497005988,
      "grad_norm": 5.4941325187683105,
      "learning_rate": 0.0003536355859709153,
      "loss": 0.1965,
      "step": 9600
    },
    {
      "epoch": 28.802395209580837,
      "grad_norm": 15.870616912841797,
      "learning_rate": 0.00035312232677502136,
      "loss": 0.2369,
      "step": 9620
    },
    {
      "epoch": 28.862275449101798,
      "grad_norm": 12.133429527282715,
      "learning_rate": 0.00035260906757912745,
      "loss": 0.2495,
      "step": 9640
    },
    {
      "epoch": 28.922155688622755,
      "grad_norm": 4.802661895751953,
      "learning_rate": 0.0003520958083832335,
      "loss": 0.2292,
      "step": 9660
    },
    {
      "epoch": 28.982035928143713,
      "grad_norm": 2.416106939315796,
      "learning_rate": 0.00035158254918733956,
      "loss": 0.2156,
      "step": 9680
    },
    {
      "epoch": 29.0,
      "eval_accuracy": 0.8504901960784313,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8529411764705882,
      "eval_accuracy_16": 0.8529411764705882,
      "eval_accuracy_17": 0.8504901960784313,
      "eval_accuracy_18": 0.8504901960784313,
      "eval_accuracy_19": 0.8480392156862745,
      "eval_accuracy_20": 0.8480392156862745,
      "eval_accuracy_21": 0.8504901960784313,
      "eval_accuracy_22": 0.8529411764705882,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8504901960784313,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.8729294891198331,
      "eval_f1": 0.8953687821612349,
      "eval_loss": 0.5537633299827576,
      "eval_runtime": 203.5127,
      "eval_samples_per_second": 2.005,
      "eval_steps_per_second": 0.251,
      "step": 9686
    },
    {
      "epoch": 29.04191616766467,
      "grad_norm": 3.7232539653778076,
      "learning_rate": 0.00035106928999144565,
      "loss": 0.3133,
      "step": 9700
    },
    {
      "epoch": 29.101796407185628,
      "grad_norm": 0.3599967658519745,
      "learning_rate": 0.00035055603079555173,
      "loss": 0.1675,
      "step": 9720
    },
    {
      "epoch": 29.161676646706585,
      "grad_norm": 7.06216287612915,
      "learning_rate": 0.00035004277159965776,
      "loss": 0.3319,
      "step": 9740
    },
    {
      "epoch": 29.221556886227546,
      "grad_norm": 4.888256549835205,
      "learning_rate": 0.00034952951240376385,
      "loss": 0.1865,
      "step": 9760
    },
    {
      "epoch": 29.281437125748504,
      "grad_norm": 2.658917188644409,
      "learning_rate": 0.00034901625320786993,
      "loss": 0.1868,
      "step": 9780
    },
    {
      "epoch": 29.34131736526946,
      "grad_norm": 13.89867115020752,
      "learning_rate": 0.000348502994011976,
      "loss": 0.2912,
      "step": 9800
    },
    {
      "epoch": 29.40119760479042,
      "grad_norm": 1.3748215436935425,
      "learning_rate": 0.0003479897348160821,
      "loss": 0.1626,
      "step": 9820
    },
    {
      "epoch": 29.461077844311376,
      "grad_norm": 6.163721561431885,
      "learning_rate": 0.00034747647562018814,
      "loss": 0.2316,
      "step": 9840
    },
    {
      "epoch": 29.520958083832337,
      "grad_norm": 3.6034045219421387,
      "learning_rate": 0.0003469632164242942,
      "loss": 0.2308,
      "step": 9860
    },
    {
      "epoch": 29.580838323353294,
      "grad_norm": 1.1154446601867676,
      "learning_rate": 0.0003464499572284003,
      "loss": 0.3107,
      "step": 9880
    },
    {
      "epoch": 29.64071856287425,
      "grad_norm": 3.1345677375793457,
      "learning_rate": 0.0003459366980325064,
      "loss": 0.1741,
      "step": 9900
    },
    {
      "epoch": 29.70059880239521,
      "grad_norm": 7.40213680267334,
      "learning_rate": 0.0003454234388366124,
      "loss": 0.1769,
      "step": 9920
    },
    {
      "epoch": 29.760479041916167,
      "grad_norm": 1.9634953737258911,
      "learning_rate": 0.0003449101796407185,
      "loss": 0.2092,
      "step": 9940
    },
    {
      "epoch": 29.820359281437124,
      "grad_norm": 2.429783344268799,
      "learning_rate": 0.0003443969204448246,
      "loss": 0.3941,
      "step": 9960
    },
    {
      "epoch": 29.880239520958085,
      "grad_norm": 9.441605567932129,
      "learning_rate": 0.0003438836612489307,
      "loss": 0.1524,
      "step": 9980
    },
    {
      "epoch": 29.940119760479043,
      "grad_norm": 2.2971458435058594,
      "learning_rate": 0.00034337040205303676,
      "loss": 0.2523,
      "step": 10000
    },
    {
      "epoch": 30.0,
      "grad_norm": 14.205320358276367,
      "learning_rate": 0.0003428571428571428,
      "loss": 0.2144,
      "step": 10020
    },
    {
      "epoch": 30.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_accuracy_10": 0.8578431372549019,
      "eval_accuracy_11": 0.8578431372549019,
      "eval_accuracy_12": 0.8651960784313726,
      "eval_accuracy_13": 0.8578431372549019,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8651960784313726,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8602941176470589,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8578431372549019,
      "eval_accuracy_21": 0.8602941176470589,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8602941176470589,
      "eval_accuracy_25": 0.8627450980392157,
      "eval_combined_score": 0.8812619816365654,
      "eval_f1": 0.902229845626072,
      "eval_loss": 0.5207176804542542,
      "eval_runtime": 203.2578,
      "eval_samples_per_second": 2.007,
      "eval_steps_per_second": 0.251,
      "step": 10020
    },
    {
      "epoch": 30.059880239520957,
      "grad_norm": 3.6486387252807617,
      "learning_rate": 0.0003423438836612489,
      "loss": 0.1887,
      "step": 10040
    },
    {
      "epoch": 30.119760479041915,
      "grad_norm": 3.938709020614624,
      "learning_rate": 0.00034183062446535497,
      "loss": 0.241,
      "step": 10060
    },
    {
      "epoch": 30.179640718562876,
      "grad_norm": 5.145548343658447,
      "learning_rate": 0.00034131736526946105,
      "loss": 0.1266,
      "step": 10080
    },
    {
      "epoch": 30.239520958083833,
      "grad_norm": 6.2533979415893555,
      "learning_rate": 0.0003408041060735671,
      "loss": 0.1861,
      "step": 10100
    },
    {
      "epoch": 30.29940119760479,
      "grad_norm": 4.8692779541015625,
      "learning_rate": 0.00034029084687767317,
      "loss": 0.1641,
      "step": 10120
    },
    {
      "epoch": 30.35928143712575,
      "grad_norm": 7.9310221672058105,
      "learning_rate": 0.00033977758768177925,
      "loss": 0.2289,
      "step": 10140
    },
    {
      "epoch": 30.419161676646706,
      "grad_norm": 263.4200744628906,
      "learning_rate": 0.00033926432848588534,
      "loss": 0.2655,
      "step": 10160
    },
    {
      "epoch": 30.479041916167663,
      "grad_norm": 14.718400001525879,
      "learning_rate": 0.00033875106928999137,
      "loss": 0.1674,
      "step": 10180
    },
    {
      "epoch": 30.538922155688624,
      "grad_norm": 12.300472259521484,
      "learning_rate": 0.00033823781009409746,
      "loss": 0.2181,
      "step": 10200
    },
    {
      "epoch": 30.59880239520958,
      "grad_norm": 6.103994846343994,
      "learning_rate": 0.00033772455089820354,
      "loss": 0.196,
      "step": 10220
    },
    {
      "epoch": 30.65868263473054,
      "grad_norm": 1.3171435594558716,
      "learning_rate": 0.0003372112917023096,
      "loss": 0.2718,
      "step": 10240
    },
    {
      "epoch": 30.718562874251496,
      "grad_norm": 8.136494636535645,
      "learning_rate": 0.0003366980325064157,
      "loss": 0.3174,
      "step": 10260
    },
    {
      "epoch": 30.778443113772454,
      "grad_norm": 5.4049458503723145,
      "learning_rate": 0.00033618477331052174,
      "loss": 0.1762,
      "step": 10280
    },
    {
      "epoch": 30.83832335329341,
      "grad_norm": 7.180954933166504,
      "learning_rate": 0.00033567151411462783,
      "loss": 0.2163,
      "step": 10300
    },
    {
      "epoch": 30.898203592814372,
      "grad_norm": 3.9918153285980225,
      "learning_rate": 0.0003351582549187339,
      "loss": 0.1703,
      "step": 10320
    },
    {
      "epoch": 30.95808383233533,
      "grad_norm": 0.2120036482810974,
      "learning_rate": 0.00033464499572284,
      "loss": 0.2477,
      "step": 10340
    },
    {
      "epoch": 31.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8553921568627451,
      "eval_accuracy_13": 0.8504901960784313,
      "eval_accuracy_14": 0.8504901960784313,
      "eval_accuracy_15": 0.8480392156862745,
      "eval_accuracy_16": 0.8504901960784313,
      "eval_accuracy_17": 0.8529411764705882,
      "eval_accuracy_18": 0.8480392156862745,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8504901960784313,
      "eval_accuracy_21": 0.8504901960784313,
      "eval_accuracy_22": 0.8480392156862745,
      "eval_accuracy_23": 0.8504901960784313,
      "eval_accuracy_24": 0.8480392156862745,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.8762126578380043,
      "eval_f1": 0.8970331588132635,
      "eval_loss": 0.522045910358429,
      "eval_runtime": 203.5037,
      "eval_samples_per_second": 2.005,
      "eval_steps_per_second": 0.251,
      "step": 10354
    },
    {
      "epoch": 31.017964071856287,
      "grad_norm": 6.866754055023193,
      "learning_rate": 0.00033413173652694603,
      "loss": 0.1239,
      "step": 10360
    },
    {
      "epoch": 31.077844311377245,
      "grad_norm": 0.11484739929437637,
      "learning_rate": 0.0003336184773310521,
      "loss": 0.2459,
      "step": 10380
    },
    {
      "epoch": 31.137724550898202,
      "grad_norm": 3.9727745056152344,
      "learning_rate": 0.0003331052181351582,
      "loss": 0.1453,
      "step": 10400
    },
    {
      "epoch": 31.197604790419163,
      "grad_norm": 3.2715940475463867,
      "learning_rate": 0.00033259195893926434,
      "loss": 0.1656,
      "step": 10420
    },
    {
      "epoch": 31.25748502994012,
      "grad_norm": 7.182013988494873,
      "learning_rate": 0.0003320786997433704,
      "loss": 0.2387,
      "step": 10440
    },
    {
      "epoch": 31.317365269461078,
      "grad_norm": 32.228477478027344,
      "learning_rate": 0.0003315654405474764,
      "loss": 0.3274,
      "step": 10460
    },
    {
      "epoch": 31.377245508982035,
      "grad_norm": 2.482142448425293,
      "learning_rate": 0.0003310521813515825,
      "loss": 0.1726,
      "step": 10480
    },
    {
      "epoch": 31.437125748502993,
      "grad_norm": 9.611062049865723,
      "learning_rate": 0.00033053892215568863,
      "loss": 0.1408,
      "step": 10500
    },
    {
      "epoch": 31.49700598802395,
      "grad_norm": 0.09219502657651901,
      "learning_rate": 0.0003300256629597947,
      "loss": 0.2512,
      "step": 10520
    },
    {
      "epoch": 31.55688622754491,
      "grad_norm": 0.8468003273010254,
      "learning_rate": 0.0003295124037639007,
      "loss": 0.1294,
      "step": 10540
    },
    {
      "epoch": 31.61676646706587,
      "grad_norm": 17.65831756591797,
      "learning_rate": 0.0003289991445680068,
      "loss": 0.1729,
      "step": 10560
    },
    {
      "epoch": 31.676646706586826,
      "grad_norm": 4.779966831207275,
      "learning_rate": 0.0003284858853721129,
      "loss": 0.2433,
      "step": 10580
    },
    {
      "epoch": 31.736526946107784,
      "grad_norm": 2.2506189346313477,
      "learning_rate": 0.000327972626176219,
      "loss": 0.215,
      "step": 10600
    },
    {
      "epoch": 31.79640718562874,
      "grad_norm": 1.2796387672424316,
      "learning_rate": 0.0003274593669803251,
      "loss": 0.2174,
      "step": 10620
    },
    {
      "epoch": 31.856287425149702,
      "grad_norm": 4.252838611602783,
      "learning_rate": 0.00032694610778443106,
      "loss": 0.1681,
      "step": 10640
    },
    {
      "epoch": 31.91616766467066,
      "grad_norm": 2.9905459880828857,
      "learning_rate": 0.0003264328485885372,
      "loss": 0.1799,
      "step": 10660
    },
    {
      "epoch": 31.976047904191617,
      "grad_norm": 6.694150447845459,
      "learning_rate": 0.0003259195893926433,
      "loss": 0.2713,
      "step": 10680
    },
    {
      "epoch": 32.0,
      "eval_accuracy": 0.8480392156862745,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8602941176470589,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8480392156862745,
      "eval_accuracy_20": 0.8529411764705882,
      "eval_accuracy_21": 0.8455882352941176,
      "eval_accuracy_22": 0.8455882352941176,
      "eval_accuracy_23": 0.8455882352941176,
      "eval_accuracy_24": 0.8480392156862745,
      "eval_accuracy_25": 0.8480392156862745,
      "eval_combined_score": 0.8702001633986927,
      "eval_f1": 0.8923611111111109,
      "eval_loss": 0.5145299434661865,
      "eval_runtime": 203.4807,
      "eval_samples_per_second": 2.005,
      "eval_steps_per_second": 0.251,
      "step": 10688
    },
    {
      "epoch": 32.035928143712574,
      "grad_norm": 1.4813177585601807,
      "learning_rate": 0.00032540633019674937,
      "loss": 0.1053,
      "step": 10700
    },
    {
      "epoch": 32.09580838323353,
      "grad_norm": 15.772080421447754,
      "learning_rate": 0.00032489307100085535,
      "loss": 0.235,
      "step": 10720
    },
    {
      "epoch": 32.15568862275449,
      "grad_norm": 0.06828536838293076,
      "learning_rate": 0.0003243798118049615,
      "loss": 0.2463,
      "step": 10740
    },
    {
      "epoch": 32.21556886227545,
      "grad_norm": 9.178966522216797,
      "learning_rate": 0.0003238665526090676,
      "loss": 0.3275,
      "step": 10760
    },
    {
      "epoch": 32.275449101796404,
      "grad_norm": 11.322216987609863,
      "learning_rate": 0.00032335329341317366,
      "loss": 0.2234,
      "step": 10780
    },
    {
      "epoch": 32.33532934131736,
      "grad_norm": 4.352841854095459,
      "learning_rate": 0.00032284003421727975,
      "loss": 0.2257,
      "step": 10800
    },
    {
      "epoch": 32.395209580838326,
      "grad_norm": 4.866506576538086,
      "learning_rate": 0.0003223267750213858,
      "loss": 0.1495,
      "step": 10820
    },
    {
      "epoch": 32.455089820359284,
      "grad_norm": 6.304713726043701,
      "learning_rate": 0.00032181351582549186,
      "loss": 0.137,
      "step": 10840
    },
    {
      "epoch": 32.51497005988024,
      "grad_norm": 2.1725194454193115,
      "learning_rate": 0.00032130025662959795,
      "loss": 0.2415,
      "step": 10860
    },
    {
      "epoch": 32.5748502994012,
      "grad_norm": 0.43696364760398865,
      "learning_rate": 0.00032078699743370403,
      "loss": 0.2068,
      "step": 10880
    },
    {
      "epoch": 32.634730538922156,
      "grad_norm": 8.272881507873535,
      "learning_rate": 0.00032027373823781006,
      "loss": 0.1615,
      "step": 10900
    },
    {
      "epoch": 32.69461077844311,
      "grad_norm": 0.4312056601047516,
      "learning_rate": 0.00031976047904191615,
      "loss": 0.2337,
      "step": 10920
    },
    {
      "epoch": 32.75449101796407,
      "grad_norm": 2.8478682041168213,
      "learning_rate": 0.00031924721984602223,
      "loss": 0.1542,
      "step": 10940
    },
    {
      "epoch": 32.81437125748503,
      "grad_norm": 6.321502208709717,
      "learning_rate": 0.0003187339606501283,
      "loss": 0.2816,
      "step": 10960
    },
    {
      "epoch": 32.874251497005986,
      "grad_norm": 0.5976132154464722,
      "learning_rate": 0.00031822070145423435,
      "loss": 0.1823,
      "step": 10980
    },
    {
      "epoch": 32.93413173652694,
      "grad_norm": 1.243360996246338,
      "learning_rate": 0.00031770744225834044,
      "loss": 0.1754,
      "step": 11000
    },
    {
      "epoch": 32.9940119760479,
      "grad_norm": 0.3840307593345642,
      "learning_rate": 0.0003171941830624465,
      "loss": 0.2088,
      "step": 11020
    },
    {
      "epoch": 33.0,
      "eval_accuracy": 0.8480392156862745,
      "eval_accuracy_10": 0.8504901960784313,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8504901960784313,
      "eval_accuracy_14": 0.8455882352941176,
      "eval_accuracy_15": 0.8455882352941176,
      "eval_accuracy_16": 0.8480392156862745,
      "eval_accuracy_17": 0.8480392156862745,
      "eval_accuracy_18": 0.8431372549019608,
      "eval_accuracy_19": 0.8431372549019608,
      "eval_accuracy_20": 0.8455882352941176,
      "eval_accuracy_21": 0.8455882352941176,
      "eval_accuracy_22": 0.8480392156862745,
      "eval_accuracy_23": 0.8480392156862745,
      "eval_accuracy_24": 0.8480392156862745,
      "eval_accuracy_25": 0.8480392156862745,
      "eval_combined_score": 0.8703863898500577,
      "eval_f1": 0.8927335640138409,
      "eval_loss": 0.6093260645866394,
      "eval_runtime": 203.506,
      "eval_samples_per_second": 2.005,
      "eval_steps_per_second": 0.251,
      "step": 11022
    },
    {
      "epoch": 33.053892215568865,
      "grad_norm": 4.986073970794678,
      "learning_rate": 0.0003166809238665526,
      "loss": 0.101,
      "step": 11040
    },
    {
      "epoch": 33.11377245508982,
      "grad_norm": 8.738085746765137,
      "learning_rate": 0.0003161676646706587,
      "loss": 0.1854,
      "step": 11060
    },
    {
      "epoch": 33.17365269461078,
      "grad_norm": 0.15522319078445435,
      "learning_rate": 0.0003156544054747647,
      "loss": 0.1623,
      "step": 11080
    },
    {
      "epoch": 33.23353293413174,
      "grad_norm": 14.198541641235352,
      "learning_rate": 0.0003151411462788708,
      "loss": 0.1973,
      "step": 11100
    },
    {
      "epoch": 33.293413173652695,
      "grad_norm": 0.9116400480270386,
      "learning_rate": 0.0003146278870829769,
      "loss": 0.2624,
      "step": 11120
    },
    {
      "epoch": 33.35329341317365,
      "grad_norm": 10.781327247619629,
      "learning_rate": 0.000314114627887083,
      "loss": 0.2125,
      "step": 11140
    },
    {
      "epoch": 33.41317365269461,
      "grad_norm": 6.2757086753845215,
      "learning_rate": 0.000313601368691189,
      "loss": 0.157,
      "step": 11160
    },
    {
      "epoch": 33.47305389221557,
      "grad_norm": 1.3246318101882935,
      "learning_rate": 0.0003130881094952951,
      "loss": 0.2296,
      "step": 11180
    },
    {
      "epoch": 33.532934131736525,
      "grad_norm": 1.5728981494903564,
      "learning_rate": 0.0003125748502994012,
      "loss": 0.1942,
      "step": 11200
    },
    {
      "epoch": 33.59281437125748,
      "grad_norm": 0.7548922300338745,
      "learning_rate": 0.00031206159110350727,
      "loss": 0.2442,
      "step": 11220
    },
    {
      "epoch": 33.65269461077844,
      "grad_norm": 10.896413803100586,
      "learning_rate": 0.00031154833190761335,
      "loss": 0.1795,
      "step": 11240
    },
    {
      "epoch": 33.712574850299404,
      "grad_norm": 9.4589262008667,
      "learning_rate": 0.0003110350727117194,
      "loss": 0.2327,
      "step": 11260
    },
    {
      "epoch": 33.77245508982036,
      "grad_norm": 4.08962869644165,
      "learning_rate": 0.00031052181351582547,
      "loss": 0.2091,
      "step": 11280
    },
    {
      "epoch": 33.83233532934132,
      "grad_norm": 0.11124465614557266,
      "learning_rate": 0.00031000855431993155,
      "loss": 0.2253,
      "step": 11300
    },
    {
      "epoch": 33.89221556886228,
      "grad_norm": 13.552796363830566,
      "learning_rate": 0.00030949529512403764,
      "loss": 0.2184,
      "step": 11320
    },
    {
      "epoch": 33.952095808383234,
      "grad_norm": 0.29997819662094116,
      "learning_rate": 0.00030898203592814367,
      "loss": 0.132,
      "step": 11340
    },
    {
      "epoch": 34.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8602941176470589,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8553921568627451,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8529411764705882,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8504901960784313,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.877440541804456,
      "eval_f1": 0.899488926746167,
      "eval_loss": 0.78279709815979,
      "eval_runtime": 203.7708,
      "eval_samples_per_second": 2.002,
      "eval_steps_per_second": 0.25,
      "step": 11356
    },
    {
      "epoch": 34.01197604790419,
      "grad_norm": 0.08221229165792465,
      "learning_rate": 0.00030846877673224976,
      "loss": 0.1559,
      "step": 11360
    },
    {
      "epoch": 34.07185628742515,
      "grad_norm": 11.005845069885254,
      "learning_rate": 0.00030795551753635584,
      "loss": 0.1602,
      "step": 11380
    },
    {
      "epoch": 34.131736526946106,
      "grad_norm": 2.0378096103668213,
      "learning_rate": 0.0003074422583404619,
      "loss": 0.1887,
      "step": 11400
    },
    {
      "epoch": 34.191616766467064,
      "grad_norm": 8.548273086547852,
      "learning_rate": 0.000306928999144568,
      "loss": 0.2142,
      "step": 11420
    },
    {
      "epoch": 34.25149700598802,
      "grad_norm": 5.68293571472168,
      "learning_rate": 0.00030641573994867404,
      "loss": 0.1492,
      "step": 11440
    },
    {
      "epoch": 34.31137724550898,
      "grad_norm": 8.563164710998535,
      "learning_rate": 0.00030590248075278013,
      "loss": 0.2437,
      "step": 11460
    },
    {
      "epoch": 34.37125748502994,
      "grad_norm": 4.355770587921143,
      "learning_rate": 0.0003053892215568862,
      "loss": 0.1534,
      "step": 11480
    },
    {
      "epoch": 34.4311377245509,
      "grad_norm": 1.7839418649673462,
      "learning_rate": 0.0003048759623609923,
      "loss": 0.2317,
      "step": 11500
    },
    {
      "epoch": 34.49101796407186,
      "grad_norm": 0.14582155644893646,
      "learning_rate": 0.00030436270316509833,
      "loss": 0.1721,
      "step": 11520
    },
    {
      "epoch": 34.550898203592816,
      "grad_norm": 6.501530170440674,
      "learning_rate": 0.0003038494439692044,
      "loss": 0.2071,
      "step": 11540
    },
    {
      "epoch": 34.61077844311377,
      "grad_norm": 4.567194938659668,
      "learning_rate": 0.0003033361847733105,
      "loss": 0.1713,
      "step": 11560
    },
    {
      "epoch": 34.67065868263473,
      "grad_norm": 0.6205886006355286,
      "learning_rate": 0.0003028229255774166,
      "loss": 0.1354,
      "step": 11580
    },
    {
      "epoch": 34.73053892215569,
      "grad_norm": 0.7428898811340332,
      "learning_rate": 0.00030230966638152267,
      "loss": 0.1607,
      "step": 11600
    },
    {
      "epoch": 34.790419161676645,
      "grad_norm": 3.5064353942871094,
      "learning_rate": 0.0003017964071856287,
      "loss": 0.2364,
      "step": 11620
    },
    {
      "epoch": 34.8502994011976,
      "grad_norm": 1.561649203300476,
      "learning_rate": 0.0003012831479897348,
      "loss": 0.2806,
      "step": 11640
    },
    {
      "epoch": 34.91017964071856,
      "grad_norm": 8.175990104675293,
      "learning_rate": 0.00030076988879384087,
      "loss": 0.2137,
      "step": 11660
    },
    {
      "epoch": 34.97005988023952,
      "grad_norm": 0.8999429941177368,
      "learning_rate": 0.00030025662959794696,
      "loss": 0.1397,
      "step": 11680
    },
    {
      "epoch": 35.0,
      "eval_accuracy": 0.8504901960784313,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8504901960784313,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8529411764705882,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8504901960784313,
      "eval_accuracy_21": 0.8455882352941176,
      "eval_accuracy_22": 0.8480392156862745,
      "eval_accuracy_23": 0.8504901960784313,
      "eval_accuracy_24": 0.8504901960784313,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.8727494009652054,
      "eval_f1": 0.8950086058519794,
      "eval_loss": 0.6359041333198547,
      "eval_runtime": 207.7062,
      "eval_samples_per_second": 1.964,
      "eval_steps_per_second": 0.246,
      "step": 11690
    },
    {
      "epoch": 35.02994011976048,
      "grad_norm": 0.32346656918525696,
      "learning_rate": 0.00029974337040205304,
      "loss": 0.1211,
      "step": 11700
    },
    {
      "epoch": 35.08982035928144,
      "grad_norm": 7.201113700866699,
      "learning_rate": 0.0002992301112061591,
      "loss": 0.1948,
      "step": 11720
    },
    {
      "epoch": 35.1497005988024,
      "grad_norm": 9.512255668640137,
      "learning_rate": 0.00029871685201026516,
      "loss": 0.2139,
      "step": 11740
    },
    {
      "epoch": 35.209580838323355,
      "grad_norm": 6.629267692565918,
      "learning_rate": 0.0002982035928143712,
      "loss": 0.163,
      "step": 11760
    },
    {
      "epoch": 35.26946107784431,
      "grad_norm": 15.28596305847168,
      "learning_rate": 0.00029769033361847733,
      "loss": 0.183,
      "step": 11780
    },
    {
      "epoch": 35.32934131736527,
      "grad_norm": 2.2507095336914062,
      "learning_rate": 0.0002971770744225834,
      "loss": 0.1598,
      "step": 11800
    },
    {
      "epoch": 35.38922155688623,
      "grad_norm": 0.3616444170475006,
      "learning_rate": 0.00029666381522668945,
      "loss": 0.1718,
      "step": 11820
    },
    {
      "epoch": 35.449101796407184,
      "grad_norm": 5.615668296813965,
      "learning_rate": 0.00029615055603079553,
      "loss": 0.1314,
      "step": 11840
    },
    {
      "epoch": 35.50898203592814,
      "grad_norm": 2.755924940109253,
      "learning_rate": 0.0002956372968349016,
      "loss": 0.2016,
      "step": 11860
    },
    {
      "epoch": 35.5688622754491,
      "grad_norm": 0.25488245487213135,
      "learning_rate": 0.0002951240376390077,
      "loss": 0.2249,
      "step": 11880
    },
    {
      "epoch": 35.62874251497006,
      "grad_norm": 12.850790977478027,
      "learning_rate": 0.00029461077844311373,
      "loss": 0.1643,
      "step": 11900
    },
    {
      "epoch": 35.68862275449102,
      "grad_norm": 0.3784223794937134,
      "learning_rate": 0.0002940975192472198,
      "loss": 0.2309,
      "step": 11920
    },
    {
      "epoch": 35.74850299401198,
      "grad_norm": 4.165396213531494,
      "learning_rate": 0.0002935842600513259,
      "loss": 0.1155,
      "step": 11940
    },
    {
      "epoch": 35.808383233532936,
      "grad_norm": 3.6173689365386963,
      "learning_rate": 0.000293071000855432,
      "loss": 0.1885,
      "step": 11960
    },
    {
      "epoch": 35.868263473053894,
      "grad_norm": 0.5011641979217529,
      "learning_rate": 0.000292557741659538,
      "loss": 0.2286,
      "step": 11980
    },
    {
      "epoch": 35.92814371257485,
      "grad_norm": 8.820659637451172,
      "learning_rate": 0.0002920444824636441,
      "loss": 0.2417,
      "step": 12000
    },
    {
      "epoch": 35.98802395209581,
      "grad_norm": 0.5850100517272949,
      "learning_rate": 0.0002915312232677502,
      "loss": 0.1749,
      "step": 12020
    },
    {
      "epoch": 36.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8529411764705882,
      "eval_accuracy_16": 0.8480392156862745,
      "eval_accuracy_17": 0.8480392156862745,
      "eval_accuracy_18": 0.8480392156862745,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8529411764705882,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8504901960784313,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8772687280040221,
      "eval_f1": 0.8991452991452993,
      "eval_loss": 0.636760950088501,
      "eval_runtime": 207.6734,
      "eval_samples_per_second": 1.965,
      "eval_steps_per_second": 0.246,
      "step": 12024
    },
    {
      "epoch": 36.047904191616766,
      "grad_norm": 1.0560646057128906,
      "learning_rate": 0.0002910179640718563,
      "loss": 0.1715,
      "step": 12040
    },
    {
      "epoch": 36.10778443113772,
      "grad_norm": 3.7046360969543457,
      "learning_rate": 0.00029050470487596236,
      "loss": 0.1678,
      "step": 12060
    },
    {
      "epoch": 36.16766467065868,
      "grad_norm": 6.2011284828186035,
      "learning_rate": 0.0002899914456800684,
      "loss": 0.1747,
      "step": 12080
    },
    {
      "epoch": 36.22754491017964,
      "grad_norm": 1.803407907485962,
      "learning_rate": 0.0002894781864841745,
      "loss": 0.1602,
      "step": 12100
    },
    {
      "epoch": 36.287425149700596,
      "grad_norm": 13.556265830993652,
      "learning_rate": 0.00028896492728828056,
      "loss": 0.2251,
      "step": 12120
    },
    {
      "epoch": 36.34730538922156,
      "grad_norm": 6.680383205413818,
      "learning_rate": 0.00028845166809238665,
      "loss": 0.2092,
      "step": 12140
    },
    {
      "epoch": 36.40718562874252,
      "grad_norm": 10.783909797668457,
      "learning_rate": 0.0002879384088964927,
      "loss": 0.1626,
      "step": 12160
    },
    {
      "epoch": 36.467065868263475,
      "grad_norm": 5.805558204650879,
      "learning_rate": 0.00028742514970059877,
      "loss": 0.2998,
      "step": 12180
    },
    {
      "epoch": 36.52694610778443,
      "grad_norm": 0.6099089980125427,
      "learning_rate": 0.00028691189050470485,
      "loss": 0.1729,
      "step": 12200
    },
    {
      "epoch": 36.58682634730539,
      "grad_norm": 20.508228302001953,
      "learning_rate": 0.00028639863130881094,
      "loss": 0.1574,
      "step": 12220
    },
    {
      "epoch": 36.64670658682635,
      "grad_norm": 3.5051357746124268,
      "learning_rate": 0.000285885372112917,
      "loss": 0.169,
      "step": 12240
    },
    {
      "epoch": 36.706586826347305,
      "grad_norm": 3.4329631328582764,
      "learning_rate": 0.00028537211291702305,
      "loss": 0.1705,
      "step": 12260
    },
    {
      "epoch": 36.76646706586826,
      "grad_norm": 2.5474154949188232,
      "learning_rate": 0.00028485885372112914,
      "loss": 0.1213,
      "step": 12280
    },
    {
      "epoch": 36.82634730538922,
      "grad_norm": 2.076014757156372,
      "learning_rate": 0.0002843455945252352,
      "loss": 0.145,
      "step": 12300
    },
    {
      "epoch": 36.88622754491018,
      "grad_norm": 7.596439361572266,
      "learning_rate": 0.0002838323353293413,
      "loss": 0.1972,
      "step": 12320
    },
    {
      "epoch": 36.946107784431135,
      "grad_norm": 0.5537683963775635,
      "learning_rate": 0.00028331907613344734,
      "loss": 0.1524,
      "step": 12340
    },
    {
      "epoch": 37.0,
      "eval_accuracy": 0.8480392156862745,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8480392156862745,
      "eval_accuracy_15": 0.8480392156862745,
      "eval_accuracy_16": 0.8504901960784313,
      "eval_accuracy_17": 0.8455882352941176,
      "eval_accuracy_18": 0.8480392156862745,
      "eval_accuracy_19": 0.8504901960784313,
      "eval_accuracy_20": 0.8504901960784313,
      "eval_accuracy_21": 0.8504901960784313,
      "eval_accuracy_22": 0.8480392156862745,
      "eval_accuracy_23": 0.8480392156862745,
      "eval_accuracy_24": 0.8480392156862745,
      "eval_accuracy_25": 0.8480392156862745,
      "eval_combined_score": 0.8712985194077632,
      "eval_f1": 0.8945578231292517,
      "eval_loss": 0.6802825927734375,
      "eval_runtime": 211.3583,
      "eval_samples_per_second": 1.93,
      "eval_steps_per_second": 0.241,
      "step": 12358
    },
    {
      "epoch": 37.0059880239521,
      "grad_norm": 3.362828493118286,
      "learning_rate": 0.0002828058169375534,
      "loss": 0.2049,
      "step": 12360
    },
    {
      "epoch": 37.06586826347306,
      "grad_norm": 4.588033199310303,
      "learning_rate": 0.0002822925577416595,
      "loss": 0.1945,
      "step": 12380
    },
    {
      "epoch": 37.125748502994014,
      "grad_norm": 2.9670469760894775,
      "learning_rate": 0.0002817792985457656,
      "loss": 0.1459,
      "step": 12400
    },
    {
      "epoch": 37.18562874251497,
      "grad_norm": 14.268146514892578,
      "learning_rate": 0.0002812660393498717,
      "loss": 0.1998,
      "step": 12420
    },
    {
      "epoch": 37.24550898203593,
      "grad_norm": 0.5448617339134216,
      "learning_rate": 0.0002807527801539777,
      "loss": 0.1478,
      "step": 12440
    },
    {
      "epoch": 37.30538922155689,
      "grad_norm": 6.916693210601807,
      "learning_rate": 0.0002802395209580838,
      "loss": 0.1757,
      "step": 12460
    },
    {
      "epoch": 37.365269461077844,
      "grad_norm": 5.779355049133301,
      "learning_rate": 0.0002797262617621899,
      "loss": 0.1431,
      "step": 12480
    },
    {
      "epoch": 37.4251497005988,
      "grad_norm": 8.269726753234863,
      "learning_rate": 0.00027921300256629597,
      "loss": 0.2353,
      "step": 12500
    },
    {
      "epoch": 37.48502994011976,
      "grad_norm": 19.194852828979492,
      "learning_rate": 0.000278699743370402,
      "loss": 0.1513,
      "step": 12520
    },
    {
      "epoch": 37.544910179640716,
      "grad_norm": 1.1553574800491333,
      "learning_rate": 0.0002781864841745081,
      "loss": 0.1925,
      "step": 12540
    },
    {
      "epoch": 37.604790419161674,
      "grad_norm": 3.594217300415039,
      "learning_rate": 0.00027767322497861417,
      "loss": 0.1389,
      "step": 12560
    },
    {
      "epoch": 37.66467065868264,
      "grad_norm": 0.26009559631347656,
      "learning_rate": 0.00027715996578272026,
      "loss": 0.1873,
      "step": 12580
    },
    {
      "epoch": 37.724550898203596,
      "grad_norm": 9.487200736999512,
      "learning_rate": 0.00027664670658682634,
      "loss": 0.1812,
      "step": 12600
    },
    {
      "epoch": 37.78443113772455,
      "grad_norm": 0.17678794264793396,
      "learning_rate": 0.0002761334473909324,
      "loss": 0.2218,
      "step": 12620
    },
    {
      "epoch": 37.84431137724551,
      "grad_norm": 7.901886940002441,
      "learning_rate": 0.00027562018819503846,
      "loss": 0.1562,
      "step": 12640
    },
    {
      "epoch": 37.90419161676647,
      "grad_norm": 1.6209819316864014,
      "learning_rate": 0.00027510692899914454,
      "loss": 0.1944,
      "step": 12660
    },
    {
      "epoch": 37.964071856287426,
      "grad_norm": 7.295859336853027,
      "learning_rate": 0.00027459366980325063,
      "loss": 0.1338,
      "step": 12680
    },
    {
      "epoch": 38.0,
      "eval_accuracy": 0.8480392156862745,
      "eval_accuracy_10": 0.8504901960784313,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8504901960784313,
      "eval_accuracy_13": 0.8504901960784313,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8504901960784313,
      "eval_accuracy_20": 0.8529411764705882,
      "eval_accuracy_21": 0.8504901960784313,
      "eval_accuracy_22": 0.8480392156862745,
      "eval_accuracy_23": 0.8504901960784313,
      "eval_accuracy_24": 0.8480392156862745,
      "eval_accuracy_25": 0.8480392156862745,
      "eval_combined_score": 0.8705713319810683,
      "eval_f1": 0.8931034482758621,
      "eval_loss": 0.6494395136833191,
      "eval_runtime": 206.3519,
      "eval_samples_per_second": 1.977,
      "eval_steps_per_second": 0.247,
      "step": 12692
    },
    {
      "epoch": 38.02395209580838,
      "grad_norm": 14.593432426452637,
      "learning_rate": 0.00027408041060735666,
      "loss": 0.2741,
      "step": 12700
    },
    {
      "epoch": 38.08383233532934,
      "grad_norm": 7.965444087982178,
      "learning_rate": 0.00027356715141146275,
      "loss": 0.2197,
      "step": 12720
    },
    {
      "epoch": 38.1437125748503,
      "grad_norm": 6.211866855621338,
      "learning_rate": 0.00027305389221556883,
      "loss": 0.1295,
      "step": 12740
    },
    {
      "epoch": 38.203592814371255,
      "grad_norm": 9.200653076171875,
      "learning_rate": 0.0002725406330196749,
      "loss": 0.1855,
      "step": 12760
    },
    {
      "epoch": 38.26347305389221,
      "grad_norm": 1.3255976438522339,
      "learning_rate": 0.00027202737382378095,
      "loss": 0.0715,
      "step": 12780
    },
    {
      "epoch": 38.32335329341317,
      "grad_norm": 0.17544178664684296,
      "learning_rate": 0.00027151411462788703,
      "loss": 0.1558,
      "step": 12800
    },
    {
      "epoch": 38.383233532934135,
      "grad_norm": 11.90302848815918,
      "learning_rate": 0.00027100085543199317,
      "loss": 0.1723,
      "step": 12820
    },
    {
      "epoch": 38.44311377245509,
      "grad_norm": 0.1697562336921692,
      "learning_rate": 0.0002704875962360992,
      "loss": 0.2737,
      "step": 12840
    },
    {
      "epoch": 38.50299401197605,
      "grad_norm": 0.15406545996665955,
      "learning_rate": 0.0002699743370402053,
      "loss": 0.1701,
      "step": 12860
    },
    {
      "epoch": 38.56287425149701,
      "grad_norm": 1.6970254182815552,
      "learning_rate": 0.0002694610778443113,
      "loss": 0.1475,
      "step": 12880
    },
    {
      "epoch": 38.622754491017965,
      "grad_norm": 0.17329151928424835,
      "learning_rate": 0.00026894781864841746,
      "loss": 0.0835,
      "step": 12900
    },
    {
      "epoch": 38.68263473053892,
      "grad_norm": 1.7988063097000122,
      "learning_rate": 0.0002684345594525235,
      "loss": 0.1539,
      "step": 12920
    },
    {
      "epoch": 38.74251497005988,
      "grad_norm": 11.127212524414062,
      "learning_rate": 0.0002679213002566296,
      "loss": 0.1271,
      "step": 12940
    },
    {
      "epoch": 38.80239520958084,
      "grad_norm": 1.2814754247665405,
      "learning_rate": 0.0002674080410607356,
      "loss": 0.1314,
      "step": 12960
    },
    {
      "epoch": 38.862275449101794,
      "grad_norm": 11.872629165649414,
      "learning_rate": 0.00026689478186484175,
      "loss": 0.3017,
      "step": 12980
    },
    {
      "epoch": 38.92215568862275,
      "grad_norm": 12.959528923034668,
      "learning_rate": 0.00026638152266894783,
      "loss": 0.213,
      "step": 13000
    },
    {
      "epoch": 38.98203592814371,
      "grad_norm": 3.3149733543395996,
      "learning_rate": 0.00026586826347305386,
      "loss": 0.2049,
      "step": 13020
    },
    {
      "epoch": 39.0,
      "eval_accuracy": 0.8627450980392157,
      "eval_accuracy_10": 0.8627450980392157,
      "eval_accuracy_11": 0.8578431372549019,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8553921568627451,
      "eval_accuracy_21": 0.8504901960784313,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.8824215000685589,
      "eval_f1": 0.9020979020979022,
      "eval_loss": 0.5890989303588867,
      "eval_runtime": 212.2097,
      "eval_samples_per_second": 1.923,
      "eval_steps_per_second": 0.24,
      "step": 13026
    },
    {
      "epoch": 39.041916167664674,
      "grad_norm": 7.096531867980957,
      "learning_rate": 0.00026535500427715995,
      "loss": 0.148,
      "step": 13040
    },
    {
      "epoch": 39.10179640718563,
      "grad_norm": 0.6819127202033997,
      "learning_rate": 0.00026484174508126603,
      "loss": 0.0595,
      "step": 13060
    },
    {
      "epoch": 39.16167664670659,
      "grad_norm": 11.8462495803833,
      "learning_rate": 0.0002643284858853721,
      "loss": 0.1839,
      "step": 13080
    },
    {
      "epoch": 39.221556886227546,
      "grad_norm": 0.1009301096200943,
      "learning_rate": 0.00026381522668947815,
      "loss": 0.2025,
      "step": 13100
    },
    {
      "epoch": 39.2814371257485,
      "grad_norm": 0.7772163152694702,
      "learning_rate": 0.00026330196749358424,
      "loss": 0.1237,
      "step": 13120
    },
    {
      "epoch": 39.34131736526946,
      "grad_norm": 12.35466194152832,
      "learning_rate": 0.0002627887082976903,
      "loss": 0.2354,
      "step": 13140
    },
    {
      "epoch": 39.40119760479042,
      "grad_norm": 0.0850304365158081,
      "learning_rate": 0.0002622754491017964,
      "loss": 0.069,
      "step": 13160
    },
    {
      "epoch": 39.461077844311376,
      "grad_norm": 0.017866848036646843,
      "learning_rate": 0.00026176218990590244,
      "loss": 0.1417,
      "step": 13180
    },
    {
      "epoch": 39.52095808383233,
      "grad_norm": 6.13978910446167,
      "learning_rate": 0.0002612489307100085,
      "loss": 0.2079,
      "step": 13200
    },
    {
      "epoch": 39.58083832335329,
      "grad_norm": 7.142071723937988,
      "learning_rate": 0.0002607356715141146,
      "loss": 0.2161,
      "step": 13220
    },
    {
      "epoch": 39.64071856287425,
      "grad_norm": 3.988123655319214,
      "learning_rate": 0.0002602224123182207,
      "loss": 0.2166,
      "step": 13240
    },
    {
      "epoch": 39.70059880239521,
      "grad_norm": 0.5237256288528442,
      "learning_rate": 0.0002597091531223268,
      "loss": 0.1856,
      "step": 13260
    },
    {
      "epoch": 39.76047904191617,
      "grad_norm": 16.82879066467285,
      "learning_rate": 0.0002591958939264328,
      "loss": 0.2006,
      "step": 13280
    },
    {
      "epoch": 39.82035928143713,
      "grad_norm": 0.27119430899620056,
      "learning_rate": 0.0002586826347305389,
      "loss": 0.1504,
      "step": 13300
    },
    {
      "epoch": 39.880239520958085,
      "grad_norm": 1.7015893459320068,
      "learning_rate": 0.000258169375534645,
      "loss": 0.1949,
      "step": 13320
    },
    {
      "epoch": 39.94011976047904,
      "grad_norm": 15.698081016540527,
      "learning_rate": 0.00025765611633875107,
      "loss": 0.1734,
      "step": 13340
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.07897870242595673,
      "learning_rate": 0.0002571428571428571,
      "loss": 0.1508,
      "step": 13360
    },
    {
      "epoch": 40.0,
      "eval_accuracy": 0.8504901960784313,
      "eval_accuracy_10": 0.8578431372549019,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8480392156862745,
      "eval_accuracy_15": 0.8455882352941176,
      "eval_accuracy_16": 0.8529411764705882,
      "eval_accuracy_17": 0.8504901960784313,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8504901960784313,
      "eval_accuracy_20": 0.8504901960784313,
      "eval_accuracy_21": 0.8480392156862745,
      "eval_accuracy_22": 0.8480392156862745,
      "eval_accuracy_23": 0.8480392156862745,
      "eval_accuracy_24": 0.8480392156862745,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.8729294891198331,
      "eval_f1": 0.8953687821612349,
      "eval_loss": 0.7281582951545715,
      "eval_runtime": 214.0837,
      "eval_samples_per_second": 1.906,
      "eval_steps_per_second": 0.238,
      "step": 13360
    },
    {
      "epoch": 40.05988023952096,
      "grad_norm": 7.901173114776611,
      "learning_rate": 0.0002566295979469632,
      "loss": 0.2323,
      "step": 13380
    },
    {
      "epoch": 40.119760479041915,
      "grad_norm": 3.587305784225464,
      "learning_rate": 0.00025611633875106927,
      "loss": 0.1792,
      "step": 13400
    },
    {
      "epoch": 40.17964071856287,
      "grad_norm": 5.871935844421387,
      "learning_rate": 0.00025560307955517535,
      "loss": 0.1847,
      "step": 13420
    },
    {
      "epoch": 40.23952095808383,
      "grad_norm": 13.089856147766113,
      "learning_rate": 0.00025508982035928144,
      "loss": 0.1983,
      "step": 13440
    },
    {
      "epoch": 40.29940119760479,
      "grad_norm": 1.4634358882904053,
      "learning_rate": 0.00025457656116338747,
      "loss": 0.2274,
      "step": 13460
    },
    {
      "epoch": 40.35928143712575,
      "grad_norm": 1.8426179885864258,
      "learning_rate": 0.00025406330196749355,
      "loss": 0.2059,
      "step": 13480
    },
    {
      "epoch": 40.41916167664671,
      "grad_norm": 5.058986663818359,
      "learning_rate": 0.00025355004277159964,
      "loss": 0.143,
      "step": 13500
    },
    {
      "epoch": 40.47904191616767,
      "grad_norm": 7.585834980010986,
      "learning_rate": 0.0002530367835757057,
      "loss": 0.1263,
      "step": 13520
    },
    {
      "epoch": 40.538922155688624,
      "grad_norm": 8.297143936157227,
      "learning_rate": 0.00025252352437981176,
      "loss": 0.1257,
      "step": 13540
    },
    {
      "epoch": 40.59880239520958,
      "grad_norm": 6.7589030265808105,
      "learning_rate": 0.00025201026518391784,
      "loss": 0.1706,
      "step": 13560
    },
    {
      "epoch": 40.65868263473054,
      "grad_norm": 4.822672367095947,
      "learning_rate": 0.00025149700598802393,
      "loss": 0.1699,
      "step": 13580
    },
    {
      "epoch": 40.7185628742515,
      "grad_norm": 11.957541465759277,
      "learning_rate": 0.00025098374679213,
      "loss": 0.1601,
      "step": 13600
    },
    {
      "epoch": 40.778443113772454,
      "grad_norm": 0.2836441397666931,
      "learning_rate": 0.0002504704875962361,
      "loss": 0.1429,
      "step": 13620
    },
    {
      "epoch": 40.83832335329341,
      "grad_norm": 6.49166202545166,
      "learning_rate": 0.00024995722840034213,
      "loss": 0.1417,
      "step": 13640
    },
    {
      "epoch": 40.89820359281437,
      "grad_norm": 1.3648171424865723,
      "learning_rate": 0.0002494439692044482,
      "loss": 0.1353,
      "step": 13660
    },
    {
      "epoch": 40.958083832335326,
      "grad_norm": 0.14873775839805603,
      "learning_rate": 0.0002489307100085543,
      "loss": 0.1548,
      "step": 13680
    },
    {
      "epoch": 41.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8627450980392157,
      "eval_accuracy_12": 0.8627450980392157,
      "eval_accuracy_13": 0.8602941176470589,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8578431372549019,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8772687280040221,
      "eval_f1": 0.8991452991452993,
      "eval_loss": 0.776930570602417,
      "eval_runtime": 211.9686,
      "eval_samples_per_second": 1.925,
      "eval_steps_per_second": 0.241,
      "step": 13694
    },
    {
      "epoch": 41.01796407185629,
      "grad_norm": 9.793846130371094,
      "learning_rate": 0.0002484174508126604,
      "loss": 0.1163,
      "step": 13700
    },
    {
      "epoch": 41.07784431137725,
      "grad_norm": 18.245826721191406,
      "learning_rate": 0.0002479041916167664,
      "loss": 0.2001,
      "step": 13720
    },
    {
      "epoch": 41.137724550898206,
      "grad_norm": 12.971733093261719,
      "learning_rate": 0.0002473909324208725,
      "loss": 0.1717,
      "step": 13740
    },
    {
      "epoch": 41.19760479041916,
      "grad_norm": 14.368821144104004,
      "learning_rate": 0.0002468776732249786,
      "loss": 0.1343,
      "step": 13760
    },
    {
      "epoch": 41.25748502994012,
      "grad_norm": 9.978633880615234,
      "learning_rate": 0.00024636441402908467,
      "loss": 0.1271,
      "step": 13780
    },
    {
      "epoch": 41.31736526946108,
      "grad_norm": 0.2898435890674591,
      "learning_rate": 0.00024585115483319076,
      "loss": 0.138,
      "step": 13800
    },
    {
      "epoch": 41.377245508982035,
      "grad_norm": 9.375334739685059,
      "learning_rate": 0.0002453378956372968,
      "loss": 0.2085,
      "step": 13820
    },
    {
      "epoch": 41.43712574850299,
      "grad_norm": 0.09588661789894104,
      "learning_rate": 0.0002448246364414029,
      "loss": 0.0845,
      "step": 13840
    },
    {
      "epoch": 41.49700598802395,
      "grad_norm": 8.854986190795898,
      "learning_rate": 0.00024431137724550896,
      "loss": 0.1728,
      "step": 13860
    },
    {
      "epoch": 41.55688622754491,
      "grad_norm": 9.399652481079102,
      "learning_rate": 0.00024379811804961505,
      "loss": 0.156,
      "step": 13880
    },
    {
      "epoch": 41.616766467065865,
      "grad_norm": 3.421220064163208,
      "learning_rate": 0.0002432848588537211,
      "loss": 0.0785,
      "step": 13900
    },
    {
      "epoch": 41.67664670658683,
      "grad_norm": 15.608441352844238,
      "learning_rate": 0.0002427715996578272,
      "loss": 0.1315,
      "step": 13920
    },
    {
      "epoch": 41.73652694610779,
      "grad_norm": 12.340551376342773,
      "learning_rate": 0.00024225834046193325,
      "loss": 0.1858,
      "step": 13940
    },
    {
      "epoch": 41.796407185628745,
      "grad_norm": 3.1789724826812744,
      "learning_rate": 0.00024174508126603933,
      "loss": 0.1659,
      "step": 13960
    },
    {
      "epoch": 41.8562874251497,
      "grad_norm": 4.3783440589904785,
      "learning_rate": 0.0002412318220701454,
      "loss": 0.2992,
      "step": 13980
    },
    {
      "epoch": 41.91616766467066,
      "grad_norm": 1.460852026939392,
      "learning_rate": 0.00024071856287425148,
      "loss": 0.1183,
      "step": 14000
    },
    {
      "epoch": 41.97604790419162,
      "grad_norm": 10.403155326843262,
      "learning_rate": 0.00024020530367835756,
      "loss": 0.179,
      "step": 14020
    },
    {
      "epoch": 42.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8627450980392157,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8627450980392157,
      "eval_accuracy_14": 0.8602941176470589,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8529411764705882,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8578431372549019,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8763917306052855,
      "eval_f1": 0.897391304347826,
      "eval_loss": 0.6771342158317566,
      "eval_runtime": 221.3105,
      "eval_samples_per_second": 1.844,
      "eval_steps_per_second": 0.23,
      "step": 14028
    },
    {
      "epoch": 42.035928143712574,
      "grad_norm": 0.05451279878616333,
      "learning_rate": 0.00023969204448246362,
      "loss": 0.0741,
      "step": 14040
    },
    {
      "epoch": 42.09580838323353,
      "grad_norm": 12.368742942810059,
      "learning_rate": 0.0002391787852865697,
      "loss": 0.1765,
      "step": 14060
    },
    {
      "epoch": 42.15568862275449,
      "grad_norm": 8.227091789245605,
      "learning_rate": 0.00023866552609067576,
      "loss": 0.157,
      "step": 14080
    },
    {
      "epoch": 42.21556886227545,
      "grad_norm": 0.6341040730476379,
      "learning_rate": 0.00023815226689478185,
      "loss": 0.2178,
      "step": 14100
    },
    {
      "epoch": 42.275449101796404,
      "grad_norm": 4.055679798126221,
      "learning_rate": 0.0002376390076988879,
      "loss": 0.178,
      "step": 14120
    },
    {
      "epoch": 42.33532934131736,
      "grad_norm": 0.5927165150642395,
      "learning_rate": 0.000237125748502994,
      "loss": 0.0725,
      "step": 14140
    },
    {
      "epoch": 42.395209580838326,
      "grad_norm": 11.022774696350098,
      "learning_rate": 0.00023661248930710005,
      "loss": 0.1852,
      "step": 14160
    },
    {
      "epoch": 42.455089820359284,
      "grad_norm": 2.145237922668457,
      "learning_rate": 0.00023609923011120614,
      "loss": 0.079,
      "step": 14180
    },
    {
      "epoch": 42.51497005988024,
      "grad_norm": 0.7199062705039978,
      "learning_rate": 0.00023558597091531222,
      "loss": 0.1366,
      "step": 14200
    },
    {
      "epoch": 42.5748502994012,
      "grad_norm": 1.3730180263519287,
      "learning_rate": 0.00023507271171941828,
      "loss": 0.1074,
      "step": 14220
    },
    {
      "epoch": 42.634730538922156,
      "grad_norm": 15.18774127960205,
      "learning_rate": 0.00023455945252352436,
      "loss": 0.2221,
      "step": 14240
    },
    {
      "epoch": 42.69461077844311,
      "grad_norm": 12.394063949584961,
      "learning_rate": 0.00023404619332763042,
      "loss": 0.21,
      "step": 14260
    },
    {
      "epoch": 42.75449101796407,
      "grad_norm": 5.794097423553467,
      "learning_rate": 0.0002335329341317365,
      "loss": 0.2552,
      "step": 14280
    },
    {
      "epoch": 42.81437125748503,
      "grad_norm": 0.1834130883216858,
      "learning_rate": 0.00023301967493584257,
      "loss": 0.1982,
      "step": 14300
    },
    {
      "epoch": 42.874251497005986,
      "grad_norm": 0.2244110405445099,
      "learning_rate": 0.00023250641573994865,
      "loss": 0.102,
      "step": 14320
    },
    {
      "epoch": 42.93413173652694,
      "grad_norm": 1.6029918193817139,
      "learning_rate": 0.0002319931565440547,
      "loss": 0.0359,
      "step": 14340
    },
    {
      "epoch": 42.9940119760479,
      "grad_norm": 10.952061653137207,
      "learning_rate": 0.0002314798973481608,
      "loss": 0.1456,
      "step": 14360
    },
    {
      "epoch": 43.0,
      "eval_accuracy": 0.8504901960784313,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8529411764705882,
      "eval_accuracy_18": 0.8602941176470589,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8529411764705882,
      "eval_accuracy_22": 0.8504901960784313,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8504901960784313,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.8727494009652054,
      "eval_f1": 0.8950086058519794,
      "eval_loss": 0.7997981309890747,
      "eval_runtime": 209.9503,
      "eval_samples_per_second": 1.943,
      "eval_steps_per_second": 0.243,
      "step": 14362
    },
    {
      "epoch": 43.053892215568865,
      "grad_norm": 11.004843711853027,
      "learning_rate": 0.00023096663815226685,
      "loss": 0.1256,
      "step": 14380
    },
    {
      "epoch": 43.11377245508982,
      "grad_norm": 19.26350212097168,
      "learning_rate": 0.00023045337895637294,
      "loss": 0.121,
      "step": 14400
    },
    {
      "epoch": 43.17365269461078,
      "grad_norm": 10.191817283630371,
      "learning_rate": 0.00022994011976047902,
      "loss": 0.1919,
      "step": 14420
    },
    {
      "epoch": 43.23353293413174,
      "grad_norm": 6.755202293395996,
      "learning_rate": 0.00022942686056458508,
      "loss": 0.1486,
      "step": 14440
    },
    {
      "epoch": 43.293413173652695,
      "grad_norm": 11.112377166748047,
      "learning_rate": 0.00022891360136869117,
      "loss": 0.097,
      "step": 14460
    },
    {
      "epoch": 43.35329341317365,
      "grad_norm": 0.010621660389006138,
      "learning_rate": 0.00022840034217279723,
      "loss": 0.1084,
      "step": 14480
    },
    {
      "epoch": 43.41317365269461,
      "grad_norm": 13.226792335510254,
      "learning_rate": 0.0002278870829769033,
      "loss": 0.1906,
      "step": 14500
    },
    {
      "epoch": 43.47305389221557,
      "grad_norm": 1.1209691762924194,
      "learning_rate": 0.00022737382378100937,
      "loss": 0.177,
      "step": 14520
    },
    {
      "epoch": 43.532934131736525,
      "grad_norm": 6.632718563079834,
      "learning_rate": 0.00022686056458511545,
      "loss": 0.2158,
      "step": 14540
    },
    {
      "epoch": 43.59281437125748,
      "grad_norm": 7.271653652191162,
      "learning_rate": 0.0002263473053892215,
      "loss": 0.1223,
      "step": 14560
    },
    {
      "epoch": 43.65269461077844,
      "grad_norm": 6.684144020080566,
      "learning_rate": 0.0002258340461933276,
      "loss": 0.1404,
      "step": 14580
    },
    {
      "epoch": 43.712574850299404,
      "grad_norm": 1.2233214378356934,
      "learning_rate": 0.0002253207869974337,
      "loss": 0.1673,
      "step": 14600
    },
    {
      "epoch": 43.77245508982036,
      "grad_norm": 5.9152984619140625,
      "learning_rate": 0.00022480752780153974,
      "loss": 0.1386,
      "step": 14620
    },
    {
      "epoch": 43.83233532934132,
      "grad_norm": 0.5599443912506104,
      "learning_rate": 0.00022429426860564585,
      "loss": 0.1173,
      "step": 14640
    },
    {
      "epoch": 43.89221556886228,
      "grad_norm": 7.9669084548950195,
      "learning_rate": 0.00022378100940975189,
      "loss": 0.1029,
      "step": 14660
    },
    {
      "epoch": 43.952095808383234,
      "grad_norm": 4.440017223358154,
      "learning_rate": 0.000223267750213858,
      "loss": 0.1269,
      "step": 14680
    },
    {
      "epoch": 44.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8651960784313726,
      "eval_accuracy_12": 0.8651960784313726,
      "eval_accuracy_13": 0.8627450980392157,
      "eval_accuracy_14": 0.8651960784313726,
      "eval_accuracy_15": 0.8651960784313726,
      "eval_accuracy_16": 0.8627450980392157,
      "eval_accuracy_17": 0.8627450980392157,
      "eval_accuracy_18": 0.8627450980392157,
      "eval_accuracy_19": 0.8676470588235294,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8651960784313726,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8602941176470589,
      "eval_combined_score": 0.8805818414322251,
      "eval_f1": 0.9008695652173914,
      "eval_loss": 0.7369723320007324,
      "eval_runtime": 220.998,
      "eval_samples_per_second": 1.846,
      "eval_steps_per_second": 0.231,
      "step": 14696
    },
    {
      "epoch": 44.01197604790419,
      "grad_norm": 5.963304042816162,
      "learning_rate": 0.00022275449101796406,
      "loss": 0.1874,
      "step": 14700
    },
    {
      "epoch": 44.07185628742515,
      "grad_norm": 10.02362060546875,
      "learning_rate": 0.00022224123182207014,
      "loss": 0.1932,
      "step": 14720
    },
    {
      "epoch": 44.131736526946106,
      "grad_norm": 0.12211962044239044,
      "learning_rate": 0.0002217279726261762,
      "loss": 0.1744,
      "step": 14740
    },
    {
      "epoch": 44.191616766467064,
      "grad_norm": 0.31853994727134705,
      "learning_rate": 0.00022121471343028229,
      "loss": 0.1164,
      "step": 14760
    },
    {
      "epoch": 44.25149700598802,
      "grad_norm": 1.2073982954025269,
      "learning_rate": 0.00022070145423438834,
      "loss": 0.1023,
      "step": 14780
    },
    {
      "epoch": 44.31137724550898,
      "grad_norm": 22.10148811340332,
      "learning_rate": 0.00022018819503849443,
      "loss": 0.0927,
      "step": 14800
    },
    {
      "epoch": 44.37125748502994,
      "grad_norm": 8.369909286499023,
      "learning_rate": 0.00021967493584260051,
      "loss": 0.1765,
      "step": 14820
    },
    {
      "epoch": 44.4311377245509,
      "grad_norm": 6.704518795013428,
      "learning_rate": 0.00021916167664670657,
      "loss": 0.1777,
      "step": 14840
    },
    {
      "epoch": 44.49101796407186,
      "grad_norm": 0.2333718091249466,
      "learning_rate": 0.00021864841745081266,
      "loss": 0.0874,
      "step": 14860
    },
    {
      "epoch": 44.550898203592816,
      "grad_norm": 1.9840784072875977,
      "learning_rate": 0.00021813515825491872,
      "loss": 0.1424,
      "step": 14880
    },
    {
      "epoch": 44.61077844311377,
      "grad_norm": 5.8177266120910645,
      "learning_rate": 0.0002176218990590248,
      "loss": 0.1529,
      "step": 14900
    },
    {
      "epoch": 44.67065868263473,
      "grad_norm": 1.2854070663452148,
      "learning_rate": 0.00021710863986313086,
      "loss": 0.1706,
      "step": 14920
    },
    {
      "epoch": 44.73053892215569,
      "grad_norm": 8.950849533081055,
      "learning_rate": 0.00021659538066723694,
      "loss": 0.0841,
      "step": 14940
    },
    {
      "epoch": 44.790419161676645,
      "grad_norm": 7.393952369689941,
      "learning_rate": 0.000216082121471343,
      "loss": 0.1397,
      "step": 14960
    },
    {
      "epoch": 44.8502994011976,
      "grad_norm": 7.54255485534668,
      "learning_rate": 0.0002155688622754491,
      "loss": 0.0869,
      "step": 14980
    },
    {
      "epoch": 44.91017964071856,
      "grad_norm": 1.7666728496551514,
      "learning_rate": 0.00021505560307955517,
      "loss": 0.0971,
      "step": 15000
    },
    {
      "epoch": 44.97005988023952,
      "grad_norm": 0.05127863958477974,
      "learning_rate": 0.00021454234388366123,
      "loss": 0.1938,
      "step": 15020
    },
    {
      "epoch": 45.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8602941176470589,
      "eval_accuracy_18": 0.8602941176470589,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8805818414322251,
      "eval_f1": 0.9008695652173914,
      "eval_loss": 0.7382798790931702,
      "eval_runtime": 223.2777,
      "eval_samples_per_second": 1.827,
      "eval_steps_per_second": 0.228,
      "step": 15030
    },
    {
      "epoch": 45.02994011976048,
      "grad_norm": 1.929795265197754,
      "learning_rate": 0.00021402908468776732,
      "loss": 0.2258,
      "step": 15040
    },
    {
      "epoch": 45.08982035928144,
      "grad_norm": 20.78601837158203,
      "learning_rate": 0.00021351582549187338,
      "loss": 0.1513,
      "step": 15060
    },
    {
      "epoch": 45.1497005988024,
      "grad_norm": 1.2662317752838135,
      "learning_rate": 0.00021300256629597946,
      "loss": 0.1284,
      "step": 15080
    },
    {
      "epoch": 45.209580838323355,
      "grad_norm": 11.915346145629883,
      "learning_rate": 0.00021248930710008552,
      "loss": 0.1238,
      "step": 15100
    },
    {
      "epoch": 45.26946107784431,
      "grad_norm": 0.16342127323150635,
      "learning_rate": 0.0002119760479041916,
      "loss": 0.0888,
      "step": 15120
    },
    {
      "epoch": 45.32934131736527,
      "grad_norm": 0.6378036737442017,
      "learning_rate": 0.00021146278870829766,
      "loss": 0.0624,
      "step": 15140
    },
    {
      "epoch": 45.38922155688623,
      "grad_norm": 0.686494767665863,
      "learning_rate": 0.00021094952951240375,
      "loss": 0.1853,
      "step": 15160
    },
    {
      "epoch": 45.449101796407184,
      "grad_norm": 13.831202507019043,
      "learning_rate": 0.0002104362703165098,
      "loss": 0.1796,
      "step": 15180
    },
    {
      "epoch": 45.50898203592814,
      "grad_norm": 0.8538357615470886,
      "learning_rate": 0.0002099230111206159,
      "loss": 0.0989,
      "step": 15200
    },
    {
      "epoch": 45.5688622754491,
      "grad_norm": 13.839202880859375,
      "learning_rate": 0.00020940975192472198,
      "loss": 0.1499,
      "step": 15220
    },
    {
      "epoch": 45.62874251497006,
      "grad_norm": 3.797942638397217,
      "learning_rate": 0.00020889649272882804,
      "loss": 0.1746,
      "step": 15240
    },
    {
      "epoch": 45.68862275449102,
      "grad_norm": 3.048530101776123,
      "learning_rate": 0.00020838323353293412,
      "loss": 0.1827,
      "step": 15260
    },
    {
      "epoch": 45.74850299401198,
      "grad_norm": 0.30090177059173584,
      "learning_rate": 0.00020786997433704018,
      "loss": 0.1897,
      "step": 15280
    },
    {
      "epoch": 45.808383233532936,
      "grad_norm": 3.7322072982788086,
      "learning_rate": 0.00020735671514114626,
      "loss": 0.1729,
      "step": 15300
    },
    {
      "epoch": 45.868263473053894,
      "grad_norm": 1.6897556781768799,
      "learning_rate": 0.00020684345594525232,
      "loss": 0.105,
      "step": 15320
    },
    {
      "epoch": 45.92814371257485,
      "grad_norm": 20.832796096801758,
      "learning_rate": 0.0002063301967493584,
      "loss": 0.1304,
      "step": 15340
    },
    {
      "epoch": 45.98802395209581,
      "grad_norm": 6.673775672912598,
      "learning_rate": 0.00020581693755346447,
      "loss": 0.1917,
      "step": 15360
    },
    {
      "epoch": 46.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8651960784313726,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8480392156862745,
      "eval_accuracy_15": 0.8529411764705882,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8529411764705882,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8627450980392157,
      "eval_accuracy_20": 0.8651960784313726,
      "eval_accuracy_21": 0.8602941176470589,
      "eval_accuracy_22": 0.8602941176470589,
      "eval_accuracy_23": 0.8602941176470589,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8797690262545697,
      "eval_f1": 0.9016949152542373,
      "eval_loss": 0.8454006314277649,
      "eval_runtime": 223.1358,
      "eval_samples_per_second": 1.828,
      "eval_steps_per_second": 0.229,
      "step": 15364
    },
    {
      "epoch": 46.047904191616766,
      "grad_norm": 1.9211193323135376,
      "learning_rate": 0.00020530367835757055,
      "loss": 0.1095,
      "step": 15380
    },
    {
      "epoch": 46.10778443113772,
      "grad_norm": 17.666378021240234,
      "learning_rate": 0.00020479041916167664,
      "loss": 0.223,
      "step": 15400
    },
    {
      "epoch": 46.16766467065868,
      "grad_norm": 0.05726848170161247,
      "learning_rate": 0.0002042771599657827,
      "loss": 0.1611,
      "step": 15420
    },
    {
      "epoch": 46.22754491017964,
      "grad_norm": 0.3795992136001587,
      "learning_rate": 0.00020376390076988878,
      "loss": 0.1921,
      "step": 15440
    },
    {
      "epoch": 46.287425149700596,
      "grad_norm": 5.768886566162109,
      "learning_rate": 0.00020325064157399484,
      "loss": 0.2222,
      "step": 15460
    },
    {
      "epoch": 46.34730538922156,
      "grad_norm": 7.387796878814697,
      "learning_rate": 0.00020273738237810092,
      "loss": 0.1312,
      "step": 15480
    },
    {
      "epoch": 46.40718562874252,
      "grad_norm": 7.69297981262207,
      "learning_rate": 0.00020222412318220698,
      "loss": 0.2223,
      "step": 15500
    },
    {
      "epoch": 46.467065868263475,
      "grad_norm": 0.9952967762947083,
      "learning_rate": 0.00020171086398631307,
      "loss": 0.1398,
      "step": 15520
    },
    {
      "epoch": 46.52694610778443,
      "grad_norm": 8.925970077514648,
      "learning_rate": 0.00020119760479041913,
      "loss": 0.154,
      "step": 15540
    },
    {
      "epoch": 46.58682634730539,
      "grad_norm": 0.0312727726995945,
      "learning_rate": 0.0002006843455945252,
      "loss": 0.0699,
      "step": 15560
    },
    {
      "epoch": 46.64670658682635,
      "grad_norm": 0.7663124799728394,
      "learning_rate": 0.00020017108639863127,
      "loss": 0.1892,
      "step": 15580
    },
    {
      "epoch": 46.706586826347305,
      "grad_norm": 0.558060884475708,
      "learning_rate": 0.00019965782720273735,
      "loss": 0.1481,
      "step": 15600
    },
    {
      "epoch": 46.76646706586826,
      "grad_norm": 1.3910351991653442,
      "learning_rate": 0.00019914456800684344,
      "loss": 0.1559,
      "step": 15620
    },
    {
      "epoch": 46.82634730538922,
      "grad_norm": 0.4260313808917999,
      "learning_rate": 0.0001986313088109495,
      "loss": 0.0547,
      "step": 15640
    },
    {
      "epoch": 46.88622754491018,
      "grad_norm": 1.0550743341445923,
      "learning_rate": 0.00019811804961505558,
      "loss": 0.1299,
      "step": 15660
    },
    {
      "epoch": 46.946107784431135,
      "grad_norm": 3.320992946624756,
      "learning_rate": 0.00019760479041916164,
      "loss": 0.082,
      "step": 15680
    },
    {
      "epoch": 47.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8627450980392157,
      "eval_accuracy_13": 0.8627450980392157,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8627450980392157,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8651960784313726,
      "eval_accuracy_20": 0.8651960784313726,
      "eval_accuracy_21": 0.8602941176470589,
      "eval_accuracy_22": 0.8602941176470589,
      "eval_accuracy_23": 0.8602941176470589,
      "eval_accuracy_24": 0.8602941176470589,
      "eval_accuracy_25": 0.8578431372549019,
      "eval_combined_score": 0.8796018407362944,
      "eval_f1": 0.901360544217687,
      "eval_loss": 0.8431047797203064,
      "eval_runtime": 223.5055,
      "eval_samples_per_second": 1.825,
      "eval_steps_per_second": 0.228,
      "step": 15698
    },
    {
      "epoch": 47.0059880239521,
      "grad_norm": 0.5330342054367065,
      "learning_rate": 0.00019709153122326773,
      "loss": 0.1228,
      "step": 15700
    },
    {
      "epoch": 47.06586826347306,
      "grad_norm": 11.580668449401855,
      "learning_rate": 0.00019657827202737379,
      "loss": 0.1676,
      "step": 15720
    },
    {
      "epoch": 47.125748502994014,
      "grad_norm": 11.761908531188965,
      "learning_rate": 0.00019606501283147987,
      "loss": 0.1638,
      "step": 15740
    },
    {
      "epoch": 47.18562874251497,
      "grad_norm": 0.41315391659736633,
      "learning_rate": 0.00019555175363558593,
      "loss": 0.1529,
      "step": 15760
    },
    {
      "epoch": 47.24550898203593,
      "grad_norm": 0.6904577016830444,
      "learning_rate": 0.00019503849443969204,
      "loss": 0.1803,
      "step": 15780
    },
    {
      "epoch": 47.30538922155689,
      "grad_norm": 20.6679630279541,
      "learning_rate": 0.00019452523524379813,
      "loss": 0.0541,
      "step": 15800
    },
    {
      "epoch": 47.365269461077844,
      "grad_norm": 13.947065353393555,
      "learning_rate": 0.00019401197604790419,
      "loss": 0.1348,
      "step": 15820
    },
    {
      "epoch": 47.4251497005988,
      "grad_norm": 7.070539474487305,
      "learning_rate": 0.00019349871685201027,
      "loss": 0.1391,
      "step": 15840
    },
    {
      "epoch": 47.48502994011976,
      "grad_norm": 0.8870264887809753,
      "learning_rate": 0.00019298545765611633,
      "loss": 0.0763,
      "step": 15860
    },
    {
      "epoch": 47.544910179640716,
      "grad_norm": 0.5493029356002808,
      "learning_rate": 0.00019247219846022241,
      "loss": 0.123,
      "step": 15880
    },
    {
      "epoch": 47.604790419161674,
      "grad_norm": 8.589324951171875,
      "learning_rate": 0.00019195893926432847,
      "loss": 0.1603,
      "step": 15900
    },
    {
      "epoch": 47.66467065868264,
      "grad_norm": 24.790142059326172,
      "learning_rate": 0.00019144568006843456,
      "loss": 0.1296,
      "step": 15920
    },
    {
      "epoch": 47.724550898203596,
      "grad_norm": 2.096656560897827,
      "learning_rate": 0.00019093242087254062,
      "loss": 0.0865,
      "step": 15940
    },
    {
      "epoch": 47.78443113772455,
      "grad_norm": 2.918557643890381,
      "learning_rate": 0.0001904191616766467,
      "loss": 0.1929,
      "step": 15960
    },
    {
      "epoch": 47.84431137724551,
      "grad_norm": 5.450136661529541,
      "learning_rate": 0.00018990590248075276,
      "loss": 0.2161,
      "step": 15980
    },
    {
      "epoch": 47.90419161676647,
      "grad_norm": 8.386955261230469,
      "learning_rate": 0.00018939264328485884,
      "loss": 0.1215,
      "step": 16000
    },
    {
      "epoch": 47.964071856287426,
      "grad_norm": 0.11298214644193649,
      "learning_rate": 0.00018887938408896493,
      "loss": 0.1226,
      "step": 16020
    },
    {
      "epoch": 48.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8553921568627451,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8480392156862745,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8627450980392157,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8602941176470589,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8602941176470589,
      "eval_accuracy_25": 0.8602941176470589,
      "eval_combined_score": 0.8785743464052287,
      "eval_f1": 0.8993055555555555,
      "eval_loss": 0.7034759521484375,
      "eval_runtime": 217.6497,
      "eval_samples_per_second": 1.875,
      "eval_steps_per_second": 0.234,
      "step": 16032
    },
    {
      "epoch": 48.02395209580838,
      "grad_norm": 5.3537445068359375,
      "learning_rate": 0.000188366124893071,
      "loss": 0.1427,
      "step": 16040
    },
    {
      "epoch": 48.08383233532934,
      "grad_norm": 5.560160160064697,
      "learning_rate": 0.00018785286569717707,
      "loss": 0.08,
      "step": 16060
    },
    {
      "epoch": 48.1437125748503,
      "grad_norm": 0.3624805212020874,
      "learning_rate": 0.00018733960650128313,
      "loss": 0.1398,
      "step": 16080
    },
    {
      "epoch": 48.203592814371255,
      "grad_norm": 0.14442892372608185,
      "learning_rate": 0.00018682634730538922,
      "loss": 0.0521,
      "step": 16100
    },
    {
      "epoch": 48.26347305389221,
      "grad_norm": 1.9213159084320068,
      "learning_rate": 0.00018631308810949528,
      "loss": 0.1575,
      "step": 16120
    },
    {
      "epoch": 48.32335329341317,
      "grad_norm": 13.561278343200684,
      "learning_rate": 0.00018579982891360136,
      "loss": 0.1412,
      "step": 16140
    },
    {
      "epoch": 48.383233532934135,
      "grad_norm": 9.426466941833496,
      "learning_rate": 0.00018528656971770742,
      "loss": 0.1314,
      "step": 16160
    },
    {
      "epoch": 48.44311377245509,
      "grad_norm": 1.273749828338623,
      "learning_rate": 0.0001847733105218135,
      "loss": 0.1075,
      "step": 16180
    },
    {
      "epoch": 48.50299401197605,
      "grad_norm": 0.9626713991165161,
      "learning_rate": 0.0001842600513259196,
      "loss": 0.0561,
      "step": 16200
    },
    {
      "epoch": 48.56287425149701,
      "grad_norm": 5.812917232513428,
      "learning_rate": 0.00018374679213002565,
      "loss": 0.1684,
      "step": 16220
    },
    {
      "epoch": 48.622754491017965,
      "grad_norm": 0.2257908135652542,
      "learning_rate": 0.00018323353293413173,
      "loss": 0.093,
      "step": 16240
    },
    {
      "epoch": 48.68263473053892,
      "grad_norm": 4.154628753662109,
      "learning_rate": 0.0001827202737382378,
      "loss": 0.1256,
      "step": 16260
    },
    {
      "epoch": 48.74251497005988,
      "grad_norm": 6.283185005187988,
      "learning_rate": 0.00018220701454234388,
      "loss": 0.1475,
      "step": 16280
    },
    {
      "epoch": 48.80239520958084,
      "grad_norm": 6.81275749206543,
      "learning_rate": 0.00018169375534644994,
      "loss": 0.1281,
      "step": 16300
    },
    {
      "epoch": 48.862275449101794,
      "grad_norm": 0.9887205958366394,
      "learning_rate": 0.00018118049615055602,
      "loss": 0.1052,
      "step": 16320
    },
    {
      "epoch": 48.92215568862275,
      "grad_norm": 10.147024154663086,
      "learning_rate": 0.00018066723695466208,
      "loss": 0.1167,
      "step": 16340
    },
    {
      "epoch": 48.98203592814371,
      "grad_norm": 10.403358459472656,
      "learning_rate": 0.00018015397775876816,
      "loss": 0.1178,
      "step": 16360
    },
    {
      "epoch": 49.0,
      "eval_accuracy": 0.8480392156862745,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8578431372549019,
      "eval_accuracy_13": 0.8504901960784313,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8627450980392157,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8504901960784313,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8455882352941176,
      "eval_accuracy_25": 0.8480392156862745,
      "eval_combined_score": 0.8707550030321407,
      "eval_f1": 0.8934707903780068,
      "eval_loss": 0.7513759136199951,
      "eval_runtime": 215.1723,
      "eval_samples_per_second": 1.896,
      "eval_steps_per_second": 0.237,
      "step": 16366
    },
    {
      "epoch": 49.041916167664674,
      "grad_norm": 3.31187105178833,
      "learning_rate": 0.00017964071856287422,
      "loss": 0.0867,
      "step": 16380
    },
    {
      "epoch": 49.10179640718563,
      "grad_norm": 0.10655327886343002,
      "learning_rate": 0.0001791274593669803,
      "loss": 0.1239,
      "step": 16400
    },
    {
      "epoch": 49.16167664670659,
      "grad_norm": 7.770005702972412,
      "learning_rate": 0.0001786142001710864,
      "loss": 0.1552,
      "step": 16420
    },
    {
      "epoch": 49.221556886227546,
      "grad_norm": 2.359191656112671,
      "learning_rate": 0.00017810094097519245,
      "loss": 0.1293,
      "step": 16440
    },
    {
      "epoch": 49.2814371257485,
      "grad_norm": 6.4099931716918945,
      "learning_rate": 0.00017758768177929854,
      "loss": 0.1339,
      "step": 16460
    },
    {
      "epoch": 49.34131736526946,
      "grad_norm": 0.7464718818664551,
      "learning_rate": 0.0001770744225834046,
      "loss": 0.0855,
      "step": 16480
    },
    {
      "epoch": 49.40119760479042,
      "grad_norm": 0.5430477261543274,
      "learning_rate": 0.00017656116338751068,
      "loss": 0.1147,
      "step": 16500
    },
    {
      "epoch": 49.461077844311376,
      "grad_norm": 17.285673141479492,
      "learning_rate": 0.00017604790419161674,
      "loss": 0.1294,
      "step": 16520
    },
    {
      "epoch": 49.52095808383233,
      "grad_norm": 0.9985037446022034,
      "learning_rate": 0.00017553464499572282,
      "loss": 0.1487,
      "step": 16540
    },
    {
      "epoch": 49.58083832335329,
      "grad_norm": 10.419341087341309,
      "learning_rate": 0.00017502138579982888,
      "loss": 0.1255,
      "step": 16560
    },
    {
      "epoch": 49.64071856287425,
      "grad_norm": 1.13472318649292,
      "learning_rate": 0.00017450812660393497,
      "loss": 0.1194,
      "step": 16580
    },
    {
      "epoch": 49.70059880239521,
      "grad_norm": 4.335930347442627,
      "learning_rate": 0.00017399486740804105,
      "loss": 0.17,
      "step": 16600
    },
    {
      "epoch": 49.76047904191617,
      "grad_norm": 1.1217519044876099,
      "learning_rate": 0.0001734816082121471,
      "loss": 0.2573,
      "step": 16620
    },
    {
      "epoch": 49.82035928143713,
      "grad_norm": 0.2302464097738266,
      "learning_rate": 0.0001729683490162532,
      "loss": 0.0844,
      "step": 16640
    },
    {
      "epoch": 49.880239520958085,
      "grad_norm": 4.54720401763916,
      "learning_rate": 0.00017245508982035925,
      "loss": 0.1366,
      "step": 16660
    },
    {
      "epoch": 49.94011976047904,
      "grad_norm": 0.09691864252090454,
      "learning_rate": 0.00017194183062446534,
      "loss": 0.0805,
      "step": 16680
    },
    {
      "epoch": 50.0,
      "grad_norm": 1.7193704843521118,
      "learning_rate": 0.0001714285714285714,
      "loss": 0.1519,
      "step": 16700
    },
    {
      "epoch": 50.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8651960784313726,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8627450980392157,
      "eval_accuracy_19": 0.8627450980392157,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8602941176470589,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8578431372549019,
      "eval_combined_score": 0.8769215517532314,
      "eval_f1": 0.8984509466437176,
      "eval_loss": 0.7560747265815735,
      "eval_runtime": 214.5816,
      "eval_samples_per_second": 1.901,
      "eval_steps_per_second": 0.238,
      "step": 16700
    },
    {
      "epoch": 50.05988023952096,
      "grad_norm": 0.779828667640686,
      "learning_rate": 0.00017091531223267748,
      "loss": 0.0517,
      "step": 16720
    },
    {
      "epoch": 50.119760479041915,
      "grad_norm": 0.9268465042114258,
      "learning_rate": 0.00017040205303678354,
      "loss": 0.14,
      "step": 16740
    },
    {
      "epoch": 50.17964071856287,
      "grad_norm": 3.2556915283203125,
      "learning_rate": 0.00016988879384088963,
      "loss": 0.0873,
      "step": 16760
    },
    {
      "epoch": 50.23952095808383,
      "grad_norm": 16.57530975341797,
      "learning_rate": 0.00016937553464499569,
      "loss": 0.1139,
      "step": 16780
    },
    {
      "epoch": 50.29940119760479,
      "grad_norm": 1.4615380764007568,
      "learning_rate": 0.00016886227544910177,
      "loss": 0.0901,
      "step": 16800
    },
    {
      "epoch": 50.35928143712575,
      "grad_norm": 0.08044570684432983,
      "learning_rate": 0.00016834901625320786,
      "loss": 0.102,
      "step": 16820
    },
    {
      "epoch": 50.41916167664671,
      "grad_norm": 17.63533592224121,
      "learning_rate": 0.00016783575705731391,
      "loss": 0.1044,
      "step": 16840
    },
    {
      "epoch": 50.47904191616767,
      "grad_norm": 0.01319632213562727,
      "learning_rate": 0.00016732249786142,
      "loss": 0.0892,
      "step": 16860
    },
    {
      "epoch": 50.538922155688624,
      "grad_norm": 0.013065934181213379,
      "learning_rate": 0.00016680923866552606,
      "loss": 0.1152,
      "step": 16880
    },
    {
      "epoch": 50.59880239520958,
      "grad_norm": 2.005995512008667,
      "learning_rate": 0.00016629597946963217,
      "loss": 0.1452,
      "step": 16900
    },
    {
      "epoch": 50.65868263473054,
      "grad_norm": 0.07414040714502335,
      "learning_rate": 0.0001657827202737382,
      "loss": 0.0724,
      "step": 16920
    },
    {
      "epoch": 50.7185628742515,
      "grad_norm": 12.179418563842773,
      "learning_rate": 0.00016526946107784431,
      "loss": 0.166,
      "step": 16940
    },
    {
      "epoch": 50.778443113772454,
      "grad_norm": 0.08375447243452072,
      "learning_rate": 0.00016475620188195034,
      "loss": 0.0852,
      "step": 16960
    },
    {
      "epoch": 50.83832335329341,
      "grad_norm": 0.895209789276123,
      "learning_rate": 0.00016424294268605646,
      "loss": 0.114,
      "step": 16980
    },
    {
      "epoch": 50.89820359281437,
      "grad_norm": 5.1914544105529785,
      "learning_rate": 0.00016372968349016254,
      "loss": 0.1028,
      "step": 17000
    },
    {
      "epoch": 50.958083832335326,
      "grad_norm": 8.33362865447998,
      "learning_rate": 0.0001632164242942686,
      "loss": 0.1126,
      "step": 17020
    },
    {
      "epoch": 51.0,
      "eval_accuracy": 0.8504901960784313,
      "eval_accuracy_10": 0.8504901960784313,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8504901960784313,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8504901960784313,
      "eval_accuracy_21": 0.8504901960784313,
      "eval_accuracy_22": 0.8504901960784313,
      "eval_accuracy_23": 0.8504901960784313,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8732859838995224,
      "eval_f1": 0.8960817717206134,
      "eval_loss": 0.8943549990653992,
      "eval_runtime": 216.0352,
      "eval_samples_per_second": 1.889,
      "eval_steps_per_second": 0.236,
      "step": 17034
    },
    {
      "epoch": 51.01796407185629,
      "grad_norm": 0.32162895798683167,
      "learning_rate": 0.00016270316509837469,
      "loss": 0.1874,
      "step": 17040
    },
    {
      "epoch": 51.07784431137725,
      "grad_norm": 0.32668718695640564,
      "learning_rate": 0.00016218990590248074,
      "loss": 0.0809,
      "step": 17060
    },
    {
      "epoch": 51.137724550898206,
      "grad_norm": 0.1627032309770584,
      "learning_rate": 0.00016167664670658683,
      "loss": 0.1067,
      "step": 17080
    },
    {
      "epoch": 51.19760479041916,
      "grad_norm": 0.15874457359313965,
      "learning_rate": 0.0001611633875106929,
      "loss": 0.272,
      "step": 17100
    },
    {
      "epoch": 51.25748502994012,
      "grad_norm": 0.167848140001297,
      "learning_rate": 0.00016065012831479897,
      "loss": 0.113,
      "step": 17120
    },
    {
      "epoch": 51.31736526946108,
      "grad_norm": 1.5638558864593506,
      "learning_rate": 0.00016013686911890503,
      "loss": 0.138,
      "step": 17140
    },
    {
      "epoch": 51.377245508982035,
      "grad_norm": 7.512766361236572,
      "learning_rate": 0.00015962360992301112,
      "loss": 0.1278,
      "step": 17160
    },
    {
      "epoch": 51.43712574850299,
      "grad_norm": 0.019277406856417656,
      "learning_rate": 0.00015911035072711718,
      "loss": 0.2112,
      "step": 17180
    },
    {
      "epoch": 51.49700598802395,
      "grad_norm": 8.648691177368164,
      "learning_rate": 0.00015859709153122326,
      "loss": 0.2172,
      "step": 17200
    },
    {
      "epoch": 51.55688622754491,
      "grad_norm": 1.0265175104141235,
      "learning_rate": 0.00015808383233532935,
      "loss": 0.1435,
      "step": 17220
    },
    {
      "epoch": 51.616766467065865,
      "grad_norm": 9.316154479980469,
      "learning_rate": 0.0001575705731394354,
      "loss": 0.0894,
      "step": 17240
    },
    {
      "epoch": 51.67664670658683,
      "grad_norm": 1.1744184494018555,
      "learning_rate": 0.0001570573139435415,
      "loss": 0.1669,
      "step": 17260
    },
    {
      "epoch": 51.73652694610779,
      "grad_norm": 1.2583330869674683,
      "learning_rate": 0.00015654405474764755,
      "loss": 0.0596,
      "step": 17280
    },
    {
      "epoch": 51.796407185628745,
      "grad_norm": 8.355146408081055,
      "learning_rate": 0.00015603079555175363,
      "loss": 0.076,
      "step": 17300
    },
    {
      "epoch": 51.8562874251497,
      "grad_norm": 0.0179912019520998,
      "learning_rate": 0.0001555175363558597,
      "loss": 0.135,
      "step": 17320
    },
    {
      "epoch": 51.91616766467066,
      "grad_norm": 8.997757911682129,
      "learning_rate": 0.00015500427715996578,
      "loss": 0.1462,
      "step": 17340
    },
    {
      "epoch": 51.97604790419162,
      "grad_norm": 11.098069190979004,
      "learning_rate": 0.00015449101796407183,
      "loss": 0.0836,
      "step": 17360
    },
    {
      "epoch": 52.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8578431372549019,
      "eval_accuracy_12": 0.8627450980392157,
      "eval_accuracy_13": 0.8578431372549019,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8651960784313726,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8651960784313726,
      "eval_accuracy_18": 0.8627450980392157,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8602941176470589,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8602941176470589,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8578431372549019,
      "eval_combined_score": 0.8767461647871584,
      "eval_f1": 0.8981001727115717,
      "eval_loss": 0.7771002650260925,
      "eval_runtime": 216.8425,
      "eval_samples_per_second": 1.882,
      "eval_steps_per_second": 0.235,
      "step": 17368
    },
    {
      "epoch": 52.035928143712574,
      "grad_norm": 9.022550582885742,
      "learning_rate": 0.00015397775876817792,
      "loss": 0.1355,
      "step": 17380
    },
    {
      "epoch": 52.09580838323353,
      "grad_norm": 1.2470812797546387,
      "learning_rate": 0.000153464499572284,
      "loss": 0.1886,
      "step": 17400
    },
    {
      "epoch": 52.15568862275449,
      "grad_norm": 0.5586839318275452,
      "learning_rate": 0.00015295124037639006,
      "loss": 0.0996,
      "step": 17420
    },
    {
      "epoch": 52.21556886227545,
      "grad_norm": 0.027336984872817993,
      "learning_rate": 0.00015243798118049615,
      "loss": 0.0783,
      "step": 17440
    },
    {
      "epoch": 52.275449101796404,
      "grad_norm": 0.4191717207431793,
      "learning_rate": 0.0001519247219846022,
      "loss": 0.1371,
      "step": 17460
    },
    {
      "epoch": 52.33532934131736,
      "grad_norm": 1.4418954849243164,
      "learning_rate": 0.0001514114627887083,
      "loss": 0.0777,
      "step": 17480
    },
    {
      "epoch": 52.395209580838326,
      "grad_norm": 0.2316749393939972,
      "learning_rate": 0.00015089820359281435,
      "loss": 0.1393,
      "step": 17500
    },
    {
      "epoch": 52.455089820359284,
      "grad_norm": 9.701044082641602,
      "learning_rate": 0.00015038494439692044,
      "loss": 0.1495,
      "step": 17520
    },
    {
      "epoch": 52.51497005988024,
      "grad_norm": 1.139439344406128,
      "learning_rate": 0.00014987168520102652,
      "loss": 0.0846,
      "step": 17540
    },
    {
      "epoch": 52.5748502994012,
      "grad_norm": 4.407792091369629,
      "learning_rate": 0.00014935842600513258,
      "loss": 0.1056,
      "step": 17560
    },
    {
      "epoch": 52.634730538922156,
      "grad_norm": 4.9662861824035645,
      "learning_rate": 0.00014884516680923867,
      "loss": 0.1229,
      "step": 17580
    },
    {
      "epoch": 52.69461077844311,
      "grad_norm": 6.412304878234863,
      "learning_rate": 0.00014833190761334472,
      "loss": 0.1251,
      "step": 17600
    },
    {
      "epoch": 52.75449101796407,
      "grad_norm": 11.71375560760498,
      "learning_rate": 0.0001478186484174508,
      "loss": 0.1017,
      "step": 17620
    },
    {
      "epoch": 52.81437125748503,
      "grad_norm": 1.3939898014068604,
      "learning_rate": 0.00014730538922155687,
      "loss": 0.0962,
      "step": 17640
    },
    {
      "epoch": 52.874251497005986,
      "grad_norm": 10.818458557128906,
      "learning_rate": 0.00014679213002566295,
      "loss": 0.1201,
      "step": 17660
    },
    {
      "epoch": 52.93413173652694,
      "grad_norm": 10.421828269958496,
      "learning_rate": 0.000146278870829769,
      "loss": 0.0965,
      "step": 17680
    },
    {
      "epoch": 52.9940119760479,
      "grad_norm": 0.07590270787477493,
      "learning_rate": 0.0001457656116338751,
      "loss": 0.0548,
      "step": 17700
    },
    {
      "epoch": 53.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_accuracy_10": 0.8578431372549019,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8602941176470589,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8578431372549019,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8602941176470589,
      "eval_combined_score": 0.8814291101055808,
      "eval_f1": 0.9025641025641027,
      "eval_loss": 0.8406293392181396,
      "eval_runtime": 215.0507,
      "eval_samples_per_second": 1.897,
      "eval_steps_per_second": 0.237,
      "step": 17702
    },
    {
      "epoch": 53.053892215568865,
      "grad_norm": 1.6041672229766846,
      "learning_rate": 0.00014525235243798118,
      "loss": 0.0892,
      "step": 17720
    },
    {
      "epoch": 53.11377245508982,
      "grad_norm": 11.9776029586792,
      "learning_rate": 0.00014473909324208724,
      "loss": 0.1282,
      "step": 17740
    },
    {
      "epoch": 53.17365269461078,
      "grad_norm": 0.5425080060958862,
      "learning_rate": 0.00014422583404619333,
      "loss": 0.17,
      "step": 17760
    },
    {
      "epoch": 53.23353293413174,
      "grad_norm": 0.6550390124320984,
      "learning_rate": 0.00014371257485029938,
      "loss": 0.13,
      "step": 17780
    },
    {
      "epoch": 53.293413173652695,
      "grad_norm": 0.11888327449560165,
      "learning_rate": 0.00014319931565440547,
      "loss": 0.1173,
      "step": 17800
    },
    {
      "epoch": 53.35329341317365,
      "grad_norm": 0.22475406527519226,
      "learning_rate": 0.00014268605645851153,
      "loss": 0.0697,
      "step": 17820
    },
    {
      "epoch": 53.41317365269461,
      "grad_norm": 7.167579174041748,
      "learning_rate": 0.0001421727972626176,
      "loss": 0.1773,
      "step": 17840
    },
    {
      "epoch": 53.47305389221557,
      "grad_norm": 15.970512390136719,
      "learning_rate": 0.00014165953806672367,
      "loss": 0.1313,
      "step": 17860
    },
    {
      "epoch": 53.532934131736525,
      "grad_norm": 3.274319648742676,
      "learning_rate": 0.00014114627887082976,
      "loss": 0.1385,
      "step": 17880
    },
    {
      "epoch": 53.59281437125748,
      "grad_norm": 4.117823123931885,
      "learning_rate": 0.00014063301967493584,
      "loss": 0.0954,
      "step": 17900
    },
    {
      "epoch": 53.65269461077844,
      "grad_norm": 0.32574620842933655,
      "learning_rate": 0.0001401197604790419,
      "loss": 0.0421,
      "step": 17920
    },
    {
      "epoch": 53.712574850299404,
      "grad_norm": 5.262526512145996,
      "learning_rate": 0.00013960650128314798,
      "loss": 0.1079,
      "step": 17940
    },
    {
      "epoch": 53.77245508982036,
      "grad_norm": 4.0519561767578125,
      "learning_rate": 0.00013909324208725404,
      "loss": 0.1006,
      "step": 17960
    },
    {
      "epoch": 53.83233532934132,
      "grad_norm": 5.001582622528076,
      "learning_rate": 0.00013857998289136013,
      "loss": 0.0957,
      "step": 17980
    },
    {
      "epoch": 53.89221556886228,
      "grad_norm": 10.317829132080078,
      "learning_rate": 0.0001380667236954662,
      "loss": 0.1261,
      "step": 18000
    },
    {
      "epoch": 53.952095808383234,
      "grad_norm": 1.198966383934021,
      "learning_rate": 0.00013755346449957227,
      "loss": 0.1526,
      "step": 18020
    },
    {
      "epoch": 54.0,
      "eval_accuracy": 0.8627450980392157,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8627450980392157,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8602941176470589,
      "eval_accuracy_14": 0.8602941176470589,
      "eval_accuracy_15": 0.8651960784313726,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8651960784313726,
      "eval_accuracy_18": 0.8651960784313726,
      "eval_accuracy_19": 0.8676470588235294,
      "eval_accuracy_20": 0.8676470588235294,
      "eval_accuracy_21": 0.8676470588235294,
      "eval_accuracy_22": 0.8676470588235294,
      "eval_accuracy_23": 0.8676470588235294,
      "eval_accuracy_24": 0.8700980392156863,
      "eval_accuracy_25": 0.8651960784313726,
      "eval_combined_score": 0.883262583383869,
      "eval_f1": 0.9037800687285222,
      "eval_loss": 0.7624532580375671,
      "eval_runtime": 213.4619,
      "eval_samples_per_second": 1.911,
      "eval_steps_per_second": 0.239,
      "step": 18036
    },
    {
      "epoch": 54.01197604790419,
      "grad_norm": 25.31565284729004,
      "learning_rate": 0.00013704020530367833,
      "loss": 0.1159,
      "step": 18040
    },
    {
      "epoch": 54.07185628742515,
      "grad_norm": 0.37737154960632324,
      "learning_rate": 0.00013652694610778442,
      "loss": 0.1026,
      "step": 18060
    },
    {
      "epoch": 54.131736526946106,
      "grad_norm": 18.881267547607422,
      "learning_rate": 0.00013601368691189047,
      "loss": 0.0977,
      "step": 18080
    },
    {
      "epoch": 54.191616766467064,
      "grad_norm": 0.10631567239761353,
      "learning_rate": 0.00013550042771599659,
      "loss": 0.0925,
      "step": 18100
    },
    {
      "epoch": 54.25149700598802,
      "grad_norm": 2.3754348754882812,
      "learning_rate": 0.00013498716852010264,
      "loss": 0.0794,
      "step": 18120
    },
    {
      "epoch": 54.31137724550898,
      "grad_norm": 15.515317916870117,
      "learning_rate": 0.00013447390932420873,
      "loss": 0.215,
      "step": 18140
    },
    {
      "epoch": 54.37125748502994,
      "grad_norm": 0.32950451970100403,
      "learning_rate": 0.0001339606501283148,
      "loss": 0.1226,
      "step": 18160
    },
    {
      "epoch": 54.4311377245509,
      "grad_norm": 3.0971059799194336,
      "learning_rate": 0.00013344739093242087,
      "loss": 0.0745,
      "step": 18180
    },
    {
      "epoch": 54.49101796407186,
      "grad_norm": 0.6862128376960754,
      "learning_rate": 0.00013293413173652693,
      "loss": 0.0872,
      "step": 18200
    },
    {
      "epoch": 54.550898203592816,
      "grad_norm": 0.030971700325608253,
      "learning_rate": 0.00013242087254063302,
      "loss": 0.0358,
      "step": 18220
    },
    {
      "epoch": 54.61077844311377,
      "grad_norm": 1.4028754234313965,
      "learning_rate": 0.00013190761334473908,
      "loss": 0.0644,
      "step": 18240
    },
    {
      "epoch": 54.67065868263473,
      "grad_norm": 13.785835266113281,
      "learning_rate": 0.00013139435414884516,
      "loss": 0.1205,
      "step": 18260
    },
    {
      "epoch": 54.73053892215569,
      "grad_norm": 11.683998107910156,
      "learning_rate": 0.00013088109495295122,
      "loss": 0.1597,
      "step": 18280
    },
    {
      "epoch": 54.790419161676645,
      "grad_norm": 0.7626842856407166,
      "learning_rate": 0.0001303678357570573,
      "loss": 0.0603,
      "step": 18300
    },
    {
      "epoch": 54.8502994011976,
      "grad_norm": 15.335663795471191,
      "learning_rate": 0.0001298545765611634,
      "loss": 0.1645,
      "step": 18320
    },
    {
      "epoch": 54.91017964071856,
      "grad_norm": 23.33817481994629,
      "learning_rate": 0.00012934131736526945,
      "loss": 0.128,
      "step": 18340
    },
    {
      "epoch": 54.97005988023952,
      "grad_norm": 21.45656394958496,
      "learning_rate": 0.00012882805816937553,
      "loss": 0.0541,
      "step": 18360
    },
    {
      "epoch": 55.0,
      "eval_accuracy": 0.8602941176470589,
      "eval_accuracy_10": 0.8627450980392157,
      "eval_accuracy_11": 0.8651960784313726,
      "eval_accuracy_12": 0.8627450980392157,
      "eval_accuracy_13": 0.8627450980392157,
      "eval_accuracy_14": 0.8627450980392157,
      "eval_accuracy_15": 0.8676470588235294,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8651960784313726,
      "eval_accuracy_18": 0.8651960784313726,
      "eval_accuracy_19": 0.8651960784313726,
      "eval_accuracy_20": 0.8676470588235294,
      "eval_accuracy_21": 0.8627450980392157,
      "eval_accuracy_22": 0.8627450980392157,
      "eval_accuracy_23": 0.8627450980392157,
      "eval_accuracy_24": 0.8602941176470589,
      "eval_accuracy_25": 0.8602941176470589,
      "eval_combined_score": 0.8805818414322251,
      "eval_f1": 0.9008695652173914,
      "eval_loss": 0.7941231727600098,
      "eval_runtime": 215.4866,
      "eval_samples_per_second": 1.893,
      "eval_steps_per_second": 0.237,
      "step": 18370
    },
    {
      "epoch": 55.02994011976048,
      "grad_norm": 13.798357009887695,
      "learning_rate": 0.0001283147989734816,
      "loss": 0.1544,
      "step": 18380
    },
    {
      "epoch": 55.08982035928144,
      "grad_norm": 0.14233867824077606,
      "learning_rate": 0.00012780153977758768,
      "loss": 0.1217,
      "step": 18400
    },
    {
      "epoch": 55.1497005988024,
      "grad_norm": 0.9790307283401489,
      "learning_rate": 0.00012728828058169373,
      "loss": 0.1256,
      "step": 18420
    },
    {
      "epoch": 55.209580838323355,
      "grad_norm": 0.059311289340257645,
      "learning_rate": 0.00012677502138579982,
      "loss": 0.1413,
      "step": 18440
    },
    {
      "epoch": 55.26946107784431,
      "grad_norm": 3.585196018218994,
      "learning_rate": 0.00012626176218990588,
      "loss": 0.0636,
      "step": 18460
    },
    {
      "epoch": 55.32934131736527,
      "grad_norm": 0.24630652368068695,
      "learning_rate": 0.00012574850299401196,
      "loss": 0.1381,
      "step": 18480
    },
    {
      "epoch": 55.38922155688623,
      "grad_norm": 0.1702076643705368,
      "learning_rate": 0.00012523524379811805,
      "loss": 0.1046,
      "step": 18500
    },
    {
      "epoch": 55.449101796407184,
      "grad_norm": 0.3834385275840759,
      "learning_rate": 0.0001247219846022241,
      "loss": 0.0815,
      "step": 18520
    },
    {
      "epoch": 55.50898203592814,
      "grad_norm": 2.0624892711639404,
      "learning_rate": 0.0001242087254063302,
      "loss": 0.1223,
      "step": 18540
    },
    {
      "epoch": 55.5688622754491,
      "grad_norm": 1.0981554985046387,
      "learning_rate": 0.00012369546621043625,
      "loss": 0.0839,
      "step": 18560
    },
    {
      "epoch": 55.62874251497006,
      "grad_norm": 4.317259788513184,
      "learning_rate": 0.00012318220701454234,
      "loss": 0.1762,
      "step": 18580
    },
    {
      "epoch": 55.68862275449102,
      "grad_norm": 7.582820892333984,
      "learning_rate": 0.0001226689478186484,
      "loss": 0.0877,
      "step": 18600
    },
    {
      "epoch": 55.74850299401198,
      "grad_norm": 0.6235707402229309,
      "learning_rate": 0.00012215568862275448,
      "loss": 0.1199,
      "step": 18620
    },
    {
      "epoch": 55.808383233532936,
      "grad_norm": 0.0524984747171402,
      "learning_rate": 0.00012164242942686055,
      "loss": 0.1295,
      "step": 18640
    },
    {
      "epoch": 55.868263473053894,
      "grad_norm": 0.08191172033548355,
      "learning_rate": 0.00012112917023096662,
      "loss": 0.1011,
      "step": 18660
    },
    {
      "epoch": 55.92814371257485,
      "grad_norm": 0.06539621204137802,
      "learning_rate": 0.0001206159110350727,
      "loss": 0.1154,
      "step": 18680
    },
    {
      "epoch": 55.98802395209581,
      "grad_norm": 10.630155563354492,
      "learning_rate": 0.00012010265183917878,
      "loss": 0.1095,
      "step": 18700
    },
    {
      "epoch": 56.0,
      "eval_accuracy": 0.8578431372549019,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8651960784313726,
      "eval_accuracy_12": 0.8627450980392157,
      "eval_accuracy_13": 0.8627450980392157,
      "eval_accuracy_14": 0.8602941176470589,
      "eval_accuracy_15": 0.8700980392156863,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8651960784313726,
      "eval_accuracy_18": 0.8602941176470589,
      "eval_accuracy_19": 0.8676470588235294,
      "eval_accuracy_20": 0.8676470588235294,
      "eval_accuracy_21": 0.8651960784313726,
      "eval_accuracy_22": 0.8602941176470589,
      "eval_accuracy_23": 0.8602941176470589,
      "eval_accuracy_24": 0.8602941176470589,
      "eval_accuracy_25": 0.8578431372549019,
      "eval_combined_score": 0.8787485582468281,
      "eval_f1": 0.8996539792387542,
      "eval_loss": 0.7426588535308838,
      "eval_runtime": 216.6779,
      "eval_samples_per_second": 1.883,
      "eval_steps_per_second": 0.235,
      "step": 18704
    },
    {
      "epoch": 56.047904191616766,
      "grad_norm": 0.551145076751709,
      "learning_rate": 0.00011958939264328485,
      "loss": 0.0975,
      "step": 18720
    },
    {
      "epoch": 56.10778443113772,
      "grad_norm": 13.519243240356445,
      "learning_rate": 0.00011907613344739092,
      "loss": 0.1052,
      "step": 18740
    },
    {
      "epoch": 56.16766467065868,
      "grad_norm": 0.3517630994319916,
      "learning_rate": 0.000118562874251497,
      "loss": 0.095,
      "step": 18760
    },
    {
      "epoch": 56.22754491017964,
      "grad_norm": 0.430563747882843,
      "learning_rate": 0.00011804961505560307,
      "loss": 0.0928,
      "step": 18780
    },
    {
      "epoch": 56.287425149700596,
      "grad_norm": 0.007508405949920416,
      "learning_rate": 0.00011753635585970914,
      "loss": 0.0489,
      "step": 18800
    },
    {
      "epoch": 56.34730538922156,
      "grad_norm": 0.5077337622642517,
      "learning_rate": 0.00011702309666381521,
      "loss": 0.1254,
      "step": 18820
    },
    {
      "epoch": 56.40718562874252,
      "grad_norm": 1.625453233718872,
      "learning_rate": 0.00011650983746792128,
      "loss": 0.134,
      "step": 18840
    },
    {
      "epoch": 56.467065868263475,
      "grad_norm": 13.39266300201416,
      "learning_rate": 0.00011599657827202735,
      "loss": 0.1085,
      "step": 18860
    },
    {
      "epoch": 56.52694610778443,
      "grad_norm": 2.221151351928711,
      "learning_rate": 0.00011548331907613343,
      "loss": 0.0693,
      "step": 18880
    },
    {
      "epoch": 56.58682634730539,
      "grad_norm": 2.4478657245635986,
      "learning_rate": 0.00011497005988023951,
      "loss": 0.1532,
      "step": 18900
    },
    {
      "epoch": 56.64670658682635,
      "grad_norm": 1.2310106754302979,
      "learning_rate": 0.00011445680068434558,
      "loss": 0.108,
      "step": 18920
    },
    {
      "epoch": 56.706586826347305,
      "grad_norm": 15.68281364440918,
      "learning_rate": 0.00011394354148845166,
      "loss": 0.1273,
      "step": 18940
    },
    {
      "epoch": 56.76646706586826,
      "grad_norm": 0.46535325050354004,
      "learning_rate": 0.00011343028229255773,
      "loss": 0.0951,
      "step": 18960
    },
    {
      "epoch": 56.82634730538922,
      "grad_norm": 0.9109021425247192,
      "learning_rate": 0.0001129170230966638,
      "loss": 0.0992,
      "step": 18980
    },
    {
      "epoch": 56.88622754491018,
      "grad_norm": 0.459554523229599,
      "learning_rate": 0.00011240376390076987,
      "loss": 0.1197,
      "step": 19000
    },
    {
      "epoch": 56.946107784431135,
      "grad_norm": 0.26802319288253784,
      "learning_rate": 0.00011189050470487594,
      "loss": 0.083,
      "step": 19020
    },
    {
      "epoch": 57.0,
      "eval_accuracy": 0.8627450980392157,
      "eval_accuracy_10": 0.8602941176470589,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8578431372549019,
      "eval_accuracy_14": 0.8651960784313726,
      "eval_accuracy_15": 0.8627450980392157,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8627450980392157,
      "eval_accuracy_18": 0.8578431372549019,
      "eval_accuracy_19": 0.8627450980392157,
      "eval_accuracy_20": 0.8627450980392157,
      "eval_accuracy_21": 0.8627450980392157,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8602941176470589,
      "eval_accuracy_24": 0.8602941176470589,
      "eval_accuracy_25": 0.8627450980392157,
      "eval_combined_score": 0.8837535014005602,
      "eval_f1": 0.9047619047619047,
      "eval_loss": 0.8670713305473328,
      "eval_runtime": 215.8828,
      "eval_samples_per_second": 1.89,
      "eval_steps_per_second": 0.236,
      "step": 19038
    },
    {
      "epoch": 57.0059880239521,
      "grad_norm": 0.9894939661026001,
      "learning_rate": 0.00011137724550898203,
      "loss": 0.0717,
      "step": 19040
    },
    {
      "epoch": 57.06586826347306,
      "grad_norm": 0.08607935160398483,
      "learning_rate": 0.0001108639863130881,
      "loss": 0.0485,
      "step": 19060
    },
    {
      "epoch": 57.125748502994014,
      "grad_norm": 0.17383840680122375,
      "learning_rate": 0.00011035072711719417,
      "loss": 0.131,
      "step": 19080
    },
    {
      "epoch": 57.18562874251497,
      "grad_norm": 12.690923690795898,
      "learning_rate": 0.00010983746792130026,
      "loss": 0.1035,
      "step": 19100
    },
    {
      "epoch": 57.24550898203593,
      "grad_norm": 6.4088664054870605,
      "learning_rate": 0.00010932420872540633,
      "loss": 0.0268,
      "step": 19120
    },
    {
      "epoch": 57.30538922155689,
      "grad_norm": 0.02742626890540123,
      "learning_rate": 0.0001088109495295124,
      "loss": 0.1149,
      "step": 19140
    },
    {
      "epoch": 57.365269461077844,
      "grad_norm": 1.4075242280960083,
      "learning_rate": 0.00010829769033361847,
      "loss": 0.0987,
      "step": 19160
    },
    {
      "epoch": 57.4251497005988,
      "grad_norm": 0.18436206877231598,
      "learning_rate": 0.00010778443113772454,
      "loss": 0.0682,
      "step": 19180
    },
    {
      "epoch": 57.48502994011976,
      "grad_norm": 7.464794635772705,
      "learning_rate": 0.00010727117194183062,
      "loss": 0.2125,
      "step": 19200
    },
    {
      "epoch": 57.544910179640716,
      "grad_norm": 2.638927459716797,
      "learning_rate": 0.00010675791274593669,
      "loss": 0.0611,
      "step": 19220
    },
    {
      "epoch": 57.604790419161674,
      "grad_norm": 7.148253440856934,
      "learning_rate": 0.00010624465355004276,
      "loss": 0.1212,
      "step": 19240
    },
    {
      "epoch": 57.66467065868264,
      "grad_norm": 16.8184871673584,
      "learning_rate": 0.00010573139435414883,
      "loss": 0.0912,
      "step": 19260
    },
    {
      "epoch": 57.724550898203596,
      "grad_norm": 6.990859031677246,
      "learning_rate": 0.0001052181351582549,
      "loss": 0.0875,
      "step": 19280
    },
    {
      "epoch": 57.78443113772455,
      "grad_norm": 2.837172508239746,
      "learning_rate": 0.00010470487596236099,
      "loss": 0.0672,
      "step": 19300
    },
    {
      "epoch": 57.84431137724551,
      "grad_norm": 0.1910434365272522,
      "learning_rate": 0.00010419161676646706,
      "loss": 0.094,
      "step": 19320
    },
    {
      "epoch": 57.90419161676647,
      "grad_norm": 0.13380971550941467,
      "learning_rate": 0.00010367835757057313,
      "loss": 0.0315,
      "step": 19340
    },
    {
      "epoch": 57.964071856287426,
      "grad_norm": 1.6622596979141235,
      "learning_rate": 0.0001031650983746792,
      "loss": 0.0343,
      "step": 19360
    },
    {
      "epoch": 58.0,
      "eval_accuracy": 0.8529411764705882,
      "eval_accuracy_10": 0.8578431372549019,
      "eval_accuracy_11": 0.8602941176470589,
      "eval_accuracy_12": 0.8602941176470589,
      "eval_accuracy_13": 0.8578431372549019,
      "eval_accuracy_14": 0.8578431372549019,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8651960784313726,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8627450980392157,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8529411764705882,
      "eval_accuracy_23": 0.8504901960784313,
      "eval_accuracy_24": 0.8504901960784313,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8749241964827168,
      "eval_f1": 0.8969072164948454,
      "eval_loss": 0.9388706088066101,
      "eval_runtime": 216.8162,
      "eval_samples_per_second": 1.882,
      "eval_steps_per_second": 0.235,
      "step": 19372
    },
    {
      "epoch": 58.02395209580838,
      "grad_norm": 4.860109329223633,
      "learning_rate": 0.00010265183917878528,
      "loss": 0.0934,
      "step": 19380
    },
    {
      "epoch": 58.08383233532934,
      "grad_norm": 19.22290802001953,
      "learning_rate": 0.00010213857998289135,
      "loss": 0.0848,
      "step": 19400
    },
    {
      "epoch": 58.1437125748503,
      "grad_norm": 0.013831894844770432,
      "learning_rate": 0.00010162532078699742,
      "loss": 0.1092,
      "step": 19420
    },
    {
      "epoch": 58.203592814371255,
      "grad_norm": 10.997995376586914,
      "learning_rate": 0.00010111206159110349,
      "loss": 0.0477,
      "step": 19440
    },
    {
      "epoch": 58.26347305389221,
      "grad_norm": 0.0206321869045496,
      "learning_rate": 0.00010059880239520956,
      "loss": 0.0623,
      "step": 19460
    },
    {
      "epoch": 58.32335329341317,
      "grad_norm": 2.2981255054473877,
      "learning_rate": 0.00010008554319931563,
      "loss": 0.1004,
      "step": 19480
    },
    {
      "epoch": 58.383233532934135,
      "grad_norm": 7.902544021606445,
      "learning_rate": 9.957228400342172e-05,
      "loss": 0.0968,
      "step": 19500
    },
    {
      "epoch": 58.44311377245509,
      "grad_norm": 0.8179789781570435,
      "learning_rate": 9.905902480752779e-05,
      "loss": 0.0734,
      "step": 19520
    },
    {
      "epoch": 58.50299401197605,
      "grad_norm": 6.878629207611084,
      "learning_rate": 9.854576561163386e-05,
      "loss": 0.1262,
      "step": 19540
    },
    {
      "epoch": 58.56287425149701,
      "grad_norm": 2.0745902061462402,
      "learning_rate": 9.803250641573994e-05,
      "loss": 0.0553,
      "step": 19560
    },
    {
      "epoch": 58.622754491017965,
      "grad_norm": 0.5017919540405273,
      "learning_rate": 9.751924721984602e-05,
      "loss": 0.0365,
      "step": 19580
    },
    {
      "epoch": 58.68263473053892,
      "grad_norm": 14.41701889038086,
      "learning_rate": 9.700598802395209e-05,
      "loss": 0.1447,
      "step": 19600
    },
    {
      "epoch": 58.74251497005988,
      "grad_norm": 10.022500038146973,
      "learning_rate": 9.649272882805816e-05,
      "loss": 0.1274,
      "step": 19620
    },
    {
      "epoch": 58.80239520958084,
      "grad_norm": 0.5568951964378357,
      "learning_rate": 9.597946963216424e-05,
      "loss": 0.0977,
      "step": 19640
    },
    {
      "epoch": 58.862275449101794,
      "grad_norm": 2.459908962249756,
      "learning_rate": 9.546621043627031e-05,
      "loss": 0.1281,
      "step": 19660
    },
    {
      "epoch": 58.92215568862275,
      "grad_norm": 3.74568510055542,
      "learning_rate": 9.495295124037638e-05,
      "loss": 0.0962,
      "step": 19680
    },
    {
      "epoch": 58.98203592814371,
      "grad_norm": 6.947103023529053,
      "learning_rate": 9.443969204448247e-05,
      "loss": 0.0339,
      "step": 19700
    },
    {
      "epoch": 59.0,
      "eval_accuracy": 0.8504901960784313,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8480392156862745,
      "eval_accuracy_15": 0.8578431372549019,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8529411764705882,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8504901960784313,
      "eval_accuracy_20": 0.8578431372549019,
      "eval_accuracy_21": 0.8504901960784313,
      "eval_accuracy_22": 0.8480392156862745,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.8725680686782484,
      "eval_f1": 0.8946459412780656,
      "eval_loss": 0.8995519280433655,
      "eval_runtime": 215.4271,
      "eval_samples_per_second": 1.894,
      "eval_steps_per_second": 0.237,
      "step": 19706
    },
    {
      "epoch": 59.041916167664674,
      "grad_norm": 1.7993730306625366,
      "learning_rate": 9.392643284858854e-05,
      "loss": 0.0352,
      "step": 19720
    },
    {
      "epoch": 59.10179640718563,
      "grad_norm": 0.5885066986083984,
      "learning_rate": 9.341317365269461e-05,
      "loss": 0.1046,
      "step": 19740
    },
    {
      "epoch": 59.16167664670659,
      "grad_norm": 0.022221814841032028,
      "learning_rate": 9.289991445680068e-05,
      "loss": 0.1031,
      "step": 19760
    },
    {
      "epoch": 59.221556886227546,
      "grad_norm": 0.03694852069020271,
      "learning_rate": 9.238665526090675e-05,
      "loss": 0.0663,
      "step": 19780
    },
    {
      "epoch": 59.2814371257485,
      "grad_norm": 12.730461120605469,
      "learning_rate": 9.187339606501282e-05,
      "loss": 0.0746,
      "step": 19800
    },
    {
      "epoch": 59.34131736526946,
      "grad_norm": 2.3741207122802734,
      "learning_rate": 9.13601368691189e-05,
      "loss": 0.0606,
      "step": 19820
    },
    {
      "epoch": 59.40119760479042,
      "grad_norm": 0.004886551760137081,
      "learning_rate": 9.084687767322497e-05,
      "loss": 0.0999,
      "step": 19840
    },
    {
      "epoch": 59.461077844311376,
      "grad_norm": 0.9411110281944275,
      "learning_rate": 9.033361847733104e-05,
      "loss": 0.1045,
      "step": 19860
    },
    {
      "epoch": 59.52095808383233,
      "grad_norm": 9.594408988952637,
      "learning_rate": 8.982035928143711e-05,
      "loss": 0.0703,
      "step": 19880
    },
    {
      "epoch": 59.58083832335329,
      "grad_norm": 7.1438446044921875,
      "learning_rate": 8.93071000855432e-05,
      "loss": 0.0764,
      "step": 19900
    },
    {
      "epoch": 59.64071856287425,
      "grad_norm": 14.95040512084961,
      "learning_rate": 8.879384088964927e-05,
      "loss": 0.0764,
      "step": 19920
    },
    {
      "epoch": 59.70059880239521,
      "grad_norm": 14.527624130249023,
      "learning_rate": 8.828058169375534e-05,
      "loss": 0.1339,
      "step": 19940
    },
    {
      "epoch": 59.76047904191617,
      "grad_norm": 11.774785995483398,
      "learning_rate": 8.776732249786141e-05,
      "loss": 0.062,
      "step": 19960
    },
    {
      "epoch": 59.82035928143713,
      "grad_norm": 21.048080444335938,
      "learning_rate": 8.725406330196748e-05,
      "loss": 0.1303,
      "step": 19980
    },
    {
      "epoch": 59.880239520958085,
      "grad_norm": 2.2285239696502686,
      "learning_rate": 8.674080410607356e-05,
      "loss": 0.0643,
      "step": 20000
    },
    {
      "epoch": 59.94011976047904,
      "grad_norm": 0.07429779320955276,
      "learning_rate": 8.622754491017963e-05,
      "loss": 0.1241,
      "step": 20020
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.7242253422737122,
      "learning_rate": 8.57142857142857e-05,
      "loss": 0.0598,
      "step": 20040
    },
    {
      "epoch": 60.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8578431372549019,
      "eval_accuracy_12": 0.8553921568627451,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8651960784313726,
      "eval_accuracy_21": 0.8627450980392157,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8504901960784313,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8769215517532314,
      "eval_f1": 0.8984509466437176,
      "eval_loss": 0.8918923735618591,
      "eval_runtime": 219.4897,
      "eval_samples_per_second": 1.859,
      "eval_steps_per_second": 0.232,
      "step": 20040
    },
    {
      "epoch": 60.05988023952096,
      "grad_norm": 3.121469020843506,
      "learning_rate": 8.520102651839177e-05,
      "loss": 0.0556,
      "step": 20060
    },
    {
      "epoch": 60.119760479041915,
      "grad_norm": 9.321379661560059,
      "learning_rate": 8.468776732249784e-05,
      "loss": 0.0605,
      "step": 20080
    },
    {
      "epoch": 60.17964071856287,
      "grad_norm": 4.753241539001465,
      "learning_rate": 8.417450812660393e-05,
      "loss": 0.0986,
      "step": 20100
    },
    {
      "epoch": 60.23952095808383,
      "grad_norm": 17.451982498168945,
      "learning_rate": 8.366124893071e-05,
      "loss": 0.0743,
      "step": 20120
    },
    {
      "epoch": 60.29940119760479,
      "grad_norm": 4.646194934844971,
      "learning_rate": 8.314798973481609e-05,
      "loss": 0.0792,
      "step": 20140
    },
    {
      "epoch": 60.35928143712575,
      "grad_norm": 4.141572952270508,
      "learning_rate": 8.263473053892216e-05,
      "loss": 0.0561,
      "step": 20160
    },
    {
      "epoch": 60.41916167664671,
      "grad_norm": 1.4071303606033325,
      "learning_rate": 8.212147134302823e-05,
      "loss": 0.0642,
      "step": 20180
    },
    {
      "epoch": 60.47904191616767,
      "grad_norm": 9.060194969177246,
      "learning_rate": 8.16082121471343e-05,
      "loss": 0.049,
      "step": 20200
    },
    {
      "epoch": 60.538922155688624,
      "grad_norm": 4.0952043533325195,
      "learning_rate": 8.109495295124037e-05,
      "loss": 0.1107,
      "step": 20220
    },
    {
      "epoch": 60.59880239520958,
      "grad_norm": 4.631337642669678,
      "learning_rate": 8.058169375534644e-05,
      "loss": 0.1745,
      "step": 20240
    },
    {
      "epoch": 60.65868263473054,
      "grad_norm": 0.2872176170349121,
      "learning_rate": 8.006843455945252e-05,
      "loss": 0.0228,
      "step": 20260
    },
    {
      "epoch": 60.7185628742515,
      "grad_norm": 3.1741745471954346,
      "learning_rate": 7.955517536355859e-05,
      "loss": 0.0682,
      "step": 20280
    },
    {
      "epoch": 60.778443113772454,
      "grad_norm": 7.452634334564209,
      "learning_rate": 7.904191616766467e-05,
      "loss": 0.0356,
      "step": 20300
    },
    {
      "epoch": 60.83832335329341,
      "grad_norm": 0.11998239159584045,
      "learning_rate": 7.852865697177074e-05,
      "loss": 0.1383,
      "step": 20320
    },
    {
      "epoch": 60.89820359281437,
      "grad_norm": 5.449955463409424,
      "learning_rate": 7.801539777587682e-05,
      "loss": 0.0849,
      "step": 20340
    },
    {
      "epoch": 60.958083832335326,
      "grad_norm": 0.05678054690361023,
      "learning_rate": 7.750213857998289e-05,
      "loss": 0.0834,
      "step": 20360
    },
    {
      "epoch": 61.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8553921568627451,
      "eval_accuracy_12": 0.8553921568627451,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8602941176470589,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8767461647871584,
      "eval_f1": 0.8981001727115717,
      "eval_loss": 0.8742111325263977,
      "eval_runtime": 215.3494,
      "eval_samples_per_second": 1.895,
      "eval_steps_per_second": 0.237,
      "step": 20374
    },
    {
      "epoch": 61.01796407185629,
      "grad_norm": 10.330290794372559,
      "learning_rate": 7.698887938408896e-05,
      "loss": 0.1019,
      "step": 20380
    },
    {
      "epoch": 61.07784431137725,
      "grad_norm": 0.4826219975948334,
      "learning_rate": 7.647562018819503e-05,
      "loss": 0.0736,
      "step": 20400
    },
    {
      "epoch": 61.137724550898206,
      "grad_norm": 23.63016700744629,
      "learning_rate": 7.59623609923011e-05,
      "loss": 0.16,
      "step": 20420
    },
    {
      "epoch": 61.19760479041916,
      "grad_norm": 0.12785619497299194,
      "learning_rate": 7.544910179640718e-05,
      "loss": 0.1572,
      "step": 20440
    },
    {
      "epoch": 61.25748502994012,
      "grad_norm": 0.702581524848938,
      "learning_rate": 7.493584260051326e-05,
      "loss": 0.062,
      "step": 20460
    },
    {
      "epoch": 61.31736526946108,
      "grad_norm": 0.003231674898415804,
      "learning_rate": 7.442258340461933e-05,
      "loss": 0.0793,
      "step": 20480
    },
    {
      "epoch": 61.377245508982035,
      "grad_norm": 0.5018599629402161,
      "learning_rate": 7.39093242087254e-05,
      "loss": 0.0776,
      "step": 20500
    },
    {
      "epoch": 61.43712574850299,
      "grad_norm": 6.113728046417236,
      "learning_rate": 7.339606501283148e-05,
      "loss": 0.0724,
      "step": 20520
    },
    {
      "epoch": 61.49700598802395,
      "grad_norm": 16.302433013916016,
      "learning_rate": 7.288280581693755e-05,
      "loss": 0.0917,
      "step": 20540
    },
    {
      "epoch": 61.55688622754491,
      "grad_norm": 0.7216030955314636,
      "learning_rate": 7.236954662104362e-05,
      "loss": 0.0687,
      "step": 20560
    },
    {
      "epoch": 61.616766467065865,
      "grad_norm": 0.0337693952023983,
      "learning_rate": 7.185628742514969e-05,
      "loss": 0.1261,
      "step": 20580
    },
    {
      "epoch": 61.67664670658683,
      "grad_norm": 0.502116322517395,
      "learning_rate": 7.134302822925576e-05,
      "loss": 0.0622,
      "step": 20600
    },
    {
      "epoch": 61.73652694610779,
      "grad_norm": 13.719822883605957,
      "learning_rate": 7.082976903336184e-05,
      "loss": 0.1093,
      "step": 20620
    },
    {
      "epoch": 61.796407185628745,
      "grad_norm": 1.2797569036483765,
      "learning_rate": 7.031650983746792e-05,
      "loss": 0.0629,
      "step": 20640
    },
    {
      "epoch": 61.8562874251497,
      "grad_norm": 0.050301749259233475,
      "learning_rate": 6.980325064157399e-05,
      "loss": 0.0578,
      "step": 20660
    },
    {
      "epoch": 61.91616766467066,
      "grad_norm": 5.021277904510498,
      "learning_rate": 6.928999144568006e-05,
      "loss": 0.0932,
      "step": 20680
    },
    {
      "epoch": 61.97604790419162,
      "grad_norm": 0.31329047679901123,
      "learning_rate": 6.877673224978614e-05,
      "loss": 0.1174,
      "step": 20700
    },
    {
      "epoch": 62.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8504901960784313,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8553921568627451,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8553921568627451,
      "eval_accuracy_15": 0.8602941176470589,
      "eval_accuracy_16": 0.8602941176470589,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8627450980392157,
      "eval_accuracy_19": 0.8602941176470589,
      "eval_accuracy_20": 0.8627450980392157,
      "eval_accuracy_21": 0.8627450980392157,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8769215517532314,
      "eval_f1": 0.8984509466437176,
      "eval_loss": 0.8675850629806519,
      "eval_runtime": 221.2337,
      "eval_samples_per_second": 1.844,
      "eval_steps_per_second": 0.231,
      "step": 20708
    },
    {
      "epoch": 62.035928143712574,
      "grad_norm": 9.229337692260742,
      "learning_rate": 6.826347305389221e-05,
      "loss": 0.1285,
      "step": 20720
    },
    {
      "epoch": 62.09580838323353,
      "grad_norm": 0.9470700025558472,
      "learning_rate": 6.775021385799829e-05,
      "loss": 0.0741,
      "step": 20740
    },
    {
      "epoch": 62.15568862275449,
      "grad_norm": 0.07022435963153839,
      "learning_rate": 6.723695466210436e-05,
      "loss": 0.0803,
      "step": 20760
    },
    {
      "epoch": 62.21556886227545,
      "grad_norm": 2.3326714038848877,
      "learning_rate": 6.672369546621044e-05,
      "loss": 0.0628,
      "step": 20780
    },
    {
      "epoch": 62.275449101796404,
      "grad_norm": 19.691232681274414,
      "learning_rate": 6.621043627031651e-05,
      "loss": 0.1511,
      "step": 20800
    },
    {
      "epoch": 62.33532934131736,
      "grad_norm": 0.2113431692123413,
      "learning_rate": 6.569717707442258e-05,
      "loss": 0.0979,
      "step": 20820
    },
    {
      "epoch": 62.395209580838326,
      "grad_norm": 4.917007923126221,
      "learning_rate": 6.518391787852865e-05,
      "loss": 0.0897,
      "step": 20840
    },
    {
      "epoch": 62.455089820359284,
      "grad_norm": 0.008383823558688164,
      "learning_rate": 6.467065868263472e-05,
      "loss": 0.0662,
      "step": 20860
    },
    {
      "epoch": 62.51497005988024,
      "grad_norm": 8.663738250732422,
      "learning_rate": 6.41573994867408e-05,
      "loss": 0.142,
      "step": 20880
    },
    {
      "epoch": 62.5748502994012,
      "grad_norm": 0.12475784122943878,
      "learning_rate": 6.364414029084687e-05,
      "loss": 0.0172,
      "step": 20900
    },
    {
      "epoch": 62.634730538922156,
      "grad_norm": 5.862710475921631,
      "learning_rate": 6.313088109495294e-05,
      "loss": 0.1858,
      "step": 20920
    },
    {
      "epoch": 62.69461077844311,
      "grad_norm": 0.012812214903533459,
      "learning_rate": 6.261762189905902e-05,
      "loss": 0.0432,
      "step": 20940
    },
    {
      "epoch": 62.75449101796407,
      "grad_norm": 0.33555543422698975,
      "learning_rate": 6.21043627031651e-05,
      "loss": 0.0279,
      "step": 20960
    },
    {
      "epoch": 62.81437125748503,
      "grad_norm": 30.550161361694336,
      "learning_rate": 6.159110350727117e-05,
      "loss": 0.0799,
      "step": 20980
    },
    {
      "epoch": 62.874251497005986,
      "grad_norm": 0.030954619869589806,
      "learning_rate": 6.107784431137724e-05,
      "loss": 0.1057,
      "step": 21000
    },
    {
      "epoch": 62.93413173652694,
      "grad_norm": 5.722110271453857,
      "learning_rate": 6.056458511548331e-05,
      "loss": 0.1229,
      "step": 21020
    },
    {
      "epoch": 62.9940119760479,
      "grad_norm": 20.17625617980957,
      "learning_rate": 6.005132591958939e-05,
      "loss": 0.1133,
      "step": 21040
    },
    {
      "epoch": 63.0,
      "eval_accuracy": 0.8504901960784313,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8504901960784313,
      "eval_accuracy_13": 0.8504901960784313,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8529411764705882,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8529411764705882,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8529411764705882,
      "eval_accuracy_24": 0.8529411764705882,
      "eval_accuracy_25": 0.8504901960784313,
      "eval_combined_score": 0.8727494009652054,
      "eval_f1": 0.8950086058519794,
      "eval_loss": 0.8955991268157959,
      "eval_runtime": 216.694,
      "eval_samples_per_second": 1.883,
      "eval_steps_per_second": 0.235,
      "step": 21042
    },
    {
      "epoch": 63.053892215568865,
      "grad_norm": 0.036389488726854324,
      "learning_rate": 5.953806672369546e-05,
      "loss": 0.0587,
      "step": 21060
    },
    {
      "epoch": 63.11377245508982,
      "grad_norm": 4.522883415222168,
      "learning_rate": 5.9024807527801534e-05,
      "loss": 0.0562,
      "step": 21080
    },
    {
      "epoch": 63.17365269461078,
      "grad_norm": 4.762433052062988,
      "learning_rate": 5.8511548331907606e-05,
      "loss": 0.1039,
      "step": 21100
    },
    {
      "epoch": 63.23353293413174,
      "grad_norm": 3.426177740097046,
      "learning_rate": 5.799828913601368e-05,
      "loss": 0.0594,
      "step": 21120
    },
    {
      "epoch": 63.293413173652695,
      "grad_norm": 12.076990127563477,
      "learning_rate": 5.7485029940119756e-05,
      "loss": 0.1418,
      "step": 21140
    },
    {
      "epoch": 63.35329341317365,
      "grad_norm": 0.01234095823019743,
      "learning_rate": 5.697177074422583e-05,
      "loss": 0.1353,
      "step": 21160
    },
    {
      "epoch": 63.41317365269461,
      "grad_norm": 15.805058479309082,
      "learning_rate": 5.64585115483319e-05,
      "loss": 0.1002,
      "step": 21180
    },
    {
      "epoch": 63.47305389221557,
      "grad_norm": 20.776594161987305,
      "learning_rate": 5.594525235243797e-05,
      "loss": 0.0457,
      "step": 21200
    },
    {
      "epoch": 63.532934131736525,
      "grad_norm": 7.687332630157471,
      "learning_rate": 5.543199315654405e-05,
      "loss": 0.0607,
      "step": 21220
    },
    {
      "epoch": 63.59281437125748,
      "grad_norm": 2.11466383934021,
      "learning_rate": 5.491873396065013e-05,
      "loss": 0.06,
      "step": 21240
    },
    {
      "epoch": 63.65269461077844,
      "grad_norm": 1.529510259628296,
      "learning_rate": 5.44054747647562e-05,
      "loss": 0.0588,
      "step": 21260
    },
    {
      "epoch": 63.712574850299404,
      "grad_norm": 0.31661802530288696,
      "learning_rate": 5.389221556886227e-05,
      "loss": 0.0559,
      "step": 21280
    },
    {
      "epoch": 63.77245508982036,
      "grad_norm": 0.035223137587308884,
      "learning_rate": 5.3378956372968344e-05,
      "loss": 0.0568,
      "step": 21300
    },
    {
      "epoch": 63.83233532934132,
      "grad_norm": 0.059318166226148605,
      "learning_rate": 5.2865697177074416e-05,
      "loss": 0.0606,
      "step": 21320
    },
    {
      "epoch": 63.89221556886228,
      "grad_norm": 0.1100095883011818,
      "learning_rate": 5.2352437981180494e-05,
      "loss": 0.1246,
      "step": 21340
    },
    {
      "epoch": 63.952095808383234,
      "grad_norm": 0.004389875568449497,
      "learning_rate": 5.1839178785286566e-05,
      "loss": 0.0481,
      "step": 21360
    },
    {
      "epoch": 64.0,
      "eval_accuracy": 0.8529411764705882,
      "eval_accuracy_10": 0.8578431372549019,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8529411764705882,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8749241964827168,
      "eval_f1": 0.8969072164948454,
      "eval_loss": 0.8913586735725403,
      "eval_runtime": 216.6408,
      "eval_samples_per_second": 1.883,
      "eval_steps_per_second": 0.235,
      "step": 21376
    },
    {
      "epoch": 64.0119760479042,
      "grad_norm": 6.5660200119018555,
      "learning_rate": 5.132591958939264e-05,
      "loss": 0.1172,
      "step": 21380
    },
    {
      "epoch": 64.07185628742515,
      "grad_norm": 0.009000648744404316,
      "learning_rate": 5.081266039349871e-05,
      "loss": 0.1148,
      "step": 21400
    },
    {
      "epoch": 64.13173652694611,
      "grad_norm": 0.04327481985092163,
      "learning_rate": 5.029940119760478e-05,
      "loss": 0.0227,
      "step": 21420
    },
    {
      "epoch": 64.19161676646706,
      "grad_norm": 0.011339801363646984,
      "learning_rate": 4.978614200171086e-05,
      "loss": 0.0796,
      "step": 21440
    },
    {
      "epoch": 64.25149700598803,
      "grad_norm": 2.604379892349243,
      "learning_rate": 4.927288280581693e-05,
      "loss": 0.0786,
      "step": 21460
    },
    {
      "epoch": 64.31137724550898,
      "grad_norm": 14.35726261138916,
      "learning_rate": 4.875962360992301e-05,
      "loss": 0.0684,
      "step": 21480
    },
    {
      "epoch": 64.37125748502994,
      "grad_norm": 8.783951759338379,
      "learning_rate": 4.824636441402908e-05,
      "loss": 0.1063,
      "step": 21500
    },
    {
      "epoch": 64.4311377245509,
      "grad_norm": 1.1785354614257812,
      "learning_rate": 4.7733105218135154e-05,
      "loss": 0.0821,
      "step": 21520
    },
    {
      "epoch": 64.49101796407186,
      "grad_norm": 15.011621475219727,
      "learning_rate": 4.721984602224123e-05,
      "loss": 0.1037,
      "step": 21540
    },
    {
      "epoch": 64.55089820359281,
      "grad_norm": 10.23011589050293,
      "learning_rate": 4.6706586826347304e-05,
      "loss": 0.0982,
      "step": 21560
    },
    {
      "epoch": 64.61077844311377,
      "grad_norm": 0.8556023240089417,
      "learning_rate": 4.6193327630453376e-05,
      "loss": 0.0614,
      "step": 21580
    },
    {
      "epoch": 64.67065868263472,
      "grad_norm": 0.25939223170280457,
      "learning_rate": 4.568006843455945e-05,
      "loss": 0.0898,
      "step": 21600
    },
    {
      "epoch": 64.73053892215569,
      "grad_norm": 0.05494634807109833,
      "learning_rate": 4.516680923866552e-05,
      "loss": 0.0521,
      "step": 21620
    },
    {
      "epoch": 64.79041916167665,
      "grad_norm": 3.568404197692871,
      "learning_rate": 4.46535500427716e-05,
      "loss": 0.0944,
      "step": 21640
    },
    {
      "epoch": 64.8502994011976,
      "grad_norm": 3.5082619190216064,
      "learning_rate": 4.414029084687767e-05,
      "loss": 0.0885,
      "step": 21660
    },
    {
      "epoch": 64.91017964071857,
      "grad_norm": 8.625649452209473,
      "learning_rate": 4.362703165098374e-05,
      "loss": 0.0551,
      "step": 21680
    },
    {
      "epoch": 64.97005988023952,
      "grad_norm": 5.53346061706543,
      "learning_rate": 4.3113772455089814e-05,
      "loss": 0.045,
      "step": 21700
    },
    {
      "epoch": 65.0,
      "eval_accuracy": 0.8529411764705882,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8529411764705882,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8480392156862745,
      "eval_accuracy_14": 0.8504901960784313,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8578431372549019,
      "eval_accuracy_21": 0.8578431372549019,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8602941176470589,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8747464503042597,
      "eval_f1": 0.896551724137931,
      "eval_loss": 0.8945298790931702,
      "eval_runtime": 217.2401,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.235,
      "step": 21710
    },
    {
      "epoch": 65.02994011976048,
      "grad_norm": 0.6009474396705627,
      "learning_rate": 4.2600513259195885e-05,
      "loss": 0.0951,
      "step": 21720
    },
    {
      "epoch": 65.08982035928143,
      "grad_norm": 0.11456327140331268,
      "learning_rate": 4.2087254063301964e-05,
      "loss": 0.0521,
      "step": 21740
    },
    {
      "epoch": 65.1497005988024,
      "grad_norm": 0.6755367517471313,
      "learning_rate": 4.157399486740804e-05,
      "loss": 0.0901,
      "step": 21760
    },
    {
      "epoch": 65.20958083832335,
      "grad_norm": 0.0308639295399189,
      "learning_rate": 4.1060735671514114e-05,
      "loss": 0.0787,
      "step": 21780
    },
    {
      "epoch": 65.26946107784431,
      "grad_norm": 0.42960643768310547,
      "learning_rate": 4.0547476475620186e-05,
      "loss": 0.0566,
      "step": 21800
    },
    {
      "epoch": 65.32934131736526,
      "grad_norm": 0.17179101705551147,
      "learning_rate": 4.003421727972626e-05,
      "loss": 0.0851,
      "step": 21820
    },
    {
      "epoch": 65.38922155688623,
      "grad_norm": 2.0144546031951904,
      "learning_rate": 3.9520958083832336e-05,
      "loss": 0.0639,
      "step": 21840
    },
    {
      "epoch": 65.44910179640719,
      "grad_norm": 1.0328365564346313,
      "learning_rate": 3.900769888793841e-05,
      "loss": 0.088,
      "step": 21860
    },
    {
      "epoch": 65.50898203592814,
      "grad_norm": 2.188164710998535,
      "learning_rate": 3.849443969204448e-05,
      "loss": 0.0469,
      "step": 21880
    },
    {
      "epoch": 65.5688622754491,
      "grad_norm": 0.4790938198566437,
      "learning_rate": 3.798118049615055e-05,
      "loss": 0.0537,
      "step": 21900
    },
    {
      "epoch": 65.62874251497006,
      "grad_norm": 11.46767520904541,
      "learning_rate": 3.746792130025663e-05,
      "loss": 0.0333,
      "step": 21920
    },
    {
      "epoch": 65.68862275449102,
      "grad_norm": 0.1349966675043106,
      "learning_rate": 3.69546621043627e-05,
      "loss": 0.0978,
      "step": 21940
    },
    {
      "epoch": 65.74850299401197,
      "grad_norm": 2.095231533050537,
      "learning_rate": 3.6441402908468774e-05,
      "loss": 0.0583,
      "step": 21960
    },
    {
      "epoch": 65.80838323353294,
      "grad_norm": 2.421898603439331,
      "learning_rate": 3.5928143712574846e-05,
      "loss": 0.0563,
      "step": 21980
    },
    {
      "epoch": 65.86826347305389,
      "grad_norm": 0.30834585428237915,
      "learning_rate": 3.541488451668092e-05,
      "loss": 0.0477,
      "step": 22000
    },
    {
      "epoch": 65.92814371257485,
      "grad_norm": 3.4015369415283203,
      "learning_rate": 3.4901625320786996e-05,
      "loss": 0.0856,
      "step": 22020
    },
    {
      "epoch": 65.9880239520958,
      "grad_norm": 0.8616799116134644,
      "learning_rate": 3.438836612489307e-05,
      "loss": 0.0399,
      "step": 22040
    },
    {
      "epoch": 66.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8553921568627451,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8504901960784313,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8504901960784313,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8529411764705882,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8578431372549019,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8769215517532314,
      "eval_f1": 0.8984509466437176,
      "eval_loss": 0.9032756686210632,
      "eval_runtime": 217.5891,
      "eval_samples_per_second": 1.875,
      "eval_steps_per_second": 0.234,
      "step": 22044
    },
    {
      "epoch": 66.04790419161677,
      "grad_norm": 0.05744165927171707,
      "learning_rate": 3.3875106928999147e-05,
      "loss": 0.0872,
      "step": 22060
    },
    {
      "epoch": 66.10778443113773,
      "grad_norm": 8.87505054473877,
      "learning_rate": 3.336184773310522e-05,
      "loss": 0.082,
      "step": 22080
    },
    {
      "epoch": 66.16766467065868,
      "grad_norm": 7.494087219238281,
      "learning_rate": 3.284858853721129e-05,
      "loss": 0.0535,
      "step": 22100
    },
    {
      "epoch": 66.22754491017965,
      "grad_norm": 6.214796543121338,
      "learning_rate": 3.233532934131736e-05,
      "loss": 0.0698,
      "step": 22120
    },
    {
      "epoch": 66.2874251497006,
      "grad_norm": 6.154991149902344,
      "learning_rate": 3.1822070145423434e-05,
      "loss": 0.0783,
      "step": 22140
    },
    {
      "epoch": 66.34730538922156,
      "grad_norm": 7.1159281730651855,
      "learning_rate": 3.130881094952951e-05,
      "loss": 0.0637,
      "step": 22160
    },
    {
      "epoch": 66.40718562874251,
      "grad_norm": 0.027528956532478333,
      "learning_rate": 3.0795551753635584e-05,
      "loss": 0.0343,
      "step": 22180
    },
    {
      "epoch": 66.46706586826348,
      "grad_norm": 5.4436140060424805,
      "learning_rate": 3.0282292557741656e-05,
      "loss": 0.0963,
      "step": 22200
    },
    {
      "epoch": 66.52694610778443,
      "grad_norm": 0.0022506059613078833,
      "learning_rate": 2.976903336184773e-05,
      "loss": 0.0271,
      "step": 22220
    },
    {
      "epoch": 66.58682634730539,
      "grad_norm": 0.4803702235221863,
      "learning_rate": 2.9255774165953803e-05,
      "loss": 0.1179,
      "step": 22240
    },
    {
      "epoch": 66.64670658682634,
      "grad_norm": 18.647762298583984,
      "learning_rate": 2.8742514970059878e-05,
      "loss": 0.0558,
      "step": 22260
    },
    {
      "epoch": 66.7065868263473,
      "grad_norm": 8.525128364562988,
      "learning_rate": 2.822925577416595e-05,
      "loss": 0.1382,
      "step": 22280
    },
    {
      "epoch": 66.76646706586827,
      "grad_norm": 0.3442932069301605,
      "learning_rate": 2.7715996578272025e-05,
      "loss": 0.0739,
      "step": 22300
    },
    {
      "epoch": 66.82634730538922,
      "grad_norm": 0.0872914046049118,
      "learning_rate": 2.72027373823781e-05,
      "loss": 0.069,
      "step": 22320
    },
    {
      "epoch": 66.88622754491018,
      "grad_norm": 14.591764450073242,
      "learning_rate": 2.6689478186484172e-05,
      "loss": 0.1108,
      "step": 22340
    },
    {
      "epoch": 66.94610778443113,
      "grad_norm": 14.852137565612793,
      "learning_rate": 2.6176218990590247e-05,
      "loss": 0.0459,
      "step": 22360
    },
    {
      "epoch": 67.0,
      "eval_accuracy": 0.8529411764705882,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8480392156862745,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8529411764705882,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8578431372549019,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8553921568627451,
      "eval_accuracy_20": 0.8553921568627451,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8747464503042597,
      "eval_f1": 0.896551724137931,
      "eval_loss": 0.8927505612373352,
      "eval_runtime": 217.079,
      "eval_samples_per_second": 1.88,
      "eval_steps_per_second": 0.235,
      "step": 22378
    },
    {
      "epoch": 67.0059880239521,
      "grad_norm": 0.6625140309333801,
      "learning_rate": 2.566295979469632e-05,
      "loss": 0.0651,
      "step": 22380
    },
    {
      "epoch": 67.06586826347305,
      "grad_norm": 0.04491480067372322,
      "learning_rate": 2.514970059880239e-05,
      "loss": 0.0804,
      "step": 22400
    },
    {
      "epoch": 67.12574850299401,
      "grad_norm": 0.18535566329956055,
      "learning_rate": 2.4636441402908466e-05,
      "loss": 0.0586,
      "step": 22420
    },
    {
      "epoch": 67.18562874251496,
      "grad_norm": 0.4853878617286682,
      "learning_rate": 2.412318220701454e-05,
      "loss": 0.0528,
      "step": 22440
    },
    {
      "epoch": 67.24550898203593,
      "grad_norm": 1.4705116748809814,
      "learning_rate": 2.3609923011120616e-05,
      "loss": 0.0218,
      "step": 22460
    },
    {
      "epoch": 67.30538922155688,
      "grad_norm": 5.595848560333252,
      "learning_rate": 2.3096663815226688e-05,
      "loss": 0.0289,
      "step": 22480
    },
    {
      "epoch": 67.36526946107784,
      "grad_norm": 0.013605375774204731,
      "learning_rate": 2.258340461933276e-05,
      "loss": 0.098,
      "step": 22500
    },
    {
      "epoch": 67.42514970059881,
      "grad_norm": 0.48752883076667786,
      "learning_rate": 2.2070145423438835e-05,
      "loss": 0.0543,
      "step": 22520
    },
    {
      "epoch": 67.48502994011976,
      "grad_norm": 15.895326614379883,
      "learning_rate": 2.1556886227544907e-05,
      "loss": 0.138,
      "step": 22540
    },
    {
      "epoch": 67.54491017964072,
      "grad_norm": 0.13069792091846466,
      "learning_rate": 2.1043627031650982e-05,
      "loss": 0.0868,
      "step": 22560
    },
    {
      "epoch": 67.60479041916167,
      "grad_norm": 0.9097193479537964,
      "learning_rate": 2.0530367835757057e-05,
      "loss": 0.0581,
      "step": 22580
    },
    {
      "epoch": 67.66467065868264,
      "grad_norm": 1.162876009941101,
      "learning_rate": 2.001710863986313e-05,
      "loss": 0.1027,
      "step": 22600
    },
    {
      "epoch": 67.72455089820359,
      "grad_norm": 7.845454216003418,
      "learning_rate": 1.9503849443969204e-05,
      "loss": 0.0452,
      "step": 22620
    },
    {
      "epoch": 67.78443113772455,
      "grad_norm": 0.5918048620223999,
      "learning_rate": 1.8990590248075276e-05,
      "loss": 0.0661,
      "step": 22640
    },
    {
      "epoch": 67.8443113772455,
      "grad_norm": 3.166720151901245,
      "learning_rate": 1.847733105218135e-05,
      "loss": 0.0589,
      "step": 22660
    },
    {
      "epoch": 67.90419161676647,
      "grad_norm": 22.173351287841797,
      "learning_rate": 1.7964071856287423e-05,
      "loss": 0.0897,
      "step": 22680
    },
    {
      "epoch": 67.96407185628742,
      "grad_norm": 0.030106641352176666,
      "learning_rate": 1.7450812660393498e-05,
      "loss": 0.066,
      "step": 22700
    },
    {
      "epoch": 68.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8578431372549019,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8529411764705882,
      "eval_accuracy_14": 0.8504901960784313,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8602941176470589,
      "eval_accuracy_21": 0.8553921568627451,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8578431372549019,
      "eval_accuracy_24": 0.8578431372549019,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8769215517532314,
      "eval_f1": 0.8984509466437176,
      "eval_loss": 0.9164710640907288,
      "eval_runtime": 215.9355,
      "eval_samples_per_second": 1.889,
      "eval_steps_per_second": 0.236,
      "step": 22712
    },
    {
      "epoch": 68.02395209580838,
      "grad_norm": 2.9782111644744873,
      "learning_rate": 1.6937553464499573e-05,
      "loss": 0.0489,
      "step": 22720
    },
    {
      "epoch": 68.08383233532935,
      "grad_norm": 0.011648007668554783,
      "learning_rate": 1.6424294268605645e-05,
      "loss": 0.0884,
      "step": 22740
    },
    {
      "epoch": 68.1437125748503,
      "grad_norm": 0.07737889140844345,
      "learning_rate": 1.5911035072711717e-05,
      "loss": 0.075,
      "step": 22760
    },
    {
      "epoch": 68.20359281437126,
      "grad_norm": 5.820946216583252,
      "learning_rate": 1.5397775876817792e-05,
      "loss": 0.0661,
      "step": 22780
    },
    {
      "epoch": 68.26347305389221,
      "grad_norm": 4.201343536376953,
      "learning_rate": 1.4884516680923866e-05,
      "loss": 0.0505,
      "step": 22800
    },
    {
      "epoch": 68.32335329341318,
      "grad_norm": 0.29085874557495117,
      "learning_rate": 1.4371257485029939e-05,
      "loss": 0.0409,
      "step": 22820
    },
    {
      "epoch": 68.38323353293413,
      "grad_norm": 16.007823944091797,
      "learning_rate": 1.3857998289136012e-05,
      "loss": 0.1305,
      "step": 22840
    },
    {
      "epoch": 68.44311377245509,
      "grad_norm": 3.3696322441101074,
      "learning_rate": 1.3344739093242086e-05,
      "loss": 0.0576,
      "step": 22860
    },
    {
      "epoch": 68.50299401197604,
      "grad_norm": 0.2784861922264099,
      "learning_rate": 1.283147989734816e-05,
      "loss": 0.0266,
      "step": 22880
    },
    {
      "epoch": 68.562874251497,
      "grad_norm": 11.871010780334473,
      "learning_rate": 1.2318220701454233e-05,
      "loss": 0.0947,
      "step": 22900
    },
    {
      "epoch": 68.62275449101796,
      "grad_norm": 18.164125442504883,
      "learning_rate": 1.1804961505560308e-05,
      "loss": 0.0566,
      "step": 22920
    },
    {
      "epoch": 68.68263473053892,
      "grad_norm": 0.030100027099251747,
      "learning_rate": 1.129170230966638e-05,
      "loss": 0.0319,
      "step": 22940
    },
    {
      "epoch": 68.74251497005989,
      "grad_norm": 0.14045238494873047,
      "learning_rate": 1.0778443113772453e-05,
      "loss": 0.0461,
      "step": 22960
    },
    {
      "epoch": 68.80239520958084,
      "grad_norm": 0.22713693976402283,
      "learning_rate": 1.0265183917878529e-05,
      "loss": 0.0465,
      "step": 22980
    },
    {
      "epoch": 68.8622754491018,
      "grad_norm": 0.6164684891700745,
      "learning_rate": 9.751924721984602e-06,
      "loss": 0.0814,
      "step": 23000
    },
    {
      "epoch": 68.92215568862275,
      "grad_norm": 0.07995063066482544,
      "learning_rate": 9.238665526090676e-06,
      "loss": 0.0603,
      "step": 23020
    },
    {
      "epoch": 68.98203592814372,
      "grad_norm": 0.05528634786605835,
      "learning_rate": 8.725406330196749e-06,
      "loss": 0.0278,
      "step": 23040
    },
    {
      "epoch": 69.0,
      "eval_accuracy": 0.8529411764705882,
      "eval_accuracy_10": 0.8504901960784313,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8504901960784313,
      "eval_accuracy_13": 0.8553921568627451,
      "eval_accuracy_14": 0.8480392156862745,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8553921568627451,
      "eval_accuracy_18": 0.8529411764705882,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8553921568627451,
      "eval_accuracy_21": 0.8529411764705882,
      "eval_accuracy_22": 0.8529411764705882,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8529411764705882,
      "eval_combined_score": 0.8747464503042597,
      "eval_f1": 0.896551724137931,
      "eval_loss": 0.9053986668586731,
      "eval_runtime": 216.5945,
      "eval_samples_per_second": 1.884,
      "eval_steps_per_second": 0.235,
      "step": 23046
    },
    {
      "epoch": 69.04191616766467,
      "grad_norm": 3.859969139099121,
      "learning_rate": 8.212147134302823e-06,
      "loss": 0.0547,
      "step": 23060
    },
    {
      "epoch": 69.10179640718563,
      "grad_norm": 0.6528806090354919,
      "learning_rate": 7.698887938408896e-06,
      "loss": 0.0199,
      "step": 23080
    },
    {
      "epoch": 69.16167664670658,
      "grad_norm": 7.324694633483887,
      "learning_rate": 7.1856287425149695e-06,
      "loss": 0.1016,
      "step": 23100
    },
    {
      "epoch": 69.22155688622755,
      "grad_norm": 11.222088813781738,
      "learning_rate": 6.672369546621043e-06,
      "loss": 0.058,
      "step": 23120
    },
    {
      "epoch": 69.2814371257485,
      "grad_norm": 0.11771416664123535,
      "learning_rate": 6.1591103507271165e-06,
      "loss": 0.0902,
      "step": 23140
    },
    {
      "epoch": 69.34131736526946,
      "grad_norm": 0.8437053561210632,
      "learning_rate": 5.64585115483319e-06,
      "loss": 0.0844,
      "step": 23160
    },
    {
      "epoch": 69.40119760479043,
      "grad_norm": 0.4406856894493103,
      "learning_rate": 5.132591958939264e-06,
      "loss": 0.0404,
      "step": 23180
    },
    {
      "epoch": 69.46107784431138,
      "grad_norm": 0.08256278187036514,
      "learning_rate": 4.619332763045338e-06,
      "loss": 0.0992,
      "step": 23200
    },
    {
      "epoch": 69.52095808383234,
      "grad_norm": 0.3311852216720581,
      "learning_rate": 4.106073567151411e-06,
      "loss": 0.0649,
      "step": 23220
    },
    {
      "epoch": 69.58083832335329,
      "grad_norm": 7.182590961456299,
      "learning_rate": 3.5928143712574848e-06,
      "loss": 0.059,
      "step": 23240
    },
    {
      "epoch": 69.64071856287426,
      "grad_norm": 2.8324389457702637,
      "learning_rate": 3.0795551753635582e-06,
      "loss": 0.0716,
      "step": 23260
    },
    {
      "epoch": 69.7005988023952,
      "grad_norm": 3.576606035232544,
      "learning_rate": 2.566295979469632e-06,
      "loss": 0.0614,
      "step": 23280
    },
    {
      "epoch": 69.76047904191617,
      "grad_norm": 0.09218384325504303,
      "learning_rate": 2.0530367835757056e-06,
      "loss": 0.1085,
      "step": 23300
    },
    {
      "epoch": 69.82035928143712,
      "grad_norm": 0.008510724641382694,
      "learning_rate": 1.5397775876817791e-06,
      "loss": 0.037,
      "step": 23320
    },
    {
      "epoch": 69.88023952095809,
      "grad_norm": 0.11843520402908325,
      "learning_rate": 1.0265183917878528e-06,
      "loss": 0.0513,
      "step": 23340
    },
    {
      "epoch": 69.94011976047904,
      "grad_norm": 6.182122230529785,
      "learning_rate": 5.132591958939264e-07,
      "loss": 0.0794,
      "step": 23360
    },
    {
      "epoch": 70.0,
      "grad_norm": 0.5814991593360901,
      "learning_rate": 0.0,
      "loss": 0.0753,
      "step": 23380
    },
    {
      "epoch": 70.0,
      "eval_accuracy": 0.8553921568627451,
      "eval_accuracy_10": 0.8529411764705882,
      "eval_accuracy_11": 0.8504901960784313,
      "eval_accuracy_12": 0.8529411764705882,
      "eval_accuracy_13": 0.8504901960784313,
      "eval_accuracy_14": 0.8504901960784313,
      "eval_accuracy_15": 0.8553921568627451,
      "eval_accuracy_16": 0.8553921568627451,
      "eval_accuracy_17": 0.8578431372549019,
      "eval_accuracy_18": 0.8553921568627451,
      "eval_accuracy_19": 0.8529411764705882,
      "eval_accuracy_20": 0.8578431372549019,
      "eval_accuracy_21": 0.8529411764705882,
      "eval_accuracy_22": 0.8553921568627451,
      "eval_accuracy_23": 0.8553921568627451,
      "eval_accuracy_24": 0.8553921568627451,
      "eval_accuracy_25": 0.8553921568627451,
      "eval_combined_score": 0.8769215517532314,
      "eval_f1": 0.8984509466437176,
      "eval_loss": 0.9116224646568298,
      "eval_runtime": 216.1523,
      "eval_samples_per_second": 1.888,
      "eval_steps_per_second": 0.236,
      "step": 23380
    },
    {
      "epoch": 70.0,
      "step": 23380,
      "total_flos": 6.137258259320832e+16,
      "train_loss": 0.2001791367745481,
      "train_runtime": 32308.1553,
      "train_samples_per_second": 7.947,
      "train_steps_per_second": 0.724
    }
  ],
  "logging_steps": 20,
  "max_steps": 23380,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 70,
  "save_steps": 2000,
  "total_flos": 6.137258259320832e+16,
  "train_batch_size": 11,
  "trial_name": null,
  "trial_params": null
}
